Dump Graph IR for mnasnet1_0 using example inputs:
graph(%self : __torch__.torchvision.models.mnasnet.MNASNet,
      %x.1 : Tensor):
  %3401 : int[] = prim::Constant[value=[2, 3]]()
  %3108 : int[] = prim::Constant[value=[0, 0]]()
  %3102 : int[] = prim::Constant[value=[1, 1]]()
  %3101 : int[] = prim::Constant[value=[2, 2]]()
  %20 : None = prim::Constant()
  %19 : bool = prim::Constant[value=0]()
  %18 : int = prim::Constant[value=2]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:150:20
  %16 : int = prim::Constant[value=1152]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %15 : int = prim::Constant[value=576]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %14 : int = prim::Constant[value=240]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %13 : int = prim::Constant[value=480]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %12 : int = prim::Constant[value=120]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %11 : int = prim::Constant[value=48]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %10 : int = prim::Constant[value=72]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %9 : int = prim::Constant[value=32]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %8 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:140:77
  %7 : float = prim::Constant[value=0.00029999999999996696]()
  %6 : str = prim::Constant[value="Expected more than 1 value per channel when training, got input size {}"]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
  %5 : int = prim::Constant[value=0]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:22
  %4 : bool = prim::Constant[value=1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2147:81
  %3 : int = prim::Constant[value=1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:24
  %2 : float = prim::Constant[value=0.20000000000000001]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/dropout.py:58:32
  %21 : __torch__.torch.nn.modules.container.___torch_mangle_73.Sequential = prim::GetAttr[name="layers"](%self)
  %22 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name="0"](%21)
  %23 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%21)
  %24 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="3"](%21)
  %25 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="4"](%21)
  %26 : __torch__.torch.nn.modules.conv.___torch_mangle_1.Conv2d = prim::GetAttr[name="6"](%21)
  %27 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="7"](%21)
  %28 : __torch__.torch.nn.modules.container.___torch_mangle_14.Sequential = prim::GetAttr[name="8"](%21)
  %29 : __torch__.torch.nn.modules.container.___torch_mangle_26.Sequential = prim::GetAttr[name="9"](%21)
  %30 : __torch__.torch.nn.modules.container.___torch_mangle_40.Sequential = prim::GetAttr[name="10"](%21)
  %31 : __torch__.torch.nn.modules.container.___torch_mangle_52.Sequential = prim::GetAttr[name="11"](%21)
  %32 : __torch__.torch.nn.modules.container.___torch_mangle_64.Sequential = prim::GetAttr[name="12"](%21)
  %33 : __torch__.torch.nn.modules.container.___torch_mangle_70.Sequential = prim::GetAttr[name="13"](%21)
  %34 : __torch__.torch.nn.modules.conv.___torch_mangle_71.Conv2d = prim::GetAttr[name="14"](%21)
  %35 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_72.BatchNorm2d = prim::GetAttr[name="15"](%21)
  %36 : Tensor = prim::GetAttr[name="weight"](%22)
  %37 : Tensor? = prim::GetAttr[name="bias"](%22)
  %input.246 : Tensor = aten::conv2d(%x.1, %36, %37, %3101, %3102, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %42 : bool = prim::GetAttr[name="training"](%23)
   = prim::If(%42) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %43 : Tensor = prim::GetAttr[name="num_batches_tracked"](%23)
      %44 : Tensor = aten::add(%43, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%23, %44)
      -> ()
    block1():
      -> ()
  %45 : bool = prim::GetAttr[name="training"](%23)
  %46 : Tensor = prim::GetAttr[name="running_mean"](%23)
  %47 : Tensor = prim::GetAttr[name="running_var"](%23)
  %48 : Tensor = prim::GetAttr[name="weight"](%23)
  %49 : Tensor = prim::GetAttr[name="bias"](%23)
   = prim::If(%45) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %50 : int[] = aten::size(%input.246) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.324 : int = aten::__getitem__(%50, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %52 : int = aten::len(%50) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %53 : int = aten::sub(%52, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.325 : int = prim::Loop(%53, %4, %size_prods.324) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.82 : int, %size_prods.326 : int):
          %57 : int = aten::add(%i.82, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %58 : int = aten::__getitem__(%50, %57) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.327 : int = aten::mul(%size_prods.326, %58) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%4, %size_prods.327)
      %60 : bool = aten::eq(%size_prods.325, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%60) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %61 : str = aten::format(%6, %50) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%61) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.247 : Tensor = aten::batch_norm(%input.246, %48, %49, %46, %47, %45, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %input.248 : Tensor = aten::relu_(%input.247) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %64 : Tensor = prim::GetAttr[name="weight"](%24)
  %65 : Tensor? = prim::GetAttr[name="bias"](%24)
  %input.249 : Tensor = aten::conv2d(%input.248, %64, %65, %3102, %3102, %3102, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %70 : bool = prim::GetAttr[name="training"](%25)
   = prim::If(%70) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %71 : Tensor = prim::GetAttr[name="num_batches_tracked"](%25)
      %72 : Tensor = aten::add(%71, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%25, %72)
      -> ()
    block1():
      -> ()
  %73 : bool = prim::GetAttr[name="training"](%25)
  %74 : Tensor = prim::GetAttr[name="running_mean"](%25)
  %75 : Tensor = prim::GetAttr[name="running_var"](%25)
  %76 : Tensor = prim::GetAttr[name="weight"](%25)
  %77 : Tensor = prim::GetAttr[name="bias"](%25)
   = prim::If(%73) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %78 : int[] = aten::size(%input.249) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.328 : int = aten::__getitem__(%78, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %80 : int = aten::len(%78) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %81 : int = aten::sub(%80, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.329 : int = prim::Loop(%81, %4, %size_prods.328) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.83 : int, %size_prods.330 : int):
          %85 : int = aten::add(%i.83, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %86 : int = aten::__getitem__(%78, %85) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.331 : int = aten::mul(%size_prods.330, %86) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%4, %size_prods.331)
      %88 : bool = aten::eq(%size_prods.329, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%88) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %89 : str = aten::format(%6, %78) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%89) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.250 : Tensor = aten::batch_norm(%input.249, %76, %77, %74, %75, %73, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %input.251 : Tensor = aten::relu_(%input.250) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %92 : Tensor = prim::GetAttr[name="weight"](%26)
  %93 : Tensor? = prim::GetAttr[name="bias"](%26)
  %input.252 : Tensor = aten::conv2d(%input.251, %92, %93, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %98 : bool = prim::GetAttr[name="training"](%27)
   = prim::If(%98) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %99 : Tensor = prim::GetAttr[name="num_batches_tracked"](%27)
      %100 : Tensor = aten::add(%99, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%27, %100)
      -> ()
    block1():
      -> ()
  %101 : bool = prim::GetAttr[name="training"](%27)
  %102 : Tensor = prim::GetAttr[name="running_mean"](%27)
  %103 : Tensor = prim::GetAttr[name="running_var"](%27)
  %104 : Tensor = prim::GetAttr[name="weight"](%27)
  %105 : Tensor = prim::GetAttr[name="bias"](%27)
   = prim::If(%101) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %106 : int[] = aten::size(%input.252) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.332 : int = aten::__getitem__(%106, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %108 : int = aten::len(%106) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %109 : int = aten::sub(%108, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.333 : int = prim::Loop(%109, %4, %size_prods.332) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.84 : int, %size_prods.334 : int):
          %113 : int = aten::add(%i.84, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %114 : int = aten::__getitem__(%106, %113) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.335 : int = aten::mul(%size_prods.334, %114) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%4, %size_prods.335)
      %116 : bool = aten::eq(%size_prods.333, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%116) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %117 : str = aten::format(%6, %106) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%117) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.253 : Tensor = aten::batch_norm(%input.252, %104, %105, %102, %103, %101, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %119 : __torch__.torchvision.models.mnasnet._InvertedResidual = prim::GetAttr[name="0"](%28)
  %120 : __torch__.torchvision.models.mnasnet.___torch_mangle_13._InvertedResidual = prim::GetAttr[name="1"](%28)
  %121 : __torch__.torchvision.models.mnasnet.___torch_mangle_13._InvertedResidual = prim::GetAttr[name="2"](%28)
  %122 : bool = prim::GetAttr[name="apply_residual"](%119)
  %input.71 : Tensor = prim::If(%122) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:56:8
    block0():
      %124 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="layers"](%119)
      %125 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv2d = prim::GetAttr[name="0"](%124)
      %126 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_4.BatchNorm2d = prim::GetAttr[name="1"](%124)
      %127 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="3"](%124)
      %128 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_4.BatchNorm2d = prim::GetAttr[name="4"](%124)
      %129 : __torch__.torch.nn.modules.conv.___torch_mangle_6.Conv2d = prim::GetAttr[name="6"](%124)
      %130 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_7.BatchNorm2d = prim::GetAttr[name="7"](%124)
      %131 : Tensor = prim::GetAttr[name="weight"](%125)
      %132 : Tensor? = prim::GetAttr[name="bias"](%125)
      %input.72 : Tensor = aten::conv2d(%input.253, %131, %132, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %137 : bool = prim::GetAttr[name="training"](%126)
       = prim::If(%137) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %138 : Tensor = prim::GetAttr[name="num_batches_tracked"](%126)
          %139 : Tensor = aten::add(%138, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%126, %139)
          -> ()
        block1():
          -> ()
      %140 : bool = prim::GetAttr[name="training"](%126)
      %141 : Tensor = prim::GetAttr[name="running_mean"](%126)
      %142 : Tensor = prim::GetAttr[name="running_var"](%126)
      %143 : Tensor = prim::GetAttr[name="weight"](%126)
      %144 : Tensor = prim::GetAttr[name="bias"](%126)
       = prim::If(%140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %145 : int[] = aten::size(%input.72) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.336 : int = aten::__getitem__(%145, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %147 : int = aten::len(%145) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %148 : int = aten::sub(%147, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.337 : int = prim::Loop(%148, %4, %size_prods.336) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.85 : int, %size_prods.338 : int):
              %152 : int = aten::add(%i.85, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %153 : int = aten::__getitem__(%145, %152) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.339 : int = aten::mul(%size_prods.338, %153) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.339)
          %155 : bool = aten::eq(%size_prods.337, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%155) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %156 : str = aten::format(%6, %145) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%156) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.73 : Tensor = aten::batch_norm(%input.72, %143, %144, %141, %142, %140, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.74 : Tensor = aten::relu_(%input.73) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %159 : Tensor = prim::GetAttr[name="weight"](%127)
      %160 : Tensor? = prim::GetAttr[name="bias"](%127)
      %input.75 : Tensor = aten::conv2d(%input.74, %159, %160, %3101, %3102, %3102, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %165 : bool = prim::GetAttr[name="training"](%128)
       = prim::If(%165) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %166 : Tensor = prim::GetAttr[name="num_batches_tracked"](%128)
          %167 : Tensor = aten::add(%166, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%128, %167)
          -> ()
        block1():
          -> ()
      %168 : bool = prim::GetAttr[name="training"](%128)
      %169 : Tensor = prim::GetAttr[name="running_mean"](%128)
      %170 : Tensor = prim::GetAttr[name="running_var"](%128)
      %171 : Tensor = prim::GetAttr[name="weight"](%128)
      %172 : Tensor = prim::GetAttr[name="bias"](%128)
       = prim::If(%168) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %173 : int[] = aten::size(%input.75) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.340 : int = aten::__getitem__(%173, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %175 : int = aten::len(%173) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %176 : int = aten::sub(%175, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.341 : int = prim::Loop(%176, %4, %size_prods.340) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.86 : int, %size_prods.342 : int):
              %180 : int = aten::add(%i.86, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %181 : int = aten::__getitem__(%173, %180) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.343 : int = aten::mul(%size_prods.342, %181) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.343)
          %183 : bool = aten::eq(%size_prods.341, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%183) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %184 : str = aten::format(%6, %173) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.76 : Tensor = aten::batch_norm(%input.75, %171, %172, %169, %170, %168, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.77 : Tensor = aten::relu_(%input.76) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %187 : Tensor = prim::GetAttr[name="weight"](%129)
      %188 : Tensor? = prim::GetAttr[name="bias"](%129)
      %input.78 : Tensor = aten::conv2d(%input.77, %187, %188, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %193 : bool = prim::GetAttr[name="training"](%130)
       = prim::If(%193) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %194 : Tensor = prim::GetAttr[name="num_batches_tracked"](%130)
          %195 : Tensor = aten::add(%194, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%130, %195)
          -> ()
        block1():
          -> ()
      %196 : bool = prim::GetAttr[name="training"](%130)
      %197 : Tensor = prim::GetAttr[name="running_mean"](%130)
      %198 : Tensor = prim::GetAttr[name="running_var"](%130)
      %199 : Tensor = prim::GetAttr[name="weight"](%130)
      %200 : Tensor = prim::GetAttr[name="bias"](%130)
       = prim::If(%196) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %201 : int[] = aten::size(%input.78) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.344 : int = aten::__getitem__(%201, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %203 : int = aten::len(%201) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %204 : int = aten::sub(%203, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.345 : int = prim::Loop(%204, %4, %size_prods.344) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.87 : int, %size_prods.346 : int):
              %208 : int = aten::add(%i.87, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %209 : int = aten::__getitem__(%201, %208) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.347 : int = aten::mul(%size_prods.346, %209) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.347)
          %211 : bool = aten::eq(%size_prods.345, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%211) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %212 : str = aten::format(%6, %201) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.79 : Tensor = aten::batch_norm(%input.78, %199, %200, %197, %198, %196, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %214 : Tensor = aten::add(%input.79, %input.253, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:57:19
      -> (%214)
    block1():
      %215 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="layers"](%119)
      %216 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv2d = prim::GetAttr[name="0"](%215)
      %217 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_4.BatchNorm2d = prim::GetAttr[name="1"](%215)
      %218 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="3"](%215)
      %219 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_4.BatchNorm2d = prim::GetAttr[name="4"](%215)
      %220 : __torch__.torch.nn.modules.conv.___torch_mangle_6.Conv2d = prim::GetAttr[name="6"](%215)
      %221 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_7.BatchNorm2d = prim::GetAttr[name="7"](%215)
      %222 : Tensor = prim::GetAttr[name="weight"](%216)
      %223 : Tensor? = prim::GetAttr[name="bias"](%216)
      %input.80 : Tensor = aten::conv2d(%input.253, %222, %223, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %228 : bool = prim::GetAttr[name="training"](%217)
       = prim::If(%228) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %229 : Tensor = prim::GetAttr[name="num_batches_tracked"](%217)
          %230 : Tensor = aten::add(%229, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%217, %230)
          -> ()
        block1():
          -> ()
      %231 : bool = prim::GetAttr[name="training"](%217)
      %232 : Tensor = prim::GetAttr[name="running_mean"](%217)
      %233 : Tensor = prim::GetAttr[name="running_var"](%217)
      %234 : Tensor = prim::GetAttr[name="weight"](%217)
      %235 : Tensor = prim::GetAttr[name="bias"](%217)
       = prim::If(%231) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %236 : int[] = aten::size(%input.80) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.96 : int = aten::__getitem__(%236, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %238 : int = aten::len(%236) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %239 : int = aten::sub(%238, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.97 : int = prim::Loop(%239, %4, %size_prods.96) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.25 : int, %size_prods.98 : int):
              %243 : int = aten::add(%i.25, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %244 : int = aten::__getitem__(%236, %243) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.99 : int = aten::mul(%size_prods.98, %244) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.99)
          %246 : bool = aten::eq(%size_prods.97, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%246) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %247 : str = aten::format(%6, %236) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%247) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.81 : Tensor = aten::batch_norm(%input.80, %234, %235, %232, %233, %231, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.82 : Tensor = aten::relu_(%input.81) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %250 : Tensor = prim::GetAttr[name="weight"](%218)
      %251 : Tensor? = prim::GetAttr[name="bias"](%218)
      %input.83 : Tensor = aten::conv2d(%input.82, %250, %251, %3101, %3102, %3102, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %256 : bool = prim::GetAttr[name="training"](%219)
       = prim::If(%256) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %257 : Tensor = prim::GetAttr[name="num_batches_tracked"](%219)
          %258 : Tensor = aten::add(%257, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%219, %258)
          -> ()
        block1():
          -> ()
      %259 : bool = prim::GetAttr[name="training"](%219)
      %260 : Tensor = prim::GetAttr[name="running_mean"](%219)
      %261 : Tensor = prim::GetAttr[name="running_var"](%219)
      %262 : Tensor = prim::GetAttr[name="weight"](%219)
      %263 : Tensor = prim::GetAttr[name="bias"](%219)
       = prim::If(%259) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %264 : int[] = aten::size(%input.83) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.100 : int = aten::__getitem__(%264, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %266 : int = aten::len(%264) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %267 : int = aten::sub(%266, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.101 : int = prim::Loop(%267, %4, %size_prods.100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.26 : int, %size_prods.102 : int):
              %271 : int = aten::add(%i.26, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %272 : int = aten::__getitem__(%264, %271) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.103 : int = aten::mul(%size_prods.102, %272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.103)
          %274 : bool = aten::eq(%size_prods.101, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%274) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %275 : str = aten::format(%6, %264) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%275) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.84 : Tensor = aten::batch_norm(%input.83, %262, %263, %260, %261, %259, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.85 : Tensor = aten::relu_(%input.84) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %278 : Tensor = prim::GetAttr[name="weight"](%220)
      %279 : Tensor? = prim::GetAttr[name="bias"](%220)
      %input.86 : Tensor = aten::conv2d(%input.85, %278, %279, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %284 : bool = prim::GetAttr[name="training"](%221)
       = prim::If(%284) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %285 : Tensor = prim::GetAttr[name="num_batches_tracked"](%221)
          %286 : Tensor = aten::add(%285, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%221, %286)
          -> ()
        block1():
          -> ()
      %287 : bool = prim::GetAttr[name="training"](%221)
      %288 : Tensor = prim::GetAttr[name="running_mean"](%221)
      %289 : Tensor = prim::GetAttr[name="running_var"](%221)
      %290 : Tensor = prim::GetAttr[name="weight"](%221)
      %291 : Tensor = prim::GetAttr[name="bias"](%221)
       = prim::If(%287) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %292 : int[] = aten::size(%input.86) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.104 : int = aten::__getitem__(%292, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %294 : int = aten::len(%292) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %295 : int = aten::sub(%294, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.105 : int = prim::Loop(%295, %4, %size_prods.104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.27 : int, %size_prods.106 : int):
              %299 : int = aten::add(%i.27, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %300 : int = aten::__getitem__(%292, %299) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.107 : int = aten::mul(%size_prods.106, %300) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.107)
          %302 : bool = aten::eq(%size_prods.105, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%302) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %303 : str = aten::format(%6, %292) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%303) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.87 : Tensor = aten::batch_norm(%input.86, %290, %291, %288, %289, %287, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.87)
  %305 : bool = prim::GetAttr[name="apply_residual"](%120)
  %input.88 : Tensor = prim::If(%305) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:56:8
    block0():
      %307 : __torch__.torch.nn.modules.container.___torch_mangle_12.Sequential = prim::GetAttr[name="layers"](%120)
      %308 : __torch__.torch.nn.modules.conv.___torch_mangle_8.Conv2d = prim::GetAttr[name="0"](%307)
      %309 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_9.BatchNorm2d = prim::GetAttr[name="1"](%307)
      %310 : __torch__.torch.nn.modules.conv.___torch_mangle_10.Conv2d = prim::GetAttr[name="3"](%307)
      %311 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_9.BatchNorm2d = prim::GetAttr[name="4"](%307)
      %312 : __torch__.torch.nn.modules.conv.___torch_mangle_11.Conv2d = prim::GetAttr[name="6"](%307)
      %313 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_7.BatchNorm2d = prim::GetAttr[name="7"](%307)
      %314 : Tensor = prim::GetAttr[name="weight"](%308)
      %315 : Tensor? = prim::GetAttr[name="bias"](%308)
      %input.89 : Tensor = aten::conv2d(%input.71, %314, %315, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %320 : bool = prim::GetAttr[name="training"](%309)
       = prim::If(%320) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %321 : Tensor = prim::GetAttr[name="num_batches_tracked"](%309)
          %322 : Tensor = aten::add(%321, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%309, %322)
          -> ()
        block1():
          -> ()
      %323 : bool = prim::GetAttr[name="training"](%309)
      %324 : Tensor = prim::GetAttr[name="running_mean"](%309)
      %325 : Tensor = prim::GetAttr[name="running_var"](%309)
      %326 : Tensor = prim::GetAttr[name="weight"](%309)
      %327 : Tensor = prim::GetAttr[name="bias"](%309)
       = prim::If(%323) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %328 : int[] = aten::size(%input.89) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.108 : int = aten::__getitem__(%328, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %330 : int = aten::len(%328) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %331 : int = aten::sub(%330, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.109 : int = prim::Loop(%331, %4, %size_prods.108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.28 : int, %size_prods.110 : int):
              %335 : int = aten::add(%i.28, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %336 : int = aten::__getitem__(%328, %335) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.111 : int = aten::mul(%size_prods.110, %336) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.111)
          %338 : bool = aten::eq(%size_prods.109, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%338) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %339 : str = aten::format(%6, %328) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%339) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.90 : Tensor = aten::batch_norm(%input.89, %326, %327, %324, %325, %323, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.91 : Tensor = aten::relu_(%input.90) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %342 : Tensor = prim::GetAttr[name="weight"](%310)
      %343 : Tensor? = prim::GetAttr[name="bias"](%310)
      %input.92 : Tensor = aten::conv2d(%input.91, %342, %343, %3102, %3102, %3102, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %348 : bool = prim::GetAttr[name="training"](%311)
       = prim::If(%348) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %349 : Tensor = prim::GetAttr[name="num_batches_tracked"](%311)
          %350 : Tensor = aten::add(%349, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%311, %350)
          -> ()
        block1():
          -> ()
      %351 : bool = prim::GetAttr[name="training"](%311)
      %352 : Tensor = prim::GetAttr[name="running_mean"](%311)
      %353 : Tensor = prim::GetAttr[name="running_var"](%311)
      %354 : Tensor = prim::GetAttr[name="weight"](%311)
      %355 : Tensor = prim::GetAttr[name="bias"](%311)
       = prim::If(%351) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %356 : int[] = aten::size(%input.92) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.112 : int = aten::__getitem__(%356, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %358 : int = aten::len(%356) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %359 : int = aten::sub(%358, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.113 : int = prim::Loop(%359, %4, %size_prods.112) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.29 : int, %size_prods.114 : int):
              %363 : int = aten::add(%i.29, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %364 : int = aten::__getitem__(%356, %363) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.115 : int = aten::mul(%size_prods.114, %364) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.115)
          %366 : bool = aten::eq(%size_prods.113, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%366) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %367 : str = aten::format(%6, %356) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%367) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.93 : Tensor = aten::batch_norm(%input.92, %354, %355, %352, %353, %351, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.94 : Tensor = aten::relu_(%input.93) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %370 : Tensor = prim::GetAttr[name="weight"](%312)
      %371 : Tensor? = prim::GetAttr[name="bias"](%312)
      %input.95 : Tensor = aten::conv2d(%input.94, %370, %371, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %376 : bool = prim::GetAttr[name="training"](%313)
       = prim::If(%376) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %377 : Tensor = prim::GetAttr[name="num_batches_tracked"](%313)
          %378 : Tensor = aten::add(%377, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%313, %378)
          -> ()
        block1():
          -> ()
      %379 : bool = prim::GetAttr[name="training"](%313)
      %380 : Tensor = prim::GetAttr[name="running_mean"](%313)
      %381 : Tensor = prim::GetAttr[name="running_var"](%313)
      %382 : Tensor = prim::GetAttr[name="weight"](%313)
      %383 : Tensor = prim::GetAttr[name="bias"](%313)
       = prim::If(%379) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %384 : int[] = aten::size(%input.95) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.116 : int = aten::__getitem__(%384, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %386 : int = aten::len(%384) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %387 : int = aten::sub(%386, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.117 : int = prim::Loop(%387, %4, %size_prods.116) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.30 : int, %size_prods.118 : int):
              %391 : int = aten::add(%i.30, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %392 : int = aten::__getitem__(%384, %391) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.119 : int = aten::mul(%size_prods.118, %392) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.119)
          %394 : bool = aten::eq(%size_prods.117, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%394) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %395 : str = aten::format(%6, %384) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%395) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.96 : Tensor = aten::batch_norm(%input.95, %382, %383, %380, %381, %379, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %397 : Tensor = aten::add(%input.96, %input.71, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:57:19
      -> (%397)
    block1():
      %398 : __torch__.torch.nn.modules.container.___torch_mangle_12.Sequential = prim::GetAttr[name="layers"](%120)
      %399 : __torch__.torch.nn.modules.conv.___torch_mangle_8.Conv2d = prim::GetAttr[name="0"](%398)
      %400 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_9.BatchNorm2d = prim::GetAttr[name="1"](%398)
      %401 : __torch__.torch.nn.modules.conv.___torch_mangle_10.Conv2d = prim::GetAttr[name="3"](%398)
      %402 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_9.BatchNorm2d = prim::GetAttr[name="4"](%398)
      %403 : __torch__.torch.nn.modules.conv.___torch_mangle_11.Conv2d = prim::GetAttr[name="6"](%398)
      %404 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_7.BatchNorm2d = prim::GetAttr[name="7"](%398)
      %405 : Tensor = prim::GetAttr[name="weight"](%399)
      %406 : Tensor? = prim::GetAttr[name="bias"](%399)
      %input.97 : Tensor = aten::conv2d(%input.71, %405, %406, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %411 : bool = prim::GetAttr[name="training"](%400)
       = prim::If(%411) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %412 : Tensor = prim::GetAttr[name="num_batches_tracked"](%400)
          %413 : Tensor = aten::add(%412, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%400, %413)
          -> ()
        block1():
          -> ()
      %414 : bool = prim::GetAttr[name="training"](%400)
      %415 : Tensor = prim::GetAttr[name="running_mean"](%400)
      %416 : Tensor = prim::GetAttr[name="running_var"](%400)
      %417 : Tensor = prim::GetAttr[name="weight"](%400)
      %418 : Tensor = prim::GetAttr[name="bias"](%400)
       = prim::If(%414) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %419 : int[] = aten::size(%input.97) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.120 : int = aten::__getitem__(%419, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %421 : int = aten::len(%419) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %422 : int = aten::sub(%421, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.121 : int = prim::Loop(%422, %4, %size_prods.120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.31 : int, %size_prods.122 : int):
              %426 : int = aten::add(%i.31, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %427 : int = aten::__getitem__(%419, %426) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.123 : int = aten::mul(%size_prods.122, %427) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.123)
          %429 : bool = aten::eq(%size_prods.121, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%429) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %430 : str = aten::format(%6, %419) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%430) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.98 : Tensor = aten::batch_norm(%input.97, %417, %418, %415, %416, %414, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.99 : Tensor = aten::relu_(%input.98) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %433 : Tensor = prim::GetAttr[name="weight"](%401)
      %434 : Tensor? = prim::GetAttr[name="bias"](%401)
      %input.100 : Tensor = aten::conv2d(%input.99, %433, %434, %3102, %3102, %3102, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %439 : bool = prim::GetAttr[name="training"](%402)
       = prim::If(%439) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %440 : Tensor = prim::GetAttr[name="num_batches_tracked"](%402)
          %441 : Tensor = aten::add(%440, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%402, %441)
          -> ()
        block1():
          -> ()
      %442 : bool = prim::GetAttr[name="training"](%402)
      %443 : Tensor = prim::GetAttr[name="running_mean"](%402)
      %444 : Tensor = prim::GetAttr[name="running_var"](%402)
      %445 : Tensor = prim::GetAttr[name="weight"](%402)
      %446 : Tensor = prim::GetAttr[name="bias"](%402)
       = prim::If(%442) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %447 : int[] = aten::size(%input.100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.124 : int = aten::__getitem__(%447, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %449 : int = aten::len(%447) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %450 : int = aten::sub(%449, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.125 : int = prim::Loop(%450, %4, %size_prods.124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.32 : int, %size_prods.126 : int):
              %454 : int = aten::add(%i.32, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %455 : int = aten::__getitem__(%447, %454) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.127 : int = aten::mul(%size_prods.126, %455) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.127)
          %457 : bool = aten::eq(%size_prods.125, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%457) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %458 : str = aten::format(%6, %447) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%458) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.101 : Tensor = aten::batch_norm(%input.100, %445, %446, %443, %444, %442, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.102 : Tensor = aten::relu_(%input.101) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %461 : Tensor = prim::GetAttr[name="weight"](%403)
      %462 : Tensor? = prim::GetAttr[name="bias"](%403)
      %input.103 : Tensor = aten::conv2d(%input.102, %461, %462, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %467 : bool = prim::GetAttr[name="training"](%404)
       = prim::If(%467) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %468 : Tensor = prim::GetAttr[name="num_batches_tracked"](%404)
          %469 : Tensor = aten::add(%468, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%404, %469)
          -> ()
        block1():
          -> ()
      %470 : bool = prim::GetAttr[name="training"](%404)
      %471 : Tensor = prim::GetAttr[name="running_mean"](%404)
      %472 : Tensor = prim::GetAttr[name="running_var"](%404)
      %473 : Tensor = prim::GetAttr[name="weight"](%404)
      %474 : Tensor = prim::GetAttr[name="bias"](%404)
       = prim::If(%470) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %475 : int[] = aten::size(%input.103) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.128 : int = aten::__getitem__(%475, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %477 : int = aten::len(%475) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %478 : int = aten::sub(%477, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.129 : int = prim::Loop(%478, %4, %size_prods.128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.33 : int, %size_prods.130 : int):
              %482 : int = aten::add(%i.33, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %483 : int = aten::__getitem__(%475, %482) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.131 : int = aten::mul(%size_prods.130, %483) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.131)
          %485 : bool = aten::eq(%size_prods.129, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%485) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %486 : str = aten::format(%6, %475) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%486) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.104 : Tensor = aten::batch_norm(%input.103, %473, %474, %471, %472, %470, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.104)
  %488 : bool = prim::GetAttr[name="apply_residual"](%121)
  %input.245 : Tensor = prim::If(%488) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:56:8
    block0():
      %490 : __torch__.torch.nn.modules.container.___torch_mangle_12.Sequential = prim::GetAttr[name="layers"](%121)
      %491 : __torch__.torch.nn.modules.conv.___torch_mangle_8.Conv2d = prim::GetAttr[name="0"](%490)
      %492 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_9.BatchNorm2d = prim::GetAttr[name="1"](%490)
      %493 : __torch__.torch.nn.modules.conv.___torch_mangle_10.Conv2d = prim::GetAttr[name="3"](%490)
      %494 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_9.BatchNorm2d = prim::GetAttr[name="4"](%490)
      %495 : __torch__.torch.nn.modules.conv.___torch_mangle_11.Conv2d = prim::GetAttr[name="6"](%490)
      %496 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_7.BatchNorm2d = prim::GetAttr[name="7"](%490)
      %497 : Tensor = prim::GetAttr[name="weight"](%491)
      %498 : Tensor? = prim::GetAttr[name="bias"](%491)
      %input.105 : Tensor = aten::conv2d(%input.88, %497, %498, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %503 : bool = prim::GetAttr[name="training"](%492)
       = prim::If(%503) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %504 : Tensor = prim::GetAttr[name="num_batches_tracked"](%492)
          %505 : Tensor = aten::add(%504, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%492, %505)
          -> ()
        block1():
          -> ()
      %506 : bool = prim::GetAttr[name="training"](%492)
      %507 : Tensor = prim::GetAttr[name="running_mean"](%492)
      %508 : Tensor = prim::GetAttr[name="running_var"](%492)
      %509 : Tensor = prim::GetAttr[name="weight"](%492)
      %510 : Tensor = prim::GetAttr[name="bias"](%492)
       = prim::If(%506) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %511 : int[] = aten::size(%input.105) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.132 : int = aten::__getitem__(%511, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %513 : int = aten::len(%511) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %514 : int = aten::sub(%513, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.133 : int = prim::Loop(%514, %4, %size_prods.132) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.34 : int, %size_prods.134 : int):
              %518 : int = aten::add(%i.34, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %519 : int = aten::__getitem__(%511, %518) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.135 : int = aten::mul(%size_prods.134, %519) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.135)
          %521 : bool = aten::eq(%size_prods.133, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%521) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %522 : str = aten::format(%6, %511) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%522) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.106 : Tensor = aten::batch_norm(%input.105, %509, %510, %507, %508, %506, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.107 : Tensor = aten::relu_(%input.106) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %525 : Tensor = prim::GetAttr[name="weight"](%493)
      %526 : Tensor? = prim::GetAttr[name="bias"](%493)
      %input.108 : Tensor = aten::conv2d(%input.107, %525, %526, %3102, %3102, %3102, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %531 : bool = prim::GetAttr[name="training"](%494)
       = prim::If(%531) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %532 : Tensor = prim::GetAttr[name="num_batches_tracked"](%494)
          %533 : Tensor = aten::add(%532, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%494, %533)
          -> ()
        block1():
          -> ()
      %534 : bool = prim::GetAttr[name="training"](%494)
      %535 : Tensor = prim::GetAttr[name="running_mean"](%494)
      %536 : Tensor = prim::GetAttr[name="running_var"](%494)
      %537 : Tensor = prim::GetAttr[name="weight"](%494)
      %538 : Tensor = prim::GetAttr[name="bias"](%494)
       = prim::If(%534) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %539 : int[] = aten::size(%input.108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.136 : int = aten::__getitem__(%539, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %541 : int = aten::len(%539) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %542 : int = aten::sub(%541, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.137 : int = prim::Loop(%542, %4, %size_prods.136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.35 : int, %size_prods.138 : int):
              %546 : int = aten::add(%i.35, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %547 : int = aten::__getitem__(%539, %546) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.139 : int = aten::mul(%size_prods.138, %547) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.139)
          %549 : bool = aten::eq(%size_prods.137, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%549) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %550 : str = aten::format(%6, %539) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%550) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.109 : Tensor = aten::batch_norm(%input.108, %537, %538, %535, %536, %534, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.110 : Tensor = aten::relu_(%input.109) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %553 : Tensor = prim::GetAttr[name="weight"](%495)
      %554 : Tensor? = prim::GetAttr[name="bias"](%495)
      %input.111 : Tensor = aten::conv2d(%input.110, %553, %554, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %559 : bool = prim::GetAttr[name="training"](%496)
       = prim::If(%559) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %560 : Tensor = prim::GetAttr[name="num_batches_tracked"](%496)
          %561 : Tensor = aten::add(%560, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%496, %561)
          -> ()
        block1():
          -> ()
      %562 : bool = prim::GetAttr[name="training"](%496)
      %563 : Tensor = prim::GetAttr[name="running_mean"](%496)
      %564 : Tensor = prim::GetAttr[name="running_var"](%496)
      %565 : Tensor = prim::GetAttr[name="weight"](%496)
      %566 : Tensor = prim::GetAttr[name="bias"](%496)
       = prim::If(%562) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %567 : int[] = aten::size(%input.111) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.140 : int = aten::__getitem__(%567, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %569 : int = aten::len(%567) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %570 : int = aten::sub(%569, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.141 : int = prim::Loop(%570, %4, %size_prods.140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.36 : int, %size_prods.142 : int):
              %574 : int = aten::add(%i.36, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %575 : int = aten::__getitem__(%567, %574) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.143 : int = aten::mul(%size_prods.142, %575) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.143)
          %577 : bool = aten::eq(%size_prods.141, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%577) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %578 : str = aten::format(%6, %567) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%578) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.112 : Tensor = aten::batch_norm(%input.111, %565, %566, %563, %564, %562, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %580 : Tensor = aten::add(%input.112, %input.88, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:57:19
      -> (%580)
    block1():
      %581 : __torch__.torch.nn.modules.container.___torch_mangle_12.Sequential = prim::GetAttr[name="layers"](%121)
      %582 : __torch__.torch.nn.modules.conv.___torch_mangle_8.Conv2d = prim::GetAttr[name="0"](%581)
      %583 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_9.BatchNorm2d = prim::GetAttr[name="1"](%581)
      %584 : __torch__.torch.nn.modules.conv.___torch_mangle_10.Conv2d = prim::GetAttr[name="3"](%581)
      %585 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_9.BatchNorm2d = prim::GetAttr[name="4"](%581)
      %586 : __torch__.torch.nn.modules.conv.___torch_mangle_11.Conv2d = prim::GetAttr[name="6"](%581)
      %587 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_7.BatchNorm2d = prim::GetAttr[name="7"](%581)
      %588 : Tensor = prim::GetAttr[name="weight"](%582)
      %589 : Tensor? = prim::GetAttr[name="bias"](%582)
      %input.113 : Tensor = aten::conv2d(%input.88, %588, %589, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %594 : bool = prim::GetAttr[name="training"](%583)
       = prim::If(%594) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %595 : Tensor = prim::GetAttr[name="num_batches_tracked"](%583)
          %596 : Tensor = aten::add(%595, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%583, %596)
          -> ()
        block1():
          -> ()
      %597 : bool = prim::GetAttr[name="training"](%583)
      %598 : Tensor = prim::GetAttr[name="running_mean"](%583)
      %599 : Tensor = prim::GetAttr[name="running_var"](%583)
      %600 : Tensor = prim::GetAttr[name="weight"](%583)
      %601 : Tensor = prim::GetAttr[name="bias"](%583)
       = prim::If(%597) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %602 : int[] = aten::size(%input.113) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.144 : int = aten::__getitem__(%602, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %604 : int = aten::len(%602) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %605 : int = aten::sub(%604, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.145 : int = prim::Loop(%605, %4, %size_prods.144) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.37 : int, %size_prods.146 : int):
              %609 : int = aten::add(%i.37, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %610 : int = aten::__getitem__(%602, %609) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.147 : int = aten::mul(%size_prods.146, %610) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.147)
          %612 : bool = aten::eq(%size_prods.145, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%612) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %613 : str = aten::format(%6, %602) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%613) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.114 : Tensor = aten::batch_norm(%input.113, %600, %601, %598, %599, %597, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.115 : Tensor = aten::relu_(%input.114) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %616 : Tensor = prim::GetAttr[name="weight"](%584)
      %617 : Tensor? = prim::GetAttr[name="bias"](%584)
      %input.116 : Tensor = aten::conv2d(%input.115, %616, %617, %3102, %3102, %3102, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %622 : bool = prim::GetAttr[name="training"](%585)
       = prim::If(%622) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %623 : Tensor = prim::GetAttr[name="num_batches_tracked"](%585)
          %624 : Tensor = aten::add(%623, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%585, %624)
          -> ()
        block1():
          -> ()
      %625 : bool = prim::GetAttr[name="training"](%585)
      %626 : Tensor = prim::GetAttr[name="running_mean"](%585)
      %627 : Tensor = prim::GetAttr[name="running_var"](%585)
      %628 : Tensor = prim::GetAttr[name="weight"](%585)
      %629 : Tensor = prim::GetAttr[name="bias"](%585)
       = prim::If(%625) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %630 : int[] = aten::size(%input.116) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.148 : int = aten::__getitem__(%630, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %632 : int = aten::len(%630) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %633 : int = aten::sub(%632, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.149 : int = prim::Loop(%633, %4, %size_prods.148) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.38 : int, %size_prods.150 : int):
              %637 : int = aten::add(%i.38, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %638 : int = aten::__getitem__(%630, %637) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.151 : int = aten::mul(%size_prods.150, %638) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.151)
          %640 : bool = aten::eq(%size_prods.149, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%640) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %641 : str = aten::format(%6, %630) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%641) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.117 : Tensor = aten::batch_norm(%input.116, %628, %629, %626, %627, %625, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.118 : Tensor = aten::relu_(%input.117) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %644 : Tensor = prim::GetAttr[name="weight"](%586)
      %645 : Tensor? = prim::GetAttr[name="bias"](%586)
      %input.119 : Tensor = aten::conv2d(%input.118, %644, %645, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %650 : bool = prim::GetAttr[name="training"](%587)
       = prim::If(%650) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %651 : Tensor = prim::GetAttr[name="num_batches_tracked"](%587)
          %652 : Tensor = aten::add(%651, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%587, %652)
          -> ()
        block1():
          -> ()
      %653 : bool = prim::GetAttr[name="training"](%587)
      %654 : Tensor = prim::GetAttr[name="running_mean"](%587)
      %655 : Tensor = prim::GetAttr[name="running_var"](%587)
      %656 : Tensor = prim::GetAttr[name="weight"](%587)
      %657 : Tensor = prim::GetAttr[name="bias"](%587)
       = prim::If(%653) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %658 : int[] = aten::size(%input.119) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.152 : int = aten::__getitem__(%658, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %660 : int = aten::len(%658) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %661 : int = aten::sub(%660, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.153 : int = prim::Loop(%661, %4, %size_prods.152) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.39 : int, %size_prods.154 : int):
              %665 : int = aten::add(%i.39, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %666 : int = aten::__getitem__(%658, %665) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.155 : int = aten::mul(%size_prods.154, %666) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.155)
          %668 : bool = aten::eq(%size_prods.153, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%668) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %669 : str = aten::format(%6, %658) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%669) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.120 : Tensor = aten::batch_norm(%input.119, %656, %657, %654, %655, %653, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.120)
  %671 : __torch__.torchvision.models.mnasnet.___torch_mangle_19._InvertedResidual = prim::GetAttr[name="0"](%29)
  %672 : __torch__.torchvision.models.mnasnet.___torch_mangle_25._InvertedResidual = prim::GetAttr[name="1"](%29)
  %673 : __torch__.torchvision.models.mnasnet.___torch_mangle_25._InvertedResidual = prim::GetAttr[name="2"](%29)
  %674 : bool = prim::GetAttr[name="apply_residual"](%671)
  %input.121 : Tensor = prim::If(%674) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:56:8
    block0():
      %676 : __torch__.torch.nn.modules.container.___torch_mangle_18.Sequential = prim::GetAttr[name="layers"](%671)
      %677 : __torch__.torch.nn.modules.conv.___torch_mangle_8.Conv2d = prim::GetAttr[name="0"](%676)
      %678 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_9.BatchNorm2d = prim::GetAttr[name="1"](%676)
      %679 : __torch__.torch.nn.modules.conv.___torch_mangle_15.Conv2d = prim::GetAttr[name="3"](%676)
      %680 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_9.BatchNorm2d = prim::GetAttr[name="4"](%676)
      %681 : __torch__.torch.nn.modules.conv.___torch_mangle_16.Conv2d = prim::GetAttr[name="6"](%676)
      %682 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_17.BatchNorm2d = prim::GetAttr[name="7"](%676)
      %683 : Tensor = prim::GetAttr[name="weight"](%677)
      %684 : Tensor? = prim::GetAttr[name="bias"](%677)
      %input.122 : Tensor = aten::conv2d(%input.245, %683, %684, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %689 : bool = prim::GetAttr[name="training"](%678)
       = prim::If(%689) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %690 : Tensor = prim::GetAttr[name="num_batches_tracked"](%678)
          %691 : Tensor = aten::add(%690, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%678, %691)
          -> ()
        block1():
          -> ()
      %692 : bool = prim::GetAttr[name="training"](%678)
      %693 : Tensor = prim::GetAttr[name="running_mean"](%678)
      %694 : Tensor = prim::GetAttr[name="running_var"](%678)
      %695 : Tensor = prim::GetAttr[name="weight"](%678)
      %696 : Tensor = prim::GetAttr[name="bias"](%678)
       = prim::If(%692) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %697 : int[] = aten::size(%input.122) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.156 : int = aten::__getitem__(%697, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %699 : int = aten::len(%697) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %700 : int = aten::sub(%699, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.157 : int = prim::Loop(%700, %4, %size_prods.156) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.40 : int, %size_prods.158 : int):
              %704 : int = aten::add(%i.40, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %705 : int = aten::__getitem__(%697, %704) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.159 : int = aten::mul(%size_prods.158, %705) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.159)
          %707 : bool = aten::eq(%size_prods.157, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%707) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %708 : str = aten::format(%6, %697) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%708) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.123 : Tensor = aten::batch_norm(%input.122, %695, %696, %693, %694, %692, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.124 : Tensor = aten::relu_(%input.123) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %711 : Tensor = prim::GetAttr[name="weight"](%679)
      %712 : Tensor? = prim::GetAttr[name="bias"](%679)
      %input.125 : Tensor = aten::conv2d(%input.124, %711, %712, %3101, %3101, %3102, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %717 : bool = prim::GetAttr[name="training"](%680)
       = prim::If(%717) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %718 : Tensor = prim::GetAttr[name="num_batches_tracked"](%680)
          %719 : Tensor = aten::add(%718, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%680, %719)
          -> ()
        block1():
          -> ()
      %720 : bool = prim::GetAttr[name="training"](%680)
      %721 : Tensor = prim::GetAttr[name="running_mean"](%680)
      %722 : Tensor = prim::GetAttr[name="running_var"](%680)
      %723 : Tensor = prim::GetAttr[name="weight"](%680)
      %724 : Tensor = prim::GetAttr[name="bias"](%680)
       = prim::If(%720) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %725 : int[] = aten::size(%input.125) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.160 : int = aten::__getitem__(%725, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %727 : int = aten::len(%725) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %728 : int = aten::sub(%727, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.161 : int = prim::Loop(%728, %4, %size_prods.160) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.41 : int, %size_prods.162 : int):
              %732 : int = aten::add(%i.41, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %733 : int = aten::__getitem__(%725, %732) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.163 : int = aten::mul(%size_prods.162, %733) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.163)
          %735 : bool = aten::eq(%size_prods.161, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%735) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %736 : str = aten::format(%6, %725) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%736) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.126 : Tensor = aten::batch_norm(%input.125, %723, %724, %721, %722, %720, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.127 : Tensor = aten::relu_(%input.126) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %739 : Tensor = prim::GetAttr[name="weight"](%681)
      %740 : Tensor? = prim::GetAttr[name="bias"](%681)
      %input.128 : Tensor = aten::conv2d(%input.127, %739, %740, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %745 : bool = prim::GetAttr[name="training"](%682)
       = prim::If(%745) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %746 : Tensor = prim::GetAttr[name="num_batches_tracked"](%682)
          %747 : Tensor = aten::add(%746, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%682, %747)
          -> ()
        block1():
          -> ()
      %748 : bool = prim::GetAttr[name="training"](%682)
      %749 : Tensor = prim::GetAttr[name="running_mean"](%682)
      %750 : Tensor = prim::GetAttr[name="running_var"](%682)
      %751 : Tensor = prim::GetAttr[name="weight"](%682)
      %752 : Tensor = prim::GetAttr[name="bias"](%682)
       = prim::If(%748) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %753 : int[] = aten::size(%input.128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.164 : int = aten::__getitem__(%753, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %755 : int = aten::len(%753) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %756 : int = aten::sub(%755, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.165 : int = prim::Loop(%756, %4, %size_prods.164) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.42 : int, %size_prods.166 : int):
              %760 : int = aten::add(%i.42, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %761 : int = aten::__getitem__(%753, %760) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.167 : int = aten::mul(%size_prods.166, %761) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.167)
          %763 : bool = aten::eq(%size_prods.165, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%763) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %764 : str = aten::format(%6, %753) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%764) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.129 : Tensor = aten::batch_norm(%input.128, %751, %752, %749, %750, %748, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %766 : Tensor = aten::add(%input.129, %input.245, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:57:19
      -> (%766)
    block1():
      %767 : __torch__.torch.nn.modules.container.___torch_mangle_18.Sequential = prim::GetAttr[name="layers"](%671)
      %768 : __torch__.torch.nn.modules.conv.___torch_mangle_8.Conv2d = prim::GetAttr[name="0"](%767)
      %769 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_9.BatchNorm2d = prim::GetAttr[name="1"](%767)
      %770 : __torch__.torch.nn.modules.conv.___torch_mangle_15.Conv2d = prim::GetAttr[name="3"](%767)
      %771 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_9.BatchNorm2d = prim::GetAttr[name="4"](%767)
      %772 : __torch__.torch.nn.modules.conv.___torch_mangle_16.Conv2d = prim::GetAttr[name="6"](%767)
      %773 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_17.BatchNorm2d = prim::GetAttr[name="7"](%767)
      %774 : Tensor = prim::GetAttr[name="weight"](%768)
      %775 : Tensor? = prim::GetAttr[name="bias"](%768)
      %input.130 : Tensor = aten::conv2d(%input.245, %774, %775, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %780 : bool = prim::GetAttr[name="training"](%769)
       = prim::If(%780) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %781 : Tensor = prim::GetAttr[name="num_batches_tracked"](%769)
          %782 : Tensor = aten::add(%781, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%769, %782)
          -> ()
        block1():
          -> ()
      %783 : bool = prim::GetAttr[name="training"](%769)
      %784 : Tensor = prim::GetAttr[name="running_mean"](%769)
      %785 : Tensor = prim::GetAttr[name="running_var"](%769)
      %786 : Tensor = prim::GetAttr[name="weight"](%769)
      %787 : Tensor = prim::GetAttr[name="bias"](%769)
       = prim::If(%783) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %788 : int[] = aten::size(%input.130) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.168 : int = aten::__getitem__(%788, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %790 : int = aten::len(%788) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %791 : int = aten::sub(%790, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.169 : int = prim::Loop(%791, %4, %size_prods.168) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.43 : int, %size_prods.170 : int):
              %795 : int = aten::add(%i.43, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %796 : int = aten::__getitem__(%788, %795) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.171 : int = aten::mul(%size_prods.170, %796) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.171)
          %798 : bool = aten::eq(%size_prods.169, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%798) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %799 : str = aten::format(%6, %788) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%799) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.131 : Tensor = aten::batch_norm(%input.130, %786, %787, %784, %785, %783, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.132 : Tensor = aten::relu_(%input.131) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %802 : Tensor = prim::GetAttr[name="weight"](%770)
      %803 : Tensor? = prim::GetAttr[name="bias"](%770)
      %input.133 : Tensor = aten::conv2d(%input.132, %802, %803, %3101, %3101, %3102, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %808 : bool = prim::GetAttr[name="training"](%771)
       = prim::If(%808) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %809 : Tensor = prim::GetAttr[name="num_batches_tracked"](%771)
          %810 : Tensor = aten::add(%809, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%771, %810)
          -> ()
        block1():
          -> ()
      %811 : bool = prim::GetAttr[name="training"](%771)
      %812 : Tensor = prim::GetAttr[name="running_mean"](%771)
      %813 : Tensor = prim::GetAttr[name="running_var"](%771)
      %814 : Tensor = prim::GetAttr[name="weight"](%771)
      %815 : Tensor = prim::GetAttr[name="bias"](%771)
       = prim::If(%811) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %816 : int[] = aten::size(%input.133) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.172 : int = aten::__getitem__(%816, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %818 : int = aten::len(%816) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %819 : int = aten::sub(%818, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.173 : int = prim::Loop(%819, %4, %size_prods.172) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.44 : int, %size_prods.174 : int):
              %823 : int = aten::add(%i.44, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %824 : int = aten::__getitem__(%816, %823) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.175 : int = aten::mul(%size_prods.174, %824) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.175)
          %826 : bool = aten::eq(%size_prods.173, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%826) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %827 : str = aten::format(%6, %816) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%827) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.134 : Tensor = aten::batch_norm(%input.133, %814, %815, %812, %813, %811, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.135 : Tensor = aten::relu_(%input.134) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %830 : Tensor = prim::GetAttr[name="weight"](%772)
      %831 : Tensor? = prim::GetAttr[name="bias"](%772)
      %input.136 : Tensor = aten::conv2d(%input.135, %830, %831, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %836 : bool = prim::GetAttr[name="training"](%773)
       = prim::If(%836) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %837 : Tensor = prim::GetAttr[name="num_batches_tracked"](%773)
          %838 : Tensor = aten::add(%837, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%773, %838)
          -> ()
        block1():
          -> ()
      %839 : bool = prim::GetAttr[name="training"](%773)
      %840 : Tensor = prim::GetAttr[name="running_mean"](%773)
      %841 : Tensor = prim::GetAttr[name="running_var"](%773)
      %842 : Tensor = prim::GetAttr[name="weight"](%773)
      %843 : Tensor = prim::GetAttr[name="bias"](%773)
       = prim::If(%839) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %844 : int[] = aten::size(%input.136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.176 : int = aten::__getitem__(%844, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %846 : int = aten::len(%844) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %847 : int = aten::sub(%846, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.177 : int = prim::Loop(%847, %4, %size_prods.176) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.45 : int, %size_prods.178 : int):
              %851 : int = aten::add(%i.45, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %852 : int = aten::__getitem__(%844, %851) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.179 : int = aten::mul(%size_prods.178, %852) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.179)
          %854 : bool = aten::eq(%size_prods.177, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%854) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %855 : str = aten::format(%6, %844) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%855) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.137 : Tensor = aten::batch_norm(%input.136, %842, %843, %840, %841, %839, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.137)
  %857 : bool = prim::GetAttr[name="apply_residual"](%672)
  %input.138 : Tensor = prim::If(%857) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:56:8
    block0():
      %859 : __torch__.torch.nn.modules.container.___torch_mangle_24.Sequential = prim::GetAttr[name="layers"](%672)
      %860 : __torch__.torch.nn.modules.conv.___torch_mangle_20.Conv2d = prim::GetAttr[name="0"](%859)
      %861 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_21.BatchNorm2d = prim::GetAttr[name="1"](%859)
      %862 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="3"](%859)
      %863 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_21.BatchNorm2d = prim::GetAttr[name="4"](%859)
      %864 : __torch__.torch.nn.modules.conv.___torch_mangle_23.Conv2d = prim::GetAttr[name="6"](%859)
      %865 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_17.BatchNorm2d = prim::GetAttr[name="7"](%859)
      %866 : Tensor = prim::GetAttr[name="weight"](%860)
      %867 : Tensor? = prim::GetAttr[name="bias"](%860)
      %input.139 : Tensor = aten::conv2d(%input.121, %866, %867, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %872 : bool = prim::GetAttr[name="training"](%861)
       = prim::If(%872) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %873 : Tensor = prim::GetAttr[name="num_batches_tracked"](%861)
          %874 : Tensor = aten::add(%873, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%861, %874)
          -> ()
        block1():
          -> ()
      %875 : bool = prim::GetAttr[name="training"](%861)
      %876 : Tensor = prim::GetAttr[name="running_mean"](%861)
      %877 : Tensor = prim::GetAttr[name="running_var"](%861)
      %878 : Tensor = prim::GetAttr[name="weight"](%861)
      %879 : Tensor = prim::GetAttr[name="bias"](%861)
       = prim::If(%875) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %880 : int[] = aten::size(%input.139) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.180 : int = aten::__getitem__(%880, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %882 : int = aten::len(%880) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %883 : int = aten::sub(%882, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.181 : int = prim::Loop(%883, %4, %size_prods.180) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.46 : int, %size_prods.182 : int):
              %887 : int = aten::add(%i.46, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %888 : int = aten::__getitem__(%880, %887) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.183 : int = aten::mul(%size_prods.182, %888) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.183)
          %890 : bool = aten::eq(%size_prods.181, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%890) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %891 : str = aten::format(%6, %880) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%891) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.140 : Tensor = aten::batch_norm(%input.139, %878, %879, %876, %877, %875, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.141 : Tensor = aten::relu_(%input.140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %894 : Tensor = prim::GetAttr[name="weight"](%862)
      %895 : Tensor? = prim::GetAttr[name="bias"](%862)
      %input.142 : Tensor = aten::conv2d(%input.141, %894, %895, %3102, %3101, %3102, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %900 : bool = prim::GetAttr[name="training"](%863)
       = prim::If(%900) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %901 : Tensor = prim::GetAttr[name="num_batches_tracked"](%863)
          %902 : Tensor = aten::add(%901, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%863, %902)
          -> ()
        block1():
          -> ()
      %903 : bool = prim::GetAttr[name="training"](%863)
      %904 : Tensor = prim::GetAttr[name="running_mean"](%863)
      %905 : Tensor = prim::GetAttr[name="running_var"](%863)
      %906 : Tensor = prim::GetAttr[name="weight"](%863)
      %907 : Tensor = prim::GetAttr[name="bias"](%863)
       = prim::If(%903) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %908 : int[] = aten::size(%input.142) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.184 : int = aten::__getitem__(%908, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %910 : int = aten::len(%908) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %911 : int = aten::sub(%910, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.185 : int = prim::Loop(%911, %4, %size_prods.184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.47 : int, %size_prods.186 : int):
              %915 : int = aten::add(%i.47, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %916 : int = aten::__getitem__(%908, %915) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.187 : int = aten::mul(%size_prods.186, %916) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.187)
          %918 : bool = aten::eq(%size_prods.185, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%918) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %919 : str = aten::format(%6, %908) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%919) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.143 : Tensor = aten::batch_norm(%input.142, %906, %907, %904, %905, %903, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.144 : Tensor = aten::relu_(%input.143) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %922 : Tensor = prim::GetAttr[name="weight"](%864)
      %923 : Tensor? = prim::GetAttr[name="bias"](%864)
      %input.145 : Tensor = aten::conv2d(%input.144, %922, %923, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %928 : bool = prim::GetAttr[name="training"](%865)
       = prim::If(%928) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %929 : Tensor = prim::GetAttr[name="num_batches_tracked"](%865)
          %930 : Tensor = aten::add(%929, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%865, %930)
          -> ()
        block1():
          -> ()
      %931 : bool = prim::GetAttr[name="training"](%865)
      %932 : Tensor = prim::GetAttr[name="running_mean"](%865)
      %933 : Tensor = prim::GetAttr[name="running_var"](%865)
      %934 : Tensor = prim::GetAttr[name="weight"](%865)
      %935 : Tensor = prim::GetAttr[name="bias"](%865)
       = prim::If(%931) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %936 : int[] = aten::size(%input.145) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.188 : int = aten::__getitem__(%936, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %938 : int = aten::len(%936) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %939 : int = aten::sub(%938, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.189 : int = prim::Loop(%939, %4, %size_prods.188) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.48 : int, %size_prods.190 : int):
              %943 : int = aten::add(%i.48, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %944 : int = aten::__getitem__(%936, %943) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.191 : int = aten::mul(%size_prods.190, %944) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.191)
          %946 : bool = aten::eq(%size_prods.189, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%946) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %947 : str = aten::format(%6, %936) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%947) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.146 : Tensor = aten::batch_norm(%input.145, %934, %935, %932, %933, %931, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %949 : Tensor = aten::add(%input.146, %input.121, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:57:19
      -> (%949)
    block1():
      %950 : __torch__.torch.nn.modules.container.___torch_mangle_24.Sequential = prim::GetAttr[name="layers"](%672)
      %951 : __torch__.torch.nn.modules.conv.___torch_mangle_20.Conv2d = prim::GetAttr[name="0"](%950)
      %952 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_21.BatchNorm2d = prim::GetAttr[name="1"](%950)
      %953 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="3"](%950)
      %954 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_21.BatchNorm2d = prim::GetAttr[name="4"](%950)
      %955 : __torch__.torch.nn.modules.conv.___torch_mangle_23.Conv2d = prim::GetAttr[name="6"](%950)
      %956 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_17.BatchNorm2d = prim::GetAttr[name="7"](%950)
      %957 : Tensor = prim::GetAttr[name="weight"](%951)
      %958 : Tensor? = prim::GetAttr[name="bias"](%951)
      %input.147 : Tensor = aten::conv2d(%input.121, %957, %958, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %963 : bool = prim::GetAttr[name="training"](%952)
       = prim::If(%963) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %964 : Tensor = prim::GetAttr[name="num_batches_tracked"](%952)
          %965 : Tensor = aten::add(%964, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%952, %965)
          -> ()
        block1():
          -> ()
      %966 : bool = prim::GetAttr[name="training"](%952)
      %967 : Tensor = prim::GetAttr[name="running_mean"](%952)
      %968 : Tensor = prim::GetAttr[name="running_var"](%952)
      %969 : Tensor = prim::GetAttr[name="weight"](%952)
      %970 : Tensor = prim::GetAttr[name="bias"](%952)
       = prim::If(%966) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %971 : int[] = aten::size(%input.147) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.192 : int = aten::__getitem__(%971, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %973 : int = aten::len(%971) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %974 : int = aten::sub(%973, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.193 : int = prim::Loop(%974, %4, %size_prods.192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.49 : int, %size_prods.194 : int):
              %978 : int = aten::add(%i.49, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %979 : int = aten::__getitem__(%971, %978) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.195 : int = aten::mul(%size_prods.194, %979) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.195)
          %981 : bool = aten::eq(%size_prods.193, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%981) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %982 : str = aten::format(%6, %971) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%982) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.148 : Tensor = aten::batch_norm(%input.147, %969, %970, %967, %968, %966, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.149 : Tensor = aten::relu_(%input.148) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %985 : Tensor = prim::GetAttr[name="weight"](%953)
      %986 : Tensor? = prim::GetAttr[name="bias"](%953)
      %input.150 : Tensor = aten::conv2d(%input.149, %985, %986, %3102, %3101, %3102, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %991 : bool = prim::GetAttr[name="training"](%954)
       = prim::If(%991) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %992 : Tensor = prim::GetAttr[name="num_batches_tracked"](%954)
          %993 : Tensor = aten::add(%992, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%954, %993)
          -> ()
        block1():
          -> ()
      %994 : bool = prim::GetAttr[name="training"](%954)
      %995 : Tensor = prim::GetAttr[name="running_mean"](%954)
      %996 : Tensor = prim::GetAttr[name="running_var"](%954)
      %997 : Tensor = prim::GetAttr[name="weight"](%954)
      %998 : Tensor = prim::GetAttr[name="bias"](%954)
       = prim::If(%994) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %999 : int[] = aten::size(%input.150) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.196 : int = aten::__getitem__(%999, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1001 : int = aten::len(%999) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1002 : int = aten::sub(%1001, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.197 : int = prim::Loop(%1002, %4, %size_prods.196) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.50 : int, %size_prods.198 : int):
              %1006 : int = aten::add(%i.50, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1007 : int = aten::__getitem__(%999, %1006) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.199 : int = aten::mul(%size_prods.198, %1007) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.199)
          %1009 : bool = aten::eq(%size_prods.197, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1009) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1010 : str = aten::format(%6, %999) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1010) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.151 : Tensor = aten::batch_norm(%input.150, %997, %998, %995, %996, %994, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.152 : Tensor = aten::relu_(%input.151) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1013 : Tensor = prim::GetAttr[name="weight"](%955)
      %1014 : Tensor? = prim::GetAttr[name="bias"](%955)
      %input.153 : Tensor = aten::conv2d(%input.152, %1013, %1014, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1019 : bool = prim::GetAttr[name="training"](%956)
       = prim::If(%1019) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1020 : Tensor = prim::GetAttr[name="num_batches_tracked"](%956)
          %1021 : Tensor = aten::add(%1020, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%956, %1021)
          -> ()
        block1():
          -> ()
      %1022 : bool = prim::GetAttr[name="training"](%956)
      %1023 : Tensor = prim::GetAttr[name="running_mean"](%956)
      %1024 : Tensor = prim::GetAttr[name="running_var"](%956)
      %1025 : Tensor = prim::GetAttr[name="weight"](%956)
      %1026 : Tensor = prim::GetAttr[name="bias"](%956)
       = prim::If(%1022) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1027 : int[] = aten::size(%input.153) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.200 : int = aten::__getitem__(%1027, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1029 : int = aten::len(%1027) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1030 : int = aten::sub(%1029, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.201 : int = prim::Loop(%1030, %4, %size_prods.200) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.51 : int, %size_prods.202 : int):
              %1034 : int = aten::add(%i.51, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1035 : int = aten::__getitem__(%1027, %1034) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.203 : int = aten::mul(%size_prods.202, %1035) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.203)
          %1037 : bool = aten::eq(%size_prods.201, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1037) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1038 : str = aten::format(%6, %1027) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1038) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.154 : Tensor = aten::batch_norm(%input.153, %1025, %1026, %1023, %1024, %1022, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.154)
  %1040 : bool = prim::GetAttr[name="apply_residual"](%673)
  %input.244 : Tensor = prim::If(%1040) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:56:8
    block0():
      %1042 : __torch__.torch.nn.modules.container.___torch_mangle_24.Sequential = prim::GetAttr[name="layers"](%673)
      %1043 : __torch__.torch.nn.modules.conv.___torch_mangle_20.Conv2d = prim::GetAttr[name="0"](%1042)
      %1044 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_21.BatchNorm2d = prim::GetAttr[name="1"](%1042)
      %1045 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="3"](%1042)
      %1046 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_21.BatchNorm2d = prim::GetAttr[name="4"](%1042)
      %1047 : __torch__.torch.nn.modules.conv.___torch_mangle_23.Conv2d = prim::GetAttr[name="6"](%1042)
      %1048 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_17.BatchNorm2d = prim::GetAttr[name="7"](%1042)
      %1049 : Tensor = prim::GetAttr[name="weight"](%1043)
      %1050 : Tensor? = prim::GetAttr[name="bias"](%1043)
      %input.155 : Tensor = aten::conv2d(%input.138, %1049, %1050, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1055 : bool = prim::GetAttr[name="training"](%1044)
       = prim::If(%1055) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1056 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1044)
          %1057 : Tensor = aten::add(%1056, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1044, %1057)
          -> ()
        block1():
          -> ()
      %1058 : bool = prim::GetAttr[name="training"](%1044)
      %1059 : Tensor = prim::GetAttr[name="running_mean"](%1044)
      %1060 : Tensor = prim::GetAttr[name="running_var"](%1044)
      %1061 : Tensor = prim::GetAttr[name="weight"](%1044)
      %1062 : Tensor = prim::GetAttr[name="bias"](%1044)
       = prim::If(%1058) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1063 : int[] = aten::size(%input.155) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.204 : int = aten::__getitem__(%1063, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1065 : int = aten::len(%1063) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1066 : int = aten::sub(%1065, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.205 : int = prim::Loop(%1066, %4, %size_prods.204) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.52 : int, %size_prods.206 : int):
              %1070 : int = aten::add(%i.52, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1071 : int = aten::__getitem__(%1063, %1070) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.207 : int = aten::mul(%size_prods.206, %1071) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.207)
          %1073 : bool = aten::eq(%size_prods.205, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1073) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1074 : str = aten::format(%6, %1063) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1074) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.156 : Tensor = aten::batch_norm(%input.155, %1061, %1062, %1059, %1060, %1058, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.157 : Tensor = aten::relu_(%input.156) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1077 : Tensor = prim::GetAttr[name="weight"](%1045)
      %1078 : Tensor? = prim::GetAttr[name="bias"](%1045)
      %input.158 : Tensor = aten::conv2d(%input.157, %1077, %1078, %3102, %3101, %3102, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1083 : bool = prim::GetAttr[name="training"](%1046)
       = prim::If(%1083) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1084 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1046)
          %1085 : Tensor = aten::add(%1084, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1046, %1085)
          -> ()
        block1():
          -> ()
      %1086 : bool = prim::GetAttr[name="training"](%1046)
      %1087 : Tensor = prim::GetAttr[name="running_mean"](%1046)
      %1088 : Tensor = prim::GetAttr[name="running_var"](%1046)
      %1089 : Tensor = prim::GetAttr[name="weight"](%1046)
      %1090 : Tensor = prim::GetAttr[name="bias"](%1046)
       = prim::If(%1086) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1091 : int[] = aten::size(%input.158) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.208 : int = aten::__getitem__(%1091, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1093 : int = aten::len(%1091) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1094 : int = aten::sub(%1093, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.209 : int = prim::Loop(%1094, %4, %size_prods.208) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.53 : int, %size_prods.210 : int):
              %1098 : int = aten::add(%i.53, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1099 : int = aten::__getitem__(%1091, %1098) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.211 : int = aten::mul(%size_prods.210, %1099) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.211)
          %1101 : bool = aten::eq(%size_prods.209, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1101) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1102 : str = aten::format(%6, %1091) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1102) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.159 : Tensor = aten::batch_norm(%input.158, %1089, %1090, %1087, %1088, %1086, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.160 : Tensor = aten::relu_(%input.159) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1105 : Tensor = prim::GetAttr[name="weight"](%1047)
      %1106 : Tensor? = prim::GetAttr[name="bias"](%1047)
      %input.161 : Tensor = aten::conv2d(%input.160, %1105, %1106, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1111 : bool = prim::GetAttr[name="training"](%1048)
       = prim::If(%1111) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1112 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1048)
          %1113 : Tensor = aten::add(%1112, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1048, %1113)
          -> ()
        block1():
          -> ()
      %1114 : bool = prim::GetAttr[name="training"](%1048)
      %1115 : Tensor = prim::GetAttr[name="running_mean"](%1048)
      %1116 : Tensor = prim::GetAttr[name="running_var"](%1048)
      %1117 : Tensor = prim::GetAttr[name="weight"](%1048)
      %1118 : Tensor = prim::GetAttr[name="bias"](%1048)
       = prim::If(%1114) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1119 : int[] = aten::size(%input.161) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.212 : int = aten::__getitem__(%1119, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1121 : int = aten::len(%1119) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1122 : int = aten::sub(%1121, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.213 : int = prim::Loop(%1122, %4, %size_prods.212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.54 : int, %size_prods.214 : int):
              %1126 : int = aten::add(%i.54, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1127 : int = aten::__getitem__(%1119, %1126) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.215 : int = aten::mul(%size_prods.214, %1127) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.215)
          %1129 : bool = aten::eq(%size_prods.213, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1129) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1130 : str = aten::format(%6, %1119) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1130) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.162 : Tensor = aten::batch_norm(%input.161, %1117, %1118, %1115, %1116, %1114, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1132 : Tensor = aten::add(%input.162, %input.138, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:57:19
      -> (%1132)
    block1():
      %1133 : __torch__.torch.nn.modules.container.___torch_mangle_24.Sequential = prim::GetAttr[name="layers"](%673)
      %1134 : __torch__.torch.nn.modules.conv.___torch_mangle_20.Conv2d = prim::GetAttr[name="0"](%1133)
      %1135 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_21.BatchNorm2d = prim::GetAttr[name="1"](%1133)
      %1136 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="3"](%1133)
      %1137 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_21.BatchNorm2d = prim::GetAttr[name="4"](%1133)
      %1138 : __torch__.torch.nn.modules.conv.___torch_mangle_23.Conv2d = prim::GetAttr[name="6"](%1133)
      %1139 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_17.BatchNorm2d = prim::GetAttr[name="7"](%1133)
      %1140 : Tensor = prim::GetAttr[name="weight"](%1134)
      %1141 : Tensor? = prim::GetAttr[name="bias"](%1134)
      %input.163 : Tensor = aten::conv2d(%input.138, %1140, %1141, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1146 : bool = prim::GetAttr[name="training"](%1135)
       = prim::If(%1146) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1147 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1135)
          %1148 : Tensor = aten::add(%1147, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1135, %1148)
          -> ()
        block1():
          -> ()
      %1149 : bool = prim::GetAttr[name="training"](%1135)
      %1150 : Tensor = prim::GetAttr[name="running_mean"](%1135)
      %1151 : Tensor = prim::GetAttr[name="running_var"](%1135)
      %1152 : Tensor = prim::GetAttr[name="weight"](%1135)
      %1153 : Tensor = prim::GetAttr[name="bias"](%1135)
       = prim::If(%1149) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1154 : int[] = aten::size(%input.163) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.216 : int = aten::__getitem__(%1154, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1156 : int = aten::len(%1154) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1157 : int = aten::sub(%1156, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.217 : int = prim::Loop(%1157, %4, %size_prods.216) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.55 : int, %size_prods.218 : int):
              %1161 : int = aten::add(%i.55, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1162 : int = aten::__getitem__(%1154, %1161) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.219 : int = aten::mul(%size_prods.218, %1162) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.219)
          %1164 : bool = aten::eq(%size_prods.217, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1164) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1165 : str = aten::format(%6, %1154) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1165) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.164 : Tensor = aten::batch_norm(%input.163, %1152, %1153, %1150, %1151, %1149, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.165 : Tensor = aten::relu_(%input.164) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1168 : Tensor = prim::GetAttr[name="weight"](%1136)
      %1169 : Tensor? = prim::GetAttr[name="bias"](%1136)
      %input.166 : Tensor = aten::conv2d(%input.165, %1168, %1169, %3102, %3101, %3102, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1174 : bool = prim::GetAttr[name="training"](%1137)
       = prim::If(%1174) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1175 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1137)
          %1176 : Tensor = aten::add(%1175, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1137, %1176)
          -> ()
        block1():
          -> ()
      %1177 : bool = prim::GetAttr[name="training"](%1137)
      %1178 : Tensor = prim::GetAttr[name="running_mean"](%1137)
      %1179 : Tensor = prim::GetAttr[name="running_var"](%1137)
      %1180 : Tensor = prim::GetAttr[name="weight"](%1137)
      %1181 : Tensor = prim::GetAttr[name="bias"](%1137)
       = prim::If(%1177) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1182 : int[] = aten::size(%input.166) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.220 : int = aten::__getitem__(%1182, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1184 : int = aten::len(%1182) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1185 : int = aten::sub(%1184, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.221 : int = prim::Loop(%1185, %4, %size_prods.220) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.56 : int, %size_prods.222 : int):
              %1189 : int = aten::add(%i.56, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1190 : int = aten::__getitem__(%1182, %1189) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.223 : int = aten::mul(%size_prods.222, %1190) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.223)
          %1192 : bool = aten::eq(%size_prods.221, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1193 : str = aten::format(%6, %1182) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1193) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.167 : Tensor = aten::batch_norm(%input.166, %1180, %1181, %1178, %1179, %1177, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.168 : Tensor = aten::relu_(%input.167) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1196 : Tensor = prim::GetAttr[name="weight"](%1138)
      %1197 : Tensor? = prim::GetAttr[name="bias"](%1138)
      %input.169 : Tensor = aten::conv2d(%input.168, %1196, %1197, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1202 : bool = prim::GetAttr[name="training"](%1139)
       = prim::If(%1202) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1203 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1139)
          %1204 : Tensor = aten::add(%1203, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1139, %1204)
          -> ()
        block1():
          -> ()
      %1205 : bool = prim::GetAttr[name="training"](%1139)
      %1206 : Tensor = prim::GetAttr[name="running_mean"](%1139)
      %1207 : Tensor = prim::GetAttr[name="running_var"](%1139)
      %1208 : Tensor = prim::GetAttr[name="weight"](%1139)
      %1209 : Tensor = prim::GetAttr[name="bias"](%1139)
       = prim::If(%1205) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1210 : int[] = aten::size(%input.169) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.224 : int = aten::__getitem__(%1210, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1212 : int = aten::len(%1210) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1213 : int = aten::sub(%1212, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.225 : int = prim::Loop(%1213, %4, %size_prods.224) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.57 : int, %size_prods.226 : int):
              %1217 : int = aten::add(%i.57, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1218 : int = aten::__getitem__(%1210, %1217) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.227 : int = aten::mul(%size_prods.226, %1218) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.227)
          %1220 : bool = aten::eq(%size_prods.225, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1220) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1221 : str = aten::format(%6, %1210) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1221) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.170 : Tensor = aten::batch_norm(%input.169, %1208, %1209, %1206, %1207, %1205, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.170)
  %1223 : __torch__.torchvision.models.mnasnet.___torch_mangle_33._InvertedResidual = prim::GetAttr[name="0"](%30)
  %1224 : __torch__.torchvision.models.mnasnet.___torch_mangle_39._InvertedResidual = prim::GetAttr[name="1"](%30)
  %1225 : __torch__.torchvision.models.mnasnet.___torch_mangle_39._InvertedResidual = prim::GetAttr[name="2"](%30)
  %1226 : bool = prim::GetAttr[name="apply_residual"](%1223)
  %input.187 : Tensor = prim::If(%1226) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:56:8
    block0():
      %1228 : __torch__.torch.nn.modules.container.___torch_mangle_32.Sequential = prim::GetAttr[name="layers"](%1223)
      %1229 : __torch__.torch.nn.modules.conv.___torch_mangle_27.Conv2d = prim::GetAttr[name="0"](%1228)
      %1230 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_28.BatchNorm2d = prim::GetAttr[name="1"](%1228)
      %1231 : __torch__.torch.nn.modules.conv.___torch_mangle_29.Conv2d = prim::GetAttr[name="3"](%1228)
      %1232 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_28.BatchNorm2d = prim::GetAttr[name="4"](%1228)
      %1233 : __torch__.torch.nn.modules.conv.___torch_mangle_30.Conv2d = prim::GetAttr[name="6"](%1228)
      %1234 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_31.BatchNorm2d = prim::GetAttr[name="7"](%1228)
      %1235 : Tensor = prim::GetAttr[name="weight"](%1229)
      %1236 : Tensor? = prim::GetAttr[name="bias"](%1229)
      %input.172 : Tensor = aten::conv2d(%input.244, %1235, %1236, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1241 : bool = prim::GetAttr[name="training"](%1230)
       = prim::If(%1241) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1242 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1230)
          %1243 : Tensor = aten::add(%1242, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1230, %1243)
          -> ()
        block1():
          -> ()
      %1244 : bool = prim::GetAttr[name="training"](%1230)
      %1245 : Tensor = prim::GetAttr[name="running_mean"](%1230)
      %1246 : Tensor = prim::GetAttr[name="running_var"](%1230)
      %1247 : Tensor = prim::GetAttr[name="weight"](%1230)
      %1248 : Tensor = prim::GetAttr[name="bias"](%1230)
       = prim::If(%1244) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1249 : int[] = aten::size(%input.172) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.228 : int = aten::__getitem__(%1249, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1251 : int = aten::len(%1249) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1252 : int = aten::sub(%1251, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.229 : int = prim::Loop(%1252, %4, %size_prods.228) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.58 : int, %size_prods.230 : int):
              %1256 : int = aten::add(%i.58, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1257 : int = aten::__getitem__(%1249, %1256) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.231 : int = aten::mul(%size_prods.230, %1257) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.231)
          %1259 : bool = aten::eq(%size_prods.229, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1259) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1260 : str = aten::format(%6, %1249) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1260) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.173 : Tensor = aten::batch_norm(%input.172, %1247, %1248, %1245, %1246, %1244, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.174 : Tensor = aten::relu_(%input.173) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1263 : Tensor = prim::GetAttr[name="weight"](%1231)
      %1264 : Tensor? = prim::GetAttr[name="bias"](%1231)
      %input.175 : Tensor = aten::conv2d(%input.174, %1263, %1264, %3101, %3101, %3102, %14) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1269 : bool = prim::GetAttr[name="training"](%1232)
       = prim::If(%1269) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1270 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1232)
          %1271 : Tensor = aten::add(%1270, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1232, %1271)
          -> ()
        block1():
          -> ()
      %1272 : bool = prim::GetAttr[name="training"](%1232)
      %1273 : Tensor = prim::GetAttr[name="running_mean"](%1232)
      %1274 : Tensor = prim::GetAttr[name="running_var"](%1232)
      %1275 : Tensor = prim::GetAttr[name="weight"](%1232)
      %1276 : Tensor = prim::GetAttr[name="bias"](%1232)
       = prim::If(%1272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1277 : int[] = aten::size(%input.175) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.232 : int = aten::__getitem__(%1277, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1279 : int = aten::len(%1277) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1280 : int = aten::sub(%1279, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.233 : int = prim::Loop(%1280, %4, %size_prods.232) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.59 : int, %size_prods.234 : int):
              %1284 : int = aten::add(%i.59, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1285 : int = aten::__getitem__(%1277, %1284) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.235 : int = aten::mul(%size_prods.234, %1285) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.235)
          %1287 : bool = aten::eq(%size_prods.233, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1287) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1288 : str = aten::format(%6, %1277) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1288) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.176 : Tensor = aten::batch_norm(%input.175, %1275, %1276, %1273, %1274, %1272, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.177 : Tensor = aten::relu_(%input.176) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1291 : Tensor = prim::GetAttr[name="weight"](%1233)
      %1292 : Tensor? = prim::GetAttr[name="bias"](%1233)
      %input.178 : Tensor = aten::conv2d(%input.177, %1291, %1292, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1297 : bool = prim::GetAttr[name="training"](%1234)
       = prim::If(%1297) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1298 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1234)
          %1299 : Tensor = aten::add(%1298, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1234, %1299)
          -> ()
        block1():
          -> ()
      %1300 : bool = prim::GetAttr[name="training"](%1234)
      %1301 : Tensor = prim::GetAttr[name="running_mean"](%1234)
      %1302 : Tensor = prim::GetAttr[name="running_var"](%1234)
      %1303 : Tensor = prim::GetAttr[name="weight"](%1234)
      %1304 : Tensor = prim::GetAttr[name="bias"](%1234)
       = prim::If(%1300) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1305 : int[] = aten::size(%input.178) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.236 : int = aten::__getitem__(%1305, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1307 : int = aten::len(%1305) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1308 : int = aten::sub(%1307, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.237 : int = prim::Loop(%1308, %4, %size_prods.236) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.60 : int, %size_prods.238 : int):
              %1312 : int = aten::add(%i.60, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1313 : int = aten::__getitem__(%1305, %1312) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.239 : int = aten::mul(%size_prods.238, %1313) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.239)
          %1315 : bool = aten::eq(%size_prods.237, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1315) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1316 : str = aten::format(%6, %1305) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1316) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.179 : Tensor = aten::batch_norm(%input.178, %1303, %1304, %1301, %1302, %1300, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1318 : Tensor = aten::add(%input.179, %input.244, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:57:19
      -> (%1318)
    block1():
      %1319 : __torch__.torch.nn.modules.container.___torch_mangle_32.Sequential = prim::GetAttr[name="layers"](%1223)
      %1320 : __torch__.torch.nn.modules.conv.___torch_mangle_27.Conv2d = prim::GetAttr[name="0"](%1319)
      %1321 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_28.BatchNorm2d = prim::GetAttr[name="1"](%1319)
      %1322 : __torch__.torch.nn.modules.conv.___torch_mangle_29.Conv2d = prim::GetAttr[name="3"](%1319)
      %1323 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_28.BatchNorm2d = prim::GetAttr[name="4"](%1319)
      %1324 : __torch__.torch.nn.modules.conv.___torch_mangle_30.Conv2d = prim::GetAttr[name="6"](%1319)
      %1325 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_31.BatchNorm2d = prim::GetAttr[name="7"](%1319)
      %1326 : Tensor = prim::GetAttr[name="weight"](%1320)
      %1327 : Tensor? = prim::GetAttr[name="bias"](%1320)
      %input.180 : Tensor = aten::conv2d(%input.244, %1326, %1327, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1332 : bool = prim::GetAttr[name="training"](%1321)
       = prim::If(%1332) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1333 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1321)
          %1334 : Tensor = aten::add(%1333, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1321, %1334)
          -> ()
        block1():
          -> ()
      %1335 : bool = prim::GetAttr[name="training"](%1321)
      %1336 : Tensor = prim::GetAttr[name="running_mean"](%1321)
      %1337 : Tensor = prim::GetAttr[name="running_var"](%1321)
      %1338 : Tensor = prim::GetAttr[name="weight"](%1321)
      %1339 : Tensor = prim::GetAttr[name="bias"](%1321)
       = prim::If(%1335) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1340 : int[] = aten::size(%input.180) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.240 : int = aten::__getitem__(%1340, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1342 : int = aten::len(%1340) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1343 : int = aten::sub(%1342, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.241 : int = prim::Loop(%1343, %4, %size_prods.240) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.61 : int, %size_prods.242 : int):
              %1347 : int = aten::add(%i.61, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1348 : int = aten::__getitem__(%1340, %1347) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.243 : int = aten::mul(%size_prods.242, %1348) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.243)
          %1350 : bool = aten::eq(%size_prods.241, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1350) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1351 : str = aten::format(%6, %1340) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1351) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.181 : Tensor = aten::batch_norm(%input.180, %1338, %1339, %1336, %1337, %1335, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.182 : Tensor = aten::relu_(%input.181) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1354 : Tensor = prim::GetAttr[name="weight"](%1322)
      %1355 : Tensor? = prim::GetAttr[name="bias"](%1322)
      %input.183 : Tensor = aten::conv2d(%input.182, %1354, %1355, %3101, %3101, %3102, %14) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1360 : bool = prim::GetAttr[name="training"](%1323)
       = prim::If(%1360) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1361 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1323)
          %1362 : Tensor = aten::add(%1361, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1323, %1362)
          -> ()
        block1():
          -> ()
      %1363 : bool = prim::GetAttr[name="training"](%1323)
      %1364 : Tensor = prim::GetAttr[name="running_mean"](%1323)
      %1365 : Tensor = prim::GetAttr[name="running_var"](%1323)
      %1366 : Tensor = prim::GetAttr[name="weight"](%1323)
      %1367 : Tensor = prim::GetAttr[name="bias"](%1323)
       = prim::If(%1363) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1368 : int[] = aten::size(%input.183) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.244 : int = aten::__getitem__(%1368, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1370 : int = aten::len(%1368) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1371 : int = aten::sub(%1370, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.245 : int = prim::Loop(%1371, %4, %size_prods.244) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.62 : int, %size_prods.246 : int):
              %1375 : int = aten::add(%i.62, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1376 : int = aten::__getitem__(%1368, %1375) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.247 : int = aten::mul(%size_prods.246, %1376) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.247)
          %1378 : bool = aten::eq(%size_prods.245, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1378) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1379 : str = aten::format(%6, %1368) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1379) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.184 : Tensor = aten::batch_norm(%input.183, %1366, %1367, %1364, %1365, %1363, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.185 : Tensor = aten::relu_(%input.184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1382 : Tensor = prim::GetAttr[name="weight"](%1324)
      %1383 : Tensor? = prim::GetAttr[name="bias"](%1324)
      %input.186 : Tensor = aten::conv2d(%input.185, %1382, %1383, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1388 : bool = prim::GetAttr[name="training"](%1325)
       = prim::If(%1388) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1389 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1325)
          %1390 : Tensor = aten::add(%1389, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1325, %1390)
          -> ()
        block1():
          -> ()
      %1391 : bool = prim::GetAttr[name="training"](%1325)
      %1392 : Tensor = prim::GetAttr[name="running_mean"](%1325)
      %1393 : Tensor = prim::GetAttr[name="running_var"](%1325)
      %1394 : Tensor = prim::GetAttr[name="weight"](%1325)
      %1395 : Tensor = prim::GetAttr[name="bias"](%1325)
       = prim::If(%1391) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1396 : int[] = aten::size(%input.186) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.248 : int = aten::__getitem__(%1396, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1398 : int = aten::len(%1396) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1399 : int = aten::sub(%1398, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.249 : int = prim::Loop(%1399, %4, %size_prods.248) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.63 : int, %size_prods.250 : int):
              %1403 : int = aten::add(%i.63, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1404 : int = aten::__getitem__(%1396, %1403) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.251 : int = aten::mul(%size_prods.250, %1404) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.251)
          %1406 : bool = aten::eq(%size_prods.249, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1406) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1407 : str = aten::format(%6, %1396) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1407) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.218 : Tensor = aten::batch_norm(%input.186, %1394, %1395, %1392, %1393, %1391, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.218)
  %1409 : bool = prim::GetAttr[name="apply_residual"](%1224)
  %input.171 : Tensor = prim::If(%1409) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:56:8
    block0():
      %1411 : __torch__.torch.nn.modules.container.___torch_mangle_38.Sequential = prim::GetAttr[name="layers"](%1224)
      %1412 : __torch__.torch.nn.modules.conv.___torch_mangle_34.Conv2d = prim::GetAttr[name="0"](%1411)
      %1413 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_35.BatchNorm2d = prim::GetAttr[name="1"](%1411)
      %1414 : __torch__.torch.nn.modules.conv.___torch_mangle_36.Conv2d = prim::GetAttr[name="3"](%1411)
      %1415 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_35.BatchNorm2d = prim::GetAttr[name="4"](%1411)
      %1416 : __torch__.torch.nn.modules.conv.___torch_mangle_37.Conv2d = prim::GetAttr[name="6"](%1411)
      %1417 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_31.BatchNorm2d = prim::GetAttr[name="7"](%1411)
      %1418 : Tensor = prim::GetAttr[name="weight"](%1412)
      %1419 : Tensor? = prim::GetAttr[name="bias"](%1412)
      %input.219 : Tensor = aten::conv2d(%input.187, %1418, %1419, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1424 : bool = prim::GetAttr[name="training"](%1413)
       = prim::If(%1424) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1425 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1413)
          %1426 : Tensor = aten::add(%1425, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1413, %1426)
          -> ()
        block1():
          -> ()
      %1427 : bool = prim::GetAttr[name="training"](%1413)
      %1428 : Tensor = prim::GetAttr[name="running_mean"](%1413)
      %1429 : Tensor = prim::GetAttr[name="running_var"](%1413)
      %1430 : Tensor = prim::GetAttr[name="weight"](%1413)
      %1431 : Tensor = prim::GetAttr[name="bias"](%1413)
       = prim::If(%1427) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1432 : int[] = aten::size(%input.219) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.300 : int = aten::__getitem__(%1432, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1434 : int = aten::len(%1432) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1435 : int = aten::sub(%1434, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.301 : int = prim::Loop(%1435, %4, %size_prods.300) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.76 : int, %size_prods.302 : int):
              %1439 : int = aten::add(%i.76, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1440 : int = aten::__getitem__(%1432, %1439) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.303 : int = aten::mul(%size_prods.302, %1440) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.303)
          %1442 : bool = aten::eq(%size_prods.301, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1442) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1443 : str = aten::format(%6, %1432) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1443) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.221 : Tensor = aten::batch_norm(%input.219, %1430, %1431, %1428, %1429, %1427, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.222 : Tensor = aten::relu_(%input.221) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1446 : Tensor = prim::GetAttr[name="weight"](%1414)
      %1447 : Tensor? = prim::GetAttr[name="bias"](%1414)
      %input.223 : Tensor = aten::conv2d(%input.222, %1446, %1447, %3102, %3101, %3102, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1452 : bool = prim::GetAttr[name="training"](%1415)
       = prim::If(%1452) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1453 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1415)
          %1454 : Tensor = aten::add(%1453, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1415, %1454)
          -> ()
        block1():
          -> ()
      %1455 : bool = prim::GetAttr[name="training"](%1415)
      %1456 : Tensor = prim::GetAttr[name="running_mean"](%1415)
      %1457 : Tensor = prim::GetAttr[name="running_var"](%1415)
      %1458 : Tensor = prim::GetAttr[name="weight"](%1415)
      %1459 : Tensor = prim::GetAttr[name="bias"](%1415)
       = prim::If(%1455) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1460 : int[] = aten::size(%input.223) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.304 : int = aten::__getitem__(%1460, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1462 : int = aten::len(%1460) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1463 : int = aten::sub(%1462, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.305 : int = prim::Loop(%1463, %4, %size_prods.304) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.77 : int, %size_prods.306 : int):
              %1467 : int = aten::add(%i.77, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1468 : int = aten::__getitem__(%1460, %1467) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.307 : int = aten::mul(%size_prods.306, %1468) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.307)
          %1470 : bool = aten::eq(%size_prods.305, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1470) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1471 : str = aten::format(%6, %1460) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1471) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.224 : Tensor = aten::batch_norm(%input.223, %1458, %1459, %1456, %1457, %1455, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.225 : Tensor = aten::relu_(%input.224) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1474 : Tensor = prim::GetAttr[name="weight"](%1416)
      %1475 : Tensor? = prim::GetAttr[name="bias"](%1416)
      %input.226 : Tensor = aten::conv2d(%input.225, %1474, %1475, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1480 : bool = prim::GetAttr[name="training"](%1417)
       = prim::If(%1480) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1481 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1417)
          %1482 : Tensor = aten::add(%1481, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1417, %1482)
          -> ()
        block1():
          -> ()
      %1483 : bool = prim::GetAttr[name="training"](%1417)
      %1484 : Tensor = prim::GetAttr[name="running_mean"](%1417)
      %1485 : Tensor = prim::GetAttr[name="running_var"](%1417)
      %1486 : Tensor = prim::GetAttr[name="weight"](%1417)
      %1487 : Tensor = prim::GetAttr[name="bias"](%1417)
       = prim::If(%1483) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1488 : int[] = aten::size(%input.226) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.308 : int = aten::__getitem__(%1488, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1490 : int = aten::len(%1488) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1491 : int = aten::sub(%1490, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.309 : int = prim::Loop(%1491, %4, %size_prods.308) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.78 : int, %size_prods.310 : int):
              %1495 : int = aten::add(%i.78, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1496 : int = aten::__getitem__(%1488, %1495) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.311 : int = aten::mul(%size_prods.310, %1496) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.311)
          %1498 : bool = aten::eq(%size_prods.309, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1498) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1499 : str = aten::format(%6, %1488) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1499) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.227 : Tensor = aten::batch_norm(%input.226, %1486, %1487, %1484, %1485, %1483, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1501 : Tensor = aten::add(%input.227, %input.187, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:57:19
      -> (%1501)
    block1():
      %1502 : __torch__.torch.nn.modules.container.___torch_mangle_38.Sequential = prim::GetAttr[name="layers"](%1224)
      %1503 : __torch__.torch.nn.modules.conv.___torch_mangle_34.Conv2d = prim::GetAttr[name="0"](%1502)
      %1504 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_35.BatchNorm2d = prim::GetAttr[name="1"](%1502)
      %1505 : __torch__.torch.nn.modules.conv.___torch_mangle_36.Conv2d = prim::GetAttr[name="3"](%1502)
      %1506 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_35.BatchNorm2d = prim::GetAttr[name="4"](%1502)
      %1507 : __torch__.torch.nn.modules.conv.___torch_mangle_37.Conv2d = prim::GetAttr[name="6"](%1502)
      %1508 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_31.BatchNorm2d = prim::GetAttr[name="7"](%1502)
      %1509 : Tensor = prim::GetAttr[name="weight"](%1503)
      %1510 : Tensor? = prim::GetAttr[name="bias"](%1503)
      %input.228 : Tensor = aten::conv2d(%input.187, %1509, %1510, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1515 : bool = prim::GetAttr[name="training"](%1504)
       = prim::If(%1515) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1516 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1504)
          %1517 : Tensor = aten::add(%1516, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1504, %1517)
          -> ()
        block1():
          -> ()
      %1518 : bool = prim::GetAttr[name="training"](%1504)
      %1519 : Tensor = prim::GetAttr[name="running_mean"](%1504)
      %1520 : Tensor = prim::GetAttr[name="running_var"](%1504)
      %1521 : Tensor = prim::GetAttr[name="weight"](%1504)
      %1522 : Tensor = prim::GetAttr[name="bias"](%1504)
       = prim::If(%1518) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1523 : int[] = aten::size(%input.228) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.312 : int = aten::__getitem__(%1523, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1525 : int = aten::len(%1523) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1526 : int = aten::sub(%1525, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.313 : int = prim::Loop(%1526, %4, %size_prods.312) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.79 : int, %size_prods.314 : int):
              %1530 : int = aten::add(%i.79, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1531 : int = aten::__getitem__(%1523, %1530) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.315 : int = aten::mul(%size_prods.314, %1531) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.315)
          %1533 : bool = aten::eq(%size_prods.313, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1533) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1534 : str = aten::format(%6, %1523) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1534) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.229 : Tensor = aten::batch_norm(%input.228, %1521, %1522, %1519, %1520, %1518, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.230 : Tensor = aten::relu_(%input.229) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1537 : Tensor = prim::GetAttr[name="weight"](%1505)
      %1538 : Tensor? = prim::GetAttr[name="bias"](%1505)
      %input.231 : Tensor = aten::conv2d(%input.230, %1537, %1538, %3102, %3101, %3102, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1543 : bool = prim::GetAttr[name="training"](%1506)
       = prim::If(%1543) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1544 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1506)
          %1545 : Tensor = aten::add(%1544, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1506, %1545)
          -> ()
        block1():
          -> ()
      %1546 : bool = prim::GetAttr[name="training"](%1506)
      %1547 : Tensor = prim::GetAttr[name="running_mean"](%1506)
      %1548 : Tensor = prim::GetAttr[name="running_var"](%1506)
      %1549 : Tensor = prim::GetAttr[name="weight"](%1506)
      %1550 : Tensor = prim::GetAttr[name="bias"](%1506)
       = prim::If(%1546) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1551 : int[] = aten::size(%input.231) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.316 : int = aten::__getitem__(%1551, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1553 : int = aten::len(%1551) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1554 : int = aten::sub(%1553, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.317 : int = prim::Loop(%1554, %4, %size_prods.316) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.80 : int, %size_prods.318 : int):
              %1558 : int = aten::add(%i.80, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1559 : int = aten::__getitem__(%1551, %1558) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.319 : int = aten::mul(%size_prods.318, %1559) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.319)
          %1561 : bool = aten::eq(%size_prods.317, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1561) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1562 : str = aten::format(%6, %1551) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1562) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.232 : Tensor = aten::batch_norm(%input.231, %1549, %1550, %1547, %1548, %1546, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.233 : Tensor = aten::relu_(%input.232) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1565 : Tensor = prim::GetAttr[name="weight"](%1507)
      %1566 : Tensor? = prim::GetAttr[name="bias"](%1507)
      %input.234 : Tensor = aten::conv2d(%input.233, %1565, %1566, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1571 : bool = prim::GetAttr[name="training"](%1508)
       = prim::If(%1571) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1572 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1508)
          %1573 : Tensor = aten::add(%1572, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1508, %1573)
          -> ()
        block1():
          -> ()
      %1574 : bool = prim::GetAttr[name="training"](%1508)
      %1575 : Tensor = prim::GetAttr[name="running_mean"](%1508)
      %1576 : Tensor = prim::GetAttr[name="running_var"](%1508)
      %1577 : Tensor = prim::GetAttr[name="weight"](%1508)
      %1578 : Tensor = prim::GetAttr[name="bias"](%1508)
       = prim::If(%1574) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1579 : int[] = aten::size(%input.234) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.320 : int = aten::__getitem__(%1579, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1581 : int = aten::len(%1579) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1582 : int = aten::sub(%1581, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.321 : int = prim::Loop(%1582, %4, %size_prods.320) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.81 : int, %size_prods.322 : int):
              %1586 : int = aten::add(%i.81, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1587 : int = aten::__getitem__(%1579, %1586) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.323 : int = aten::mul(%size_prods.322, %1587) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.323)
          %1589 : bool = aten::eq(%size_prods.321, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1589) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1590 : str = aten::format(%6, %1579) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1590) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.235 : Tensor = aten::batch_norm(%input.234, %1577, %1578, %1575, %1576, %1574, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.235)
  %1592 : bool = prim::GetAttr[name="apply_residual"](%1225)
  %input.243 : Tensor = prim::If(%1592) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:56:8
    block0():
      %1594 : __torch__.torch.nn.modules.container.___torch_mangle_38.Sequential = prim::GetAttr[name="layers"](%1225)
      %1595 : __torch__.torch.nn.modules.conv.___torch_mangle_34.Conv2d = prim::GetAttr[name="0"](%1594)
      %1596 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_35.BatchNorm2d = prim::GetAttr[name="1"](%1594)
      %1597 : __torch__.torch.nn.modules.conv.___torch_mangle_36.Conv2d = prim::GetAttr[name="3"](%1594)
      %1598 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_35.BatchNorm2d = prim::GetAttr[name="4"](%1594)
      %1599 : __torch__.torch.nn.modules.conv.___torch_mangle_37.Conv2d = prim::GetAttr[name="6"](%1594)
      %1600 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_31.BatchNorm2d = prim::GetAttr[name="7"](%1594)
      %1601 : Tensor = prim::GetAttr[name="weight"](%1595)
      %1602 : Tensor? = prim::GetAttr[name="bias"](%1595)
      %input.188 : Tensor = aten::conv2d(%input.171, %1601, %1602, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1607 : bool = prim::GetAttr[name="training"](%1596)
       = prim::If(%1607) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1608 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1596)
          %1609 : Tensor = aten::add(%1608, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1596, %1609)
          -> ()
        block1():
          -> ()
      %1610 : bool = prim::GetAttr[name="training"](%1596)
      %1611 : Tensor = prim::GetAttr[name="running_mean"](%1596)
      %1612 : Tensor = prim::GetAttr[name="running_var"](%1596)
      %1613 : Tensor = prim::GetAttr[name="weight"](%1596)
      %1614 : Tensor = prim::GetAttr[name="bias"](%1596)
       = prim::If(%1610) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1615 : int[] = aten::size(%input.188) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.252 : int = aten::__getitem__(%1615, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1617 : int = aten::len(%1615) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1618 : int = aten::sub(%1617, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.253 : int = prim::Loop(%1618, %4, %size_prods.252) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.64 : int, %size_prods.254 : int):
              %1622 : int = aten::add(%i.64, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1623 : int = aten::__getitem__(%1615, %1622) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.255 : int = aten::mul(%size_prods.254, %1623) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.255)
          %1625 : bool = aten::eq(%size_prods.253, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1625) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1626 : str = aten::format(%6, %1615) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1626) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.189 : Tensor = aten::batch_norm(%input.188, %1613, %1614, %1611, %1612, %1610, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.190 : Tensor = aten::relu_(%input.189) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1629 : Tensor = prim::GetAttr[name="weight"](%1597)
      %1630 : Tensor? = prim::GetAttr[name="bias"](%1597)
      %input.191 : Tensor = aten::conv2d(%input.190, %1629, %1630, %3102, %3101, %3102, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1635 : bool = prim::GetAttr[name="training"](%1598)
       = prim::If(%1635) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1636 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1598)
          %1637 : Tensor = aten::add(%1636, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1598, %1637)
          -> ()
        block1():
          -> ()
      %1638 : bool = prim::GetAttr[name="training"](%1598)
      %1639 : Tensor = prim::GetAttr[name="running_mean"](%1598)
      %1640 : Tensor = prim::GetAttr[name="running_var"](%1598)
      %1641 : Tensor = prim::GetAttr[name="weight"](%1598)
      %1642 : Tensor = prim::GetAttr[name="bias"](%1598)
       = prim::If(%1638) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1643 : int[] = aten::size(%input.191) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.256 : int = aten::__getitem__(%1643, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1645 : int = aten::len(%1643) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1646 : int = aten::sub(%1645, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.257 : int = prim::Loop(%1646, %4, %size_prods.256) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.65 : int, %size_prods.258 : int):
              %1650 : int = aten::add(%i.65, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1651 : int = aten::__getitem__(%1643, %1650) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.259 : int = aten::mul(%size_prods.258, %1651) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.259)
          %1653 : bool = aten::eq(%size_prods.257, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1653) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1654 : str = aten::format(%6, %1643) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1654) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.192 : Tensor = aten::batch_norm(%input.191, %1641, %1642, %1639, %1640, %1638, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.193 : Tensor = aten::relu_(%input.192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1657 : Tensor = prim::GetAttr[name="weight"](%1599)
      %1658 : Tensor? = prim::GetAttr[name="bias"](%1599)
      %input.194 : Tensor = aten::conv2d(%input.193, %1657, %1658, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1663 : bool = prim::GetAttr[name="training"](%1600)
       = prim::If(%1663) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1664 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1600)
          %1665 : Tensor = aten::add(%1664, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1600, %1665)
          -> ()
        block1():
          -> ()
      %1666 : bool = prim::GetAttr[name="training"](%1600)
      %1667 : Tensor = prim::GetAttr[name="running_mean"](%1600)
      %1668 : Tensor = prim::GetAttr[name="running_var"](%1600)
      %1669 : Tensor = prim::GetAttr[name="weight"](%1600)
      %1670 : Tensor = prim::GetAttr[name="bias"](%1600)
       = prim::If(%1666) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1671 : int[] = aten::size(%input.194) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.260 : int = aten::__getitem__(%1671, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1673 : int = aten::len(%1671) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1674 : int = aten::sub(%1673, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.261 : int = prim::Loop(%1674, %4, %size_prods.260) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.66 : int, %size_prods.262 : int):
              %1678 : int = aten::add(%i.66, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1679 : int = aten::__getitem__(%1671, %1678) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.263 : int = aten::mul(%size_prods.262, %1679) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.263)
          %1681 : bool = aten::eq(%size_prods.261, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1681) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1682 : str = aten::format(%6, %1671) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1682) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.195 : Tensor = aten::batch_norm(%input.194, %1669, %1670, %1667, %1668, %1666, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1684 : Tensor = aten::add(%input.195, %input.171, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:57:19
      -> (%1684)
    block1():
      %1685 : __torch__.torch.nn.modules.container.___torch_mangle_38.Sequential = prim::GetAttr[name="layers"](%1225)
      %1686 : __torch__.torch.nn.modules.conv.___torch_mangle_34.Conv2d = prim::GetAttr[name="0"](%1685)
      %1687 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_35.BatchNorm2d = prim::GetAttr[name="1"](%1685)
      %1688 : __torch__.torch.nn.modules.conv.___torch_mangle_36.Conv2d = prim::GetAttr[name="3"](%1685)
      %1689 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_35.BatchNorm2d = prim::GetAttr[name="4"](%1685)
      %1690 : __torch__.torch.nn.modules.conv.___torch_mangle_37.Conv2d = prim::GetAttr[name="6"](%1685)
      %1691 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_31.BatchNorm2d = prim::GetAttr[name="7"](%1685)
      %1692 : Tensor = prim::GetAttr[name="weight"](%1686)
      %1693 : Tensor? = prim::GetAttr[name="bias"](%1686)
      %input.196 : Tensor = aten::conv2d(%input.171, %1692, %1693, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1698 : bool = prim::GetAttr[name="training"](%1687)
       = prim::If(%1698) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1699 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1687)
          %1700 : Tensor = aten::add(%1699, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1687, %1700)
          -> ()
        block1():
          -> ()
      %1701 : bool = prim::GetAttr[name="training"](%1687)
      %1702 : Tensor = prim::GetAttr[name="running_mean"](%1687)
      %1703 : Tensor = prim::GetAttr[name="running_var"](%1687)
      %1704 : Tensor = prim::GetAttr[name="weight"](%1687)
      %1705 : Tensor = prim::GetAttr[name="bias"](%1687)
       = prim::If(%1701) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1706 : int[] = aten::size(%input.196) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.264 : int = aten::__getitem__(%1706, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1708 : int = aten::len(%1706) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1709 : int = aten::sub(%1708, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.265 : int = prim::Loop(%1709, %4, %size_prods.264) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.67 : int, %size_prods.266 : int):
              %1713 : int = aten::add(%i.67, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1714 : int = aten::__getitem__(%1706, %1713) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.267 : int = aten::mul(%size_prods.266, %1714) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.267)
          %1716 : bool = aten::eq(%size_prods.265, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1716) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1717 : str = aten::format(%6, %1706) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1717) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.197 : Tensor = aten::batch_norm(%input.196, %1704, %1705, %1702, %1703, %1701, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.198 : Tensor = aten::relu_(%input.197) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1720 : Tensor = prim::GetAttr[name="weight"](%1688)
      %1721 : Tensor? = prim::GetAttr[name="bias"](%1688)
      %input.199 : Tensor = aten::conv2d(%input.198, %1720, %1721, %3102, %3101, %3102, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1726 : bool = prim::GetAttr[name="training"](%1689)
       = prim::If(%1726) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1727 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1689)
          %1728 : Tensor = aten::add(%1727, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1689, %1728)
          -> ()
        block1():
          -> ()
      %1729 : bool = prim::GetAttr[name="training"](%1689)
      %1730 : Tensor = prim::GetAttr[name="running_mean"](%1689)
      %1731 : Tensor = prim::GetAttr[name="running_var"](%1689)
      %1732 : Tensor = prim::GetAttr[name="weight"](%1689)
      %1733 : Tensor = prim::GetAttr[name="bias"](%1689)
       = prim::If(%1729) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1734 : int[] = aten::size(%input.199) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.268 : int = aten::__getitem__(%1734, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1736 : int = aten::len(%1734) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1737 : int = aten::sub(%1736, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.269 : int = prim::Loop(%1737, %4, %size_prods.268) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.68 : int, %size_prods.270 : int):
              %1741 : int = aten::add(%i.68, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1742 : int = aten::__getitem__(%1734, %1741) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.271 : int = aten::mul(%size_prods.270, %1742) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.271)
          %1744 : bool = aten::eq(%size_prods.269, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1744) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1745 : str = aten::format(%6, %1734) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1745) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.200 : Tensor = aten::batch_norm(%input.199, %1732, %1733, %1730, %1731, %1729, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.201 : Tensor = aten::relu_(%input.200) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1748 : Tensor = prim::GetAttr[name="weight"](%1690)
      %1749 : Tensor? = prim::GetAttr[name="bias"](%1690)
      %input.202 : Tensor = aten::conv2d(%input.201, %1748, %1749, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1754 : bool = prim::GetAttr[name="training"](%1691)
       = prim::If(%1754) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1755 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1691)
          %1756 : Tensor = aten::add(%1755, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1691, %1756)
          -> ()
        block1():
          -> ()
      %1757 : bool = prim::GetAttr[name="training"](%1691)
      %1758 : Tensor = prim::GetAttr[name="running_mean"](%1691)
      %1759 : Tensor = prim::GetAttr[name="running_var"](%1691)
      %1760 : Tensor = prim::GetAttr[name="weight"](%1691)
      %1761 : Tensor = prim::GetAttr[name="bias"](%1691)
       = prim::If(%1757) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1762 : int[] = aten::size(%input.202) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.272 : int = aten::__getitem__(%1762, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1764 : int = aten::len(%1762) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1765 : int = aten::sub(%1764, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.273 : int = prim::Loop(%1765, %4, %size_prods.272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.69 : int, %size_prods.274 : int):
              %1769 : int = aten::add(%i.69, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1770 : int = aten::__getitem__(%1762, %1769) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.275 : int = aten::mul(%size_prods.274, %1770) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.275)
          %1772 : bool = aten::eq(%size_prods.273, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1772) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1773 : str = aten::format(%6, %1762) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1773) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.203 : Tensor = aten::batch_norm(%input.202, %1760, %1761, %1758, %1759, %1757, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.203)
  %1775 : __torch__.torchvision.models.mnasnet.___torch_mangle_45._InvertedResidual = prim::GetAttr[name="0"](%31)
  %1776 : __torch__.torchvision.models.mnasnet.___torch_mangle_51._InvertedResidual = prim::GetAttr[name="1"](%31)
  %1777 : bool = prim::GetAttr[name="apply_residual"](%1775)
  %input.220 : Tensor = prim::If(%1777) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:56:8
    block0():
      %1779 : __torch__.torch.nn.modules.container.___torch_mangle_44.Sequential = prim::GetAttr[name="layers"](%1775)
      %1780 : __torch__.torch.nn.modules.conv.___torch_mangle_34.Conv2d = prim::GetAttr[name="0"](%1779)
      %1781 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_35.BatchNorm2d = prim::GetAttr[name="1"](%1779)
      %1782 : __torch__.torch.nn.modules.conv.___torch_mangle_41.Conv2d = prim::GetAttr[name="3"](%1779)
      %1783 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_35.BatchNorm2d = prim::GetAttr[name="4"](%1779)
      %1784 : __torch__.torch.nn.modules.conv.___torch_mangle_42.Conv2d = prim::GetAttr[name="6"](%1779)
      %1785 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_43.BatchNorm2d = prim::GetAttr[name="7"](%1779)
      %1786 : Tensor = prim::GetAttr[name="weight"](%1780)
      %1787 : Tensor? = prim::GetAttr[name="bias"](%1780)
      %input.237 : Tensor = aten::conv2d(%input.243, %1786, %1787, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1792 : bool = prim::GetAttr[name="training"](%1781)
       = prim::If(%1792) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1793 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1781)
          %1794 : Tensor = aten::add(%1793, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1781, %1794)
          -> ()
        block1():
          -> ()
      %1795 : bool = prim::GetAttr[name="training"](%1781)
      %1796 : Tensor = prim::GetAttr[name="running_mean"](%1781)
      %1797 : Tensor = prim::GetAttr[name="running_var"](%1781)
      %1798 : Tensor = prim::GetAttr[name="weight"](%1781)
      %1799 : Tensor = prim::GetAttr[name="bias"](%1781)
       = prim::If(%1795) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1800 : int[] = aten::size(%input.237) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.276 : int = aten::__getitem__(%1800, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1802 : int = aten::len(%1800) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1803 : int = aten::sub(%1802, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.277 : int = prim::Loop(%1803, %4, %size_prods.276) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.70 : int, %size_prods.278 : int):
              %1807 : int = aten::add(%i.70, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1808 : int = aten::__getitem__(%1800, %1807) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.279 : int = aten::mul(%size_prods.278, %1808) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.279)
          %1810 : bool = aten::eq(%size_prods.277, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1810) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1811 : str = aten::format(%6, %1800) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1811) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.254 : Tensor = aten::batch_norm(%input.237, %1798, %1799, %1796, %1797, %1795, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.204 : Tensor = aten::relu_(%input.254) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1814 : Tensor = prim::GetAttr[name="weight"](%1782)
      %1815 : Tensor? = prim::GetAttr[name="bias"](%1782)
      %input.205 : Tensor = aten::conv2d(%input.204, %1814, %1815, %3102, %3102, %3102, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1820 : bool = prim::GetAttr[name="training"](%1783)
       = prim::If(%1820) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1821 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1783)
          %1822 : Tensor = aten::add(%1821, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1783, %1822)
          -> ()
        block1():
          -> ()
      %1823 : bool = prim::GetAttr[name="training"](%1783)
      %1824 : Tensor = prim::GetAttr[name="running_mean"](%1783)
      %1825 : Tensor = prim::GetAttr[name="running_var"](%1783)
      %1826 : Tensor = prim::GetAttr[name="weight"](%1783)
      %1827 : Tensor = prim::GetAttr[name="bias"](%1783)
       = prim::If(%1823) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1828 : int[] = aten::size(%input.205) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.280 : int = aten::__getitem__(%1828, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1830 : int = aten::len(%1828) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1831 : int = aten::sub(%1830, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.281 : int = prim::Loop(%1831, %4, %size_prods.280) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.71 : int, %size_prods.282 : int):
              %1835 : int = aten::add(%i.71, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1836 : int = aten::__getitem__(%1828, %1835) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.283 : int = aten::mul(%size_prods.282, %1836) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.283)
          %1838 : bool = aten::eq(%size_prods.281, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1838) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1839 : str = aten::format(%6, %1828) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1839) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.206 : Tensor = aten::batch_norm(%input.205, %1826, %1827, %1824, %1825, %1823, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.207 : Tensor = aten::relu_(%input.206) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1842 : Tensor = prim::GetAttr[name="weight"](%1784)
      %1843 : Tensor? = prim::GetAttr[name="bias"](%1784)
      %input.208 : Tensor = aten::conv2d(%input.207, %1842, %1843, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1848 : bool = prim::GetAttr[name="training"](%1785)
       = prim::If(%1848) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1849 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1785)
          %1850 : Tensor = aten::add(%1849, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1785, %1850)
          -> ()
        block1():
          -> ()
      %1851 : bool = prim::GetAttr[name="training"](%1785)
      %1852 : Tensor = prim::GetAttr[name="running_mean"](%1785)
      %1853 : Tensor = prim::GetAttr[name="running_var"](%1785)
      %1854 : Tensor = prim::GetAttr[name="weight"](%1785)
      %1855 : Tensor = prim::GetAttr[name="bias"](%1785)
       = prim::If(%1851) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1856 : int[] = aten::size(%input.208) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.284 : int = aten::__getitem__(%1856, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1858 : int = aten::len(%1856) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1859 : int = aten::sub(%1858, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.285 : int = prim::Loop(%1859, %4, %size_prods.284) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.72 : int, %size_prods.286 : int):
              %1863 : int = aten::add(%i.72, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1864 : int = aten::__getitem__(%1856, %1863) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.287 : int = aten::mul(%size_prods.286, %1864) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.287)
          %1866 : bool = aten::eq(%size_prods.285, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1866) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1867 : str = aten::format(%6, %1856) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1867) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.209 : Tensor = aten::batch_norm(%input.208, %1854, %1855, %1852, %1853, %1851, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1869 : Tensor = aten::add(%input.209, %input.243, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:57:19
      -> (%1869)
    block1():
      %1870 : __torch__.torch.nn.modules.container.___torch_mangle_44.Sequential = prim::GetAttr[name="layers"](%1775)
      %1871 : __torch__.torch.nn.modules.conv.___torch_mangle_34.Conv2d = prim::GetAttr[name="0"](%1870)
      %1872 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_35.BatchNorm2d = prim::GetAttr[name="1"](%1870)
      %1873 : __torch__.torch.nn.modules.conv.___torch_mangle_41.Conv2d = prim::GetAttr[name="3"](%1870)
      %1874 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_35.BatchNorm2d = prim::GetAttr[name="4"](%1870)
      %1875 : __torch__.torch.nn.modules.conv.___torch_mangle_42.Conv2d = prim::GetAttr[name="6"](%1870)
      %1876 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_43.BatchNorm2d = prim::GetAttr[name="7"](%1870)
      %1877 : Tensor = prim::GetAttr[name="weight"](%1871)
      %1878 : Tensor? = prim::GetAttr[name="bias"](%1871)
      %input.210 : Tensor = aten::conv2d(%input.243, %1877, %1878, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1883 : bool = prim::GetAttr[name="training"](%1872)
       = prim::If(%1883) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1884 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1872)
          %1885 : Tensor = aten::add(%1884, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1872, %1885)
          -> ()
        block1():
          -> ()
      %1886 : bool = prim::GetAttr[name="training"](%1872)
      %1887 : Tensor = prim::GetAttr[name="running_mean"](%1872)
      %1888 : Tensor = prim::GetAttr[name="running_var"](%1872)
      %1889 : Tensor = prim::GetAttr[name="weight"](%1872)
      %1890 : Tensor = prim::GetAttr[name="bias"](%1872)
       = prim::If(%1886) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1891 : int[] = aten::size(%input.210) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.288 : int = aten::__getitem__(%1891, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1893 : int = aten::len(%1891) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1894 : int = aten::sub(%1893, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.289 : int = prim::Loop(%1894, %4, %size_prods.288) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.73 : int, %size_prods.290 : int):
              %1898 : int = aten::add(%i.73, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1899 : int = aten::__getitem__(%1891, %1898) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.291 : int = aten::mul(%size_prods.290, %1899) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.291)
          %1901 : bool = aten::eq(%size_prods.289, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1901) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1902 : str = aten::format(%6, %1891) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1902) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.211 : Tensor = aten::batch_norm(%input.210, %1889, %1890, %1887, %1888, %1886, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.212 : Tensor = aten::relu_(%input.211) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1905 : Tensor = prim::GetAttr[name="weight"](%1873)
      %1906 : Tensor? = prim::GetAttr[name="bias"](%1873)
      %input.213 : Tensor = aten::conv2d(%input.212, %1905, %1906, %3102, %3102, %3102, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1911 : bool = prim::GetAttr[name="training"](%1874)
       = prim::If(%1911) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1912 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1874)
          %1913 : Tensor = aten::add(%1912, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1874, %1913)
          -> ()
        block1():
          -> ()
      %1914 : bool = prim::GetAttr[name="training"](%1874)
      %1915 : Tensor = prim::GetAttr[name="running_mean"](%1874)
      %1916 : Tensor = prim::GetAttr[name="running_var"](%1874)
      %1917 : Tensor = prim::GetAttr[name="weight"](%1874)
      %1918 : Tensor = prim::GetAttr[name="bias"](%1874)
       = prim::If(%1914) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1919 : int[] = aten::size(%input.213) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.292 : int = aten::__getitem__(%1919, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1921 : int = aten::len(%1919) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1922 : int = aten::sub(%1921, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.293 : int = prim::Loop(%1922, %4, %size_prods.292) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.74 : int, %size_prods.294 : int):
              %1926 : int = aten::add(%i.74, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1927 : int = aten::__getitem__(%1919, %1926) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.295 : int = aten::mul(%size_prods.294, %1927) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.295)
          %1929 : bool = aten::eq(%size_prods.293, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1929) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1930 : str = aten::format(%6, %1919) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1930) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.214 : Tensor = aten::batch_norm(%input.213, %1917, %1918, %1915, %1916, %1914, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.215 : Tensor = aten::relu_(%input.214) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1933 : Tensor = prim::GetAttr[name="weight"](%1875)
      %1934 : Tensor? = prim::GetAttr[name="bias"](%1875)
      %input.216 : Tensor = aten::conv2d(%input.215, %1933, %1934, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1939 : bool = prim::GetAttr[name="training"](%1876)
       = prim::If(%1939) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1940 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1876)
          %1941 : Tensor = aten::add(%1940, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1876, %1941)
          -> ()
        block1():
          -> ()
      %1942 : bool = prim::GetAttr[name="training"](%1876)
      %1943 : Tensor = prim::GetAttr[name="running_mean"](%1876)
      %1944 : Tensor = prim::GetAttr[name="running_var"](%1876)
      %1945 : Tensor = prim::GetAttr[name="weight"](%1876)
      %1946 : Tensor = prim::GetAttr[name="bias"](%1876)
       = prim::If(%1942) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1947 : int[] = aten::size(%input.216) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.296 : int = aten::__getitem__(%1947, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1949 : int = aten::len(%1947) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1950 : int = aten::sub(%1949, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.297 : int = prim::Loop(%1950, %4, %size_prods.296) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.75 : int, %size_prods.298 : int):
              %1954 : int = aten::add(%i.75, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1955 : int = aten::__getitem__(%1947, %1954) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.299 : int = aten::mul(%size_prods.298, %1955) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.299)
          %1957 : bool = aten::eq(%size_prods.297, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1957) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1958 : str = aten::format(%6, %1947) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1958) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.217 : Tensor = aten::batch_norm(%input.216, %1945, %1946, %1943, %1944, %1942, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.217)
  %1960 : bool = prim::GetAttr[name="apply_residual"](%1776)
  %input.240 : Tensor = prim::If(%1960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:56:8
    block0():
      %1962 : __torch__.torch.nn.modules.container.___torch_mangle_50.Sequential = prim::GetAttr[name="layers"](%1776)
      %1963 : __torch__.torch.nn.modules.conv.___torch_mangle_46.Conv2d = prim::GetAttr[name="0"](%1962)
      %1964 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_47.BatchNorm2d = prim::GetAttr[name="1"](%1962)
      %1965 : __torch__.torch.nn.modules.conv.___torch_mangle_48.Conv2d = prim::GetAttr[name="3"](%1962)
      %1966 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_47.BatchNorm2d = prim::GetAttr[name="4"](%1962)
      %1967 : __torch__.torch.nn.modules.conv.___torch_mangle_49.Conv2d = prim::GetAttr[name="6"](%1962)
      %1968 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_43.BatchNorm2d = prim::GetAttr[name="7"](%1962)
      %1969 : Tensor = prim::GetAttr[name="weight"](%1963)
      %1970 : Tensor? = prim::GetAttr[name="bias"](%1963)
      %input.255 : Tensor = aten::conv2d(%input.220, %1969, %1970, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1975 : bool = prim::GetAttr[name="training"](%1964)
       = prim::If(%1975) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1976 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1964)
          %1977 : Tensor = aten::add(%1976, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1964, %1977)
          -> ()
        block1():
          -> ()
      %1978 : bool = prim::GetAttr[name="training"](%1964)
      %1979 : Tensor = prim::GetAttr[name="running_mean"](%1964)
      %1980 : Tensor = prim::GetAttr[name="running_var"](%1964)
      %1981 : Tensor = prim::GetAttr[name="weight"](%1964)
      %1982 : Tensor = prim::GetAttr[name="bias"](%1964)
       = prim::If(%1978) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1983 : int[] = aten::size(%input.255) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.348 : int = aten::__getitem__(%1983, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1985 : int = aten::len(%1983) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1986 : int = aten::sub(%1985, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.349 : int = prim::Loop(%1986, %4, %size_prods.348) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.88 : int, %size_prods.350 : int):
              %1990 : int = aten::add(%i.88, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1991 : int = aten::__getitem__(%1983, %1990) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.351 : int = aten::mul(%size_prods.350, %1991) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.351)
          %1993 : bool = aten::eq(%size_prods.349, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1993) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1994 : str = aten::format(%6, %1983) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1994) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.256 : Tensor = aten::batch_norm(%input.255, %1981, %1982, %1979, %1980, %1978, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.257 : Tensor = aten::relu_(%input.256) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1997 : Tensor = prim::GetAttr[name="weight"](%1965)
      %1998 : Tensor? = prim::GetAttr[name="bias"](%1965)
      %input.258 : Tensor = aten::conv2d(%input.257, %1997, %1998, %3102, %3102, %3102, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2003 : bool = prim::GetAttr[name="training"](%1966)
       = prim::If(%2003) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2004 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1966)
          %2005 : Tensor = aten::add(%2004, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1966, %2005)
          -> ()
        block1():
          -> ()
      %2006 : bool = prim::GetAttr[name="training"](%1966)
      %2007 : Tensor = prim::GetAttr[name="running_mean"](%1966)
      %2008 : Tensor = prim::GetAttr[name="running_var"](%1966)
      %2009 : Tensor = prim::GetAttr[name="weight"](%1966)
      %2010 : Tensor = prim::GetAttr[name="bias"](%1966)
       = prim::If(%2006) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2011 : int[] = aten::size(%input.258) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.352 : int = aten::__getitem__(%2011, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2013 : int = aten::len(%2011) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2014 : int = aten::sub(%2013, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.353 : int = prim::Loop(%2014, %4, %size_prods.352) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.89 : int, %size_prods.354 : int):
              %2018 : int = aten::add(%i.89, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2019 : int = aten::__getitem__(%2011, %2018) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.355 : int = aten::mul(%size_prods.354, %2019) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.355)
          %2021 : bool = aten::eq(%size_prods.353, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2021) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2022 : str = aten::format(%6, %2011) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2022) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.259 : Tensor = aten::batch_norm(%input.258, %2009, %2010, %2007, %2008, %2006, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.260 : Tensor = aten::relu_(%input.259) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2025 : Tensor = prim::GetAttr[name="weight"](%1967)
      %2026 : Tensor? = prim::GetAttr[name="bias"](%1967)
      %input.261 : Tensor = aten::conv2d(%input.260, %2025, %2026, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2031 : bool = prim::GetAttr[name="training"](%1968)
       = prim::If(%2031) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2032 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1968)
          %2033 : Tensor = aten::add(%2032, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1968, %2033)
          -> ()
        block1():
          -> ()
      %2034 : bool = prim::GetAttr[name="training"](%1968)
      %2035 : Tensor = prim::GetAttr[name="running_mean"](%1968)
      %2036 : Tensor = prim::GetAttr[name="running_var"](%1968)
      %2037 : Tensor = prim::GetAttr[name="weight"](%1968)
      %2038 : Tensor = prim::GetAttr[name="bias"](%1968)
       = prim::If(%2034) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2039 : int[] = aten::size(%input.261) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.356 : int = aten::__getitem__(%2039, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2041 : int = aten::len(%2039) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2042 : int = aten::sub(%2041, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.357 : int = prim::Loop(%2042, %4, %size_prods.356) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.90 : int, %size_prods.358 : int):
              %2046 : int = aten::add(%i.90, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2047 : int = aten::__getitem__(%2039, %2046) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.359 : int = aten::mul(%size_prods.358, %2047) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.359)
          %2049 : bool = aten::eq(%size_prods.357, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2049) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2050 : str = aten::format(%6, %2039) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2050) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.262 : Tensor = aten::batch_norm(%input.261, %2037, %2038, %2035, %2036, %2034, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2052 : Tensor = aten::add(%input.262, %input.220, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:57:19
      -> (%2052)
    block1():
      %2053 : __torch__.torch.nn.modules.container.___torch_mangle_50.Sequential = prim::GetAttr[name="layers"](%1776)
      %2054 : __torch__.torch.nn.modules.conv.___torch_mangle_46.Conv2d = prim::GetAttr[name="0"](%2053)
      %2055 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_47.BatchNorm2d = prim::GetAttr[name="1"](%2053)
      %2056 : __torch__.torch.nn.modules.conv.___torch_mangle_48.Conv2d = prim::GetAttr[name="3"](%2053)
      %2057 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_47.BatchNorm2d = prim::GetAttr[name="4"](%2053)
      %2058 : __torch__.torch.nn.modules.conv.___torch_mangle_49.Conv2d = prim::GetAttr[name="6"](%2053)
      %2059 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_43.BatchNorm2d = prim::GetAttr[name="7"](%2053)
      %2060 : Tensor = prim::GetAttr[name="weight"](%2054)
      %2061 : Tensor? = prim::GetAttr[name="bias"](%2054)
      %input.263 : Tensor = aten::conv2d(%input.220, %2060, %2061, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2066 : bool = prim::GetAttr[name="training"](%2055)
       = prim::If(%2066) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2067 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2055)
          %2068 : Tensor = aten::add(%2067, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2055, %2068)
          -> ()
        block1():
          -> ()
      %2069 : bool = prim::GetAttr[name="training"](%2055)
      %2070 : Tensor = prim::GetAttr[name="running_mean"](%2055)
      %2071 : Tensor = prim::GetAttr[name="running_var"](%2055)
      %2072 : Tensor = prim::GetAttr[name="weight"](%2055)
      %2073 : Tensor = prim::GetAttr[name="bias"](%2055)
       = prim::If(%2069) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2074 : int[] = aten::size(%input.263) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.360 : int = aten::__getitem__(%2074, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2076 : int = aten::len(%2074) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2077 : int = aten::sub(%2076, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.361 : int = prim::Loop(%2077, %4, %size_prods.360) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.91 : int, %size_prods.362 : int):
              %2081 : int = aten::add(%i.91, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2082 : int = aten::__getitem__(%2074, %2081) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.363 : int = aten::mul(%size_prods.362, %2082) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.363)
          %2084 : bool = aten::eq(%size_prods.361, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2084) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2085 : str = aten::format(%6, %2074) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2085) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.264 : Tensor = aten::batch_norm(%input.263, %2072, %2073, %2070, %2071, %2069, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.265 : Tensor = aten::relu_(%input.264) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2088 : Tensor = prim::GetAttr[name="weight"](%2056)
      %2089 : Tensor? = prim::GetAttr[name="bias"](%2056)
      %input.266 : Tensor = aten::conv2d(%input.265, %2088, %2089, %3102, %3102, %3102, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2094 : bool = prim::GetAttr[name="training"](%2057)
       = prim::If(%2094) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2095 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2057)
          %2096 : Tensor = aten::add(%2095, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2057, %2096)
          -> ()
        block1():
          -> ()
      %2097 : bool = prim::GetAttr[name="training"](%2057)
      %2098 : Tensor = prim::GetAttr[name="running_mean"](%2057)
      %2099 : Tensor = prim::GetAttr[name="running_var"](%2057)
      %2100 : Tensor = prim::GetAttr[name="weight"](%2057)
      %2101 : Tensor = prim::GetAttr[name="bias"](%2057)
       = prim::If(%2097) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2102 : int[] = aten::size(%input.266) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.364 : int = aten::__getitem__(%2102, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2104 : int = aten::len(%2102) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2105 : int = aten::sub(%2104, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.365 : int = prim::Loop(%2105, %4, %size_prods.364) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.92 : int, %size_prods.366 : int):
              %2109 : int = aten::add(%i.92, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2110 : int = aten::__getitem__(%2102, %2109) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.367 : int = aten::mul(%size_prods.366, %2110) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.367)
          %2112 : bool = aten::eq(%size_prods.365, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2112) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2113 : str = aten::format(%6, %2102) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2113) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.267 : Tensor = aten::batch_norm(%input.266, %2100, %2101, %2098, %2099, %2097, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.268 : Tensor = aten::relu_(%input.267) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2116 : Tensor = prim::GetAttr[name="weight"](%2058)
      %2117 : Tensor? = prim::GetAttr[name="bias"](%2058)
      %input.269 : Tensor = aten::conv2d(%input.268, %2116, %2117, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2122 : bool = prim::GetAttr[name="training"](%2059)
       = prim::If(%2122) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2123 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2059)
          %2124 : Tensor = aten::add(%2123, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2059, %2124)
          -> ()
        block1():
          -> ()
      %2125 : bool = prim::GetAttr[name="training"](%2059)
      %2126 : Tensor = prim::GetAttr[name="running_mean"](%2059)
      %2127 : Tensor = prim::GetAttr[name="running_var"](%2059)
      %2128 : Tensor = prim::GetAttr[name="weight"](%2059)
      %2129 : Tensor = prim::GetAttr[name="bias"](%2059)
       = prim::If(%2125) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2130 : int[] = aten::size(%input.269) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.368 : int = aten::__getitem__(%2130, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2132 : int = aten::len(%2130) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2133 : int = aten::sub(%2132, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.369 : int = prim::Loop(%2133, %4, %size_prods.368) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.93 : int, %size_prods.370 : int):
              %2137 : int = aten::add(%i.93, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2138 : int = aten::__getitem__(%2130, %2137) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.371 : int = aten::mul(%size_prods.370, %2138) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.371)
          %2140 : bool = aten::eq(%size_prods.369, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2141 : str = aten::format(%6, %2130) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2141) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.270 : Tensor = aten::batch_norm(%input.269, %2128, %2129, %2126, %2127, %2125, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.270)
  %2143 : __torch__.torchvision.models.mnasnet.___torch_mangle_57._InvertedResidual = prim::GetAttr[name="0"](%32)
  %2144 : __torch__.torchvision.models.mnasnet.___torch_mangle_63._InvertedResidual = prim::GetAttr[name="1"](%32)
  %2145 : __torch__.torchvision.models.mnasnet.___torch_mangle_63._InvertedResidual = prim::GetAttr[name="2"](%32)
  %2146 : __torch__.torchvision.models.mnasnet.___torch_mangle_63._InvertedResidual = prim::GetAttr[name="3"](%32)
  %2147 : bool = prim::GetAttr[name="apply_residual"](%2143)
  %input.22 : Tensor = prim::If(%2147) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:56:8
    block0():
      %2149 : __torch__.torch.nn.modules.container.___torch_mangle_56.Sequential = prim::GetAttr[name="layers"](%2143)
      %2150 : __torch__.torch.nn.modules.conv.___torch_mangle_46.Conv2d = prim::GetAttr[name="0"](%2149)
      %2151 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_47.BatchNorm2d = prim::GetAttr[name="1"](%2149)
      %2152 : __torch__.torch.nn.modules.conv.___torch_mangle_53.Conv2d = prim::GetAttr[name="3"](%2149)
      %2153 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_47.BatchNorm2d = prim::GetAttr[name="4"](%2149)
      %2154 : __torch__.torch.nn.modules.conv.___torch_mangle_54.Conv2d = prim::GetAttr[name="6"](%2149)
      %2155 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_55.BatchNorm2d = prim::GetAttr[name="7"](%2149)
      %2156 : Tensor = prim::GetAttr[name="weight"](%2150)
      %2157 : Tensor? = prim::GetAttr[name="bias"](%2150)
      %input.23 : Tensor = aten::conv2d(%input.240, %2156, %2157, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2162 : bool = prim::GetAttr[name="training"](%2151)
       = prim::If(%2162) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2163 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2151)
          %2164 : Tensor = aten::add(%2163, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2151, %2164)
          -> ()
        block1():
          -> ()
      %2165 : bool = prim::GetAttr[name="training"](%2151)
      %2166 : Tensor = prim::GetAttr[name="running_mean"](%2151)
      %2167 : Tensor = prim::GetAttr[name="running_var"](%2151)
      %2168 : Tensor = prim::GetAttr[name="weight"](%2151)
      %2169 : Tensor = prim::GetAttr[name="bias"](%2151)
       = prim::If(%2165) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2170 : int[] = aten::size(%input.23) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.24 : int = aten::__getitem__(%2170, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2172 : int = aten::len(%2170) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2173 : int = aten::sub(%2172, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.25 : int = prim::Loop(%2173, %4, %size_prods.24) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.7 : int, %size_prods.26 : int):
              %2177 : int = aten::add(%i.7, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2178 : int = aten::__getitem__(%2170, %2177) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.27 : int = aten::mul(%size_prods.26, %2178) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.27)
          %2180 : bool = aten::eq(%size_prods.25, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2180) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2181 : str = aten::format(%6, %2170) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2181) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.24 : Tensor = aten::batch_norm(%input.23, %2168, %2169, %2166, %2167, %2165, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.25 : Tensor = aten::relu_(%input.24) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2184 : Tensor = prim::GetAttr[name="weight"](%2152)
      %2185 : Tensor? = prim::GetAttr[name="bias"](%2152)
      %input.26 : Tensor = aten::conv2d(%input.25, %2184, %2185, %3101, %3101, %3102, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2190 : bool = prim::GetAttr[name="training"](%2153)
       = prim::If(%2190) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2191 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2153)
          %2192 : Tensor = aten::add(%2191, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2153, %2192)
          -> ()
        block1():
          -> ()
      %2193 : bool = prim::GetAttr[name="training"](%2153)
      %2194 : Tensor = prim::GetAttr[name="running_mean"](%2153)
      %2195 : Tensor = prim::GetAttr[name="running_var"](%2153)
      %2196 : Tensor = prim::GetAttr[name="weight"](%2153)
      %2197 : Tensor = prim::GetAttr[name="bias"](%2153)
       = prim::If(%2193) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2198 : int[] = aten::size(%input.26) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.28 : int = aten::__getitem__(%2198, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2200 : int = aten::len(%2198) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2201 : int = aten::sub(%2200, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.29 : int = prim::Loop(%2201, %4, %size_prods.28) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.8 : int, %size_prods.30 : int):
              %2205 : int = aten::add(%i.8, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2206 : int = aten::__getitem__(%2198, %2205) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.31 : int = aten::mul(%size_prods.30, %2206) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.31)
          %2208 : bool = aten::eq(%size_prods.29, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2208) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2209 : str = aten::format(%6, %2198) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2209) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.27 : Tensor = aten::batch_norm(%input.26, %2196, %2197, %2194, %2195, %2193, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.28 : Tensor = aten::relu_(%input.27) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2212 : Tensor = prim::GetAttr[name="weight"](%2154)
      %2213 : Tensor? = prim::GetAttr[name="bias"](%2154)
      %input.29 : Tensor = aten::conv2d(%input.28, %2212, %2213, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2218 : bool = prim::GetAttr[name="training"](%2155)
       = prim::If(%2218) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2219 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2155)
          %2220 : Tensor = aten::add(%2219, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2155, %2220)
          -> ()
        block1():
          -> ()
      %2221 : bool = prim::GetAttr[name="training"](%2155)
      %2222 : Tensor = prim::GetAttr[name="running_mean"](%2155)
      %2223 : Tensor = prim::GetAttr[name="running_var"](%2155)
      %2224 : Tensor = prim::GetAttr[name="weight"](%2155)
      %2225 : Tensor = prim::GetAttr[name="bias"](%2155)
       = prim::If(%2221) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2226 : int[] = aten::size(%input.29) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.32 : int = aten::__getitem__(%2226, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2228 : int = aten::len(%2226) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2229 : int = aten::sub(%2228, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.33 : int = prim::Loop(%2229, %4, %size_prods.32) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.9 : int, %size_prods.34 : int):
              %2233 : int = aten::add(%i.9, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2234 : int = aten::__getitem__(%2226, %2233) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.35 : int = aten::mul(%size_prods.34, %2234) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.35)
          %2236 : bool = aten::eq(%size_prods.33, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2236) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2237 : str = aten::format(%6, %2226) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2237) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.30 : Tensor = aten::batch_norm(%input.29, %2224, %2225, %2222, %2223, %2221, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2239 : Tensor = aten::add(%input.30, %input.240, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:57:19
      -> (%2239)
    block1():
      %2240 : __torch__.torch.nn.modules.container.___torch_mangle_56.Sequential = prim::GetAttr[name="layers"](%2143)
      %2241 : __torch__.torch.nn.modules.conv.___torch_mangle_46.Conv2d = prim::GetAttr[name="0"](%2240)
      %2242 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_47.BatchNorm2d = prim::GetAttr[name="1"](%2240)
      %2243 : __torch__.torch.nn.modules.conv.___torch_mangle_53.Conv2d = prim::GetAttr[name="3"](%2240)
      %2244 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_47.BatchNorm2d = prim::GetAttr[name="4"](%2240)
      %2245 : __torch__.torch.nn.modules.conv.___torch_mangle_54.Conv2d = prim::GetAttr[name="6"](%2240)
      %2246 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_55.BatchNorm2d = prim::GetAttr[name="7"](%2240)
      %2247 : Tensor = prim::GetAttr[name="weight"](%2241)
      %2248 : Tensor? = prim::GetAttr[name="bias"](%2241)
      %input.31 : Tensor = aten::conv2d(%input.240, %2247, %2248, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2253 : bool = prim::GetAttr[name="training"](%2242)
       = prim::If(%2253) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2254 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2242)
          %2255 : Tensor = aten::add(%2254, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2242, %2255)
          -> ()
        block1():
          -> ()
      %2256 : bool = prim::GetAttr[name="training"](%2242)
      %2257 : Tensor = prim::GetAttr[name="running_mean"](%2242)
      %2258 : Tensor = prim::GetAttr[name="running_var"](%2242)
      %2259 : Tensor = prim::GetAttr[name="weight"](%2242)
      %2260 : Tensor = prim::GetAttr[name="bias"](%2242)
       = prim::If(%2256) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2261 : int[] = aten::size(%input.31) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.36 : int = aten::__getitem__(%2261, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2263 : int = aten::len(%2261) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2264 : int = aten::sub(%2263, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.37 : int = prim::Loop(%2264, %4, %size_prods.36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.10 : int, %size_prods.38 : int):
              %2268 : int = aten::add(%i.10, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2269 : int = aten::__getitem__(%2261, %2268) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.39 : int = aten::mul(%size_prods.38, %2269) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.39)
          %2271 : bool = aten::eq(%size_prods.37, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2271) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2272 : str = aten::format(%6, %2261) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.32 : Tensor = aten::batch_norm(%input.31, %2259, %2260, %2257, %2258, %2256, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.33 : Tensor = aten::relu_(%input.32) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2275 : Tensor = prim::GetAttr[name="weight"](%2243)
      %2276 : Tensor? = prim::GetAttr[name="bias"](%2243)
      %input.34 : Tensor = aten::conv2d(%input.33, %2275, %2276, %3101, %3101, %3102, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2281 : bool = prim::GetAttr[name="training"](%2244)
       = prim::If(%2281) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2282 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2244)
          %2283 : Tensor = aten::add(%2282, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2244, %2283)
          -> ()
        block1():
          -> ()
      %2284 : bool = prim::GetAttr[name="training"](%2244)
      %2285 : Tensor = prim::GetAttr[name="running_mean"](%2244)
      %2286 : Tensor = prim::GetAttr[name="running_var"](%2244)
      %2287 : Tensor = prim::GetAttr[name="weight"](%2244)
      %2288 : Tensor = prim::GetAttr[name="bias"](%2244)
       = prim::If(%2284) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2289 : int[] = aten::size(%input.34) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.40 : int = aten::__getitem__(%2289, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2291 : int = aten::len(%2289) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2292 : int = aten::sub(%2291, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.41 : int = prim::Loop(%2292, %4, %size_prods.40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.11 : int, %size_prods.42 : int):
              %2296 : int = aten::add(%i.11, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2297 : int = aten::__getitem__(%2289, %2296) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.43 : int = aten::mul(%size_prods.42, %2297) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.43)
          %2299 : bool = aten::eq(%size_prods.41, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2299) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2300 : str = aten::format(%6, %2289) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2300) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.35 : Tensor = aten::batch_norm(%input.34, %2287, %2288, %2285, %2286, %2284, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.36 : Tensor = aten::relu_(%input.35) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2303 : Tensor = prim::GetAttr[name="weight"](%2245)
      %2304 : Tensor? = prim::GetAttr[name="bias"](%2245)
      %input.37 : Tensor = aten::conv2d(%input.36, %2303, %2304, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2309 : bool = prim::GetAttr[name="training"](%2246)
       = prim::If(%2309) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2310 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2246)
          %2311 : Tensor = aten::add(%2310, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2246, %2311)
          -> ()
        block1():
          -> ()
      %2312 : bool = prim::GetAttr[name="training"](%2246)
      %2313 : Tensor = prim::GetAttr[name="running_mean"](%2246)
      %2314 : Tensor = prim::GetAttr[name="running_var"](%2246)
      %2315 : Tensor = prim::GetAttr[name="weight"](%2246)
      %2316 : Tensor = prim::GetAttr[name="bias"](%2246)
       = prim::If(%2312) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2317 : int[] = aten::size(%input.37) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.44 : int = aten::__getitem__(%2317, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2319 : int = aten::len(%2317) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2320 : int = aten::sub(%2319, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.45 : int = prim::Loop(%2320, %4, %size_prods.44) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.12 : int, %size_prods.46 : int):
              %2324 : int = aten::add(%i.12, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2325 : int = aten::__getitem__(%2317, %2324) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.47 : int = aten::mul(%size_prods.46, %2325) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.47)
          %2327 : bool = aten::eq(%size_prods.45, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2327) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2328 : str = aten::format(%6, %2317) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2328) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.38 : Tensor = aten::batch_norm(%input.37, %2315, %2316, %2313, %2314, %2312, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.38)
  %2330 : bool = prim::GetAttr[name="apply_residual"](%2144)
  %input.20 : Tensor = prim::If(%2330) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:56:8
    block0():
      %2332 : __torch__.torch.nn.modules.container.___torch_mangle_62.Sequential = prim::GetAttr[name="layers"](%2144)
      %2333 : __torch__.torch.nn.modules.conv.___torch_mangle_58.Conv2d = prim::GetAttr[name="0"](%2332)
      %2334 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="1"](%2332)
      %2335 : __torch__.torch.nn.modules.conv.___torch_mangle_60.Conv2d = prim::GetAttr[name="3"](%2332)
      %2336 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="4"](%2332)
      %2337 : __torch__.torch.nn.modules.conv.___torch_mangle_61.Conv2d = prim::GetAttr[name="6"](%2332)
      %2338 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_55.BatchNorm2d = prim::GetAttr[name="7"](%2332)
      %2339 : Tensor = prim::GetAttr[name="weight"](%2333)
      %2340 : Tensor? = prim::GetAttr[name="bias"](%2333)
      %input.39 : Tensor = aten::conv2d(%input.22, %2339, %2340, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2345 : bool = prim::GetAttr[name="training"](%2334)
       = prim::If(%2345) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2346 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2334)
          %2347 : Tensor = aten::add(%2346, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2334, %2347)
          -> ()
        block1():
          -> ()
      %2348 : bool = prim::GetAttr[name="training"](%2334)
      %2349 : Tensor = prim::GetAttr[name="running_mean"](%2334)
      %2350 : Tensor = prim::GetAttr[name="running_var"](%2334)
      %2351 : Tensor = prim::GetAttr[name="weight"](%2334)
      %2352 : Tensor = prim::GetAttr[name="bias"](%2334)
       = prim::If(%2348) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2353 : int[] = aten::size(%input.39) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.48 : int = aten::__getitem__(%2353, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2355 : int = aten::len(%2353) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2356 : int = aten::sub(%2355, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.49 : int = prim::Loop(%2356, %4, %size_prods.48) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.13 : int, %size_prods.50 : int):
              %2360 : int = aten::add(%i.13, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2361 : int = aten::__getitem__(%2353, %2360) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.51 : int = aten::mul(%size_prods.50, %2361) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.51)
          %2363 : bool = aten::eq(%size_prods.49, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2363) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2364 : str = aten::format(%6, %2353) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2364) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.40 : Tensor = aten::batch_norm(%input.39, %2351, %2352, %2349, %2350, %2348, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.41 : Tensor = aten::relu_(%input.40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2367 : Tensor = prim::GetAttr[name="weight"](%2335)
      %2368 : Tensor? = prim::GetAttr[name="bias"](%2335)
      %input.42 : Tensor = aten::conv2d(%input.41, %2367, %2368, %3102, %3101, %3102, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2373 : bool = prim::GetAttr[name="training"](%2336)
       = prim::If(%2373) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2374 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2336)
          %2375 : Tensor = aten::add(%2374, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2336, %2375)
          -> ()
        block1():
          -> ()
      %2376 : bool = prim::GetAttr[name="training"](%2336)
      %2377 : Tensor = prim::GetAttr[name="running_mean"](%2336)
      %2378 : Tensor = prim::GetAttr[name="running_var"](%2336)
      %2379 : Tensor = prim::GetAttr[name="weight"](%2336)
      %2380 : Tensor = prim::GetAttr[name="bias"](%2336)
       = prim::If(%2376) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2381 : int[] = aten::size(%input.42) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.52 : int = aten::__getitem__(%2381, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2383 : int = aten::len(%2381) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2384 : int = aten::sub(%2383, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.53 : int = prim::Loop(%2384, %4, %size_prods.52) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.14 : int, %size_prods.54 : int):
              %2388 : int = aten::add(%i.14, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2389 : int = aten::__getitem__(%2381, %2388) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.55 : int = aten::mul(%size_prods.54, %2389) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.55)
          %2391 : bool = aten::eq(%size_prods.53, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2391) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2392 : str = aten::format(%6, %2381) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2392) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.43 : Tensor = aten::batch_norm(%input.42, %2379, %2380, %2377, %2378, %2376, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.44 : Tensor = aten::relu_(%input.43) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2395 : Tensor = prim::GetAttr[name="weight"](%2337)
      %2396 : Tensor? = prim::GetAttr[name="bias"](%2337)
      %input.45 : Tensor = aten::conv2d(%input.44, %2395, %2396, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2401 : bool = prim::GetAttr[name="training"](%2338)
       = prim::If(%2401) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2402 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2338)
          %2403 : Tensor = aten::add(%2402, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2338, %2403)
          -> ()
        block1():
          -> ()
      %2404 : bool = prim::GetAttr[name="training"](%2338)
      %2405 : Tensor = prim::GetAttr[name="running_mean"](%2338)
      %2406 : Tensor = prim::GetAttr[name="running_var"](%2338)
      %2407 : Tensor = prim::GetAttr[name="weight"](%2338)
      %2408 : Tensor = prim::GetAttr[name="bias"](%2338)
       = prim::If(%2404) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2409 : int[] = aten::size(%input.45) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.56 : int = aten::__getitem__(%2409, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2411 : int = aten::len(%2409) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2412 : int = aten::sub(%2411, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.57 : int = prim::Loop(%2412, %4, %size_prods.56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.15 : int, %size_prods.58 : int):
              %2416 : int = aten::add(%i.15, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2417 : int = aten::__getitem__(%2409, %2416) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.59 : int = aten::mul(%size_prods.58, %2417) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.59)
          %2419 : bool = aten::eq(%size_prods.57, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2419) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2420 : str = aten::format(%6, %2409) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2420) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.46 : Tensor = aten::batch_norm(%input.45, %2407, %2408, %2405, %2406, %2404, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2422 : Tensor = aten::add(%input.46, %input.22, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:57:19
      -> (%2422)
    block1():
      %2423 : __torch__.torch.nn.modules.container.___torch_mangle_62.Sequential = prim::GetAttr[name="layers"](%2144)
      %2424 : __torch__.torch.nn.modules.conv.___torch_mangle_58.Conv2d = prim::GetAttr[name="0"](%2423)
      %2425 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="1"](%2423)
      %2426 : __torch__.torch.nn.modules.conv.___torch_mangle_60.Conv2d = prim::GetAttr[name="3"](%2423)
      %2427 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="4"](%2423)
      %2428 : __torch__.torch.nn.modules.conv.___torch_mangle_61.Conv2d = prim::GetAttr[name="6"](%2423)
      %2429 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_55.BatchNorm2d = prim::GetAttr[name="7"](%2423)
      %2430 : Tensor = prim::GetAttr[name="weight"](%2424)
      %2431 : Tensor? = prim::GetAttr[name="bias"](%2424)
      %input.47 : Tensor = aten::conv2d(%input.22, %2430, %2431, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2436 : bool = prim::GetAttr[name="training"](%2425)
       = prim::If(%2436) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2437 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2425)
          %2438 : Tensor = aten::add(%2437, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2425, %2438)
          -> ()
        block1():
          -> ()
      %2439 : bool = prim::GetAttr[name="training"](%2425)
      %2440 : Tensor = prim::GetAttr[name="running_mean"](%2425)
      %2441 : Tensor = prim::GetAttr[name="running_var"](%2425)
      %2442 : Tensor = prim::GetAttr[name="weight"](%2425)
      %2443 : Tensor = prim::GetAttr[name="bias"](%2425)
       = prim::If(%2439) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2444 : int[] = aten::size(%input.47) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.60 : int = aten::__getitem__(%2444, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2446 : int = aten::len(%2444) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2447 : int = aten::sub(%2446, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.61 : int = prim::Loop(%2447, %4, %size_prods.60) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.16 : int, %size_prods.62 : int):
              %2451 : int = aten::add(%i.16, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2452 : int = aten::__getitem__(%2444, %2451) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.63 : int = aten::mul(%size_prods.62, %2452) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.63)
          %2454 : bool = aten::eq(%size_prods.61, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2454) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2455 : str = aten::format(%6, %2444) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2455) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.48 : Tensor = aten::batch_norm(%input.47, %2442, %2443, %2440, %2441, %2439, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.49 : Tensor = aten::relu_(%input.48) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2458 : Tensor = prim::GetAttr[name="weight"](%2426)
      %2459 : Tensor? = prim::GetAttr[name="bias"](%2426)
      %input.50 : Tensor = aten::conv2d(%input.49, %2458, %2459, %3102, %3101, %3102, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2464 : bool = prim::GetAttr[name="training"](%2427)
       = prim::If(%2464) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2465 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2427)
          %2466 : Tensor = aten::add(%2465, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2427, %2466)
          -> ()
        block1():
          -> ()
      %2467 : bool = prim::GetAttr[name="training"](%2427)
      %2468 : Tensor = prim::GetAttr[name="running_mean"](%2427)
      %2469 : Tensor = prim::GetAttr[name="running_var"](%2427)
      %2470 : Tensor = prim::GetAttr[name="weight"](%2427)
      %2471 : Tensor = prim::GetAttr[name="bias"](%2427)
       = prim::If(%2467) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2472 : int[] = aten::size(%input.50) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.64 : int = aten::__getitem__(%2472, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2474 : int = aten::len(%2472) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2475 : int = aten::sub(%2474, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.65 : int = prim::Loop(%2475, %4, %size_prods.64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.17 : int, %size_prods.66 : int):
              %2479 : int = aten::add(%i.17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2480 : int = aten::__getitem__(%2472, %2479) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.67 : int = aten::mul(%size_prods.66, %2480) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.67)
          %2482 : bool = aten::eq(%size_prods.65, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2482) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2483 : str = aten::format(%6, %2472) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2483) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.51 : Tensor = aten::batch_norm(%input.50, %2470, %2471, %2468, %2469, %2467, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.52 : Tensor = aten::relu_(%input.51) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2486 : Tensor = prim::GetAttr[name="weight"](%2428)
      %2487 : Tensor? = prim::GetAttr[name="bias"](%2428)
      %input.53 : Tensor = aten::conv2d(%input.52, %2486, %2487, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2492 : bool = prim::GetAttr[name="training"](%2429)
       = prim::If(%2492) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2493 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2429)
          %2494 : Tensor = aten::add(%2493, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2429, %2494)
          -> ()
        block1():
          -> ()
      %2495 : bool = prim::GetAttr[name="training"](%2429)
      %2496 : Tensor = prim::GetAttr[name="running_mean"](%2429)
      %2497 : Tensor = prim::GetAttr[name="running_var"](%2429)
      %2498 : Tensor = prim::GetAttr[name="weight"](%2429)
      %2499 : Tensor = prim::GetAttr[name="bias"](%2429)
       = prim::If(%2495) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2500 : int[] = aten::size(%input.53) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.68 : int = aten::__getitem__(%2500, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2502 : int = aten::len(%2500) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2503 : int = aten::sub(%2502, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.69 : int = prim::Loop(%2503, %4, %size_prods.68) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.18 : int, %size_prods.70 : int):
              %2507 : int = aten::add(%i.18, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2508 : int = aten::__getitem__(%2500, %2507) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.71 : int = aten::mul(%size_prods.70, %2508) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.71)
          %2510 : bool = aten::eq(%size_prods.69, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2510) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2511 : str = aten::format(%6, %2500) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2511) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.54 : Tensor = aten::batch_norm(%input.53, %2498, %2499, %2496, %2497, %2495, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.54)
  %2513 : bool = prim::GetAttr[name="apply_residual"](%2145)
  %input.21 : Tensor = prim::If(%2513) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:56:8
    block0():
      %2515 : __torch__.torch.nn.modules.container.___torch_mangle_62.Sequential = prim::GetAttr[name="layers"](%2145)
      %2516 : __torch__.torch.nn.modules.conv.___torch_mangle_58.Conv2d = prim::GetAttr[name="0"](%2515)
      %2517 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="1"](%2515)
      %2518 : __torch__.torch.nn.modules.conv.___torch_mangle_60.Conv2d = prim::GetAttr[name="3"](%2515)
      %2519 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="4"](%2515)
      %2520 : __torch__.torch.nn.modules.conv.___torch_mangle_61.Conv2d = prim::GetAttr[name="6"](%2515)
      %2521 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_55.BatchNorm2d = prim::GetAttr[name="7"](%2515)
      %2522 : Tensor = prim::GetAttr[name="weight"](%2516)
      %2523 : Tensor? = prim::GetAttr[name="bias"](%2516)
      %input.55 : Tensor = aten::conv2d(%input.20, %2522, %2523, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2528 : bool = prim::GetAttr[name="training"](%2517)
       = prim::If(%2528) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2529 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2517)
          %2530 : Tensor = aten::add(%2529, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2517, %2530)
          -> ()
        block1():
          -> ()
      %2531 : bool = prim::GetAttr[name="training"](%2517)
      %2532 : Tensor = prim::GetAttr[name="running_mean"](%2517)
      %2533 : Tensor = prim::GetAttr[name="running_var"](%2517)
      %2534 : Tensor = prim::GetAttr[name="weight"](%2517)
      %2535 : Tensor = prim::GetAttr[name="bias"](%2517)
       = prim::If(%2531) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2536 : int[] = aten::size(%input.55) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.72 : int = aten::__getitem__(%2536, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2538 : int = aten::len(%2536) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2539 : int = aten::sub(%2538, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.73 : int = prim::Loop(%2539, %4, %size_prods.72) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.19 : int, %size_prods.74 : int):
              %2543 : int = aten::add(%i.19, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2544 : int = aten::__getitem__(%2536, %2543) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.75 : int = aten::mul(%size_prods.74, %2544) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.75)
          %2546 : bool = aten::eq(%size_prods.73, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2546) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2547 : str = aten::format(%6, %2536) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2547) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.56 : Tensor = aten::batch_norm(%input.55, %2534, %2535, %2532, %2533, %2531, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.57 : Tensor = aten::relu_(%input.56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2550 : Tensor = prim::GetAttr[name="weight"](%2518)
      %2551 : Tensor? = prim::GetAttr[name="bias"](%2518)
      %input.58 : Tensor = aten::conv2d(%input.57, %2550, %2551, %3102, %3101, %3102, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2556 : bool = prim::GetAttr[name="training"](%2519)
       = prim::If(%2556) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2557 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2519)
          %2558 : Tensor = aten::add(%2557, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2519, %2558)
          -> ()
        block1():
          -> ()
      %2559 : bool = prim::GetAttr[name="training"](%2519)
      %2560 : Tensor = prim::GetAttr[name="running_mean"](%2519)
      %2561 : Tensor = prim::GetAttr[name="running_var"](%2519)
      %2562 : Tensor = prim::GetAttr[name="weight"](%2519)
      %2563 : Tensor = prim::GetAttr[name="bias"](%2519)
       = prim::If(%2559) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2564 : int[] = aten::size(%input.58) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.76 : int = aten::__getitem__(%2564, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2566 : int = aten::len(%2564) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2567 : int = aten::sub(%2566, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.77 : int = prim::Loop(%2567, %4, %size_prods.76) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.20 : int, %size_prods.78 : int):
              %2571 : int = aten::add(%i.20, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2572 : int = aten::__getitem__(%2564, %2571) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.79 : int = aten::mul(%size_prods.78, %2572) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.79)
          %2574 : bool = aten::eq(%size_prods.77, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2574) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2575 : str = aten::format(%6, %2564) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2575) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.59 : Tensor = aten::batch_norm(%input.58, %2562, %2563, %2560, %2561, %2559, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.60 : Tensor = aten::relu_(%input.59) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2578 : Tensor = prim::GetAttr[name="weight"](%2520)
      %2579 : Tensor? = prim::GetAttr[name="bias"](%2520)
      %input.61 : Tensor = aten::conv2d(%input.60, %2578, %2579, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2584 : bool = prim::GetAttr[name="training"](%2521)
       = prim::If(%2584) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2585 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2521)
          %2586 : Tensor = aten::add(%2585, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2521, %2586)
          -> ()
        block1():
          -> ()
      %2587 : bool = prim::GetAttr[name="training"](%2521)
      %2588 : Tensor = prim::GetAttr[name="running_mean"](%2521)
      %2589 : Tensor = prim::GetAttr[name="running_var"](%2521)
      %2590 : Tensor = prim::GetAttr[name="weight"](%2521)
      %2591 : Tensor = prim::GetAttr[name="bias"](%2521)
       = prim::If(%2587) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2592 : int[] = aten::size(%input.61) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.80 : int = aten::__getitem__(%2592, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2594 : int = aten::len(%2592) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2595 : int = aten::sub(%2594, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.81 : int = prim::Loop(%2595, %4, %size_prods.80) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.21 : int, %size_prods.82 : int):
              %2599 : int = aten::add(%i.21, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2600 : int = aten::__getitem__(%2592, %2599) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.83 : int = aten::mul(%size_prods.82, %2600) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.83)
          %2602 : bool = aten::eq(%size_prods.81, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2602) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2603 : str = aten::format(%6, %2592) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2603) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.62 : Tensor = aten::batch_norm(%input.61, %2590, %2591, %2588, %2589, %2587, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2605 : Tensor = aten::add(%input.62, %input.20, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:57:19
      -> (%2605)
    block1():
      %2606 : __torch__.torch.nn.modules.container.___torch_mangle_62.Sequential = prim::GetAttr[name="layers"](%2145)
      %2607 : __torch__.torch.nn.modules.conv.___torch_mangle_58.Conv2d = prim::GetAttr[name="0"](%2606)
      %2608 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="1"](%2606)
      %2609 : __torch__.torch.nn.modules.conv.___torch_mangle_60.Conv2d = prim::GetAttr[name="3"](%2606)
      %2610 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="4"](%2606)
      %2611 : __torch__.torch.nn.modules.conv.___torch_mangle_61.Conv2d = prim::GetAttr[name="6"](%2606)
      %2612 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_55.BatchNorm2d = prim::GetAttr[name="7"](%2606)
      %2613 : Tensor = prim::GetAttr[name="weight"](%2607)
      %2614 : Tensor? = prim::GetAttr[name="bias"](%2607)
      %input.63 : Tensor = aten::conv2d(%input.20, %2613, %2614, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2619 : bool = prim::GetAttr[name="training"](%2608)
       = prim::If(%2619) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2620 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2608)
          %2621 : Tensor = aten::add(%2620, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2608, %2621)
          -> ()
        block1():
          -> ()
      %2622 : bool = prim::GetAttr[name="training"](%2608)
      %2623 : Tensor = prim::GetAttr[name="running_mean"](%2608)
      %2624 : Tensor = prim::GetAttr[name="running_var"](%2608)
      %2625 : Tensor = prim::GetAttr[name="weight"](%2608)
      %2626 : Tensor = prim::GetAttr[name="bias"](%2608)
       = prim::If(%2622) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2627 : int[] = aten::size(%input.63) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.84 : int = aten::__getitem__(%2627, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2629 : int = aten::len(%2627) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2630 : int = aten::sub(%2629, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.85 : int = prim::Loop(%2630, %4, %size_prods.84) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.22 : int, %size_prods.86 : int):
              %2634 : int = aten::add(%i.22, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2635 : int = aten::__getitem__(%2627, %2634) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.87 : int = aten::mul(%size_prods.86, %2635) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.87)
          %2637 : bool = aten::eq(%size_prods.85, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2637) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2638 : str = aten::format(%6, %2627) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2638) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.64 : Tensor = aten::batch_norm(%input.63, %2625, %2626, %2623, %2624, %2622, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.65 : Tensor = aten::relu_(%input.64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2641 : Tensor = prim::GetAttr[name="weight"](%2609)
      %2642 : Tensor? = prim::GetAttr[name="bias"](%2609)
      %input.66 : Tensor = aten::conv2d(%input.65, %2641, %2642, %3102, %3101, %3102, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2647 : bool = prim::GetAttr[name="training"](%2610)
       = prim::If(%2647) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2648 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2610)
          %2649 : Tensor = aten::add(%2648, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2610, %2649)
          -> ()
        block1():
          -> ()
      %2650 : bool = prim::GetAttr[name="training"](%2610)
      %2651 : Tensor = prim::GetAttr[name="running_mean"](%2610)
      %2652 : Tensor = prim::GetAttr[name="running_var"](%2610)
      %2653 : Tensor = prim::GetAttr[name="weight"](%2610)
      %2654 : Tensor = prim::GetAttr[name="bias"](%2610)
       = prim::If(%2650) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2655 : int[] = aten::size(%input.66) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.88 : int = aten::__getitem__(%2655, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2657 : int = aten::len(%2655) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2658 : int = aten::sub(%2657, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.89 : int = prim::Loop(%2658, %4, %size_prods.88) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.23 : int, %size_prods.90 : int):
              %2662 : int = aten::add(%i.23, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2663 : int = aten::__getitem__(%2655, %2662) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.91 : int = aten::mul(%size_prods.90, %2663) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.91)
          %2665 : bool = aten::eq(%size_prods.89, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2665) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2666 : str = aten::format(%6, %2655) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2666) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.67 : Tensor = aten::batch_norm(%input.66, %2653, %2654, %2651, %2652, %2650, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.68 : Tensor = aten::relu_(%input.67) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2669 : Tensor = prim::GetAttr[name="weight"](%2611)
      %2670 : Tensor? = prim::GetAttr[name="bias"](%2611)
      %input.69 : Tensor = aten::conv2d(%input.68, %2669, %2670, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2675 : bool = prim::GetAttr[name="training"](%2612)
       = prim::If(%2675) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2676 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2612)
          %2677 : Tensor = aten::add(%2676, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2612, %2677)
          -> ()
        block1():
          -> ()
      %2678 : bool = prim::GetAttr[name="training"](%2612)
      %2679 : Tensor = prim::GetAttr[name="running_mean"](%2612)
      %2680 : Tensor = prim::GetAttr[name="running_var"](%2612)
      %2681 : Tensor = prim::GetAttr[name="weight"](%2612)
      %2682 : Tensor = prim::GetAttr[name="bias"](%2612)
       = prim::If(%2678) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2683 : int[] = aten::size(%input.69) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.92 : int = aten::__getitem__(%2683, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2685 : int = aten::len(%2683) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2686 : int = aten::sub(%2685, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.93 : int = prim::Loop(%2686, %4, %size_prods.92) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.24 : int, %size_prods.94 : int):
              %2690 : int = aten::add(%i.24, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2691 : int = aten::__getitem__(%2683, %2690) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.95 : int = aten::mul(%size_prods.94, %2691) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.95)
          %2693 : bool = aten::eq(%size_prods.93, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2693) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2694 : str = aten::format(%6, %2683) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2694) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.70 : Tensor = aten::batch_norm(%input.69, %2681, %2682, %2679, %2680, %2678, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.70)
  %2696 : bool = prim::GetAttr[name="apply_residual"](%2146)
  %input.238 : Tensor = prim::If(%2696) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:56:8
    block0():
      %2698 : __torch__.torch.nn.modules.container.___torch_mangle_62.Sequential = prim::GetAttr[name="layers"](%2146)
      %2699 : __torch__.torch.nn.modules.conv.___torch_mangle_58.Conv2d = prim::GetAttr[name="0"](%2698)
      %2700 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="1"](%2698)
      %2701 : __torch__.torch.nn.modules.conv.___torch_mangle_60.Conv2d = prim::GetAttr[name="3"](%2698)
      %2702 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="4"](%2698)
      %2703 : __torch__.torch.nn.modules.conv.___torch_mangle_61.Conv2d = prim::GetAttr[name="6"](%2698)
      %2704 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_55.BatchNorm2d = prim::GetAttr[name="7"](%2698)
      %2705 : Tensor = prim::GetAttr[name="weight"](%2699)
      %2706 : Tensor? = prim::GetAttr[name="bias"](%2699)
      %input.271 : Tensor = aten::conv2d(%input.21, %2705, %2706, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2711 : bool = prim::GetAttr[name="training"](%2700)
       = prim::If(%2711) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2712 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2700)
          %2713 : Tensor = aten::add(%2712, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2700, %2713)
          -> ()
        block1():
          -> ()
      %2714 : bool = prim::GetAttr[name="training"](%2700)
      %2715 : Tensor = prim::GetAttr[name="running_mean"](%2700)
      %2716 : Tensor = prim::GetAttr[name="running_var"](%2700)
      %2717 : Tensor = prim::GetAttr[name="weight"](%2700)
      %2718 : Tensor = prim::GetAttr[name="bias"](%2700)
       = prim::If(%2714) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2719 : int[] = aten::size(%input.271) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.372 : int = aten::__getitem__(%2719, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2721 : int = aten::len(%2719) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2722 : int = aten::sub(%2721, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.373 : int = prim::Loop(%2722, %4, %size_prods.372) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.94 : int, %size_prods.374 : int):
              %2726 : int = aten::add(%i.94, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2727 : int = aten::__getitem__(%2719, %2726) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.375 : int = aten::mul(%size_prods.374, %2727) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.375)
          %2729 : bool = aten::eq(%size_prods.373, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2729) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2730 : str = aten::format(%6, %2719) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2730) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.272 : Tensor = aten::batch_norm(%input.271, %2717, %2718, %2715, %2716, %2714, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.273 : Tensor = aten::relu_(%input.272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2733 : Tensor = prim::GetAttr[name="weight"](%2701)
      %2734 : Tensor? = prim::GetAttr[name="bias"](%2701)
      %input.274 : Tensor = aten::conv2d(%input.273, %2733, %2734, %3102, %3101, %3102, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2739 : bool = prim::GetAttr[name="training"](%2702)
       = prim::If(%2739) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2740 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2702)
          %2741 : Tensor = aten::add(%2740, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2702, %2741)
          -> ()
        block1():
          -> ()
      %2742 : bool = prim::GetAttr[name="training"](%2702)
      %2743 : Tensor = prim::GetAttr[name="running_mean"](%2702)
      %2744 : Tensor = prim::GetAttr[name="running_var"](%2702)
      %2745 : Tensor = prim::GetAttr[name="weight"](%2702)
      %2746 : Tensor = prim::GetAttr[name="bias"](%2702)
       = prim::If(%2742) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2747 : int[] = aten::size(%input.274) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.376 : int = aten::__getitem__(%2747, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2749 : int = aten::len(%2747) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2750 : int = aten::sub(%2749, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.377 : int = prim::Loop(%2750, %4, %size_prods.376) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.95 : int, %size_prods.378 : int):
              %2754 : int = aten::add(%i.95, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2755 : int = aten::__getitem__(%2747, %2754) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.379 : int = aten::mul(%size_prods.378, %2755) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.379)
          %2757 : bool = aten::eq(%size_prods.377, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2757) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2758 : str = aten::format(%6, %2747) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2758) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.275 : Tensor = aten::batch_norm(%input.274, %2745, %2746, %2743, %2744, %2742, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.276 : Tensor = aten::relu_(%input.275) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2761 : Tensor = prim::GetAttr[name="weight"](%2703)
      %2762 : Tensor? = prim::GetAttr[name="bias"](%2703)
      %input.277 : Tensor = aten::conv2d(%input.276, %2761, %2762, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2767 : bool = prim::GetAttr[name="training"](%2704)
       = prim::If(%2767) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2768 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2704)
          %2769 : Tensor = aten::add(%2768, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2704, %2769)
          -> ()
        block1():
          -> ()
      %2770 : bool = prim::GetAttr[name="training"](%2704)
      %2771 : Tensor = prim::GetAttr[name="running_mean"](%2704)
      %2772 : Tensor = prim::GetAttr[name="running_var"](%2704)
      %2773 : Tensor = prim::GetAttr[name="weight"](%2704)
      %2774 : Tensor = prim::GetAttr[name="bias"](%2704)
       = prim::If(%2770) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2775 : int[] = aten::size(%input.277) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.380 : int = aten::__getitem__(%2775, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2777 : int = aten::len(%2775) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2778 : int = aten::sub(%2777, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.381 : int = prim::Loop(%2778, %4, %size_prods.380) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.96 : int, %size_prods.382 : int):
              %2782 : int = aten::add(%i.96, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2783 : int = aten::__getitem__(%2775, %2782) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.383 : int = aten::mul(%size_prods.382, %2783) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.383)
          %2785 : bool = aten::eq(%size_prods.381, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2785) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2786 : str = aten::format(%6, %2775) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2786) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.278 : Tensor = aten::batch_norm(%input.277, %2773, %2774, %2771, %2772, %2770, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2788 : Tensor = aten::add(%input.278, %input.21, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:57:19
      -> (%2788)
    block1():
      %2789 : __torch__.torch.nn.modules.container.___torch_mangle_62.Sequential = prim::GetAttr[name="layers"](%2146)
      %2790 : __torch__.torch.nn.modules.conv.___torch_mangle_58.Conv2d = prim::GetAttr[name="0"](%2789)
      %2791 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="1"](%2789)
      %2792 : __torch__.torch.nn.modules.conv.___torch_mangle_60.Conv2d = prim::GetAttr[name="3"](%2789)
      %2793 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="4"](%2789)
      %2794 : __torch__.torch.nn.modules.conv.___torch_mangle_61.Conv2d = prim::GetAttr[name="6"](%2789)
      %2795 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_55.BatchNorm2d = prim::GetAttr[name="7"](%2789)
      %2796 : Tensor = prim::GetAttr[name="weight"](%2790)
      %2797 : Tensor? = prim::GetAttr[name="bias"](%2790)
      %input.279 : Tensor = aten::conv2d(%input.21, %2796, %2797, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2802 : bool = prim::GetAttr[name="training"](%2791)
       = prim::If(%2802) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2803 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2791)
          %2804 : Tensor = aten::add(%2803, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2791, %2804)
          -> ()
        block1():
          -> ()
      %2805 : bool = prim::GetAttr[name="training"](%2791)
      %2806 : Tensor = prim::GetAttr[name="running_mean"](%2791)
      %2807 : Tensor = prim::GetAttr[name="running_var"](%2791)
      %2808 : Tensor = prim::GetAttr[name="weight"](%2791)
      %2809 : Tensor = prim::GetAttr[name="bias"](%2791)
       = prim::If(%2805) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2810 : int[] = aten::size(%input.279) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.384 : int = aten::__getitem__(%2810, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2812 : int = aten::len(%2810) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2813 : int = aten::sub(%2812, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.385 : int = prim::Loop(%2813, %4, %size_prods.384) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.97 : int, %size_prods.386 : int):
              %2817 : int = aten::add(%i.97, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2818 : int = aten::__getitem__(%2810, %2817) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.387 : int = aten::mul(%size_prods.386, %2818) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.387)
          %2820 : bool = aten::eq(%size_prods.385, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2820) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2821 : str = aten::format(%6, %2810) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2821) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.280 : Tensor = aten::batch_norm(%input.279, %2808, %2809, %2806, %2807, %2805, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.281 : Tensor = aten::relu_(%input.280) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2824 : Tensor = prim::GetAttr[name="weight"](%2792)
      %2825 : Tensor? = prim::GetAttr[name="bias"](%2792)
      %input.282 : Tensor = aten::conv2d(%input.281, %2824, %2825, %3102, %3101, %3102, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2830 : bool = prim::GetAttr[name="training"](%2793)
       = prim::If(%2830) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2831 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2793)
          %2832 : Tensor = aten::add(%2831, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2793, %2832)
          -> ()
        block1():
          -> ()
      %2833 : bool = prim::GetAttr[name="training"](%2793)
      %2834 : Tensor = prim::GetAttr[name="running_mean"](%2793)
      %2835 : Tensor = prim::GetAttr[name="running_var"](%2793)
      %2836 : Tensor = prim::GetAttr[name="weight"](%2793)
      %2837 : Tensor = prim::GetAttr[name="bias"](%2793)
       = prim::If(%2833) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2838 : int[] = aten::size(%input.282) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.388 : int = aten::__getitem__(%2838, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2840 : int = aten::len(%2838) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2841 : int = aten::sub(%2840, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.389 : int = prim::Loop(%2841, %4, %size_prods.388) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.98 : int, %size_prods.390 : int):
              %2845 : int = aten::add(%i.98, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2846 : int = aten::__getitem__(%2838, %2845) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.391 : int = aten::mul(%size_prods.390, %2846) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.391)
          %2848 : bool = aten::eq(%size_prods.389, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2848) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2849 : str = aten::format(%6, %2838) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2849) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.283 : Tensor = aten::batch_norm(%input.282, %2836, %2837, %2834, %2835, %2833, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.284 : Tensor = aten::relu_(%input.283) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2852 : Tensor = prim::GetAttr[name="weight"](%2794)
      %2853 : Tensor? = prim::GetAttr[name="bias"](%2794)
      %input.285 : Tensor = aten::conv2d(%input.284, %2852, %2853, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2858 : bool = prim::GetAttr[name="training"](%2795)
       = prim::If(%2858) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2859 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2795)
          %2860 : Tensor = aten::add(%2859, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2795, %2860)
          -> ()
        block1():
          -> ()
      %2861 : bool = prim::GetAttr[name="training"](%2795)
      %2862 : Tensor = prim::GetAttr[name="running_mean"](%2795)
      %2863 : Tensor = prim::GetAttr[name="running_var"](%2795)
      %2864 : Tensor = prim::GetAttr[name="weight"](%2795)
      %2865 : Tensor = prim::GetAttr[name="bias"](%2795)
       = prim::If(%2861) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2866 : int[] = aten::size(%input.285) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.392 : int = aten::__getitem__(%2866, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2868 : int = aten::len(%2866) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2869 : int = aten::sub(%2868, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.393 : int = prim::Loop(%2869, %4, %size_prods.392) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.99 : int, %size_prods.394 : int):
              %2873 : int = aten::add(%i.99, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2874 : int = aten::__getitem__(%2866, %2873) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.395 : int = aten::mul(%size_prods.394, %2874) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.395)
          %2876 : bool = aten::eq(%size_prods.393, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2876) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2877 : str = aten::format(%6, %2866) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2877) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.286 : Tensor = aten::batch_norm(%input.285, %2864, %2865, %2862, %2863, %2861, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.286)
  %2879 : __torch__.torchvision.models.mnasnet.___torch_mangle_69._InvertedResidual = prim::GetAttr[name="0"](%33)
  %2880 : bool = prim::GetAttr[name="apply_residual"](%2879)
  %input.242 : Tensor = prim::If(%2880) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:56:8
    block0():
      %2882 : __torch__.torch.nn.modules.container.___torch_mangle_68.Sequential = prim::GetAttr[name="layers"](%2879)
      %2883 : __torch__.torch.nn.modules.conv.___torch_mangle_58.Conv2d = prim::GetAttr[name="0"](%2882)
      %2884 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="1"](%2882)
      %2885 : __torch__.torch.nn.modules.conv.___torch_mangle_65.Conv2d = prim::GetAttr[name="3"](%2882)
      %2886 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="4"](%2882)
      %2887 : __torch__.torch.nn.modules.conv.___torch_mangle_66.Conv2d = prim::GetAttr[name="6"](%2882)
      %2888 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_67.BatchNorm2d = prim::GetAttr[name="7"](%2882)
      %2889 : Tensor = prim::GetAttr[name="weight"](%2883)
      %2890 : Tensor? = prim::GetAttr[name="bias"](%2883)
      %input.4 : Tensor = aten::conv2d(%input.238, %2889, %2890, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2895 : bool = prim::GetAttr[name="training"](%2884)
       = prim::If(%2895) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2896 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2884)
          %2897 : Tensor = aten::add(%2896, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2884, %2897)
          -> ()
        block1():
          -> ()
      %2898 : bool = prim::GetAttr[name="training"](%2884)
      %2899 : Tensor = prim::GetAttr[name="running_mean"](%2884)
      %2900 : Tensor = prim::GetAttr[name="running_var"](%2884)
      %2901 : Tensor = prim::GetAttr[name="weight"](%2884)
      %2902 : Tensor = prim::GetAttr[name="bias"](%2884)
       = prim::If(%2898) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2903 : int[] = aten::size(%input.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.12 : int = aten::__getitem__(%2903, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2905 : int = aten::len(%2903) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2906 : int = aten::sub(%2905, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.13 : int = prim::Loop(%2906, %4, %size_prods.12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.4 : int, %size_prods.14 : int):
              %2910 : int = aten::add(%i.4, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2911 : int = aten::__getitem__(%2903, %2910) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.15 : int = aten::mul(%size_prods.14, %2911) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.15)
          %2913 : bool = aten::eq(%size_prods.13, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2913) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2914 : str = aten::format(%6, %2903) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2914) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.6 : Tensor = aten::batch_norm(%input.4, %2901, %2902, %2899, %2900, %2898, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.8 : Tensor = aten::relu_(%input.6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2917 : Tensor = prim::GetAttr[name="weight"](%2885)
      %2918 : Tensor? = prim::GetAttr[name="bias"](%2885)
      %input.10 : Tensor = aten::conv2d(%input.8, %2917, %2918, %3102, %3102, %3102, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2923 : bool = prim::GetAttr[name="training"](%2886)
       = prim::If(%2923) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2924 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2886)
          %2925 : Tensor = aten::add(%2924, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2886, %2925)
          -> ()
        block1():
          -> ()
      %2926 : bool = prim::GetAttr[name="training"](%2886)
      %2927 : Tensor = prim::GetAttr[name="running_mean"](%2886)
      %2928 : Tensor = prim::GetAttr[name="running_var"](%2886)
      %2929 : Tensor = prim::GetAttr[name="weight"](%2886)
      %2930 : Tensor = prim::GetAttr[name="bias"](%2886)
       = prim::If(%2926) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2931 : int[] = aten::size(%input.10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.16 : int = aten::__getitem__(%2931, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2933 : int = aten::len(%2931) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2934 : int = aten::sub(%2933, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.17 : int = prim::Loop(%2934, %4, %size_prods.16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.5 : int, %size_prods.18 : int):
              %2938 : int = aten::add(%i.5, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2939 : int = aten::__getitem__(%2931, %2938) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.19 : int = aten::mul(%size_prods.18, %2939) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.19)
          %2941 : bool = aten::eq(%size_prods.17, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2941) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2942 : str = aten::format(%6, %2931) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2942) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.12 : Tensor = aten::batch_norm(%input.10, %2929, %2930, %2927, %2928, %2926, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.14 : Tensor = aten::relu_(%input.12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2945 : Tensor = prim::GetAttr[name="weight"](%2887)
      %2946 : Tensor? = prim::GetAttr[name="bias"](%2887)
      %input.16 : Tensor = aten::conv2d(%input.14, %2945, %2946, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2951 : bool = prim::GetAttr[name="training"](%2888)
       = prim::If(%2951) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2952 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2888)
          %2953 : Tensor = aten::add(%2952, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2888, %2953)
          -> ()
        block1():
          -> ()
      %2954 : bool = prim::GetAttr[name="training"](%2888)
      %2955 : Tensor = prim::GetAttr[name="running_mean"](%2888)
      %2956 : Tensor = prim::GetAttr[name="running_var"](%2888)
      %2957 : Tensor = prim::GetAttr[name="weight"](%2888)
      %2958 : Tensor = prim::GetAttr[name="bias"](%2888)
       = prim::If(%2954) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2959 : int[] = aten::size(%input.16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.20 : int = aten::__getitem__(%2959, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2961 : int = aten::len(%2959) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2962 : int = aten::sub(%2961, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.21 : int = prim::Loop(%2962, %4, %size_prods.20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.6 : int, %size_prods.22 : int):
              %2966 : int = aten::add(%i.6, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2967 : int = aten::__getitem__(%2959, %2966) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.23 : int = aten::mul(%size_prods.22, %2967) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.23)
          %2969 : bool = aten::eq(%size_prods.21, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2969) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2970 : str = aten::format(%6, %2959) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2970) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.18 : Tensor = aten::batch_norm(%input.16, %2957, %2958, %2955, %2956, %2954, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2972 : Tensor = aten::add(%input.18, %input.238, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:57:19
      -> (%2972)
    block1():
      %2973 : __torch__.torch.nn.modules.container.___torch_mangle_68.Sequential = prim::GetAttr[name="layers"](%2879)
      %2974 : __torch__.torch.nn.modules.conv.___torch_mangle_58.Conv2d = prim::GetAttr[name="0"](%2973)
      %2975 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="1"](%2973)
      %2976 : __torch__.torch.nn.modules.conv.___torch_mangle_65.Conv2d = prim::GetAttr[name="3"](%2973)
      %2977 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="4"](%2973)
      %2978 : __torch__.torch.nn.modules.conv.___torch_mangle_66.Conv2d = prim::GetAttr[name="6"](%2973)
      %2979 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_67.BatchNorm2d = prim::GetAttr[name="7"](%2973)
      %2980 : Tensor = prim::GetAttr[name="weight"](%2974)
      %2981 : Tensor? = prim::GetAttr[name="bias"](%2974)
      %input.19 : Tensor = aten::conv2d(%input.238, %2980, %2981, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2986 : bool = prim::GetAttr[name="training"](%2975)
       = prim::If(%2986) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2987 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2975)
          %2988 : Tensor = aten::add(%2987, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2975, %2988)
          -> ()
        block1():
          -> ()
      %2989 : bool = prim::GetAttr[name="training"](%2975)
      %2990 : Tensor = prim::GetAttr[name="running_mean"](%2975)
      %2991 : Tensor = prim::GetAttr[name="running_var"](%2975)
      %2992 : Tensor = prim::GetAttr[name="weight"](%2975)
      %2993 : Tensor = prim::GetAttr[name="bias"](%2975)
       = prim::If(%2989) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2994 : int[] = aten::size(%input.19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.2 : int = aten::__getitem__(%2994, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2996 : int = aten::len(%2994) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2997 : int = aten::sub(%2996, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.4 : int = prim::Loop(%2997, %4, %size_prods.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.2 : int, %size_prods.7 : int):
              %3001 : int = aten::add(%i.2, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3002 : int = aten::__getitem__(%2994, %3001) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.5 : int = aten::mul(%size_prods.7, %3002) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.5)
          %3004 : bool = aten::eq(%size_prods.4, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3004) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3005 : str = aten::format(%6, %2994) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3005) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.241 : Tensor = aten::batch_norm(%input.19, %2992, %2993, %2990, %2991, %2989, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.7 : Tensor = aten::relu_(%input.241) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3008 : Tensor = prim::GetAttr[name="weight"](%2976)
      %3009 : Tensor? = prim::GetAttr[name="bias"](%2976)
      %input.9 : Tensor = aten::conv2d(%input.7, %3008, %3009, %3102, %3102, %3102, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3014 : bool = prim::GetAttr[name="training"](%2977)
       = prim::If(%3014) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3015 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2977)
          %3016 : Tensor = aten::add(%3015, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2977, %3016)
          -> ()
        block1():
          -> ()
      %3017 : bool = prim::GetAttr[name="training"](%2977)
      %3018 : Tensor = prim::GetAttr[name="running_mean"](%2977)
      %3019 : Tensor = prim::GetAttr[name="running_var"](%2977)
      %3020 : Tensor = prim::GetAttr[name="weight"](%2977)
      %3021 : Tensor = prim::GetAttr[name="bias"](%2977)
       = prim::If(%3017) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3022 : int[] = aten::size(%input.9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.8 : int = aten::__getitem__(%3022, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3024 : int = aten::len(%3022) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3025 : int = aten::sub(%3024, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.9 : int = prim::Loop(%3025, %4, %size_prods.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.3 : int, %size_prods.10 : int):
              %3029 : int = aten::add(%i.3, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3030 : int = aten::__getitem__(%3022, %3029) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.11 : int = aten::mul(%size_prods.10, %3030) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.11)
          %3032 : bool = aten::eq(%size_prods.9, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3032) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3033 : str = aten::format(%6, %3022) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3033) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.11 : Tensor = aten::batch_norm(%input.9, %3020, %3021, %3018, %3019, %3017, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.13 : Tensor = aten::relu_(%input.11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3036 : Tensor = prim::GetAttr[name="weight"](%2978)
      %3037 : Tensor? = prim::GetAttr[name="bias"](%2978)
      %input.15 : Tensor = aten::conv2d(%input.13, %3036, %3037, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3042 : bool = prim::GetAttr[name="training"](%2979)
       = prim::If(%3042) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3043 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2979)
          %3044 : Tensor = aten::add(%3043, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2979, %3044)
          -> ()
        block1():
          -> ()
      %3045 : bool = prim::GetAttr[name="training"](%2979)
      %3046 : Tensor = prim::GetAttr[name="running_mean"](%2979)
      %3047 : Tensor = prim::GetAttr[name="running_var"](%2979)
      %3048 : Tensor = prim::GetAttr[name="weight"](%2979)
      %3049 : Tensor = prim::GetAttr[name="bias"](%2979)
       = prim::If(%3045) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3050 : int[] = aten::size(%input.15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.396 : int = aten::__getitem__(%3050, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3052 : int = aten::len(%3050) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3053 : int = aten::sub(%3052, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.397 : int = prim::Loop(%3053, %4, %size_prods.396) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.100 : int, %size_prods.398 : int):
              %3057 : int = aten::add(%i.100, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3058 : int = aten::__getitem__(%3050, %3057) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.399 : int = aten::mul(%size_prods.398, %3058) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%4, %size_prods.399)
          %3060 : bool = aten::eq(%size_prods.397, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3060) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3061 : str = aten::format(%6, %3050) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3061) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.17 : Tensor = aten::batch_norm(%input.15, %3048, %3049, %3046, %3047, %3045, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.17)
  %3063 : Tensor = prim::GetAttr[name="weight"](%34)
  %3064 : Tensor? = prim::GetAttr[name="bias"](%34)
  %input.236 : Tensor = aten::conv2d(%input.242, %3063, %3064, %3102, %3108, %3102, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %3069 : bool = prim::GetAttr[name="training"](%35)
   = prim::If(%3069) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %3070 : Tensor = prim::GetAttr[name="num_batches_tracked"](%35)
      %3071 : Tensor = aten::add(%3070, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%35, %3071)
      -> ()
    block1():
      -> ()
  %3072 : bool = prim::GetAttr[name="training"](%35)
  %3073 : Tensor = prim::GetAttr[name="running_mean"](%35)
  %3074 : Tensor = prim::GetAttr[name="running_var"](%35)
  %3075 : Tensor = prim::GetAttr[name="weight"](%35)
  %3076 : Tensor = prim::GetAttr[name="bias"](%35)
   = prim::If(%3072) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %3077 : int[] = aten::size(%input.236) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.1 : int = aten::__getitem__(%3077, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %3079 : int = aten::len(%3077) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %3080 : int = aten::sub(%3079, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods : int = prim::Loop(%3080, %4, %size_prods.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.1 : int, %size_prods.6 : int):
          %3084 : int = aten::add(%i.1, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %3085 : int = aten::__getitem__(%3077, %3084) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.3 : int = aten::mul(%size_prods.6, %3085) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%4, %size_prods.3)
      %3087 : bool = aten::eq(%size_prods, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%3087) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %3088 : str = aten::format(%6, %3077) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%3088) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.239 : Tensor = aten::batch_norm(%input.236, %3075, %3076, %3073, %3074, %3072, %7, %8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %x.3 : Tensor = aten::relu_(%input.239) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %x.5 : Tensor = aten::mean(%x.3, %3401, %19, %20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mnasnet.py:150:12
  %3093 : __torch__.torch.nn.modules.container.___torch_mangle_74.Sequential = prim::GetAttr[name="classifier"](%self)
  %3094 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="0"](%3093)
  %3095 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="1"](%3093)
  %3096 : bool = prim::GetAttr[name="training"](%3094)
  %input.3 : Tensor = aten::dropout_(%x.5, %2, %3096) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:11
  %3098 : Tensor = prim::GetAttr[name="weight"](%3095)
  %3099 : Tensor = prim::GetAttr[name="bias"](%3095)
  %input.5 : Tensor = aten::linear(%input.3, %3098, %3099) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
  return (%input.5)

