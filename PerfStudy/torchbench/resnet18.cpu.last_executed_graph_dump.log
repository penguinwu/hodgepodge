graph(%self : __torch__.torchvision.models.resnet.ResNet,
      %x.1 : Tensor):
  %674 : int[] = prim::Constant[value=[0, 0]]()
  %650 : int[] = prim::Constant[value=[1, 1]]()
  %649 : int[] = prim::Constant[value=[3, 3]]()
  %648 : int[] = prim::Constant[value=[2, 2]]()
  %12 : str = prim::Constant[value="AssertionError: "]()
  %11 : bool = prim::Constant[value=0]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/pooling.py:163:57
  %10 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:140:77
  %9 : float = prim::Constant[value=0.10000000000000001]()
  %8 : str = prim::Constant[value="Expected more than 1 value per channel when training, got input size {}"]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
  %7 : int = prim::Constant[value=0]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:22
  %6 : bool = prim::Constant[value=1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2147:81
  %5 : int = prim::Constant[value=2]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:45
  %3 : int = prim::Constant[value=1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:243:29
  %2 : int = prim::Constant[value=-1]()
  %13 : __torch__.torch.nn.modules.conv.___torch_mangle_61.Conv2d = prim::GetAttr[name="conv1"](%self)
  %14 : Tensor = prim::GetAttr[name="weight"](%13)
  %15 : Tensor? = prim::GetAttr[name="bias"](%13)
  %x.3 : Tensor = aten::conv2d(%x.1, %14, %15, %648, %649, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %20 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="bn1"](%self)
  %21 : bool = prim::GetAttr[name="training"](%20)
   = prim::If(%21) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %22 : Tensor = prim::GetAttr[name="num_batches_tracked"](%20)
      %23 : Tensor = aten::add(%22, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%20, %23)
      -> ()
    block1():
      -> ()
  %24 : bool = prim::GetAttr[name="training"](%20)
  %25 : Tensor = prim::GetAttr[name="running_mean"](%20)
  %26 : Tensor = prim::GetAttr[name="running_var"](%20)
  %27 : Tensor = prim::GetAttr[name="weight"](%20)
  %28 : Tensor = prim::GetAttr[name="bias"](%20)
   = prim::If(%24) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %29 : int[] = aten::size(%x.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.28 : int = aten::__getitem__(%29, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %31 : int = aten::len(%29) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %32 : int = aten::sub(%31, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.29 : int = prim::Loop(%32, %6, %size_prods.28) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.8 : int, %size_prods.30 : int):
          %36 : int = aten::add(%i.8, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %37 : int = aten::__getitem__(%29, %36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.31 : int = aten::mul(%size_prods.30, %37) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.31)
      %39 : bool = aten::eq(%size_prods.29, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%39) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %40 : str = aten::format(%8, %29) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %x.5 : Tensor = aten::batch_norm(%x.3, %27, %28, %25, %26, %24, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %x.7 : Tensor = aten::relu_(%x.5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %x.9 : Tensor = aten::max_pool2d(%x.7, %649, %648, %650, %650, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:659:11
  %48 : __torch__.torch.nn.modules.container.___torch_mangle_409.Sequential = prim::GetAttr[name="layer1"](%self)
  %49 : __torch__.torchvision.models.resnet.BasicBlock = prim::GetAttr[name="0"](%48)
  %50 : __torch__.torchvision.models.resnet.BasicBlock = prim::GetAttr[name="1"](%48)
  %51 : __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d = prim::GetAttr[name="conv1"](%49)
  %52 : Tensor = prim::GetAttr[name="weight"](%51)
  %53 : Tensor? = prim::GetAttr[name="bias"](%51)
  %out.13 : Tensor = aten::conv2d(%x.9, %52, %53, %650, %650, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %58 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="bn1"](%49)
  %59 : bool = prim::GetAttr[name="training"](%58)
   = prim::If(%59) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %60 : Tensor = prim::GetAttr[name="num_batches_tracked"](%58)
      %61 : Tensor = aten::add(%60, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%58, %61)
      -> ()
    block1():
      -> ()
  %62 : bool = prim::GetAttr[name="training"](%58)
  %63 : Tensor = prim::GetAttr[name="running_mean"](%58)
  %64 : Tensor = prim::GetAttr[name="running_var"](%58)
  %65 : Tensor = prim::GetAttr[name="weight"](%58)
  %66 : Tensor = prim::GetAttr[name="bias"](%58)
   = prim::If(%62) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %67 : int[] = aten::size(%out.13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.24 : int = aten::__getitem__(%67, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %69 : int = aten::len(%67) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %70 : int = aten::sub(%69, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.25 : int = prim::Loop(%70, %6, %size_prods.24) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.7 : int, %size_prods.26 : int):
          %74 : int = aten::add(%i.7, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %75 : int = aten::__getitem__(%67, %74) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.27 : int = aten::mul(%size_prods.26, %75) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.27)
      %77 : bool = aten::eq(%size_prods.25, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%77) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %78 : str = aten::format(%8, %67) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%78) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.14 : Tensor = aten::batch_norm(%out.13, %65, %66, %63, %64, %62, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.15 : Tensor = aten::relu_(%out.14) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %81 : __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d = prim::GetAttr[name="conv2"](%49)
  %82 : Tensor = prim::GetAttr[name="weight"](%81)
  %83 : Tensor? = prim::GetAttr[name="bias"](%81)
  %out.16 : Tensor = aten::conv2d(%out.15, %82, %83, %650, %650, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %88 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="bn2"](%49)
  %89 : bool = prim::GetAttr[name="training"](%88)
   = prim::If(%89) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %90 : Tensor = prim::GetAttr[name="num_batches_tracked"](%88)
      %91 : Tensor = aten::add(%90, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%88, %91)
      -> ()
    block1():
      -> ()
  %92 : bool = prim::GetAttr[name="training"](%88)
  %93 : Tensor = prim::GetAttr[name="running_mean"](%88)
  %94 : Tensor = prim::GetAttr[name="running_var"](%88)
  %95 : Tensor = prim::GetAttr[name="weight"](%88)
  %96 : Tensor = prim::GetAttr[name="bias"](%88)
   = prim::If(%92) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %97 : int[] = aten::size(%out.16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.20 : int = aten::__getitem__(%97, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %99 : int = aten::len(%97) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %100 : int = aten::sub(%99, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.21 : int = prim::Loop(%100, %6, %size_prods.20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.6 : int, %size_prods.22 : int):
          %104 : int = aten::add(%i.6, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %105 : int = aten::__getitem__(%97, %104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.23 : int = aten::mul(%size_prods.22, %105) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.23)
      %107 : bool = aten::eq(%size_prods.21, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%107) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %108 : str = aten::format(%8, %97) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.17 : Tensor = aten::batch_norm(%out.16, %95, %96, %93, %94, %92, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.18 : Tensor = aten::add_(%out.17, %x.9, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:80:8
  %input.6 : Tensor = aten::relu_(%out.18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %112 : __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d = prim::GetAttr[name="conv1"](%50)
  %113 : Tensor = prim::GetAttr[name="weight"](%112)
  %114 : Tensor? = prim::GetAttr[name="bias"](%112)
  %out.19 : Tensor = aten::conv2d(%input.6, %113, %114, %650, %650, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %119 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="bn1"](%50)
  %120 : bool = prim::GetAttr[name="training"](%119)
   = prim::If(%120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %121 : Tensor = prim::GetAttr[name="num_batches_tracked"](%119)
      %122 : Tensor = aten::add(%121, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%119, %122)
      -> ()
    block1():
      -> ()
  %123 : bool = prim::GetAttr[name="training"](%119)
  %124 : Tensor = prim::GetAttr[name="running_mean"](%119)
  %125 : Tensor = prim::GetAttr[name="running_var"](%119)
  %126 : Tensor = prim::GetAttr[name="weight"](%119)
  %127 : Tensor = prim::GetAttr[name="bias"](%119)
   = prim::If(%123) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %128 : int[] = aten::size(%out.19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.32 : int = aten::__getitem__(%128, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %130 : int = aten::len(%128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %131 : int = aten::sub(%130, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.33 : int = prim::Loop(%131, %6, %size_prods.32) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.9 : int, %size_prods.34 : int):
          %135 : int = aten::add(%i.9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %136 : int = aten::__getitem__(%128, %135) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.35 : int = aten::mul(%size_prods.34, %136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.35)
      %138 : bool = aten::eq(%size_prods.33, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%138) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %139 : str = aten::format(%8, %128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%139) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.20 : Tensor = aten::batch_norm(%out.19, %126, %127, %124, %125, %123, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.21 : Tensor = aten::relu_(%out.20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %142 : __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d = prim::GetAttr[name="conv2"](%50)
  %143 : Tensor = prim::GetAttr[name="weight"](%142)
  %144 : Tensor? = prim::GetAttr[name="bias"](%142)
  %out.22 : Tensor = aten::conv2d(%out.21, %143, %144, %650, %650, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %149 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="bn2"](%50)
  %150 : bool = prim::GetAttr[name="training"](%149)
   = prim::If(%150) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %151 : Tensor = prim::GetAttr[name="num_batches_tracked"](%149)
      %152 : Tensor = aten::add(%151, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%149, %152)
      -> ()
    block1():
      -> ()
  %153 : bool = prim::GetAttr[name="training"](%149)
  %154 : Tensor = prim::GetAttr[name="running_mean"](%149)
  %155 : Tensor = prim::GetAttr[name="running_var"](%149)
  %156 : Tensor = prim::GetAttr[name="weight"](%149)
  %157 : Tensor = prim::GetAttr[name="bias"](%149)
   = prim::If(%153) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %158 : int[] = aten::size(%out.22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.36 : int = aten::__getitem__(%158, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %160 : int = aten::len(%158) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %161 : int = aten::sub(%160, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.37 : int = prim::Loop(%161, %6, %size_prods.36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.10 : int, %size_prods.38 : int):
          %165 : int = aten::add(%i.10, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %166 : int = aten::__getitem__(%158, %165) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.39 : int = aten::mul(%size_prods.38, %166) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.39)
      %168 : bool = aten::eq(%size_prods.37, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%168) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %169 : str = aten::format(%8, %158) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%169) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.23 : Tensor = aten::batch_norm(%out.22, %156, %157, %154, %155, %153, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.24 : Tensor = aten::add_(%out.23, %input.6, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:80:8
  %x.11 : Tensor = aten::relu_(%out.24) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %173 : __torch__.torch.nn.modules.container.___torch_mangle_415.Sequential = prim::GetAttr[name="layer2"](%self)
  %174 : __torch__.torchvision.models.resnet.___torch_mangle_413.BasicBlock = prim::GetAttr[name="0"](%173)
  %175 : __torch__.torchvision.models.resnet.___torch_mangle_414.BasicBlock = prim::GetAttr[name="1"](%173)
  %176 : __torch__.torch.nn.modules.conv.___torch_mangle_410.Conv2d = prim::GetAttr[name="conv1"](%174)
  %177 : Tensor = prim::GetAttr[name="weight"](%176)
  %178 : Tensor? = prim::GetAttr[name="bias"](%176)
  %out.25 : Tensor = aten::conv2d(%x.11, %177, %178, %648, %650, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %183 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_64.BatchNorm2d = prim::GetAttr[name="bn1"](%174)
  %184 : bool = prim::GetAttr[name="training"](%183)
   = prim::If(%184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %185 : Tensor = prim::GetAttr[name="num_batches_tracked"](%183)
      %186 : Tensor = aten::add(%185, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%183, %186)
      -> ()
    block1():
      -> ()
  %187 : bool = prim::GetAttr[name="training"](%183)
  %188 : Tensor = prim::GetAttr[name="running_mean"](%183)
  %189 : Tensor = prim::GetAttr[name="running_var"](%183)
  %190 : Tensor = prim::GetAttr[name="weight"](%183)
  %191 : Tensor = prim::GetAttr[name="bias"](%183)
   = prim::If(%187) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %192 : int[] = aten::size(%out.25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.40 : int = aten::__getitem__(%192, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %194 : int = aten::len(%192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %195 : int = aten::sub(%194, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.41 : int = prim::Loop(%195, %6, %size_prods.40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.11 : int, %size_prods.42 : int):
          %199 : int = aten::add(%i.11, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %200 : int = aten::__getitem__(%192, %199) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.43 : int = aten::mul(%size_prods.42, %200) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.43)
      %202 : bool = aten::eq(%size_prods.41, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%202) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %203 : str = aten::format(%8, %192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%203) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.26 : Tensor = aten::batch_norm(%out.25, %190, %191, %188, %189, %187, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.27 : Tensor = aten::relu_(%out.26) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %206 : __torch__.torch.nn.modules.conv.___torch_mangle_17.Conv2d = prim::GetAttr[name="conv2"](%174)
  %207 : Tensor = prim::GetAttr[name="weight"](%206)
  %208 : Tensor? = prim::GetAttr[name="bias"](%206)
  %out.28 : Tensor = aten::conv2d(%out.27, %207, %208, %650, %650, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %213 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_64.BatchNorm2d = prim::GetAttr[name="bn2"](%174)
  %214 : bool = prim::GetAttr[name="training"](%213)
   = prim::If(%214) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %215 : Tensor = prim::GetAttr[name="num_batches_tracked"](%213)
      %216 : Tensor = aten::add(%215, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%213, %216)
      -> ()
    block1():
      -> ()
  %217 : bool = prim::GetAttr[name="training"](%213)
  %218 : Tensor = prim::GetAttr[name="running_mean"](%213)
  %219 : Tensor = prim::GetAttr[name="running_var"](%213)
  %220 : Tensor = prim::GetAttr[name="weight"](%213)
  %221 : Tensor = prim::GetAttr[name="bias"](%213)
   = prim::If(%217) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %222 : int[] = aten::size(%out.28) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.44 : int = aten::__getitem__(%222, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %224 : int = aten::len(%222) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %225 : int = aten::sub(%224, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.45 : int = prim::Loop(%225, %6, %size_prods.44) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.12 : int, %size_prods.46 : int):
          %229 : int = aten::add(%i.12, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %230 : int = aten::__getitem__(%222, %229) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.47 : int = aten::mul(%size_prods.46, %230) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.47)
      %232 : bool = aten::eq(%size_prods.45, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%232) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %233 : str = aten::format(%8, %222) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%233) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.29 : Tensor = aten::batch_norm(%out.28, %220, %221, %218, %219, %217, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %235 : __torch__.torch.nn.modules.container.___torch_mangle_412.Sequential = prim::GetAttr[name="downsample"](%174)
  %236 : __torch__.torch.nn.modules.conv.___torch_mangle_411.Conv2d = prim::GetAttr[name="0"](%235)
  %237 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_64.BatchNorm2d = prim::GetAttr[name="1"](%235)
  %238 : Tensor = prim::GetAttr[name="weight"](%236)
  %239 : Tensor? = prim::GetAttr[name="bias"](%236)
  %input.8 : Tensor = aten::conv2d(%x.11, %238, %239, %648, %674, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %244 : bool = prim::GetAttr[name="training"](%237)
   = prim::If(%244) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %245 : Tensor = prim::GetAttr[name="num_batches_tracked"](%237)
      %246 : Tensor = aten::add(%245, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%237, %246)
      -> ()
    block1():
      -> ()
  %247 : bool = prim::GetAttr[name="training"](%237)
  %248 : Tensor = prim::GetAttr[name="running_mean"](%237)
  %249 : Tensor = prim::GetAttr[name="running_var"](%237)
  %250 : Tensor = prim::GetAttr[name="weight"](%237)
  %251 : Tensor = prim::GetAttr[name="bias"](%237)
   = prim::If(%247) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %252 : int[] = aten::size(%input.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.48 : int = aten::__getitem__(%252, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %254 : int = aten::len(%252) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %255 : int = aten::sub(%254, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.49 : int = prim::Loop(%255, %6, %size_prods.48) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.13 : int, %size_prods.50 : int):
          %259 : int = aten::add(%i.13, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %260 : int = aten::__getitem__(%252, %259) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.51 : int = aten::mul(%size_prods.50, %260) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.51)
      %262 : bool = aten::eq(%size_prods.49, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%262) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %263 : str = aten::format(%8, %252) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%263) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %identity.2 : Tensor = aten::batch_norm(%input.8, %250, %251, %248, %249, %247, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.30 : Tensor = aten::add_(%out.29, %identity.2, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:80:8
  %input.7 : Tensor = aten::relu_(%out.30) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %267 : __torch__.torch.nn.modules.conv.___torch_mangle_17.Conv2d = prim::GetAttr[name="conv1"](%175)
  %268 : Tensor = prim::GetAttr[name="weight"](%267)
  %269 : Tensor? = prim::GetAttr[name="bias"](%267)
  %out.31 : Tensor = aten::conv2d(%input.7, %268, %269, %650, %650, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %274 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_64.BatchNorm2d = prim::GetAttr[name="bn1"](%175)
  %275 : bool = prim::GetAttr[name="training"](%274)
   = prim::If(%275) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %276 : Tensor = prim::GetAttr[name="num_batches_tracked"](%274)
      %277 : Tensor = aten::add(%276, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%274, %277)
      -> ()
    block1():
      -> ()
  %278 : bool = prim::GetAttr[name="training"](%274)
  %279 : Tensor = prim::GetAttr[name="running_mean"](%274)
  %280 : Tensor = prim::GetAttr[name="running_var"](%274)
  %281 : Tensor = prim::GetAttr[name="weight"](%274)
  %282 : Tensor = prim::GetAttr[name="bias"](%274)
   = prim::If(%278) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %283 : int[] = aten::size(%out.31) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.52 : int = aten::__getitem__(%283, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %285 : int = aten::len(%283) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %286 : int = aten::sub(%285, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.53 : int = prim::Loop(%286, %6, %size_prods.52) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.14 : int, %size_prods.54 : int):
          %290 : int = aten::add(%i.14, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %291 : int = aten::__getitem__(%283, %290) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.55 : int = aten::mul(%size_prods.54, %291) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.55)
      %293 : bool = aten::eq(%size_prods.53, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%293) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %294 : str = aten::format(%8, %283) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%294) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.32 : Tensor = aten::batch_norm(%out.31, %281, %282, %279, %280, %278, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.33 : Tensor = aten::relu_(%out.32) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %297 : __torch__.torch.nn.modules.conv.___torch_mangle_17.Conv2d = prim::GetAttr[name="conv2"](%175)
  %298 : Tensor = prim::GetAttr[name="weight"](%297)
  %299 : Tensor? = prim::GetAttr[name="bias"](%297)
  %out.34 : Tensor = aten::conv2d(%out.33, %298, %299, %650, %650, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %304 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_64.BatchNorm2d = prim::GetAttr[name="bn2"](%175)
  %305 : bool = prim::GetAttr[name="training"](%304)
   = prim::If(%305) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %306 : Tensor = prim::GetAttr[name="num_batches_tracked"](%304)
      %307 : Tensor = aten::add(%306, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%304, %307)
      -> ()
    block1():
      -> ()
  %308 : bool = prim::GetAttr[name="training"](%304)
  %309 : Tensor = prim::GetAttr[name="running_mean"](%304)
  %310 : Tensor = prim::GetAttr[name="running_var"](%304)
  %311 : Tensor = prim::GetAttr[name="weight"](%304)
  %312 : Tensor = prim::GetAttr[name="bias"](%304)
   = prim::If(%308) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %313 : int[] = aten::size(%out.34) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.56 : int = aten::__getitem__(%313, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %315 : int = aten::len(%313) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %316 : int = aten::sub(%315, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.57 : int = prim::Loop(%316, %6, %size_prods.56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.15 : int, %size_prods.58 : int):
          %320 : int = aten::add(%i.15, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %321 : int = aten::__getitem__(%313, %320) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.59 : int = aten::mul(%size_prods.58, %321) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.59)
      %323 : bool = aten::eq(%size_prods.57, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%323) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %324 : str = aten::format(%8, %313) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%324) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.35 : Tensor = aten::batch_norm(%out.34, %311, %312, %309, %310, %308, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.36 : Tensor = aten::add_(%out.35, %input.7, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:80:8
  %x.13 : Tensor = aten::relu_(%out.36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %328 : __torch__.torch.nn.modules.container.___torch_mangle_421.Sequential = prim::GetAttr[name="layer3"](%self)
  %329 : __torch__.torchvision.models.resnet.___torch_mangle_419.BasicBlock = prim::GetAttr[name="0"](%328)
  %330 : __torch__.torchvision.models.resnet.___torch_mangle_420.BasicBlock = prim::GetAttr[name="1"](%328)
  %331 : __torch__.torch.nn.modules.conv.___torch_mangle_416.Conv2d = prim::GetAttr[name="conv1"](%329)
  %332 : Tensor = prim::GetAttr[name="weight"](%331)
  %333 : Tensor? = prim::GetAttr[name="bias"](%331)
  %out.37 : Tensor = aten::conv2d(%x.13, %332, %333, %648, %650, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %338 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_80.BatchNorm2d = prim::GetAttr[name="bn1"](%329)
  %339 : bool = prim::GetAttr[name="training"](%338)
   = prim::If(%339) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %340 : Tensor = prim::GetAttr[name="num_batches_tracked"](%338)
      %341 : Tensor = aten::add(%340, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%338, %341)
      -> ()
    block1():
      -> ()
  %342 : bool = prim::GetAttr[name="training"](%338)
  %343 : Tensor = prim::GetAttr[name="running_mean"](%338)
  %344 : Tensor = prim::GetAttr[name="running_var"](%338)
  %345 : Tensor = prim::GetAttr[name="weight"](%338)
  %346 : Tensor = prim::GetAttr[name="bias"](%338)
   = prim::If(%342) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %347 : int[] = aten::size(%out.37) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.60 : int = aten::__getitem__(%347, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %349 : int = aten::len(%347) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %350 : int = aten::sub(%349, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.61 : int = prim::Loop(%350, %6, %size_prods.60) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.16 : int, %size_prods.62 : int):
          %354 : int = aten::add(%i.16, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %355 : int = aten::__getitem__(%347, %354) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.63 : int = aten::mul(%size_prods.62, %355) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.63)
      %357 : bool = aten::eq(%size_prods.61, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%357) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %358 : str = aten::format(%8, %347) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%358) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.38 : Tensor = aten::batch_norm(%out.37, %345, %346, %343, %344, %342, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.39 : Tensor = aten::relu_(%out.38) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %361 : __torch__.torch.nn.modules.conv.___torch_mangle_20.Conv2d = prim::GetAttr[name="conv2"](%329)
  %362 : Tensor = prim::GetAttr[name="weight"](%361)
  %363 : Tensor? = prim::GetAttr[name="bias"](%361)
  %out.40 : Tensor = aten::conv2d(%out.39, %362, %363, %650, %650, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %368 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_80.BatchNorm2d = prim::GetAttr[name="bn2"](%329)
  %369 : bool = prim::GetAttr[name="training"](%368)
   = prim::If(%369) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %370 : Tensor = prim::GetAttr[name="num_batches_tracked"](%368)
      %371 : Tensor = aten::add(%370, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%368, %371)
      -> ()
    block1():
      -> ()
  %372 : bool = prim::GetAttr[name="training"](%368)
  %373 : Tensor = prim::GetAttr[name="running_mean"](%368)
  %374 : Tensor = prim::GetAttr[name="running_var"](%368)
  %375 : Tensor = prim::GetAttr[name="weight"](%368)
  %376 : Tensor = prim::GetAttr[name="bias"](%368)
   = prim::If(%372) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %377 : int[] = aten::size(%out.40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.64 : int = aten::__getitem__(%377, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %379 : int = aten::len(%377) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %380 : int = aten::sub(%379, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.65 : int = prim::Loop(%380, %6, %size_prods.64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.17 : int, %size_prods.66 : int):
          %384 : int = aten::add(%i.17, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %385 : int = aten::__getitem__(%377, %384) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.67 : int = aten::mul(%size_prods.66, %385) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.67)
      %387 : bool = aten::eq(%size_prods.65, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%387) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %388 : str = aten::format(%8, %377) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%388) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.41 : Tensor = aten::batch_norm(%out.40, %375, %376, %373, %374, %372, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %390 : __torch__.torch.nn.modules.container.___torch_mangle_418.Sequential = prim::GetAttr[name="downsample"](%329)
  %391 : __torch__.torch.nn.modules.conv.___torch_mangle_417.Conv2d = prim::GetAttr[name="0"](%390)
  %392 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_80.BatchNorm2d = prim::GetAttr[name="1"](%390)
  %393 : Tensor = prim::GetAttr[name="weight"](%391)
  %394 : Tensor? = prim::GetAttr[name="bias"](%391)
  %input.10 : Tensor = aten::conv2d(%x.13, %393, %394, %648, %674, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %399 : bool = prim::GetAttr[name="training"](%392)
   = prim::If(%399) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %400 : Tensor = prim::GetAttr[name="num_batches_tracked"](%392)
      %401 : Tensor = aten::add(%400, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%392, %401)
      -> ()
    block1():
      -> ()
  %402 : bool = prim::GetAttr[name="training"](%392)
  %403 : Tensor = prim::GetAttr[name="running_mean"](%392)
  %404 : Tensor = prim::GetAttr[name="running_var"](%392)
  %405 : Tensor = prim::GetAttr[name="weight"](%392)
  %406 : Tensor = prim::GetAttr[name="bias"](%392)
   = prim::If(%402) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %407 : int[] = aten::size(%input.10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.68 : int = aten::__getitem__(%407, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %409 : int = aten::len(%407) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %410 : int = aten::sub(%409, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.69 : int = prim::Loop(%410, %6, %size_prods.68) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.18 : int, %size_prods.70 : int):
          %414 : int = aten::add(%i.18, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %415 : int = aten::__getitem__(%407, %414) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.71 : int = aten::mul(%size_prods.70, %415) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.71)
      %417 : bool = aten::eq(%size_prods.69, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%417) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %418 : str = aten::format(%8, %407) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%418) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %identity.3 : Tensor = aten::batch_norm(%input.10, %405, %406, %403, %404, %402, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.42 : Tensor = aten::add_(%out.41, %identity.3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:80:8
  %input.9 : Tensor = aten::relu_(%out.42) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %422 : __torch__.torch.nn.modules.conv.___torch_mangle_20.Conv2d = prim::GetAttr[name="conv1"](%330)
  %423 : Tensor = prim::GetAttr[name="weight"](%422)
  %424 : Tensor? = prim::GetAttr[name="bias"](%422)
  %out.43 : Tensor = aten::conv2d(%input.9, %423, %424, %650, %650, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %429 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_80.BatchNorm2d = prim::GetAttr[name="bn1"](%330)
  %430 : bool = prim::GetAttr[name="training"](%429)
   = prim::If(%430) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %431 : Tensor = prim::GetAttr[name="num_batches_tracked"](%429)
      %432 : Tensor = aten::add(%431, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%429, %432)
      -> ()
    block1():
      -> ()
  %433 : bool = prim::GetAttr[name="training"](%429)
  %434 : Tensor = prim::GetAttr[name="running_mean"](%429)
  %435 : Tensor = prim::GetAttr[name="running_var"](%429)
  %436 : Tensor = prim::GetAttr[name="weight"](%429)
  %437 : Tensor = prim::GetAttr[name="bias"](%429)
   = prim::If(%433) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %438 : int[] = aten::size(%out.43) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.72 : int = aten::__getitem__(%438, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %440 : int = aten::len(%438) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %441 : int = aten::sub(%440, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.73 : int = prim::Loop(%441, %6, %size_prods.72) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.19 : int, %size_prods.74 : int):
          %445 : int = aten::add(%i.19, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %446 : int = aten::__getitem__(%438, %445) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.75 : int = aten::mul(%size_prods.74, %446) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.75)
      %448 : bool = aten::eq(%size_prods.73, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%448) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %449 : str = aten::format(%8, %438) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%449) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.44 : Tensor = aten::batch_norm(%out.43, %436, %437, %434, %435, %433, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.45 : Tensor = aten::relu_(%out.44) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %452 : __torch__.torch.nn.modules.conv.___torch_mangle_20.Conv2d = prim::GetAttr[name="conv2"](%330)
  %453 : Tensor = prim::GetAttr[name="weight"](%452)
  %454 : Tensor? = prim::GetAttr[name="bias"](%452)
  %out.46 : Tensor = aten::conv2d(%out.45, %453, %454, %650, %650, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %459 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_80.BatchNorm2d = prim::GetAttr[name="bn2"](%330)
  %460 : bool = prim::GetAttr[name="training"](%459)
   = prim::If(%460) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %461 : Tensor = prim::GetAttr[name="num_batches_tracked"](%459)
      %462 : Tensor = aten::add(%461, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%459, %462)
      -> ()
    block1():
      -> ()
  %463 : bool = prim::GetAttr[name="training"](%459)
  %464 : Tensor = prim::GetAttr[name="running_mean"](%459)
  %465 : Tensor = prim::GetAttr[name="running_var"](%459)
  %466 : Tensor = prim::GetAttr[name="weight"](%459)
  %467 : Tensor = prim::GetAttr[name="bias"](%459)
   = prim::If(%463) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %468 : int[] = aten::size(%out.46) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.76 : int = aten::__getitem__(%468, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %470 : int = aten::len(%468) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %471 : int = aten::sub(%470, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.77 : int = prim::Loop(%471, %6, %size_prods.76) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.20 : int, %size_prods.78 : int):
          %475 : int = aten::add(%i.20, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %476 : int = aten::__getitem__(%468, %475) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.79 : int = aten::mul(%size_prods.78, %476) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.79)
      %478 : bool = aten::eq(%size_prods.77, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%478) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %479 : str = aten::format(%8, %468) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%479) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.47 : Tensor = aten::batch_norm(%out.46, %466, %467, %464, %465, %463, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.48 : Tensor = aten::add_(%out.47, %input.9, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:80:8
  %x.15 : Tensor = aten::relu_(%out.48) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %483 : __torch__.torch.nn.modules.container.___torch_mangle_427.Sequential = prim::GetAttr[name="layer4"](%self)
  %484 : __torch__.torchvision.models.resnet.___torch_mangle_425.BasicBlock = prim::GetAttr[name="0"](%483)
  %485 : __torch__.torchvision.models.resnet.___torch_mangle_426.BasicBlock = prim::GetAttr[name="1"](%483)
  %486 : __torch__.torch.nn.modules.conv.___torch_mangle_422.Conv2d = prim::GetAttr[name="conv1"](%484)
  %487 : Tensor = prim::GetAttr[name="weight"](%486)
  %488 : Tensor? = prim::GetAttr[name="bias"](%486)
  %out.2 : Tensor = aten::conv2d(%x.15, %487, %488, %648, %650, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %493 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_105.BatchNorm2d = prim::GetAttr[name="bn1"](%484)
  %494 : bool = prim::GetAttr[name="training"](%493)
   = prim::If(%494) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %495 : Tensor = prim::GetAttr[name="num_batches_tracked"](%493)
      %496 : Tensor = aten::add(%495, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%493, %496)
      -> ()
    block1():
      -> ()
  %497 : bool = prim::GetAttr[name="training"](%493)
  %498 : Tensor = prim::GetAttr[name="running_mean"](%493)
  %499 : Tensor = prim::GetAttr[name="running_var"](%493)
  %500 : Tensor = prim::GetAttr[name="weight"](%493)
  %501 : Tensor = prim::GetAttr[name="bias"](%493)
   = prim::If(%497) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %502 : int[] = aten::size(%out.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.12 : int = aten::__getitem__(%502, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %504 : int = aten::len(%502) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %505 : int = aten::sub(%504, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.13 : int = prim::Loop(%505, %6, %size_prods.12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.4 : int, %size_prods.14 : int):
          %509 : int = aten::add(%i.4, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %510 : int = aten::__getitem__(%502, %509) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.15 : int = aten::mul(%size_prods.14, %510) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.15)
      %512 : bool = aten::eq(%size_prods.13, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%512) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %513 : str = aten::format(%8, %502) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%513) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.4 : Tensor = aten::batch_norm(%out.2, %500, %501, %498, %499, %497, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.6 : Tensor = aten::relu_(%out.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %516 : __torch__.torch.nn.modules.conv.___torch_mangle_23.Conv2d = prim::GetAttr[name="conv2"](%484)
  %517 : Tensor = prim::GetAttr[name="weight"](%516)
  %518 : Tensor? = prim::GetAttr[name="bias"](%516)
  %out.8 : Tensor = aten::conv2d(%out.6, %517, %518, %650, %650, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %523 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_105.BatchNorm2d = prim::GetAttr[name="bn2"](%484)
  %524 : bool = prim::GetAttr[name="training"](%523)
   = prim::If(%524) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %525 : Tensor = prim::GetAttr[name="num_batches_tracked"](%523)
      %526 : Tensor = aten::add(%525, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%523, %526)
      -> ()
    block1():
      -> ()
  %527 : bool = prim::GetAttr[name="training"](%523)
  %528 : Tensor = prim::GetAttr[name="running_mean"](%523)
  %529 : Tensor = prim::GetAttr[name="running_var"](%523)
  %530 : Tensor = prim::GetAttr[name="weight"](%523)
  %531 : Tensor = prim::GetAttr[name="bias"](%523)
   = prim::If(%527) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %532 : int[] = aten::size(%out.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.8 : int = aten::__getitem__(%532, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %534 : int = aten::len(%532) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %535 : int = aten::sub(%534, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.9 : int = prim::Loop(%535, %6, %size_prods.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.3 : int, %size_prods.10 : int):
          %539 : int = aten::add(%i.3, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %540 : int = aten::__getitem__(%532, %539) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.11 : int = aten::mul(%size_prods.10, %540) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.11)
      %542 : bool = aten::eq(%size_prods.9, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%542) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %543 : str = aten::format(%8, %532) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%543) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.10 : Tensor = aten::batch_norm(%out.8, %530, %531, %528, %529, %527, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %545 : __torch__.torch.nn.modules.container.___torch_mangle_424.Sequential = prim::GetAttr[name="downsample"](%484)
  %546 : __torch__.torch.nn.modules.conv.___torch_mangle_423.Conv2d = prim::GetAttr[name="0"](%545)
  %547 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_105.BatchNorm2d = prim::GetAttr[name="1"](%545)
  %548 : Tensor = prim::GetAttr[name="weight"](%546)
  %549 : Tensor? = prim::GetAttr[name="bias"](%546)
  %input.3 : Tensor = aten::conv2d(%x.15, %548, %549, %648, %674, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %554 : bool = prim::GetAttr[name="training"](%547)
   = prim::If(%554) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %555 : Tensor = prim::GetAttr[name="num_batches_tracked"](%547)
      %556 : Tensor = aten::add(%555, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%547, %556)
      -> ()
    block1():
      -> ()
  %557 : bool = prim::GetAttr[name="training"](%547)
  %558 : Tensor = prim::GetAttr[name="running_mean"](%547)
  %559 : Tensor = prim::GetAttr[name="running_var"](%547)
  %560 : Tensor = prim::GetAttr[name="weight"](%547)
  %561 : Tensor = prim::GetAttr[name="bias"](%547)
   = prim::If(%557) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %562 : int[] = aten::size(%input.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.16 : int = aten::__getitem__(%562, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %564 : int = aten::len(%562) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %565 : int = aten::sub(%564, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.17 : int = prim::Loop(%565, %6, %size_prods.16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.5 : int, %size_prods.18 : int):
          %569 : int = aten::add(%i.5, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %570 : int = aten::__getitem__(%562, %569) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.19 : int = aten::mul(%size_prods.18, %570) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.19)
      %572 : bool = aten::eq(%size_prods.17, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%572) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %573 : str = aten::format(%8, %562) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%573) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %identity.1 : Tensor = aten::batch_norm(%input.3, %560, %561, %558, %559, %557, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.12 : Tensor = aten::add_(%out.10, %identity.1, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:80:8
  %input.4 : Tensor = aten::relu_(%out.12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %577 : __torch__.torch.nn.modules.conv.___torch_mangle_23.Conv2d = prim::GetAttr[name="conv1"](%485)
  %578 : Tensor = prim::GetAttr[name="weight"](%577)
  %579 : Tensor? = prim::GetAttr[name="bias"](%577)
  %out.1 : Tensor = aten::conv2d(%input.4, %578, %579, %650, %650, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %584 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_105.BatchNorm2d = prim::GetAttr[name="bn1"](%485)
  %585 : bool = prim::GetAttr[name="training"](%584)
   = prim::If(%585) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %586 : Tensor = prim::GetAttr[name="num_batches_tracked"](%584)
      %587 : Tensor = aten::add(%586, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%584, %587)
      -> ()
    block1():
      -> ()
  %588 : bool = prim::GetAttr[name="training"](%584)
  %589 : Tensor = prim::GetAttr[name="running_mean"](%584)
  %590 : Tensor = prim::GetAttr[name="running_var"](%584)
  %591 : Tensor = prim::GetAttr[name="weight"](%584)
  %592 : Tensor = prim::GetAttr[name="bias"](%584)
   = prim::If(%588) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %593 : int[] = aten::size(%out.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.2 : int = aten::__getitem__(%593, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %595 : int = aten::len(%593) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %596 : int = aten::sub(%595, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.4 : int = prim::Loop(%596, %6, %size_prods.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.2 : int, %size_prods.7 : int):
          %600 : int = aten::add(%i.2, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %601 : int = aten::__getitem__(%593, %600) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.5 : int = aten::mul(%size_prods.7, %601) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.5)
      %603 : bool = aten::eq(%size_prods.4, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%603) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %604 : str = aten::format(%8, %593) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%604) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.3 : Tensor = aten::batch_norm(%out.1, %591, %592, %589, %590, %588, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.5 : Tensor = aten::relu_(%out.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %607 : __torch__.torch.nn.modules.conv.___torch_mangle_23.Conv2d = prim::GetAttr[name="conv2"](%485)
  %608 : Tensor = prim::GetAttr[name="weight"](%607)
  %609 : Tensor? = prim::GetAttr[name="bias"](%607)
  %out.7 : Tensor = aten::conv2d(%out.5, %608, %609, %650, %650, %650, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %614 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_105.BatchNorm2d = prim::GetAttr[name="bn2"](%485)
  %615 : bool = prim::GetAttr[name="training"](%614)
   = prim::If(%615) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %616 : Tensor = prim::GetAttr[name="num_batches_tracked"](%614)
      %617 : Tensor = aten::add(%616, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%614, %617)
      -> ()
    block1():
      -> ()
  %618 : bool = prim::GetAttr[name="training"](%614)
  %619 : Tensor = prim::GetAttr[name="running_mean"](%614)
  %620 : Tensor = prim::GetAttr[name="running_var"](%614)
  %621 : Tensor = prim::GetAttr[name="weight"](%614)
  %622 : Tensor = prim::GetAttr[name="bias"](%614)
   = prim::If(%618) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %623 : int[] = aten::size(%out.7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.1 : int = aten::__getitem__(%623, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %625 : int = aten::len(%623) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %626 : int = aten::sub(%625, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods : int = prim::Loop(%626, %6, %size_prods.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.1 : int, %size_prods.6 : int):
          %630 : int = aten::add(%i.1, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %631 : int = aten::__getitem__(%623, %630) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.3 : int = aten::mul(%size_prods.6, %631) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.3)
      %633 : bool = aten::eq(%size_prods, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%633) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %634 : str = aten::format(%8, %623) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%634) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.9 : Tensor = aten::batch_norm(%out.7, %621, %622, %619, %620, %618, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.11 : Tensor = aten::add_(%out.9, %input.4, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:80:8
  %x.17 : Tensor = aten::relu_(%out.11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %639 : int[] = aten::size(%x.17) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1036:51
  %640 : int = aten::len(%639) # <string>:5:9
  %641 : bool = aten::gt(%640, %5) # <string>:5:9
   = prim::If(%641) # <string>:5:2
    block0():
      -> ()
    block1():
       = prim::RaiseException(%12) # <string>:5:2
      -> ()
  %x.19 : Tensor = aten::adaptive_avg_pool2d(%x.17, %650) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
  %x.21 : Tensor = aten::flatten(%x.19, %3, %2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:243:12
  %644 : __torch__.torch.nn.modules.linear.___torch_mangle_429.Linear = prim::GetAttr[name="fc"](%self)
  %645 : Tensor = prim::GetAttr[name="weight"](%644)
  %646 : Tensor = prim::GetAttr[name="bias"](%644)
  %x.23 : Tensor = aten::linear(%x.21, %645, %646) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
  return (%x.23)

