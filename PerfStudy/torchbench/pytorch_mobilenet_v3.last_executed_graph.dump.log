Warning: <module 'torchbenchmark.models.maskrcnn_benchmark' (namespace)> does not define attribute Model, skip it
Dump Graph IR for pytorch_mobilenetv3
graph(%self : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.MobileNetV3,
      %x.1 : Tensor):
  %3186 : int[] = prim::Constant[value=[2]]()
  %3185 : int[] = prim::Constant[value=[3]]()
  %2963 : int[] = prim::Constant[value=[0, 0]]()
  %2960 : int[] = prim::Constant[value=[1, 1]]()
  %2959 : int[] = prim::Constant[value=[2, 2]]()
  %25 : None = prim::Constant()
  %24 : bool = prim::Constant[value=0]()
  %22 : int = prim::Constant[value=2]() # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:205:27
  %21 : int = prim::Constant[value=576]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %20 : int = prim::Constant[value=288]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %19 : int = prim::Constant[value=144]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %18 : int = prim::Constant[value=120]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %17 : int = prim::Constant[value=240]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %16 : int = prim::Constant[value=96]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %15 : int = prim::Constant[value=88]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %14 : int = prim::Constant[value=72]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %13 : str = prim::Constant[value="AssertionError: "]()
  %12 : int = prim::Constant[value=16]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %11 : int = prim::Constant[value=1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:24
  %10 : bool = prim::Constant[value=1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2147:81
  %9 : int = prim::Constant[value=0]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:22
  %8 : str = prim::Constant[value="Expected more than 1 value per channel when training, got input size {}"]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
  %7 : float = prim::Constant[value=0.10000000000000001]()
  %6 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:140:77
  %5 : float = prim::Constant[value=0.]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1280:27
  %4 : float = prim::Constant[value=6.]() # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:59
  %3 : float = prim::Constant[value=3.]() # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:31
  %2 : float = prim::Constant[value=0.80000000000000004]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/dropout.py:58:32
  %26 : __torch__.torch.nn.modules.container.___torch_mangle_82.Sequential = prim::GetAttr[name="features"](%self)
  %27 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="0"](%26)
  %28 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.MobileBottleneck = prim::GetAttr[name="1"](%26)
  %29 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_11.MobileBottleneck = prim::GetAttr[name="2"](%26)
  %30 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_17.MobileBottleneck = prim::GetAttr[name="3"](%26)
  %31 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_28.MobileBottleneck = prim::GetAttr[name="4"](%26)
  %32 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_38.MobileBottleneck = prim::GetAttr[name="5"](%26)
  %33 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_38.MobileBottleneck = prim::GetAttr[name="6"](%26)
  %34 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_49.MobileBottleneck = prim::GetAttr[name="7"](%26)
  %35 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_59.MobileBottleneck = prim::GetAttr[name="8"](%26)
  %36 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_69.MobileBottleneck = prim::GetAttr[name="9"](%26)
  %37 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_79.MobileBottleneck = prim::GetAttr[name="10"](%26)
  %38 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_79.MobileBottleneck = prim::GetAttr[name="11"](%26)
  %39 : __torch__.torch.nn.modules.container.___torch_mangle_80.Sequential = prim::GetAttr[name="12"](%26)
  %40 : __torch__.torch.nn.modules.conv.___torch_mangle_81.Conv2d = prim::GetAttr[name="14"](%26)
  %41 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="15"](%26)
  %42 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name="0"](%27)
  %43 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%27)
  %44 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%27)
  %45 : Tensor = prim::GetAttr[name="weight"](%42)
  %46 : Tensor? = prim::GetAttr[name="bias"](%42)
  %input.39 : Tensor = aten::conv2d(%x.1, %45, %46, %2959, %2960, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %51 : bool = prim::GetAttr[name="training"](%43)
   = prim::If(%51) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %52 : Tensor = prim::GetAttr[name="num_batches_tracked"](%43)
      %53 : Tensor = aten::add(%52, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%43, %53)
      -> ()
    block1():
      -> ()
  %54 : bool = prim::GetAttr[name="training"](%43)
  %55 : Tensor = prim::GetAttr[name="running_mean"](%43)
  %56 : Tensor = prim::GetAttr[name="running_var"](%43)
  %57 : Tensor = prim::GetAttr[name="weight"](%43)
  %58 : Tensor = prim::GetAttr[name="bias"](%43)
   = prim::If(%54) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %59 : int[] = aten::size(%input.39) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.24 : int = aten::__getitem__(%59, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %61 : int = aten::len(%59) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %62 : int = aten::sub(%61, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.25 : int = prim::Loop(%62, %10, %size_prods.24) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.7 : int, %size_prods.26 : int):
          %66 : int = aten::add(%i.7, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %67 : int = aten::__getitem__(%59, %66) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.27 : int = aten::mul(%size_prods.26, %67) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%10, %size_prods.27)
      %69 : bool = aten::eq(%size_prods.25, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%69) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %70 : str = aten::format(%8, %59) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%70) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.40 : Tensor = aten::batch_norm(%input.39, %57, %58, %55, %56, %54, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %72 : Tensor = aten::add(%input.40, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
  %73 : bool = prim::GetAttr[name="inplace"](%44)
  %result.21 : Tensor = prim::If(%73) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
    block0():
      %result.22 : Tensor = aten::hardtanh_(%72, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      -> (%result.22)
    block1():
      %result.23 : Tensor = aten::hardtanh(%72, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
      -> (%result.23)
  %77 : Tensor = aten::mul(%input.40, %result.21) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
  %input.41 : Tensor = aten::div(%77, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
  %79 : bool = prim::GetAttr[name="use_res_connect"](%28)
  %input.37 : Tensor = prim::If(%79) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:112:8
    block0():
      %81 : __torch__.torch.nn.modules.container.___torch_mangle_4.Sequential = prim::GetAttr[name="conv"](%28)
      %82 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="0"](%81)
      %83 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%81)
      %84 : __torch__.torch.nn.modules.conv.___torch_mangle_1.Conv2d = prim::GetAttr[name="3"](%81)
      %85 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="4"](%81)
      %86 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.SEModule = prim::GetAttr[name="5"](%81)
      %87 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="7"](%81)
      %88 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="8"](%81)
      %89 : Tensor = prim::GetAttr[name="weight"](%82)
      %90 : Tensor? = prim::GetAttr[name="bias"](%82)
      %input.79 : Tensor = aten::conv2d(%input.41, %89, %90, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %95 : bool = prim::GetAttr[name="training"](%83)
       = prim::If(%95) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %96 : Tensor = prim::GetAttr[name="num_batches_tracked"](%83)
          %97 : Tensor = aten::add(%96, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%83, %97)
          -> ()
        block1():
          -> ()
      %98 : bool = prim::GetAttr[name="training"](%83)
      %99 : Tensor = prim::GetAttr[name="running_mean"](%83)
      %100 : Tensor = prim::GetAttr[name="running_var"](%83)
      %101 : Tensor = prim::GetAttr[name="weight"](%83)
      %102 : Tensor = prim::GetAttr[name="bias"](%83)
       = prim::If(%98) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %103 : int[] = aten::size(%input.79) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.28 : int = aten::__getitem__(%103, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %105 : int = aten::len(%103) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %106 : int = aten::sub(%105, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.29 : int = prim::Loop(%106, %10, %size_prods.28) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.8 : int, %size_prods.30 : int):
              %110 : int = aten::add(%i.8, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %111 : int = aten::__getitem__(%103, %110) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.31 : int = aten::mul(%size_prods.30, %111) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.31)
          %113 : bool = aten::eq(%size_prods.29, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%113) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %114 : str = aten::format(%8, %103) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%114) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.51 : Tensor = aten::batch_norm(%input.79, %101, %102, %99, %100, %98, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.52 : Tensor = aten::relu_(%input.51) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %117 : Tensor = prim::GetAttr[name="weight"](%84)
      %118 : Tensor? = prim::GetAttr[name="bias"](%84)
      %input.53 : Tensor = aten::conv2d(%input.52, %117, %118, %2959, %2960, %2960, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %123 : bool = prim::GetAttr[name="training"](%85)
       = prim::If(%123) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %124 : Tensor = prim::GetAttr[name="num_batches_tracked"](%85)
          %125 : Tensor = aten::add(%124, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%85, %125)
          -> ()
        block1():
          -> ()
      %126 : bool = prim::GetAttr[name="training"](%85)
      %127 : Tensor = prim::GetAttr[name="running_mean"](%85)
      %128 : Tensor = prim::GetAttr[name="running_var"](%85)
      %129 : Tensor = prim::GetAttr[name="weight"](%85)
      %130 : Tensor = prim::GetAttr[name="bias"](%85)
       = prim::If(%126) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %131 : int[] = aten::size(%input.53) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.32 : int = aten::__getitem__(%131, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %133 : int = aten::len(%131) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %134 : int = aten::sub(%133, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.33 : int = prim::Loop(%134, %10, %size_prods.32) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.9 : int, %size_prods.34 : int):
              %138 : int = aten::add(%i.9, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %139 : int = aten::__getitem__(%131, %138) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.35 : int = aten::mul(%size_prods.34, %139) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.35)
          %141 : bool = aten::eq(%size_prods.33, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%141) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %142 : str = aten::format(%8, %131) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%142) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.54 : Tensor = aten::batch_norm(%input.53, %129, %130, %127, %128, %126, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %144 : int[] = aten::size(%input.54) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.3 : int, %c.3 : int, %147 : int, %148 : int = prim::ListUnpack(%144)
      %151 : int = aten::len(%144) # <string>:5:9
      %152 : bool = aten::gt(%151, %22) # <string>:5:9
       = prim::If(%152) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %153 : Tensor = aten::adaptive_avg_pool2d(%input.54, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %154 : int[] = prim::ListConstruct(%b.3, %c.3)
      %y.5 : Tensor = aten::view(%153, %154) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %156 : __torch__.torch.nn.modules.container.___torch_mangle_3.Sequential = prim::GetAttr[name="fc"](%86)
      %157 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="0"](%156)
      %158 : __torch__.torch.nn.modules.linear.___torch_mangle_2.Linear = prim::GetAttr[name="2"](%156)
      %159 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%156)
      %160 : Tensor = prim::GetAttr[name="weight"](%157)
      %input.84 : Tensor = aten::linear(%y.5, %160, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.85 : Tensor = aten::relu_(%input.84) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %163 : Tensor = prim::GetAttr[name="weight"](%158)
      %input.86 : Tensor = aten::linear(%input.85, %163, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %165 : Tensor = aten::add(%input.86, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %166 : bool = prim::GetAttr[name="inplace"](%159)
      %result.25 : Tensor = prim::If(%166) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.19 : Tensor = aten::hardtanh_(%165, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.19)
        block1():
          %result.20 : Tensor = aten::hardtanh(%165, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.20)
      %input.87 : Tensor = aten::div(%result.25, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %171 : int[] = prim::ListConstruct(%b.3, %c.3, %11, %11)
      %y.6 : Tensor = aten::view(%input.87, %171) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %173 : Tensor = aten::expand_as(%y.6, %input.54) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.88 : Tensor = aten::mul(%input.54, %173) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %input.89 : Tensor = aten::relu_(%input.88) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %176 : Tensor = prim::GetAttr[name="weight"](%87)
      %177 : Tensor? = prim::GetAttr[name="bias"](%87)
      %input.90 : Tensor = aten::conv2d(%input.89, %176, %177, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %182 : bool = prim::GetAttr[name="training"](%88)
       = prim::If(%182) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %183 : Tensor = prim::GetAttr[name="num_batches_tracked"](%88)
          %184 : Tensor = aten::add(%183, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%88, %184)
          -> ()
        block1():
          -> ()
      %185 : bool = prim::GetAttr[name="training"](%88)
      %186 : Tensor = prim::GetAttr[name="running_mean"](%88)
      %187 : Tensor = prim::GetAttr[name="running_var"](%88)
      %188 : Tensor = prim::GetAttr[name="weight"](%88)
      %189 : Tensor = prim::GetAttr[name="bias"](%88)
       = prim::If(%185) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %190 : int[] = aten::size(%input.90) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.36 : int = aten::__getitem__(%190, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %192 : int = aten::len(%190) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %193 : int = aten::sub(%192, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.37 : int = prim::Loop(%193, %10, %size_prods.36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.10 : int, %size_prods.38 : int):
              %197 : int = aten::add(%i.10, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %198 : int = aten::__getitem__(%190, %197) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.39 : int = aten::mul(%size_prods.38, %198) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.39)
          %200 : bool = aten::eq(%size_prods.37, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%200) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %201 : str = aten::format(%8, %190) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%201) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.91 : Tensor = aten::batch_norm(%input.90, %188, %189, %186, %187, %185, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %203 : Tensor = aten::add(%input.41, %input.91, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:113:19
      -> (%203)
    block1():
      %204 : __torch__.torch.nn.modules.container.___torch_mangle_4.Sequential = prim::GetAttr[name="conv"](%28)
      %205 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="0"](%204)
      %206 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%204)
      %207 : __torch__.torch.nn.modules.conv.___torch_mangle_1.Conv2d = prim::GetAttr[name="3"](%204)
      %208 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="4"](%204)
      %209 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.SEModule = prim::GetAttr[name="5"](%204)
      %210 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="7"](%204)
      %211 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="8"](%204)
      %212 : Tensor = prim::GetAttr[name="weight"](%205)
      %213 : Tensor? = prim::GetAttr[name="bias"](%205)
      %input.47 : Tensor = aten::conv2d(%input.41, %212, %213, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %218 : bool = prim::GetAttr[name="training"](%206)
       = prim::If(%218) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %219 : Tensor = prim::GetAttr[name="num_batches_tracked"](%206)
          %220 : Tensor = aten::add(%219, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%206, %220)
          -> ()
        block1():
          -> ()
      %221 : bool = prim::GetAttr[name="training"](%206)
      %222 : Tensor = prim::GetAttr[name="running_mean"](%206)
      %223 : Tensor = prim::GetAttr[name="running_var"](%206)
      %224 : Tensor = prim::GetAttr[name="weight"](%206)
      %225 : Tensor = prim::GetAttr[name="bias"](%206)
       = prim::If(%221) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %226 : int[] = aten::size(%input.47) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.40 : int = aten::__getitem__(%226, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %228 : int = aten::len(%226) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %229 : int = aten::sub(%228, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.41 : int = prim::Loop(%229, %10, %size_prods.40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.11 : int, %size_prods.42 : int):
              %233 : int = aten::add(%i.11, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %234 : int = aten::__getitem__(%226, %233) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.43 : int = aten::mul(%size_prods.42, %234) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.43)
          %236 : bool = aten::eq(%size_prods.41, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%236) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %237 : str = aten::format(%8, %226) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%237) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.48 : Tensor = aten::batch_norm(%input.47, %224, %225, %222, %223, %221, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.49 : Tensor = aten::relu_(%input.48) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %240 : Tensor = prim::GetAttr[name="weight"](%207)
      %241 : Tensor? = prim::GetAttr[name="bias"](%207)
      %input.50 : Tensor = aten::conv2d(%input.49, %240, %241, %2959, %2960, %2960, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %246 : bool = prim::GetAttr[name="training"](%208)
       = prim::If(%246) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %247 : Tensor = prim::GetAttr[name="num_batches_tracked"](%208)
          %248 : Tensor = aten::add(%247, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%208, %248)
          -> ()
        block1():
          -> ()
      %249 : bool = prim::GetAttr[name="training"](%208)
      %250 : Tensor = prim::GetAttr[name="running_mean"](%208)
      %251 : Tensor = prim::GetAttr[name="running_var"](%208)
      %252 : Tensor = prim::GetAttr[name="weight"](%208)
      %253 : Tensor = prim::GetAttr[name="bias"](%208)
       = prim::If(%249) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %254 : int[] = aten::size(%input.50) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.44 : int = aten::__getitem__(%254, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %256 : int = aten::len(%254) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %257 : int = aten::sub(%256, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.45 : int = prim::Loop(%257, %10, %size_prods.44) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.12 : int, %size_prods.46 : int):
              %261 : int = aten::add(%i.12, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %262 : int = aten::__getitem__(%254, %261) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.47 : int = aten::mul(%size_prods.46, %262) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.47)
          %264 : bool = aten::eq(%size_prods.45, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%264) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %265 : str = aten::format(%8, %254) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%265) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.96 : Tensor = aten::batch_norm(%input.50, %252, %253, %250, %251, %249, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %267 : int[] = aten::size(%input.96) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.4 : int, %c.4 : int, %270 : int, %271 : int = prim::ListUnpack(%267)
      %274 : int = aten::len(%267) # <string>:5:9
      %275 : bool = aten::gt(%274, %22) # <string>:5:9
       = prim::If(%275) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %276 : Tensor = aten::adaptive_avg_pool2d(%input.96, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %277 : int[] = prim::ListConstruct(%b.4, %c.4)
      %y.7 : Tensor = aten::view(%276, %277) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %279 : __torch__.torch.nn.modules.container.___torch_mangle_3.Sequential = prim::GetAttr[name="fc"](%209)
      %280 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="0"](%279)
      %281 : __torch__.torch.nn.modules.linear.___torch_mangle_2.Linear = prim::GetAttr[name="2"](%279)
      %282 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%279)
      %283 : Tensor = prim::GetAttr[name="weight"](%280)
      %input.55 : Tensor = aten::linear(%y.7, %283, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.56 : Tensor = aten::relu_(%input.55) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %286 : Tensor = prim::GetAttr[name="weight"](%281)
      %input.57 : Tensor = aten::linear(%input.56, %286, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %288 : Tensor = aten::add(%input.57, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %289 : bool = prim::GetAttr[name="inplace"](%282)
      %result.24 : Tensor = prim::If(%289) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.18 : Tensor = aten::hardtanh_(%288, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.18)
        block1():
          %result.26 : Tensor = aten::hardtanh(%288, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.26)
      %input.58 : Tensor = aten::div(%result.24, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %294 : int[] = prim::ListConstruct(%b.4, %c.4, %11, %11)
      %y.8 : Tensor = aten::view(%input.58, %294) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %296 : Tensor = aten::expand_as(%y.8, %input.96) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.59 : Tensor = aten::mul(%input.96, %296) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %input.60 : Tensor = aten::relu_(%input.59) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %299 : Tensor = prim::GetAttr[name="weight"](%210)
      %300 : Tensor? = prim::GetAttr[name="bias"](%210)
      %input.61 : Tensor = aten::conv2d(%input.60, %299, %300, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %305 : bool = prim::GetAttr[name="training"](%211)
       = prim::If(%305) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %306 : Tensor = prim::GetAttr[name="num_batches_tracked"](%211)
          %307 : Tensor = aten::add(%306, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%211, %307)
          -> ()
        block1():
          -> ()
      %308 : bool = prim::GetAttr[name="training"](%211)
      %309 : Tensor = prim::GetAttr[name="running_mean"](%211)
      %310 : Tensor = prim::GetAttr[name="running_var"](%211)
      %311 : Tensor = prim::GetAttr[name="weight"](%211)
      %312 : Tensor = prim::GetAttr[name="bias"](%211)
       = prim::If(%308) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %313 : int[] = aten::size(%input.61) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.48 : int = aten::__getitem__(%313, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %315 : int = aten::len(%313) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %316 : int = aten::sub(%315, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.49 : int = prim::Loop(%316, %10, %size_prods.48) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.13 : int, %size_prods.50 : int):
              %320 : int = aten::add(%i.13, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %321 : int = aten::__getitem__(%313, %320) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.51 : int = aten::mul(%size_prods.50, %321) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.51)
          %323 : bool = aten::eq(%size_prods.49, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%323) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %324 : str = aten::format(%8, %313) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%324) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.62 : Tensor = aten::batch_norm(%input.61, %311, %312, %309, %310, %308, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.62)
  %326 : bool = prim::GetAttr[name="use_res_connect"](%29)
  %input.36 : Tensor = prim::If(%326) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:112:8
    block0():
      %328 : __torch__.torch.nn.modules.container.___torch_mangle_10.Sequential = prim::GetAttr[name="conv"](%29)
      %329 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="0"](%328)
      %330 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d = prim::GetAttr[name="1"](%328)
      %331 : __torch__.torch.nn.modules.conv.___torch_mangle_7.Conv2d = prim::GetAttr[name="3"](%328)
      %332 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d = prim::GetAttr[name="4"](%328)
      %333 : __torch__.torch.nn.modules.conv.___torch_mangle_8.Conv2d = prim::GetAttr[name="7"](%328)
      %334 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_9.BatchNorm2d = prim::GetAttr[name="8"](%328)
      %335 : Tensor = prim::GetAttr[name="weight"](%329)
      %336 : Tensor? = prim::GetAttr[name="bias"](%329)
      %input.63 : Tensor = aten::conv2d(%input.37, %335, %336, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %341 : bool = prim::GetAttr[name="training"](%330)
       = prim::If(%341) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %342 : Tensor = prim::GetAttr[name="num_batches_tracked"](%330)
          %343 : Tensor = aten::add(%342, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%330, %343)
          -> ()
        block1():
          -> ()
      %344 : bool = prim::GetAttr[name="training"](%330)
      %345 : Tensor = prim::GetAttr[name="running_mean"](%330)
      %346 : Tensor = prim::GetAttr[name="running_var"](%330)
      %347 : Tensor = prim::GetAttr[name="weight"](%330)
      %348 : Tensor = prim::GetAttr[name="bias"](%330)
       = prim::If(%344) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %349 : int[] = aten::size(%input.63) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.52 : int = aten::__getitem__(%349, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %351 : int = aten::len(%349) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %352 : int = aten::sub(%351, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.53 : int = prim::Loop(%352, %10, %size_prods.52) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.14 : int, %size_prods.54 : int):
              %356 : int = aten::add(%i.14, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %357 : int = aten::__getitem__(%349, %356) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.55 : int = aten::mul(%size_prods.54, %357) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.55)
          %359 : bool = aten::eq(%size_prods.53, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%359) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %360 : str = aten::format(%8, %349) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%360) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.64 : Tensor = aten::batch_norm(%input.63, %347, %348, %345, %346, %344, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.65 : Tensor = aten::relu_(%input.64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %363 : Tensor = prim::GetAttr[name="weight"](%331)
      %364 : Tensor? = prim::GetAttr[name="bias"](%331)
      %input.66 : Tensor = aten::conv2d(%input.65, %363, %364, %2959, %2960, %2960, %14) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %369 : bool = prim::GetAttr[name="training"](%332)
       = prim::If(%369) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %370 : Tensor = prim::GetAttr[name="num_batches_tracked"](%332)
          %371 : Tensor = aten::add(%370, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%332, %371)
          -> ()
        block1():
          -> ()
      %372 : bool = prim::GetAttr[name="training"](%332)
      %373 : Tensor = prim::GetAttr[name="running_mean"](%332)
      %374 : Tensor = prim::GetAttr[name="running_var"](%332)
      %375 : Tensor = prim::GetAttr[name="weight"](%332)
      %376 : Tensor = prim::GetAttr[name="bias"](%332)
       = prim::If(%372) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %377 : int[] = aten::size(%input.66) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.56 : int = aten::__getitem__(%377, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %379 : int = aten::len(%377) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %380 : int = aten::sub(%379, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.57 : int = prim::Loop(%380, %10, %size_prods.56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.15 : int, %size_prods.58 : int):
              %384 : int = aten::add(%i.15, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %385 : int = aten::__getitem__(%377, %384) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.59 : int = aten::mul(%size_prods.58, %385) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.59)
          %387 : bool = aten::eq(%size_prods.57, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%387) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %388 : str = aten::format(%8, %377) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%388) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.67 : Tensor = aten::batch_norm(%input.66, %375, %376, %373, %374, %372, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.68 : Tensor = aten::relu_(%input.67) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %391 : Tensor = prim::GetAttr[name="weight"](%333)
      %392 : Tensor? = prim::GetAttr[name="bias"](%333)
      %input.69 : Tensor = aten::conv2d(%input.68, %391, %392, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %397 : bool = prim::GetAttr[name="training"](%334)
       = prim::If(%397) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %398 : Tensor = prim::GetAttr[name="num_batches_tracked"](%334)
          %399 : Tensor = aten::add(%398, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%334, %399)
          -> ()
        block1():
          -> ()
      %400 : bool = prim::GetAttr[name="training"](%334)
      %401 : Tensor = prim::GetAttr[name="running_mean"](%334)
      %402 : Tensor = prim::GetAttr[name="running_var"](%334)
      %403 : Tensor = prim::GetAttr[name="weight"](%334)
      %404 : Tensor = prim::GetAttr[name="bias"](%334)
       = prim::If(%400) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %405 : int[] = aten::size(%input.69) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.60 : int = aten::__getitem__(%405, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %407 : int = aten::len(%405) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %408 : int = aten::sub(%407, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.61 : int = prim::Loop(%408, %10, %size_prods.60) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.16 : int, %size_prods.62 : int):
              %412 : int = aten::add(%i.16, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %413 : int = aten::__getitem__(%405, %412) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.63 : int = aten::mul(%size_prods.62, %413) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.63)
          %415 : bool = aten::eq(%size_prods.61, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%415) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %416 : str = aten::format(%8, %405) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%416) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.70 : Tensor = aten::batch_norm(%input.69, %403, %404, %401, %402, %400, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %418 : Tensor = aten::add(%input.37, %input.70, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:113:19
      -> (%418)
    block1():
      %419 : __torch__.torch.nn.modules.container.___torch_mangle_10.Sequential = prim::GetAttr[name="conv"](%29)
      %420 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="0"](%419)
      %421 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d = prim::GetAttr[name="1"](%419)
      %422 : __torch__.torch.nn.modules.conv.___torch_mangle_7.Conv2d = prim::GetAttr[name="3"](%419)
      %423 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d = prim::GetAttr[name="4"](%419)
      %424 : __torch__.torch.nn.modules.conv.___torch_mangle_8.Conv2d = prim::GetAttr[name="7"](%419)
      %425 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_9.BatchNorm2d = prim::GetAttr[name="8"](%419)
      %426 : Tensor = prim::GetAttr[name="weight"](%420)
      %427 : Tensor? = prim::GetAttr[name="bias"](%420)
      %input.71 : Tensor = aten::conv2d(%input.37, %426, %427, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %432 : bool = prim::GetAttr[name="training"](%421)
       = prim::If(%432) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %433 : Tensor = prim::GetAttr[name="num_batches_tracked"](%421)
          %434 : Tensor = aten::add(%433, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%421, %434)
          -> ()
        block1():
          -> ()
      %435 : bool = prim::GetAttr[name="training"](%421)
      %436 : Tensor = prim::GetAttr[name="running_mean"](%421)
      %437 : Tensor = prim::GetAttr[name="running_var"](%421)
      %438 : Tensor = prim::GetAttr[name="weight"](%421)
      %439 : Tensor = prim::GetAttr[name="bias"](%421)
       = prim::If(%435) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %440 : int[] = aten::size(%input.71) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.64 : int = aten::__getitem__(%440, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %442 : int = aten::len(%440) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %443 : int = aten::sub(%442, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.65 : int = prim::Loop(%443, %10, %size_prods.64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.17 : int, %size_prods.66 : int):
              %447 : int = aten::add(%i.17, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %448 : int = aten::__getitem__(%440, %447) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.67 : int = aten::mul(%size_prods.66, %448) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.67)
          %450 : bool = aten::eq(%size_prods.65, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%450) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %451 : str = aten::format(%8, %440) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%451) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.72 : Tensor = aten::batch_norm(%input.71, %438, %439, %436, %437, %435, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.73 : Tensor = aten::relu_(%input.72) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %454 : Tensor = prim::GetAttr[name="weight"](%422)
      %455 : Tensor? = prim::GetAttr[name="bias"](%422)
      %input.74 : Tensor = aten::conv2d(%input.73, %454, %455, %2959, %2960, %2960, %14) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %460 : bool = prim::GetAttr[name="training"](%423)
       = prim::If(%460) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %461 : Tensor = prim::GetAttr[name="num_batches_tracked"](%423)
          %462 : Tensor = aten::add(%461, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%423, %462)
          -> ()
        block1():
          -> ()
      %463 : bool = prim::GetAttr[name="training"](%423)
      %464 : Tensor = prim::GetAttr[name="running_mean"](%423)
      %465 : Tensor = prim::GetAttr[name="running_var"](%423)
      %466 : Tensor = prim::GetAttr[name="weight"](%423)
      %467 : Tensor = prim::GetAttr[name="bias"](%423)
       = prim::If(%463) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %468 : int[] = aten::size(%input.74) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.68 : int = aten::__getitem__(%468, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %470 : int = aten::len(%468) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %471 : int = aten::sub(%470, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.69 : int = prim::Loop(%471, %10, %size_prods.68) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.18 : int, %size_prods.70 : int):
              %475 : int = aten::add(%i.18, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %476 : int = aten::__getitem__(%468, %475) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.71 : int = aten::mul(%size_prods.70, %476) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.71)
          %478 : bool = aten::eq(%size_prods.69, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%478) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %479 : str = aten::format(%8, %468) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%479) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.75 : Tensor = aten::batch_norm(%input.74, %466, %467, %464, %465, %463, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.76 : Tensor = aten::relu_(%input.75) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %482 : Tensor = prim::GetAttr[name="weight"](%424)
      %483 : Tensor? = prim::GetAttr[name="bias"](%424)
      %input.77 : Tensor = aten::conv2d(%input.76, %482, %483, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %488 : bool = prim::GetAttr[name="training"](%425)
       = prim::If(%488) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %489 : Tensor = prim::GetAttr[name="num_batches_tracked"](%425)
          %490 : Tensor = aten::add(%489, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%425, %490)
          -> ()
        block1():
          -> ()
      %491 : bool = prim::GetAttr[name="training"](%425)
      %492 : Tensor = prim::GetAttr[name="running_mean"](%425)
      %493 : Tensor = prim::GetAttr[name="running_var"](%425)
      %494 : Tensor = prim::GetAttr[name="weight"](%425)
      %495 : Tensor = prim::GetAttr[name="bias"](%425)
       = prim::If(%491) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %496 : int[] = aten::size(%input.77) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.72 : int = aten::__getitem__(%496, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %498 : int = aten::len(%496) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %499 : int = aten::sub(%498, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.73 : int = prim::Loop(%499, %10, %size_prods.72) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.19 : int, %size_prods.74 : int):
              %503 : int = aten::add(%i.19, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %504 : int = aten::__getitem__(%496, %503) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.75 : int = aten::mul(%size_prods.74, %504) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.75)
          %506 : bool = aten::eq(%size_prods.73, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%506) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %507 : str = aten::format(%8, %496) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%507) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.78 : Tensor = aten::batch_norm(%input.77, %494, %495, %492, %493, %491, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.78)
  %509 : bool = prim::GetAttr[name="use_res_connect"](%30)
  %input.42 : Tensor = prim::If(%509) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:112:8
    block0():
      %511 : __torch__.torch.nn.modules.container.___torch_mangle_16.Sequential = prim::GetAttr[name="conv"](%30)
      %512 : __torch__.torch.nn.modules.conv.___torch_mangle_12.Conv2d = prim::GetAttr[name="0"](%511)
      %513 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%511)
      %514 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="3"](%511)
      %515 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%511)
      %516 : __torch__.torch.nn.modules.conv.___torch_mangle_15.Conv2d = prim::GetAttr[name="7"](%511)
      %517 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_9.BatchNorm2d = prim::GetAttr[name="8"](%511)
      %518 : Tensor = prim::GetAttr[name="weight"](%512)
      %519 : Tensor? = prim::GetAttr[name="bias"](%512)
      %input.92 : Tensor = aten::conv2d(%input.36, %518, %519, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %524 : bool = prim::GetAttr[name="training"](%513)
       = prim::If(%524) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %525 : Tensor = prim::GetAttr[name="num_batches_tracked"](%513)
          %526 : Tensor = aten::add(%525, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%513, %526)
          -> ()
        block1():
          -> ()
      %527 : bool = prim::GetAttr[name="training"](%513)
      %528 : Tensor = prim::GetAttr[name="running_mean"](%513)
      %529 : Tensor = prim::GetAttr[name="running_var"](%513)
      %530 : Tensor = prim::GetAttr[name="weight"](%513)
      %531 : Tensor = prim::GetAttr[name="bias"](%513)
       = prim::If(%527) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %532 : int[] = aten::size(%input.92) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.76 : int = aten::__getitem__(%532, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %534 : int = aten::len(%532) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %535 : int = aten::sub(%534, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.77 : int = prim::Loop(%535, %10, %size_prods.76) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.20 : int, %size_prods.78 : int):
              %539 : int = aten::add(%i.20, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %540 : int = aten::__getitem__(%532, %539) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.79 : int = aten::mul(%size_prods.78, %540) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.79)
          %542 : bool = aten::eq(%size_prods.77, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%542) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %543 : str = aten::format(%8, %532) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%543) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.93 : Tensor = aten::batch_norm(%input.92, %530, %531, %528, %529, %527, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.94 : Tensor = aten::relu_(%input.93) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %546 : Tensor = prim::GetAttr[name="weight"](%514)
      %547 : Tensor? = prim::GetAttr[name="bias"](%514)
      %input.95 : Tensor = aten::conv2d(%input.94, %546, %547, %2960, %2960, %2960, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %552 : bool = prim::GetAttr[name="training"](%515)
       = prim::If(%552) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %553 : Tensor = prim::GetAttr[name="num_batches_tracked"](%515)
          %554 : Tensor = aten::add(%553, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%515, %554)
          -> ()
        block1():
          -> ()
      %555 : bool = prim::GetAttr[name="training"](%515)
      %556 : Tensor = prim::GetAttr[name="running_mean"](%515)
      %557 : Tensor = prim::GetAttr[name="running_var"](%515)
      %558 : Tensor = prim::GetAttr[name="weight"](%515)
      %559 : Tensor = prim::GetAttr[name="bias"](%515)
       = prim::If(%555) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %560 : int[] = aten::size(%input.95) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.80 : int = aten::__getitem__(%560, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %562 : int = aten::len(%560) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %563 : int = aten::sub(%562, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.81 : int = prim::Loop(%563, %10, %size_prods.80) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.21 : int, %size_prods.82 : int):
              %567 : int = aten::add(%i.21, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %568 : int = aten::__getitem__(%560, %567) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.83 : int = aten::mul(%size_prods.82, %568) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.83)
          %570 : bool = aten::eq(%size_prods.81, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%570) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %571 : str = aten::format(%8, %560) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%571) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.80 : Tensor = aten::batch_norm(%input.95, %558, %559, %556, %557, %555, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.81 : Tensor = aten::relu_(%input.80) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %574 : Tensor = prim::GetAttr[name="weight"](%516)
      %575 : Tensor? = prim::GetAttr[name="bias"](%516)
      %input.82 : Tensor = aten::conv2d(%input.81, %574, %575, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %580 : bool = prim::GetAttr[name="training"](%517)
       = prim::If(%580) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %581 : Tensor = prim::GetAttr[name="num_batches_tracked"](%517)
          %582 : Tensor = aten::add(%581, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%517, %582)
          -> ()
        block1():
          -> ()
      %583 : bool = prim::GetAttr[name="training"](%517)
      %584 : Tensor = prim::GetAttr[name="running_mean"](%517)
      %585 : Tensor = prim::GetAttr[name="running_var"](%517)
      %586 : Tensor = prim::GetAttr[name="weight"](%517)
      %587 : Tensor = prim::GetAttr[name="bias"](%517)
       = prim::If(%583) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %588 : int[] = aten::size(%input.82) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.84 : int = aten::__getitem__(%588, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %590 : int = aten::len(%588) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %591 : int = aten::sub(%590, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.85 : int = prim::Loop(%591, %10, %size_prods.84) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.22 : int, %size_prods.86 : int):
              %595 : int = aten::add(%i.22, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %596 : int = aten::__getitem__(%588, %595) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.87 : int = aten::mul(%size_prods.86, %596) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.87)
          %598 : bool = aten::eq(%size_prods.85, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%598) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %599 : str = aten::format(%8, %588) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%599) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.83 : Tensor = aten::batch_norm(%input.82, %586, %587, %584, %585, %583, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %601 : Tensor = aten::add(%input.36, %input.83, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:113:19
      -> (%601)
    block1():
      %602 : __torch__.torch.nn.modules.container.___torch_mangle_16.Sequential = prim::GetAttr[name="conv"](%30)
      %603 : __torch__.torch.nn.modules.conv.___torch_mangle_12.Conv2d = prim::GetAttr[name="0"](%602)
      %604 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%602)
      %605 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="3"](%602)
      %606 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%602)
      %607 : __torch__.torch.nn.modules.conv.___torch_mangle_15.Conv2d = prim::GetAttr[name="7"](%602)
      %608 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_9.BatchNorm2d = prim::GetAttr[name="8"](%602)
      %609 : Tensor = prim::GetAttr[name="weight"](%603)
      %610 : Tensor? = prim::GetAttr[name="bias"](%603)
      %input.97 : Tensor = aten::conv2d(%input.36, %609, %610, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %615 : bool = prim::GetAttr[name="training"](%604)
       = prim::If(%615) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %616 : Tensor = prim::GetAttr[name="num_batches_tracked"](%604)
          %617 : Tensor = aten::add(%616, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%604, %617)
          -> ()
        block1():
          -> ()
      %618 : bool = prim::GetAttr[name="training"](%604)
      %619 : Tensor = prim::GetAttr[name="running_mean"](%604)
      %620 : Tensor = prim::GetAttr[name="running_var"](%604)
      %621 : Tensor = prim::GetAttr[name="weight"](%604)
      %622 : Tensor = prim::GetAttr[name="bias"](%604)
       = prim::If(%618) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %623 : int[] = aten::size(%input.97) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.88 : int = aten::__getitem__(%623, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %625 : int = aten::len(%623) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %626 : int = aten::sub(%625, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.89 : int = prim::Loop(%626, %10, %size_prods.88) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.23 : int, %size_prods.90 : int):
              %630 : int = aten::add(%i.23, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %631 : int = aten::__getitem__(%623, %630) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.91 : int = aten::mul(%size_prods.90, %631) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.91)
          %633 : bool = aten::eq(%size_prods.89, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%633) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %634 : str = aten::format(%8, %623) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%634) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.98 : Tensor = aten::batch_norm(%input.97, %621, %622, %619, %620, %618, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.99 : Tensor = aten::relu_(%input.98) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %637 : Tensor = prim::GetAttr[name="weight"](%605)
      %638 : Tensor? = prim::GetAttr[name="bias"](%605)
      %input.100 : Tensor = aten::conv2d(%input.99, %637, %638, %2960, %2960, %2960, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %643 : bool = prim::GetAttr[name="training"](%606)
       = prim::If(%643) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %644 : Tensor = prim::GetAttr[name="num_batches_tracked"](%606)
          %645 : Tensor = aten::add(%644, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%606, %645)
          -> ()
        block1():
          -> ()
      %646 : bool = prim::GetAttr[name="training"](%606)
      %647 : Tensor = prim::GetAttr[name="running_mean"](%606)
      %648 : Tensor = prim::GetAttr[name="running_var"](%606)
      %649 : Tensor = prim::GetAttr[name="weight"](%606)
      %650 : Tensor = prim::GetAttr[name="bias"](%606)
       = prim::If(%646) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %651 : int[] = aten::size(%input.100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.92 : int = aten::__getitem__(%651, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %653 : int = aten::len(%651) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %654 : int = aten::sub(%653, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.93 : int = prim::Loop(%654, %10, %size_prods.92) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.24 : int, %size_prods.94 : int):
              %658 : int = aten::add(%i.24, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %659 : int = aten::__getitem__(%651, %658) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.95 : int = aten::mul(%size_prods.94, %659) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.95)
          %661 : bool = aten::eq(%size_prods.93, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%661) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %662 : str = aten::format(%8, %651) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%662) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.101 : Tensor = aten::batch_norm(%input.100, %649, %650, %647, %648, %646, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.102 : Tensor = aten::relu_(%input.101) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %665 : Tensor = prim::GetAttr[name="weight"](%607)
      %666 : Tensor? = prim::GetAttr[name="bias"](%607)
      %input.103 : Tensor = aten::conv2d(%input.102, %665, %666, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %671 : bool = prim::GetAttr[name="training"](%608)
       = prim::If(%671) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %672 : Tensor = prim::GetAttr[name="num_batches_tracked"](%608)
          %673 : Tensor = aten::add(%672, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%608, %673)
          -> ()
        block1():
          -> ()
      %674 : bool = prim::GetAttr[name="training"](%608)
      %675 : Tensor = prim::GetAttr[name="running_mean"](%608)
      %676 : Tensor = prim::GetAttr[name="running_var"](%608)
      %677 : Tensor = prim::GetAttr[name="weight"](%608)
      %678 : Tensor = prim::GetAttr[name="bias"](%608)
       = prim::If(%674) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %679 : int[] = aten::size(%input.103) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.96 : int = aten::__getitem__(%679, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %681 : int = aten::len(%679) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %682 : int = aten::sub(%681, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.97 : int = prim::Loop(%682, %10, %size_prods.96) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.25 : int, %size_prods.98 : int):
              %686 : int = aten::add(%i.25, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %687 : int = aten::__getitem__(%679, %686) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.99 : int = aten::mul(%size_prods.98, %687) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.99)
          %689 : bool = aten::eq(%size_prods.97, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%689) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %690 : str = aten::format(%8, %679) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%690) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.104 : Tensor = aten::batch_norm(%input.103, %677, %678, %675, %676, %674, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.104)
  %692 : bool = prim::GetAttr[name="use_res_connect"](%31)
  %input.38 : Tensor = prim::If(%692) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:112:8
    block0():
      %694 : __torch__.torch.nn.modules.container.___torch_mangle_27.Sequential = prim::GetAttr[name="conv"](%31)
      %695 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="0"](%694)
      %696 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_19.BatchNorm2d = prim::GetAttr[name="1"](%694)
      %697 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%694)
      %698 : __torch__.torch.nn.modules.conv.___torch_mangle_20.Conv2d = prim::GetAttr[name="3"](%694)
      %699 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_19.BatchNorm2d = prim::GetAttr[name="4"](%694)
      %700 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_24.SEModule = prim::GetAttr[name="5"](%694)
      %701 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="6"](%694)
      %702 : __torch__.torch.nn.modules.conv.___torch_mangle_25.Conv2d = prim::GetAttr[name="7"](%694)
      %703 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_26.BatchNorm2d = prim::GetAttr[name="8"](%694)
      %704 : Tensor = prim::GetAttr[name="weight"](%695)
      %705 : Tensor? = prim::GetAttr[name="bias"](%695)
      %input.105 : Tensor = aten::conv2d(%input.42, %704, %705, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %710 : bool = prim::GetAttr[name="training"](%696)
       = prim::If(%710) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %711 : Tensor = prim::GetAttr[name="num_batches_tracked"](%696)
          %712 : Tensor = aten::add(%711, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%696, %712)
          -> ()
        block1():
          -> ()
      %713 : bool = prim::GetAttr[name="training"](%696)
      %714 : Tensor = prim::GetAttr[name="running_mean"](%696)
      %715 : Tensor = prim::GetAttr[name="running_var"](%696)
      %716 : Tensor = prim::GetAttr[name="weight"](%696)
      %717 : Tensor = prim::GetAttr[name="bias"](%696)
       = prim::If(%713) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %718 : int[] = aten::size(%input.105) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.100 : int = aten::__getitem__(%718, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %720 : int = aten::len(%718) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %721 : int = aten::sub(%720, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.101 : int = prim::Loop(%721, %10, %size_prods.100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.26 : int, %size_prods.102 : int):
              %725 : int = aten::add(%i.26, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %726 : int = aten::__getitem__(%718, %725) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.103 : int = aten::mul(%size_prods.102, %726) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.103)
          %728 : bool = aten::eq(%size_prods.101, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%728) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %729 : str = aten::format(%8, %718) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%729) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.106 : Tensor = aten::batch_norm(%input.105, %716, %717, %714, %715, %713, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %731 : Tensor = aten::add(%input.106, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %732 : bool = prim::GetAttr[name="inplace"](%697)
      %result.27 : Tensor = prim::If(%732) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.28 : Tensor = aten::hardtanh_(%731, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.28)
        block1():
          %result.29 : Tensor = aten::hardtanh(%731, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.29)
      %736 : Tensor = aten::mul(%input.106, %result.27) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.107 : Tensor = aten::div(%736, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %738 : Tensor = prim::GetAttr[name="weight"](%698)
      %739 : Tensor? = prim::GetAttr[name="bias"](%698)
      %input.108 : Tensor = aten::conv2d(%input.107, %738, %739, %2959, %2959, %2960, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %744 : bool = prim::GetAttr[name="training"](%699)
       = prim::If(%744) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %745 : Tensor = prim::GetAttr[name="num_batches_tracked"](%699)
          %746 : Tensor = aten::add(%745, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%699, %746)
          -> ()
        block1():
          -> ()
      %747 : bool = prim::GetAttr[name="training"](%699)
      %748 : Tensor = prim::GetAttr[name="running_mean"](%699)
      %749 : Tensor = prim::GetAttr[name="running_var"](%699)
      %750 : Tensor = prim::GetAttr[name="weight"](%699)
      %751 : Tensor = prim::GetAttr[name="bias"](%699)
       = prim::If(%747) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %752 : int[] = aten::size(%input.108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.104 : int = aten::__getitem__(%752, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %754 : int = aten::len(%752) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %755 : int = aten::sub(%754, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.105 : int = prim::Loop(%755, %10, %size_prods.104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.27 : int, %size_prods.106 : int):
              %759 : int = aten::add(%i.27, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %760 : int = aten::__getitem__(%752, %759) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.107 : int = aten::mul(%size_prods.106, %760) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.107)
          %762 : bool = aten::eq(%size_prods.105, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%762) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %763 : str = aten::format(%8, %752) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%763) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.109 : Tensor = aten::batch_norm(%input.108, %750, %751, %748, %749, %747, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %765 : int[] = aten::size(%input.109) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.5 : int, %c.5 : int, %768 : int, %769 : int = prim::ListUnpack(%765)
      %772 : int = aten::len(%765) # <string>:5:9
      %773 : bool = aten::gt(%772, %22) # <string>:5:9
       = prim::If(%773) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %774 : Tensor = aten::adaptive_avg_pool2d(%input.109, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %775 : int[] = prim::ListConstruct(%b.5, %c.5)
      %y.9 : Tensor = aten::view(%774, %775) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %777 : __torch__.torch.nn.modules.container.___torch_mangle_23.Sequential = prim::GetAttr[name="fc"](%700)
      %778 : __torch__.torch.nn.modules.linear.___torch_mangle_21.Linear = prim::GetAttr[name="0"](%777)
      %779 : __torch__.torch.nn.modules.linear.___torch_mangle_22.Linear = prim::GetAttr[name="2"](%777)
      %780 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%777)
      %781 : Tensor = prim::GetAttr[name="weight"](%778)
      %input.110 : Tensor = aten::linear(%y.9, %781, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.111 : Tensor = aten::relu_(%input.110) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %784 : Tensor = prim::GetAttr[name="weight"](%779)
      %input.112 : Tensor = aten::linear(%input.111, %784, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %786 : Tensor = aten::add(%input.112, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %787 : bool = prim::GetAttr[name="inplace"](%780)
      %result.30 : Tensor = prim::If(%787) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.31 : Tensor = aten::hardtanh_(%786, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.31)
        block1():
          %result.32 : Tensor = aten::hardtanh(%786, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.32)
      %input.113 : Tensor = aten::div(%result.30, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %792 : int[] = prim::ListConstruct(%b.5, %c.5, %11, %11)
      %y.10 : Tensor = aten::view(%input.113, %792) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %794 : Tensor = aten::expand_as(%y.10, %input.109) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.114 : Tensor = aten::mul(%input.109, %794) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %796 : Tensor = aten::add(%input.114, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %797 : bool = prim::GetAttr[name="inplace"](%701)
      %result.33 : Tensor = prim::If(%797) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.34 : Tensor = aten::hardtanh_(%796, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.34)
        block1():
          %result.35 : Tensor = aten::hardtanh(%796, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.35)
      %801 : Tensor = aten::mul(%input.114, %result.33) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.115 : Tensor = aten::div(%801, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %803 : Tensor = prim::GetAttr[name="weight"](%702)
      %804 : Tensor? = prim::GetAttr[name="bias"](%702)
      %input.116 : Tensor = aten::conv2d(%input.115, %803, %804, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %809 : bool = prim::GetAttr[name="training"](%703)
       = prim::If(%809) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %810 : Tensor = prim::GetAttr[name="num_batches_tracked"](%703)
          %811 : Tensor = aten::add(%810, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%703, %811)
          -> ()
        block1():
          -> ()
      %812 : bool = prim::GetAttr[name="training"](%703)
      %813 : Tensor = prim::GetAttr[name="running_mean"](%703)
      %814 : Tensor = prim::GetAttr[name="running_var"](%703)
      %815 : Tensor = prim::GetAttr[name="weight"](%703)
      %816 : Tensor = prim::GetAttr[name="bias"](%703)
       = prim::If(%812) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %817 : int[] = aten::size(%input.116) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.108 : int = aten::__getitem__(%817, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %819 : int = aten::len(%817) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %820 : int = aten::sub(%819, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.109 : int = prim::Loop(%820, %10, %size_prods.108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.28 : int, %size_prods.110 : int):
              %824 : int = aten::add(%i.28, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %825 : int = aten::__getitem__(%817, %824) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.111 : int = aten::mul(%size_prods.110, %825) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.111)
          %827 : bool = aten::eq(%size_prods.109, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%827) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %828 : str = aten::format(%8, %817) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%828) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.117 : Tensor = aten::batch_norm(%input.116, %815, %816, %813, %814, %812, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %830 : Tensor = aten::add(%input.42, %input.117, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:113:19
      -> (%830)
    block1():
      %831 : __torch__.torch.nn.modules.container.___torch_mangle_27.Sequential = prim::GetAttr[name="conv"](%31)
      %832 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="0"](%831)
      %833 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_19.BatchNorm2d = prim::GetAttr[name="1"](%831)
      %834 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%831)
      %835 : __torch__.torch.nn.modules.conv.___torch_mangle_20.Conv2d = prim::GetAttr[name="3"](%831)
      %836 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_19.BatchNorm2d = prim::GetAttr[name="4"](%831)
      %837 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_24.SEModule = prim::GetAttr[name="5"](%831)
      %838 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="6"](%831)
      %839 : __torch__.torch.nn.modules.conv.___torch_mangle_25.Conv2d = prim::GetAttr[name="7"](%831)
      %840 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_26.BatchNorm2d = prim::GetAttr[name="8"](%831)
      %841 : Tensor = prim::GetAttr[name="weight"](%832)
      %842 : Tensor? = prim::GetAttr[name="bias"](%832)
      %input.118 : Tensor = aten::conv2d(%input.42, %841, %842, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %847 : bool = prim::GetAttr[name="training"](%833)
       = prim::If(%847) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %848 : Tensor = prim::GetAttr[name="num_batches_tracked"](%833)
          %849 : Tensor = aten::add(%848, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%833, %849)
          -> ()
        block1():
          -> ()
      %850 : bool = prim::GetAttr[name="training"](%833)
      %851 : Tensor = prim::GetAttr[name="running_mean"](%833)
      %852 : Tensor = prim::GetAttr[name="running_var"](%833)
      %853 : Tensor = prim::GetAttr[name="weight"](%833)
      %854 : Tensor = prim::GetAttr[name="bias"](%833)
       = prim::If(%850) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %855 : int[] = aten::size(%input.118) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.112 : int = aten::__getitem__(%855, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %857 : int = aten::len(%855) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %858 : int = aten::sub(%857, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.113 : int = prim::Loop(%858, %10, %size_prods.112) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.29 : int, %size_prods.114 : int):
              %862 : int = aten::add(%i.29, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %863 : int = aten::__getitem__(%855, %862) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.115 : int = aten::mul(%size_prods.114, %863) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.115)
          %865 : bool = aten::eq(%size_prods.113, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%865) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %866 : str = aten::format(%8, %855) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%866) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.119 : Tensor = aten::batch_norm(%input.118, %853, %854, %851, %852, %850, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %868 : Tensor = aten::add(%input.119, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %869 : bool = prim::GetAttr[name="inplace"](%834)
      %result.36 : Tensor = prim::If(%869) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.37 : Tensor = aten::hardtanh_(%868, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.37)
        block1():
          %result.38 : Tensor = aten::hardtanh(%868, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.38)
      %873 : Tensor = aten::mul(%input.119, %result.36) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.120 : Tensor = aten::div(%873, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %875 : Tensor = prim::GetAttr[name="weight"](%835)
      %876 : Tensor? = prim::GetAttr[name="bias"](%835)
      %input.121 : Tensor = aten::conv2d(%input.120, %875, %876, %2959, %2959, %2960, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %881 : bool = prim::GetAttr[name="training"](%836)
       = prim::If(%881) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %882 : Tensor = prim::GetAttr[name="num_batches_tracked"](%836)
          %883 : Tensor = aten::add(%882, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%836, %883)
          -> ()
        block1():
          -> ()
      %884 : bool = prim::GetAttr[name="training"](%836)
      %885 : Tensor = prim::GetAttr[name="running_mean"](%836)
      %886 : Tensor = prim::GetAttr[name="running_var"](%836)
      %887 : Tensor = prim::GetAttr[name="weight"](%836)
      %888 : Tensor = prim::GetAttr[name="bias"](%836)
       = prim::If(%884) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %889 : int[] = aten::size(%input.121) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.116 : int = aten::__getitem__(%889, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %891 : int = aten::len(%889) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %892 : int = aten::sub(%891, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.117 : int = prim::Loop(%892, %10, %size_prods.116) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.30 : int, %size_prods.118 : int):
              %896 : int = aten::add(%i.30, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %897 : int = aten::__getitem__(%889, %896) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.119 : int = aten::mul(%size_prods.118, %897) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.119)
          %899 : bool = aten::eq(%size_prods.117, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%899) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %900 : str = aten::format(%8, %889) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%900) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.122 : Tensor = aten::batch_norm(%input.121, %887, %888, %885, %886, %884, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %902 : int[] = aten::size(%input.122) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.6 : int, %c.6 : int, %905 : int, %906 : int = prim::ListUnpack(%902)
      %909 : int = aten::len(%902) # <string>:5:9
      %910 : bool = aten::gt(%909, %22) # <string>:5:9
       = prim::If(%910) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %911 : Tensor = aten::adaptive_avg_pool2d(%input.122, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %912 : int[] = prim::ListConstruct(%b.6, %c.6)
      %y.11 : Tensor = aten::view(%911, %912) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %914 : __torch__.torch.nn.modules.container.___torch_mangle_23.Sequential = prim::GetAttr[name="fc"](%837)
      %915 : __torch__.torch.nn.modules.linear.___torch_mangle_21.Linear = prim::GetAttr[name="0"](%914)
      %916 : __torch__.torch.nn.modules.linear.___torch_mangle_22.Linear = prim::GetAttr[name="2"](%914)
      %917 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%914)
      %918 : Tensor = prim::GetAttr[name="weight"](%915)
      %input.123 : Tensor = aten::linear(%y.11, %918, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.124 : Tensor = aten::relu_(%input.123) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %921 : Tensor = prim::GetAttr[name="weight"](%916)
      %input.125 : Tensor = aten::linear(%input.124, %921, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %923 : Tensor = aten::add(%input.125, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %924 : bool = prim::GetAttr[name="inplace"](%917)
      %result.39 : Tensor = prim::If(%924) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.40 : Tensor = aten::hardtanh_(%923, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.40)
        block1():
          %result.41 : Tensor = aten::hardtanh(%923, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.41)
      %input.126 : Tensor = aten::div(%result.39, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %929 : int[] = prim::ListConstruct(%b.6, %c.6, %11, %11)
      %y.12 : Tensor = aten::view(%input.126, %929) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %931 : Tensor = aten::expand_as(%y.12, %input.122) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.127 : Tensor = aten::mul(%input.122, %931) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %933 : Tensor = aten::add(%input.127, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %934 : bool = prim::GetAttr[name="inplace"](%838)
      %result.42 : Tensor = prim::If(%934) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.43 : Tensor = aten::hardtanh_(%933, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.43)
        block1():
          %result.44 : Tensor = aten::hardtanh(%933, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.44)
      %938 : Tensor = aten::mul(%input.127, %result.42) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.128 : Tensor = aten::div(%938, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %940 : Tensor = prim::GetAttr[name="weight"](%839)
      %941 : Tensor? = prim::GetAttr[name="bias"](%839)
      %input.129 : Tensor = aten::conv2d(%input.128, %940, %941, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %946 : bool = prim::GetAttr[name="training"](%840)
       = prim::If(%946) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %947 : Tensor = prim::GetAttr[name="num_batches_tracked"](%840)
          %948 : Tensor = aten::add(%947, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%840, %948)
          -> ()
        block1():
          -> ()
      %949 : bool = prim::GetAttr[name="training"](%840)
      %950 : Tensor = prim::GetAttr[name="running_mean"](%840)
      %951 : Tensor = prim::GetAttr[name="running_var"](%840)
      %952 : Tensor = prim::GetAttr[name="weight"](%840)
      %953 : Tensor = prim::GetAttr[name="bias"](%840)
       = prim::If(%949) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %954 : int[] = aten::size(%input.129) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.120 : int = aten::__getitem__(%954, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %956 : int = aten::len(%954) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %957 : int = aten::sub(%956, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.121 : int = prim::Loop(%957, %10, %size_prods.120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.31 : int, %size_prods.122 : int):
              %961 : int = aten::add(%i.31, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %962 : int = aten::__getitem__(%954, %961) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.123 : int = aten::mul(%size_prods.122, %962) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.123)
          %964 : bool = aten::eq(%size_prods.121, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%964) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %965 : str = aten::format(%8, %954) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%965) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.130 : Tensor = aten::batch_norm(%input.129, %952, %953, %950, %951, %949, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.130)
  %967 : bool = prim::GetAttr[name="use_res_connect"](%32)
  %input.43 : Tensor = prim::If(%967) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:112:8
    block0():
      %969 : __torch__.torch.nn.modules.container.___torch_mangle_37.Sequential = prim::GetAttr[name="conv"](%32)
      %970 : __torch__.torch.nn.modules.conv.___torch_mangle_29.Conv2d = prim::GetAttr[name="0"](%969)
      %971 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_30.BatchNorm2d = prim::GetAttr[name="1"](%969)
      %972 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%969)
      %973 : __torch__.torch.nn.modules.conv.___torch_mangle_31.Conv2d = prim::GetAttr[name="3"](%969)
      %974 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_30.BatchNorm2d = prim::GetAttr[name="4"](%969)
      %975 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_35.SEModule = prim::GetAttr[name="5"](%969)
      %976 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="6"](%969)
      %977 : __torch__.torch.nn.modules.conv.___torch_mangle_36.Conv2d = prim::GetAttr[name="7"](%969)
      %978 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_26.BatchNorm2d = prim::GetAttr[name="8"](%969)
      %979 : Tensor = prim::GetAttr[name="weight"](%970)
      %980 : Tensor? = prim::GetAttr[name="bias"](%970)
      %input.131 : Tensor = aten::conv2d(%input.38, %979, %980, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %985 : bool = prim::GetAttr[name="training"](%971)
       = prim::If(%985) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %986 : Tensor = prim::GetAttr[name="num_batches_tracked"](%971)
          %987 : Tensor = aten::add(%986, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%971, %987)
          -> ()
        block1():
          -> ()
      %988 : bool = prim::GetAttr[name="training"](%971)
      %989 : Tensor = prim::GetAttr[name="running_mean"](%971)
      %990 : Tensor = prim::GetAttr[name="running_var"](%971)
      %991 : Tensor = prim::GetAttr[name="weight"](%971)
      %992 : Tensor = prim::GetAttr[name="bias"](%971)
       = prim::If(%988) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %993 : int[] = aten::size(%input.131) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.124 : int = aten::__getitem__(%993, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %995 : int = aten::len(%993) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %996 : int = aten::sub(%995, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.125 : int = prim::Loop(%996, %10, %size_prods.124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.32 : int, %size_prods.126 : int):
              %1000 : int = aten::add(%i.32, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1001 : int = aten::__getitem__(%993, %1000) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.127 : int = aten::mul(%size_prods.126, %1001) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.127)
          %1003 : bool = aten::eq(%size_prods.125, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1003) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1004 : str = aten::format(%8, %993) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1004) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.132 : Tensor = aten::batch_norm(%input.131, %991, %992, %989, %990, %988, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1006 : Tensor = aten::add(%input.132, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %1007 : bool = prim::GetAttr[name="inplace"](%972)
      %result.45 : Tensor = prim::If(%1007) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.46 : Tensor = aten::hardtanh_(%1006, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.46)
        block1():
          %result.47 : Tensor = aten::hardtanh(%1006, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.47)
      %1011 : Tensor = aten::mul(%input.132, %result.45) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.133 : Tensor = aten::div(%1011, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %1013 : Tensor = prim::GetAttr[name="weight"](%973)
      %1014 : Tensor? = prim::GetAttr[name="bias"](%973)
      %input.134 : Tensor = aten::conv2d(%input.133, %1013, %1014, %2960, %2959, %2960, %17) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1019 : bool = prim::GetAttr[name="training"](%974)
       = prim::If(%1019) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1020 : Tensor = prim::GetAttr[name="num_batches_tracked"](%974)
          %1021 : Tensor = aten::add(%1020, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%974, %1021)
          -> ()
        block1():
          -> ()
      %1022 : bool = prim::GetAttr[name="training"](%974)
      %1023 : Tensor = prim::GetAttr[name="running_mean"](%974)
      %1024 : Tensor = prim::GetAttr[name="running_var"](%974)
      %1025 : Tensor = prim::GetAttr[name="weight"](%974)
      %1026 : Tensor = prim::GetAttr[name="bias"](%974)
       = prim::If(%1022) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1027 : int[] = aten::size(%input.134) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.128 : int = aten::__getitem__(%1027, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1029 : int = aten::len(%1027) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1030 : int = aten::sub(%1029, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.129 : int = prim::Loop(%1030, %10, %size_prods.128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.33 : int, %size_prods.130 : int):
              %1034 : int = aten::add(%i.33, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1035 : int = aten::__getitem__(%1027, %1034) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.131 : int = aten::mul(%size_prods.130, %1035) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.131)
          %1037 : bool = aten::eq(%size_prods.129, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1037) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1038 : str = aten::format(%8, %1027) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1038) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.135 : Tensor = aten::batch_norm(%input.134, %1025, %1026, %1023, %1024, %1022, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1040 : int[] = aten::size(%input.135) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.7 : int, %c.7 : int, %1043 : int, %1044 : int = prim::ListUnpack(%1040)
      %1047 : int = aten::len(%1040) # <string>:5:9
      %1048 : bool = aten::gt(%1047, %22) # <string>:5:9
       = prim::If(%1048) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %1049 : Tensor = aten::adaptive_avg_pool2d(%input.135, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %1050 : int[] = prim::ListConstruct(%b.7, %c.7)
      %y.13 : Tensor = aten::view(%1049, %1050) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %1052 : __torch__.torch.nn.modules.container.___torch_mangle_34.Sequential = prim::GetAttr[name="fc"](%975)
      %1053 : __torch__.torch.nn.modules.linear.___torch_mangle_32.Linear = prim::GetAttr[name="0"](%1052)
      %1054 : __torch__.torch.nn.modules.linear.___torch_mangle_33.Linear = prim::GetAttr[name="2"](%1052)
      %1055 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%1052)
      %1056 : Tensor = prim::GetAttr[name="weight"](%1053)
      %input.136 : Tensor = aten::linear(%y.13, %1056, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.137 : Tensor = aten::relu_(%input.136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1059 : Tensor = prim::GetAttr[name="weight"](%1054)
      %input.138 : Tensor = aten::linear(%input.137, %1059, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %1061 : Tensor = aten::add(%input.138, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %1062 : bool = prim::GetAttr[name="inplace"](%1055)
      %result.48 : Tensor = prim::If(%1062) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.49 : Tensor = aten::hardtanh_(%1061, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.49)
        block1():
          %result.50 : Tensor = aten::hardtanh(%1061, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.50)
      %input.139 : Tensor = aten::div(%result.48, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %1067 : int[] = prim::ListConstruct(%b.7, %c.7, %11, %11)
      %y.14 : Tensor = aten::view(%input.139, %1067) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %1069 : Tensor = aten::expand_as(%y.14, %input.135) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.140 : Tensor = aten::mul(%input.135, %1069) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %1071 : Tensor = aten::add(%input.140, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %1072 : bool = prim::GetAttr[name="inplace"](%976)
      %result.51 : Tensor = prim::If(%1072) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.52 : Tensor = aten::hardtanh_(%1071, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.52)
        block1():
          %result.53 : Tensor = aten::hardtanh(%1071, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.53)
      %1076 : Tensor = aten::mul(%input.140, %result.51) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.141 : Tensor = aten::div(%1076, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %1078 : Tensor = prim::GetAttr[name="weight"](%977)
      %1079 : Tensor? = prim::GetAttr[name="bias"](%977)
      %input.142 : Tensor = aten::conv2d(%input.141, %1078, %1079, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1084 : bool = prim::GetAttr[name="training"](%978)
       = prim::If(%1084) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1085 : Tensor = prim::GetAttr[name="num_batches_tracked"](%978)
          %1086 : Tensor = aten::add(%1085, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%978, %1086)
          -> ()
        block1():
          -> ()
      %1087 : bool = prim::GetAttr[name="training"](%978)
      %1088 : Tensor = prim::GetAttr[name="running_mean"](%978)
      %1089 : Tensor = prim::GetAttr[name="running_var"](%978)
      %1090 : Tensor = prim::GetAttr[name="weight"](%978)
      %1091 : Tensor = prim::GetAttr[name="bias"](%978)
       = prim::If(%1087) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1092 : int[] = aten::size(%input.142) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.132 : int = aten::__getitem__(%1092, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1094 : int = aten::len(%1092) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1095 : int = aten::sub(%1094, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.133 : int = prim::Loop(%1095, %10, %size_prods.132) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.34 : int, %size_prods.134 : int):
              %1099 : int = aten::add(%i.34, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1100 : int = aten::__getitem__(%1092, %1099) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.135 : int = aten::mul(%size_prods.134, %1100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.135)
          %1102 : bool = aten::eq(%size_prods.133, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1102) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1103 : str = aten::format(%8, %1092) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1103) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.143 : Tensor = aten::batch_norm(%input.142, %1090, %1091, %1088, %1089, %1087, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1105 : Tensor = aten::add(%input.38, %input.143, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:113:19
      -> (%1105)
    block1():
      %1106 : __torch__.torch.nn.modules.container.___torch_mangle_37.Sequential = prim::GetAttr[name="conv"](%32)
      %1107 : __torch__.torch.nn.modules.conv.___torch_mangle_29.Conv2d = prim::GetAttr[name="0"](%1106)
      %1108 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_30.BatchNorm2d = prim::GetAttr[name="1"](%1106)
      %1109 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%1106)
      %1110 : __torch__.torch.nn.modules.conv.___torch_mangle_31.Conv2d = prim::GetAttr[name="3"](%1106)
      %1111 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_30.BatchNorm2d = prim::GetAttr[name="4"](%1106)
      %1112 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_35.SEModule = prim::GetAttr[name="5"](%1106)
      %1113 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="6"](%1106)
      %1114 : __torch__.torch.nn.modules.conv.___torch_mangle_36.Conv2d = prim::GetAttr[name="7"](%1106)
      %1115 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_26.BatchNorm2d = prim::GetAttr[name="8"](%1106)
      %1116 : Tensor = prim::GetAttr[name="weight"](%1107)
      %1117 : Tensor? = prim::GetAttr[name="bias"](%1107)
      %input.144 : Tensor = aten::conv2d(%input.38, %1116, %1117, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1122 : bool = prim::GetAttr[name="training"](%1108)
       = prim::If(%1122) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1123 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1108)
          %1124 : Tensor = aten::add(%1123, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1108, %1124)
          -> ()
        block1():
          -> ()
      %1125 : bool = prim::GetAttr[name="training"](%1108)
      %1126 : Tensor = prim::GetAttr[name="running_mean"](%1108)
      %1127 : Tensor = prim::GetAttr[name="running_var"](%1108)
      %1128 : Tensor = prim::GetAttr[name="weight"](%1108)
      %1129 : Tensor = prim::GetAttr[name="bias"](%1108)
       = prim::If(%1125) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1130 : int[] = aten::size(%input.144) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.136 : int = aten::__getitem__(%1130, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1132 : int = aten::len(%1130) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1133 : int = aten::sub(%1132, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.137 : int = prim::Loop(%1133, %10, %size_prods.136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.35 : int, %size_prods.138 : int):
              %1137 : int = aten::add(%i.35, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1138 : int = aten::__getitem__(%1130, %1137) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.139 : int = aten::mul(%size_prods.138, %1138) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.139)
          %1140 : bool = aten::eq(%size_prods.137, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1141 : str = aten::format(%8, %1130) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1141) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.145 : Tensor = aten::batch_norm(%input.144, %1128, %1129, %1126, %1127, %1125, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1143 : Tensor = aten::add(%input.145, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %1144 : bool = prim::GetAttr[name="inplace"](%1109)
      %result.54 : Tensor = prim::If(%1144) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.55 : Tensor = aten::hardtanh_(%1143, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.55)
        block1():
          %result.56 : Tensor = aten::hardtanh(%1143, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.56)
      %1148 : Tensor = aten::mul(%input.145, %result.54) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.146 : Tensor = aten::div(%1148, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %1150 : Tensor = prim::GetAttr[name="weight"](%1110)
      %1151 : Tensor? = prim::GetAttr[name="bias"](%1110)
      %input.147 : Tensor = aten::conv2d(%input.146, %1150, %1151, %2960, %2959, %2960, %17) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1156 : bool = prim::GetAttr[name="training"](%1111)
       = prim::If(%1156) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1157 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1111)
          %1158 : Tensor = aten::add(%1157, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1111, %1158)
          -> ()
        block1():
          -> ()
      %1159 : bool = prim::GetAttr[name="training"](%1111)
      %1160 : Tensor = prim::GetAttr[name="running_mean"](%1111)
      %1161 : Tensor = prim::GetAttr[name="running_var"](%1111)
      %1162 : Tensor = prim::GetAttr[name="weight"](%1111)
      %1163 : Tensor = prim::GetAttr[name="bias"](%1111)
       = prim::If(%1159) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1164 : int[] = aten::size(%input.147) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.140 : int = aten::__getitem__(%1164, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1166 : int = aten::len(%1164) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1167 : int = aten::sub(%1166, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.141 : int = prim::Loop(%1167, %10, %size_prods.140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.36 : int, %size_prods.142 : int):
              %1171 : int = aten::add(%i.36, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1172 : int = aten::__getitem__(%1164, %1171) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.143 : int = aten::mul(%size_prods.142, %1172) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.143)
          %1174 : bool = aten::eq(%size_prods.141, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1174) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1175 : str = aten::format(%8, %1164) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1175) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.148 : Tensor = aten::batch_norm(%input.147, %1162, %1163, %1160, %1161, %1159, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1177 : int[] = aten::size(%input.148) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.8 : int, %c.8 : int, %1180 : int, %1181 : int = prim::ListUnpack(%1177)
      %1184 : int = aten::len(%1177) # <string>:5:9
      %1185 : bool = aten::gt(%1184, %22) # <string>:5:9
       = prim::If(%1185) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %1186 : Tensor = aten::adaptive_avg_pool2d(%input.148, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %1187 : int[] = prim::ListConstruct(%b.8, %c.8)
      %y.15 : Tensor = aten::view(%1186, %1187) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %1189 : __torch__.torch.nn.modules.container.___torch_mangle_34.Sequential = prim::GetAttr[name="fc"](%1112)
      %1190 : __torch__.torch.nn.modules.linear.___torch_mangle_32.Linear = prim::GetAttr[name="0"](%1189)
      %1191 : __torch__.torch.nn.modules.linear.___torch_mangle_33.Linear = prim::GetAttr[name="2"](%1189)
      %1192 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%1189)
      %1193 : Tensor = prim::GetAttr[name="weight"](%1190)
      %input.149 : Tensor = aten::linear(%y.15, %1193, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.150 : Tensor = aten::relu_(%input.149) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1196 : Tensor = prim::GetAttr[name="weight"](%1191)
      %input.151 : Tensor = aten::linear(%input.150, %1196, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %1198 : Tensor = aten::add(%input.151, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %1199 : bool = prim::GetAttr[name="inplace"](%1192)
      %result.57 : Tensor = prim::If(%1199) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.58 : Tensor = aten::hardtanh_(%1198, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.58)
        block1():
          %result.59 : Tensor = aten::hardtanh(%1198, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.59)
      %input.152 : Tensor = aten::div(%result.57, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %1204 : int[] = prim::ListConstruct(%b.8, %c.8, %11, %11)
      %y.16 : Tensor = aten::view(%input.152, %1204) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %1206 : Tensor = aten::expand_as(%y.16, %input.148) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.153 : Tensor = aten::mul(%input.148, %1206) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %1208 : Tensor = aten::add(%input.153, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %1209 : bool = prim::GetAttr[name="inplace"](%1113)
      %result.60 : Tensor = prim::If(%1209) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.61 : Tensor = aten::hardtanh_(%1208, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.61)
        block1():
          %result.62 : Tensor = aten::hardtanh(%1208, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.62)
      %1213 : Tensor = aten::mul(%input.153, %result.60) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.154 : Tensor = aten::div(%1213, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %1215 : Tensor = prim::GetAttr[name="weight"](%1114)
      %1216 : Tensor? = prim::GetAttr[name="bias"](%1114)
      %input.155 : Tensor = aten::conv2d(%input.154, %1215, %1216, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1221 : bool = prim::GetAttr[name="training"](%1115)
       = prim::If(%1221) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1222 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1115)
          %1223 : Tensor = aten::add(%1222, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1115, %1223)
          -> ()
        block1():
          -> ()
      %1224 : bool = prim::GetAttr[name="training"](%1115)
      %1225 : Tensor = prim::GetAttr[name="running_mean"](%1115)
      %1226 : Tensor = prim::GetAttr[name="running_var"](%1115)
      %1227 : Tensor = prim::GetAttr[name="weight"](%1115)
      %1228 : Tensor = prim::GetAttr[name="bias"](%1115)
       = prim::If(%1224) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1229 : int[] = aten::size(%input.155) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.144 : int = aten::__getitem__(%1229, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1231 : int = aten::len(%1229) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1232 : int = aten::sub(%1231, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.145 : int = prim::Loop(%1232, %10, %size_prods.144) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.37 : int, %size_prods.146 : int):
              %1236 : int = aten::add(%i.37, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1237 : int = aten::__getitem__(%1229, %1236) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.147 : int = aten::mul(%size_prods.146, %1237) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.147)
          %1239 : bool = aten::eq(%size_prods.145, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1239) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1240 : str = aten::format(%8, %1229) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1240) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.156 : Tensor = aten::batch_norm(%input.155, %1227, %1228, %1225, %1226, %1224, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.156)
  %1242 : bool = prim::GetAttr[name="use_res_connect"](%33)
  %input.44 : Tensor = prim::If(%1242) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:112:8
    block0():
      %1244 : __torch__.torch.nn.modules.container.___torch_mangle_37.Sequential = prim::GetAttr[name="conv"](%33)
      %1245 : __torch__.torch.nn.modules.conv.___torch_mangle_29.Conv2d = prim::GetAttr[name="0"](%1244)
      %1246 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_30.BatchNorm2d = prim::GetAttr[name="1"](%1244)
      %1247 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%1244)
      %1248 : __torch__.torch.nn.modules.conv.___torch_mangle_31.Conv2d = prim::GetAttr[name="3"](%1244)
      %1249 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_30.BatchNorm2d = prim::GetAttr[name="4"](%1244)
      %1250 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_35.SEModule = prim::GetAttr[name="5"](%1244)
      %1251 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="6"](%1244)
      %1252 : __torch__.torch.nn.modules.conv.___torch_mangle_36.Conv2d = prim::GetAttr[name="7"](%1244)
      %1253 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_26.BatchNorm2d = prim::GetAttr[name="8"](%1244)
      %1254 : Tensor = prim::GetAttr[name="weight"](%1245)
      %1255 : Tensor? = prim::GetAttr[name="bias"](%1245)
      %input.157 : Tensor = aten::conv2d(%input.43, %1254, %1255, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1260 : bool = prim::GetAttr[name="training"](%1246)
       = prim::If(%1260) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1261 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1246)
          %1262 : Tensor = aten::add(%1261, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1246, %1262)
          -> ()
        block1():
          -> ()
      %1263 : bool = prim::GetAttr[name="training"](%1246)
      %1264 : Tensor = prim::GetAttr[name="running_mean"](%1246)
      %1265 : Tensor = prim::GetAttr[name="running_var"](%1246)
      %1266 : Tensor = prim::GetAttr[name="weight"](%1246)
      %1267 : Tensor = prim::GetAttr[name="bias"](%1246)
       = prim::If(%1263) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1268 : int[] = aten::size(%input.157) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.148 : int = aten::__getitem__(%1268, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1270 : int = aten::len(%1268) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1271 : int = aten::sub(%1270, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.149 : int = prim::Loop(%1271, %10, %size_prods.148) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.38 : int, %size_prods.150 : int):
              %1275 : int = aten::add(%i.38, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1276 : int = aten::__getitem__(%1268, %1275) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.151 : int = aten::mul(%size_prods.150, %1276) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.151)
          %1278 : bool = aten::eq(%size_prods.149, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1278) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1279 : str = aten::format(%8, %1268) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1279) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.158 : Tensor = aten::batch_norm(%input.157, %1266, %1267, %1264, %1265, %1263, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1281 : Tensor = aten::add(%input.158, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %1282 : bool = prim::GetAttr[name="inplace"](%1247)
      %result.63 : Tensor = prim::If(%1282) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.64 : Tensor = aten::hardtanh_(%1281, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.64)
        block1():
          %result.65 : Tensor = aten::hardtanh(%1281, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.65)
      %1286 : Tensor = aten::mul(%input.158, %result.63) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.159 : Tensor = aten::div(%1286, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %1288 : Tensor = prim::GetAttr[name="weight"](%1248)
      %1289 : Tensor? = prim::GetAttr[name="bias"](%1248)
      %input.160 : Tensor = aten::conv2d(%input.159, %1288, %1289, %2960, %2959, %2960, %17) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1294 : bool = prim::GetAttr[name="training"](%1249)
       = prim::If(%1294) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1295 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1249)
          %1296 : Tensor = aten::add(%1295, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1249, %1296)
          -> ()
        block1():
          -> ()
      %1297 : bool = prim::GetAttr[name="training"](%1249)
      %1298 : Tensor = prim::GetAttr[name="running_mean"](%1249)
      %1299 : Tensor = prim::GetAttr[name="running_var"](%1249)
      %1300 : Tensor = prim::GetAttr[name="weight"](%1249)
      %1301 : Tensor = prim::GetAttr[name="bias"](%1249)
       = prim::If(%1297) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1302 : int[] = aten::size(%input.160) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.152 : int = aten::__getitem__(%1302, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1304 : int = aten::len(%1302) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1305 : int = aten::sub(%1304, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.153 : int = prim::Loop(%1305, %10, %size_prods.152) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.39 : int, %size_prods.154 : int):
              %1309 : int = aten::add(%i.39, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1310 : int = aten::__getitem__(%1302, %1309) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.155 : int = aten::mul(%size_prods.154, %1310) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.155)
          %1312 : bool = aten::eq(%size_prods.153, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1312) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1313 : str = aten::format(%8, %1302) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1313) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.161 : Tensor = aten::batch_norm(%input.160, %1300, %1301, %1298, %1299, %1297, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1315 : int[] = aten::size(%input.161) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.9 : int, %c.9 : int, %1318 : int, %1319 : int = prim::ListUnpack(%1315)
      %1322 : int = aten::len(%1315) # <string>:5:9
      %1323 : bool = aten::gt(%1322, %22) # <string>:5:9
       = prim::If(%1323) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %1324 : Tensor = aten::adaptive_avg_pool2d(%input.161, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %1325 : int[] = prim::ListConstruct(%b.9, %c.9)
      %y.17 : Tensor = aten::view(%1324, %1325) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %1327 : __torch__.torch.nn.modules.container.___torch_mangle_34.Sequential = prim::GetAttr[name="fc"](%1250)
      %1328 : __torch__.torch.nn.modules.linear.___torch_mangle_32.Linear = prim::GetAttr[name="0"](%1327)
      %1329 : __torch__.torch.nn.modules.linear.___torch_mangle_33.Linear = prim::GetAttr[name="2"](%1327)
      %1330 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%1327)
      %1331 : Tensor = prim::GetAttr[name="weight"](%1328)
      %input.162 : Tensor = aten::linear(%y.17, %1331, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.163 : Tensor = aten::relu_(%input.162) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1334 : Tensor = prim::GetAttr[name="weight"](%1329)
      %input.164 : Tensor = aten::linear(%input.163, %1334, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %1336 : Tensor = aten::add(%input.164, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %1337 : bool = prim::GetAttr[name="inplace"](%1330)
      %result.66 : Tensor = prim::If(%1337) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.67 : Tensor = aten::hardtanh_(%1336, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.67)
        block1():
          %result.68 : Tensor = aten::hardtanh(%1336, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.68)
      %input.165 : Tensor = aten::div(%result.66, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %1342 : int[] = prim::ListConstruct(%b.9, %c.9, %11, %11)
      %y.18 : Tensor = aten::view(%input.165, %1342) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %1344 : Tensor = aten::expand_as(%y.18, %input.161) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.166 : Tensor = aten::mul(%input.161, %1344) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %1346 : Tensor = aten::add(%input.166, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %1347 : bool = prim::GetAttr[name="inplace"](%1251)
      %result.69 : Tensor = prim::If(%1347) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.70 : Tensor = aten::hardtanh_(%1346, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.70)
        block1():
          %result.71 : Tensor = aten::hardtanh(%1346, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.71)
      %1351 : Tensor = aten::mul(%input.166, %result.69) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.167 : Tensor = aten::div(%1351, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %1353 : Tensor = prim::GetAttr[name="weight"](%1252)
      %1354 : Tensor? = prim::GetAttr[name="bias"](%1252)
      %input.168 : Tensor = aten::conv2d(%input.167, %1353, %1354, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1359 : bool = prim::GetAttr[name="training"](%1253)
       = prim::If(%1359) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1360 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1253)
          %1361 : Tensor = aten::add(%1360, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1253, %1361)
          -> ()
        block1():
          -> ()
      %1362 : bool = prim::GetAttr[name="training"](%1253)
      %1363 : Tensor = prim::GetAttr[name="running_mean"](%1253)
      %1364 : Tensor = prim::GetAttr[name="running_var"](%1253)
      %1365 : Tensor = prim::GetAttr[name="weight"](%1253)
      %1366 : Tensor = prim::GetAttr[name="bias"](%1253)
       = prim::If(%1362) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1367 : int[] = aten::size(%input.168) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.156 : int = aten::__getitem__(%1367, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1369 : int = aten::len(%1367) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1370 : int = aten::sub(%1369, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.157 : int = prim::Loop(%1370, %10, %size_prods.156) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.40 : int, %size_prods.158 : int):
              %1374 : int = aten::add(%i.40, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1375 : int = aten::__getitem__(%1367, %1374) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.159 : int = aten::mul(%size_prods.158, %1375) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.159)
          %1377 : bool = aten::eq(%size_prods.157, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1377) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1378 : str = aten::format(%8, %1367) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1378) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.169 : Tensor = aten::batch_norm(%input.168, %1365, %1366, %1363, %1364, %1362, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1380 : Tensor = aten::add(%input.43, %input.169, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:113:19
      -> (%1380)
    block1():
      %1381 : __torch__.torch.nn.modules.container.___torch_mangle_37.Sequential = prim::GetAttr[name="conv"](%33)
      %1382 : __torch__.torch.nn.modules.conv.___torch_mangle_29.Conv2d = prim::GetAttr[name="0"](%1381)
      %1383 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_30.BatchNorm2d = prim::GetAttr[name="1"](%1381)
      %1384 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%1381)
      %1385 : __torch__.torch.nn.modules.conv.___torch_mangle_31.Conv2d = prim::GetAttr[name="3"](%1381)
      %1386 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_30.BatchNorm2d = prim::GetAttr[name="4"](%1381)
      %1387 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_35.SEModule = prim::GetAttr[name="5"](%1381)
      %1388 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="6"](%1381)
      %1389 : __torch__.torch.nn.modules.conv.___torch_mangle_36.Conv2d = prim::GetAttr[name="7"](%1381)
      %1390 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_26.BatchNorm2d = prim::GetAttr[name="8"](%1381)
      %1391 : Tensor = prim::GetAttr[name="weight"](%1382)
      %1392 : Tensor? = prim::GetAttr[name="bias"](%1382)
      %input.170 : Tensor = aten::conv2d(%input.43, %1391, %1392, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1397 : bool = prim::GetAttr[name="training"](%1383)
       = prim::If(%1397) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1398 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1383)
          %1399 : Tensor = aten::add(%1398, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1383, %1399)
          -> ()
        block1():
          -> ()
      %1400 : bool = prim::GetAttr[name="training"](%1383)
      %1401 : Tensor = prim::GetAttr[name="running_mean"](%1383)
      %1402 : Tensor = prim::GetAttr[name="running_var"](%1383)
      %1403 : Tensor = prim::GetAttr[name="weight"](%1383)
      %1404 : Tensor = prim::GetAttr[name="bias"](%1383)
       = prim::If(%1400) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1405 : int[] = aten::size(%input.170) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.160 : int = aten::__getitem__(%1405, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1407 : int = aten::len(%1405) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1408 : int = aten::sub(%1407, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.161 : int = prim::Loop(%1408, %10, %size_prods.160) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.41 : int, %size_prods.162 : int):
              %1412 : int = aten::add(%i.41, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1413 : int = aten::__getitem__(%1405, %1412) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.163 : int = aten::mul(%size_prods.162, %1413) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.163)
          %1415 : bool = aten::eq(%size_prods.161, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1415) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1416 : str = aten::format(%8, %1405) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1416) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.171 : Tensor = aten::batch_norm(%input.170, %1403, %1404, %1401, %1402, %1400, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1418 : Tensor = aten::add(%input.171, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %1419 : bool = prim::GetAttr[name="inplace"](%1384)
      %result.72 : Tensor = prim::If(%1419) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.73 : Tensor = aten::hardtanh_(%1418, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.73)
        block1():
          %result.74 : Tensor = aten::hardtanh(%1418, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.74)
      %1423 : Tensor = aten::mul(%input.171, %result.72) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.172 : Tensor = aten::div(%1423, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %1425 : Tensor = prim::GetAttr[name="weight"](%1385)
      %1426 : Tensor? = prim::GetAttr[name="bias"](%1385)
      %input.173 : Tensor = aten::conv2d(%input.172, %1425, %1426, %2960, %2959, %2960, %17) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1431 : bool = prim::GetAttr[name="training"](%1386)
       = prim::If(%1431) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1432 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1386)
          %1433 : Tensor = aten::add(%1432, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1386, %1433)
          -> ()
        block1():
          -> ()
      %1434 : bool = prim::GetAttr[name="training"](%1386)
      %1435 : Tensor = prim::GetAttr[name="running_mean"](%1386)
      %1436 : Tensor = prim::GetAttr[name="running_var"](%1386)
      %1437 : Tensor = prim::GetAttr[name="weight"](%1386)
      %1438 : Tensor = prim::GetAttr[name="bias"](%1386)
       = prim::If(%1434) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1439 : int[] = aten::size(%input.173) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.164 : int = aten::__getitem__(%1439, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1441 : int = aten::len(%1439) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1442 : int = aten::sub(%1441, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.165 : int = prim::Loop(%1442, %10, %size_prods.164) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.42 : int, %size_prods.166 : int):
              %1446 : int = aten::add(%i.42, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1447 : int = aten::__getitem__(%1439, %1446) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.167 : int = aten::mul(%size_prods.166, %1447) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.167)
          %1449 : bool = aten::eq(%size_prods.165, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1449) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1450 : str = aten::format(%8, %1439) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1450) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.174 : Tensor = aten::batch_norm(%input.173, %1437, %1438, %1435, %1436, %1434, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1452 : int[] = aten::size(%input.174) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.10 : int, %c.10 : int, %1455 : int, %1456 : int = prim::ListUnpack(%1452)
      %1459 : int = aten::len(%1452) # <string>:5:9
      %1460 : bool = aten::gt(%1459, %22) # <string>:5:9
       = prim::If(%1460) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %1461 : Tensor = aten::adaptive_avg_pool2d(%input.174, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %1462 : int[] = prim::ListConstruct(%b.10, %c.10)
      %y.19 : Tensor = aten::view(%1461, %1462) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %1464 : __torch__.torch.nn.modules.container.___torch_mangle_34.Sequential = prim::GetAttr[name="fc"](%1387)
      %1465 : __torch__.torch.nn.modules.linear.___torch_mangle_32.Linear = prim::GetAttr[name="0"](%1464)
      %1466 : __torch__.torch.nn.modules.linear.___torch_mangle_33.Linear = prim::GetAttr[name="2"](%1464)
      %1467 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%1464)
      %1468 : Tensor = prim::GetAttr[name="weight"](%1465)
      %input.175 : Tensor = aten::linear(%y.19, %1468, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.176 : Tensor = aten::relu_(%input.175) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1471 : Tensor = prim::GetAttr[name="weight"](%1466)
      %input.177 : Tensor = aten::linear(%input.176, %1471, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %1473 : Tensor = aten::add(%input.177, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %1474 : bool = prim::GetAttr[name="inplace"](%1467)
      %result.75 : Tensor = prim::If(%1474) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.76 : Tensor = aten::hardtanh_(%1473, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.76)
        block1():
          %result.77 : Tensor = aten::hardtanh(%1473, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.77)
      %input.178 : Tensor = aten::div(%result.75, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %1479 : int[] = prim::ListConstruct(%b.10, %c.10, %11, %11)
      %y.20 : Tensor = aten::view(%input.178, %1479) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %1481 : Tensor = aten::expand_as(%y.20, %input.174) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.179 : Tensor = aten::mul(%input.174, %1481) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %1483 : Tensor = aten::add(%input.179, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %1484 : bool = prim::GetAttr[name="inplace"](%1388)
      %result.78 : Tensor = prim::If(%1484) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.79 : Tensor = aten::hardtanh_(%1483, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.79)
        block1():
          %result.80 : Tensor = aten::hardtanh(%1483, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.80)
      %1488 : Tensor = aten::mul(%input.179, %result.78) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.180 : Tensor = aten::div(%1488, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %1490 : Tensor = prim::GetAttr[name="weight"](%1389)
      %1491 : Tensor? = prim::GetAttr[name="bias"](%1389)
      %input.181 : Tensor = aten::conv2d(%input.180, %1490, %1491, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1496 : bool = prim::GetAttr[name="training"](%1390)
       = prim::If(%1496) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1497 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1390)
          %1498 : Tensor = aten::add(%1497, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1390, %1498)
          -> ()
        block1():
          -> ()
      %1499 : bool = prim::GetAttr[name="training"](%1390)
      %1500 : Tensor = prim::GetAttr[name="running_mean"](%1390)
      %1501 : Tensor = prim::GetAttr[name="running_var"](%1390)
      %1502 : Tensor = prim::GetAttr[name="weight"](%1390)
      %1503 : Tensor = prim::GetAttr[name="bias"](%1390)
       = prim::If(%1499) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1504 : int[] = aten::size(%input.181) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.168 : int = aten::__getitem__(%1504, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1506 : int = aten::len(%1504) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1507 : int = aten::sub(%1506, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.169 : int = prim::Loop(%1507, %10, %size_prods.168) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.43 : int, %size_prods.170 : int):
              %1511 : int = aten::add(%i.43, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1512 : int = aten::__getitem__(%1504, %1511) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.171 : int = aten::mul(%size_prods.170, %1512) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.171)
          %1514 : bool = aten::eq(%size_prods.169, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1514) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1515 : str = aten::format(%8, %1504) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1515) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.182 : Tensor = aten::batch_norm(%input.181, %1502, %1503, %1500, %1501, %1499, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.182)
  %1517 : bool = prim::GetAttr[name="use_res_connect"](%34)
  %input.45 : Tensor = prim::If(%1517) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:112:8
    block0():
      %1519 : __torch__.torch.nn.modules.container.___torch_mangle_48.Sequential = prim::GetAttr[name="conv"](%34)
      %1520 : __torch__.torch.nn.modules.conv.___torch_mangle_39.Conv2d = prim::GetAttr[name="0"](%1519)
      %1521 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_40.BatchNorm2d = prim::GetAttr[name="1"](%1519)
      %1522 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%1519)
      %1523 : __torch__.torch.nn.modules.conv.___torch_mangle_41.Conv2d = prim::GetAttr[name="3"](%1519)
      %1524 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_40.BatchNorm2d = prim::GetAttr[name="4"](%1519)
      %1525 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_45.SEModule = prim::GetAttr[name="5"](%1519)
      %1526 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="6"](%1519)
      %1527 : __torch__.torch.nn.modules.conv.___torch_mangle_46.Conv2d = prim::GetAttr[name="7"](%1519)
      %1528 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_47.BatchNorm2d = prim::GetAttr[name="8"](%1519)
      %1529 : Tensor = prim::GetAttr[name="weight"](%1520)
      %1530 : Tensor? = prim::GetAttr[name="bias"](%1520)
      %input.183 : Tensor = aten::conv2d(%input.44, %1529, %1530, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1535 : bool = prim::GetAttr[name="training"](%1521)
       = prim::If(%1535) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1536 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1521)
          %1537 : Tensor = aten::add(%1536, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1521, %1537)
          -> ()
        block1():
          -> ()
      %1538 : bool = prim::GetAttr[name="training"](%1521)
      %1539 : Tensor = prim::GetAttr[name="running_mean"](%1521)
      %1540 : Tensor = prim::GetAttr[name="running_var"](%1521)
      %1541 : Tensor = prim::GetAttr[name="weight"](%1521)
      %1542 : Tensor = prim::GetAttr[name="bias"](%1521)
       = prim::If(%1538) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1543 : int[] = aten::size(%input.183) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.172 : int = aten::__getitem__(%1543, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1545 : int = aten::len(%1543) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1546 : int = aten::sub(%1545, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.173 : int = prim::Loop(%1546, %10, %size_prods.172) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.44 : int, %size_prods.174 : int):
              %1550 : int = aten::add(%i.44, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1551 : int = aten::__getitem__(%1543, %1550) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.175 : int = aten::mul(%size_prods.174, %1551) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.175)
          %1553 : bool = aten::eq(%size_prods.173, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1553) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1554 : str = aten::format(%8, %1543) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1554) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.184 : Tensor = aten::batch_norm(%input.183, %1541, %1542, %1539, %1540, %1538, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1556 : Tensor = aten::add(%input.184, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %1557 : bool = prim::GetAttr[name="inplace"](%1522)
      %result.81 : Tensor = prim::If(%1557) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.82 : Tensor = aten::hardtanh_(%1556, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.82)
        block1():
          %result.83 : Tensor = aten::hardtanh(%1556, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.83)
      %1561 : Tensor = aten::mul(%input.184, %result.81) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.185 : Tensor = aten::div(%1561, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %1563 : Tensor = prim::GetAttr[name="weight"](%1523)
      %1564 : Tensor? = prim::GetAttr[name="bias"](%1523)
      %input.186 : Tensor = aten::conv2d(%input.185, %1563, %1564, %2960, %2959, %2960, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1569 : bool = prim::GetAttr[name="training"](%1524)
       = prim::If(%1569) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1570 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1524)
          %1571 : Tensor = aten::add(%1570, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1524, %1571)
          -> ()
        block1():
          -> ()
      %1572 : bool = prim::GetAttr[name="training"](%1524)
      %1573 : Tensor = prim::GetAttr[name="running_mean"](%1524)
      %1574 : Tensor = prim::GetAttr[name="running_var"](%1524)
      %1575 : Tensor = prim::GetAttr[name="weight"](%1524)
      %1576 : Tensor = prim::GetAttr[name="bias"](%1524)
       = prim::If(%1572) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1577 : int[] = aten::size(%input.186) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.176 : int = aten::__getitem__(%1577, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1579 : int = aten::len(%1577) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1580 : int = aten::sub(%1579, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.177 : int = prim::Loop(%1580, %10, %size_prods.176) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.45 : int, %size_prods.178 : int):
              %1584 : int = aten::add(%i.45, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1585 : int = aten::__getitem__(%1577, %1584) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.179 : int = aten::mul(%size_prods.178, %1585) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.179)
          %1587 : bool = aten::eq(%size_prods.177, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1587) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1588 : str = aten::format(%8, %1577) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1588) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.187 : Tensor = aten::batch_norm(%input.186, %1575, %1576, %1573, %1574, %1572, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1590 : int[] = aten::size(%input.187) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.11 : int, %c.11 : int, %1593 : int, %1594 : int = prim::ListUnpack(%1590)
      %1597 : int = aten::len(%1590) # <string>:5:9
      %1598 : bool = aten::gt(%1597, %22) # <string>:5:9
       = prim::If(%1598) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %1599 : Tensor = aten::adaptive_avg_pool2d(%input.187, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %1600 : int[] = prim::ListConstruct(%b.11, %c.11)
      %y.21 : Tensor = aten::view(%1599, %1600) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %1602 : __torch__.torch.nn.modules.container.___torch_mangle_44.Sequential = prim::GetAttr[name="fc"](%1525)
      %1603 : __torch__.torch.nn.modules.linear.___torch_mangle_42.Linear = prim::GetAttr[name="0"](%1602)
      %1604 : __torch__.torch.nn.modules.linear.___torch_mangle_43.Linear = prim::GetAttr[name="2"](%1602)
      %1605 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%1602)
      %1606 : Tensor = prim::GetAttr[name="weight"](%1603)
      %input.188 : Tensor = aten::linear(%y.21, %1606, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.189 : Tensor = aten::relu_(%input.188) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1609 : Tensor = prim::GetAttr[name="weight"](%1604)
      %input.190 : Tensor = aten::linear(%input.189, %1609, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %1611 : Tensor = aten::add(%input.190, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %1612 : bool = prim::GetAttr[name="inplace"](%1605)
      %result.84 : Tensor = prim::If(%1612) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.85 : Tensor = aten::hardtanh_(%1611, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.85)
        block1():
          %result.86 : Tensor = aten::hardtanh(%1611, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.86)
      %input.191 : Tensor = aten::div(%result.84, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %1617 : int[] = prim::ListConstruct(%b.11, %c.11, %11, %11)
      %y.22 : Tensor = aten::view(%input.191, %1617) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %1619 : Tensor = aten::expand_as(%y.22, %input.187) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.192 : Tensor = aten::mul(%input.187, %1619) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %1621 : Tensor = aten::add(%input.192, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %1622 : bool = prim::GetAttr[name="inplace"](%1526)
      %result.87 : Tensor = prim::If(%1622) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.88 : Tensor = aten::hardtanh_(%1621, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.88)
        block1():
          %result.89 : Tensor = aten::hardtanh(%1621, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.89)
      %1626 : Tensor = aten::mul(%input.192, %result.87) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.193 : Tensor = aten::div(%1626, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %1628 : Tensor = prim::GetAttr[name="weight"](%1527)
      %1629 : Tensor? = prim::GetAttr[name="bias"](%1527)
      %input.194 : Tensor = aten::conv2d(%input.193, %1628, %1629, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1634 : bool = prim::GetAttr[name="training"](%1528)
       = prim::If(%1634) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1635 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1528)
          %1636 : Tensor = aten::add(%1635, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1528, %1636)
          -> ()
        block1():
          -> ()
      %1637 : bool = prim::GetAttr[name="training"](%1528)
      %1638 : Tensor = prim::GetAttr[name="running_mean"](%1528)
      %1639 : Tensor = prim::GetAttr[name="running_var"](%1528)
      %1640 : Tensor = prim::GetAttr[name="weight"](%1528)
      %1641 : Tensor = prim::GetAttr[name="bias"](%1528)
       = prim::If(%1637) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1642 : int[] = aten::size(%input.194) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.180 : int = aten::__getitem__(%1642, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1644 : int = aten::len(%1642) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1645 : int = aten::sub(%1644, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.181 : int = prim::Loop(%1645, %10, %size_prods.180) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.46 : int, %size_prods.182 : int):
              %1649 : int = aten::add(%i.46, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1650 : int = aten::__getitem__(%1642, %1649) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.183 : int = aten::mul(%size_prods.182, %1650) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.183)
          %1652 : bool = aten::eq(%size_prods.181, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1652) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1653 : str = aten::format(%8, %1642) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1653) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.195 : Tensor = aten::batch_norm(%input.194, %1640, %1641, %1638, %1639, %1637, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1655 : Tensor = aten::add(%input.44, %input.195, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:113:19
      -> (%1655)
    block1():
      %1656 : __torch__.torch.nn.modules.container.___torch_mangle_48.Sequential = prim::GetAttr[name="conv"](%34)
      %1657 : __torch__.torch.nn.modules.conv.___torch_mangle_39.Conv2d = prim::GetAttr[name="0"](%1656)
      %1658 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_40.BatchNorm2d = prim::GetAttr[name="1"](%1656)
      %1659 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%1656)
      %1660 : __torch__.torch.nn.modules.conv.___torch_mangle_41.Conv2d = prim::GetAttr[name="3"](%1656)
      %1661 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_40.BatchNorm2d = prim::GetAttr[name="4"](%1656)
      %1662 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_45.SEModule = prim::GetAttr[name="5"](%1656)
      %1663 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="6"](%1656)
      %1664 : __torch__.torch.nn.modules.conv.___torch_mangle_46.Conv2d = prim::GetAttr[name="7"](%1656)
      %1665 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_47.BatchNorm2d = prim::GetAttr[name="8"](%1656)
      %1666 : Tensor = prim::GetAttr[name="weight"](%1657)
      %1667 : Tensor? = prim::GetAttr[name="bias"](%1657)
      %input.196 : Tensor = aten::conv2d(%input.44, %1666, %1667, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1672 : bool = prim::GetAttr[name="training"](%1658)
       = prim::If(%1672) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1673 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1658)
          %1674 : Tensor = aten::add(%1673, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1658, %1674)
          -> ()
        block1():
          -> ()
      %1675 : bool = prim::GetAttr[name="training"](%1658)
      %1676 : Tensor = prim::GetAttr[name="running_mean"](%1658)
      %1677 : Tensor = prim::GetAttr[name="running_var"](%1658)
      %1678 : Tensor = prim::GetAttr[name="weight"](%1658)
      %1679 : Tensor = prim::GetAttr[name="bias"](%1658)
       = prim::If(%1675) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1680 : int[] = aten::size(%input.196) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.184 : int = aten::__getitem__(%1680, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1682 : int = aten::len(%1680) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1683 : int = aten::sub(%1682, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.185 : int = prim::Loop(%1683, %10, %size_prods.184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.47 : int, %size_prods.186 : int):
              %1687 : int = aten::add(%i.47, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1688 : int = aten::__getitem__(%1680, %1687) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.187 : int = aten::mul(%size_prods.186, %1688) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.187)
          %1690 : bool = aten::eq(%size_prods.185, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1690) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1691 : str = aten::format(%8, %1680) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1691) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.197 : Tensor = aten::batch_norm(%input.196, %1678, %1679, %1676, %1677, %1675, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1693 : Tensor = aten::add(%input.197, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %1694 : bool = prim::GetAttr[name="inplace"](%1659)
      %result.90 : Tensor = prim::If(%1694) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.91 : Tensor = aten::hardtanh_(%1693, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.91)
        block1():
          %result.92 : Tensor = aten::hardtanh(%1693, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.92)
      %1698 : Tensor = aten::mul(%input.197, %result.90) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.198 : Tensor = aten::div(%1698, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %1700 : Tensor = prim::GetAttr[name="weight"](%1660)
      %1701 : Tensor? = prim::GetAttr[name="bias"](%1660)
      %input.199 : Tensor = aten::conv2d(%input.198, %1700, %1701, %2960, %2959, %2960, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1706 : bool = prim::GetAttr[name="training"](%1661)
       = prim::If(%1706) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1707 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1661)
          %1708 : Tensor = aten::add(%1707, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1661, %1708)
          -> ()
        block1():
          -> ()
      %1709 : bool = prim::GetAttr[name="training"](%1661)
      %1710 : Tensor = prim::GetAttr[name="running_mean"](%1661)
      %1711 : Tensor = prim::GetAttr[name="running_var"](%1661)
      %1712 : Tensor = prim::GetAttr[name="weight"](%1661)
      %1713 : Tensor = prim::GetAttr[name="bias"](%1661)
       = prim::If(%1709) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1714 : int[] = aten::size(%input.199) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.188 : int = aten::__getitem__(%1714, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1716 : int = aten::len(%1714) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1717 : int = aten::sub(%1716, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.189 : int = prim::Loop(%1717, %10, %size_prods.188) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.48 : int, %size_prods.190 : int):
              %1721 : int = aten::add(%i.48, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1722 : int = aten::__getitem__(%1714, %1721) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.191 : int = aten::mul(%size_prods.190, %1722) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.191)
          %1724 : bool = aten::eq(%size_prods.189, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1724) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1725 : str = aten::format(%8, %1714) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1725) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.200 : Tensor = aten::batch_norm(%input.199, %1712, %1713, %1710, %1711, %1709, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1727 : int[] = aten::size(%input.200) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.12 : int, %c.12 : int, %1730 : int, %1731 : int = prim::ListUnpack(%1727)
      %1734 : int = aten::len(%1727) # <string>:5:9
      %1735 : bool = aten::gt(%1734, %22) # <string>:5:9
       = prim::If(%1735) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %1736 : Tensor = aten::adaptive_avg_pool2d(%input.200, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %1737 : int[] = prim::ListConstruct(%b.12, %c.12)
      %y.23 : Tensor = aten::view(%1736, %1737) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %1739 : __torch__.torch.nn.modules.container.___torch_mangle_44.Sequential = prim::GetAttr[name="fc"](%1662)
      %1740 : __torch__.torch.nn.modules.linear.___torch_mangle_42.Linear = prim::GetAttr[name="0"](%1739)
      %1741 : __torch__.torch.nn.modules.linear.___torch_mangle_43.Linear = prim::GetAttr[name="2"](%1739)
      %1742 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%1739)
      %1743 : Tensor = prim::GetAttr[name="weight"](%1740)
      %input.201 : Tensor = aten::linear(%y.23, %1743, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.202 : Tensor = aten::relu_(%input.201) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1746 : Tensor = prim::GetAttr[name="weight"](%1741)
      %input.203 : Tensor = aten::linear(%input.202, %1746, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %1748 : Tensor = aten::add(%input.203, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %1749 : bool = prim::GetAttr[name="inplace"](%1742)
      %result.93 : Tensor = prim::If(%1749) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.94 : Tensor = aten::hardtanh_(%1748, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.94)
        block1():
          %result.95 : Tensor = aten::hardtanh(%1748, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.95)
      %input.204 : Tensor = aten::div(%result.93, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %1754 : int[] = prim::ListConstruct(%b.12, %c.12, %11, %11)
      %y.24 : Tensor = aten::view(%input.204, %1754) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %1756 : Tensor = aten::expand_as(%y.24, %input.200) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.205 : Tensor = aten::mul(%input.200, %1756) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %1758 : Tensor = aten::add(%input.205, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %1759 : bool = prim::GetAttr[name="inplace"](%1663)
      %result.96 : Tensor = prim::If(%1759) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.97 : Tensor = aten::hardtanh_(%1758, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.97)
        block1():
          %result.98 : Tensor = aten::hardtanh(%1758, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.98)
      %1763 : Tensor = aten::mul(%input.205, %result.96) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.206 : Tensor = aten::div(%1763, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %1765 : Tensor = prim::GetAttr[name="weight"](%1664)
      %1766 : Tensor? = prim::GetAttr[name="bias"](%1664)
      %input.207 : Tensor = aten::conv2d(%input.206, %1765, %1766, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1771 : bool = prim::GetAttr[name="training"](%1665)
       = prim::If(%1771) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1772 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1665)
          %1773 : Tensor = aten::add(%1772, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1665, %1773)
          -> ()
        block1():
          -> ()
      %1774 : bool = prim::GetAttr[name="training"](%1665)
      %1775 : Tensor = prim::GetAttr[name="running_mean"](%1665)
      %1776 : Tensor = prim::GetAttr[name="running_var"](%1665)
      %1777 : Tensor = prim::GetAttr[name="weight"](%1665)
      %1778 : Tensor = prim::GetAttr[name="bias"](%1665)
       = prim::If(%1774) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1779 : int[] = aten::size(%input.207) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.192 : int = aten::__getitem__(%1779, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1781 : int = aten::len(%1779) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1782 : int = aten::sub(%1781, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.193 : int = prim::Loop(%1782, %10, %size_prods.192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.49 : int, %size_prods.194 : int):
              %1786 : int = aten::add(%i.49, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1787 : int = aten::__getitem__(%1779, %1786) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.195 : int = aten::mul(%size_prods.194, %1787) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.195)
          %1789 : bool = aten::eq(%size_prods.193, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1789) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1790 : str = aten::format(%8, %1779) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1790) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.208 : Tensor = aten::batch_norm(%input.207, %1777, %1778, %1775, %1776, %1774, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.208)
  %1792 : bool = prim::GetAttr[name="use_res_connect"](%35)
  %input.46 : Tensor = prim::If(%1792) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:112:8
    block0():
      %1794 : __torch__.torch.nn.modules.container.___torch_mangle_58.Sequential = prim::GetAttr[name="conv"](%35)
      %1795 : __torch__.torch.nn.modules.conv.___torch_mangle_50.Conv2d = prim::GetAttr[name="0"](%1794)
      %1796 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_51.BatchNorm2d = prim::GetAttr[name="1"](%1794)
      %1797 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%1794)
      %1798 : __torch__.torch.nn.modules.conv.___torch_mangle_52.Conv2d = prim::GetAttr[name="3"](%1794)
      %1799 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_51.BatchNorm2d = prim::GetAttr[name="4"](%1794)
      %1800 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_56.SEModule = prim::GetAttr[name="5"](%1794)
      %1801 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="6"](%1794)
      %1802 : __torch__.torch.nn.modules.conv.___torch_mangle_57.Conv2d = prim::GetAttr[name="7"](%1794)
      %1803 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_47.BatchNorm2d = prim::GetAttr[name="8"](%1794)
      %1804 : Tensor = prim::GetAttr[name="weight"](%1795)
      %1805 : Tensor? = prim::GetAttr[name="bias"](%1795)
      %input.209 : Tensor = aten::conv2d(%input.45, %1804, %1805, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1810 : bool = prim::GetAttr[name="training"](%1796)
       = prim::If(%1810) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1811 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1796)
          %1812 : Tensor = aten::add(%1811, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1796, %1812)
          -> ()
        block1():
          -> ()
      %1813 : bool = prim::GetAttr[name="training"](%1796)
      %1814 : Tensor = prim::GetAttr[name="running_mean"](%1796)
      %1815 : Tensor = prim::GetAttr[name="running_var"](%1796)
      %1816 : Tensor = prim::GetAttr[name="weight"](%1796)
      %1817 : Tensor = prim::GetAttr[name="bias"](%1796)
       = prim::If(%1813) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1818 : int[] = aten::size(%input.209) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.196 : int = aten::__getitem__(%1818, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1820 : int = aten::len(%1818) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1821 : int = aten::sub(%1820, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.197 : int = prim::Loop(%1821, %10, %size_prods.196) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.50 : int, %size_prods.198 : int):
              %1825 : int = aten::add(%i.50, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1826 : int = aten::__getitem__(%1818, %1825) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.199 : int = aten::mul(%size_prods.198, %1826) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.199)
          %1828 : bool = aten::eq(%size_prods.197, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1828) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1829 : str = aten::format(%8, %1818) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1829) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.210 : Tensor = aten::batch_norm(%input.209, %1816, %1817, %1814, %1815, %1813, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1831 : Tensor = aten::add(%input.210, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %1832 : bool = prim::GetAttr[name="inplace"](%1797)
      %result.99 : Tensor = prim::If(%1832) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.100 : Tensor = aten::hardtanh_(%1831, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.100)
        block1():
          %result.101 : Tensor = aten::hardtanh(%1831, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.101)
      %1836 : Tensor = aten::mul(%input.210, %result.99) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.211 : Tensor = aten::div(%1836, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %1838 : Tensor = prim::GetAttr[name="weight"](%1798)
      %1839 : Tensor? = prim::GetAttr[name="bias"](%1798)
      %input.212 : Tensor = aten::conv2d(%input.211, %1838, %1839, %2960, %2959, %2960, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1844 : bool = prim::GetAttr[name="training"](%1799)
       = prim::If(%1844) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1845 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1799)
          %1846 : Tensor = aten::add(%1845, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1799, %1846)
          -> ()
        block1():
          -> ()
      %1847 : bool = prim::GetAttr[name="training"](%1799)
      %1848 : Tensor = prim::GetAttr[name="running_mean"](%1799)
      %1849 : Tensor = prim::GetAttr[name="running_var"](%1799)
      %1850 : Tensor = prim::GetAttr[name="weight"](%1799)
      %1851 : Tensor = prim::GetAttr[name="bias"](%1799)
       = prim::If(%1847) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1852 : int[] = aten::size(%input.212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.200 : int = aten::__getitem__(%1852, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1854 : int = aten::len(%1852) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1855 : int = aten::sub(%1854, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.201 : int = prim::Loop(%1855, %10, %size_prods.200) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.51 : int, %size_prods.202 : int):
              %1859 : int = aten::add(%i.51, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1860 : int = aten::__getitem__(%1852, %1859) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.203 : int = aten::mul(%size_prods.202, %1860) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.203)
          %1862 : bool = aten::eq(%size_prods.201, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1862) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1863 : str = aten::format(%8, %1852) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1863) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.213 : Tensor = aten::batch_norm(%input.212, %1850, %1851, %1848, %1849, %1847, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1865 : int[] = aten::size(%input.213) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.13 : int, %c.13 : int, %1868 : int, %1869 : int = prim::ListUnpack(%1865)
      %1872 : int = aten::len(%1865) # <string>:5:9
      %1873 : bool = aten::gt(%1872, %22) # <string>:5:9
       = prim::If(%1873) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %1874 : Tensor = aten::adaptive_avg_pool2d(%input.213, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %1875 : int[] = prim::ListConstruct(%b.13, %c.13)
      %y.25 : Tensor = aten::view(%1874, %1875) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %1877 : __torch__.torch.nn.modules.container.___torch_mangle_55.Sequential = prim::GetAttr[name="fc"](%1800)
      %1878 : __torch__.torch.nn.modules.linear.___torch_mangle_53.Linear = prim::GetAttr[name="0"](%1877)
      %1879 : __torch__.torch.nn.modules.linear.___torch_mangle_54.Linear = prim::GetAttr[name="2"](%1877)
      %1880 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%1877)
      %1881 : Tensor = prim::GetAttr[name="weight"](%1878)
      %input.214 : Tensor = aten::linear(%y.25, %1881, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.215 : Tensor = aten::relu_(%input.214) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1884 : Tensor = prim::GetAttr[name="weight"](%1879)
      %input.216 : Tensor = aten::linear(%input.215, %1884, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %1886 : Tensor = aten::add(%input.216, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %1887 : bool = prim::GetAttr[name="inplace"](%1880)
      %result.102 : Tensor = prim::If(%1887) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.103 : Tensor = aten::hardtanh_(%1886, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.103)
        block1():
          %result.104 : Tensor = aten::hardtanh(%1886, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.104)
      %input.217 : Tensor = aten::div(%result.102, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %1892 : int[] = prim::ListConstruct(%b.13, %c.13, %11, %11)
      %y.26 : Tensor = aten::view(%input.217, %1892) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %1894 : Tensor = aten::expand_as(%y.26, %input.213) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.218 : Tensor = aten::mul(%input.213, %1894) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %1896 : Tensor = aten::add(%input.218, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %1897 : bool = prim::GetAttr[name="inplace"](%1801)
      %result.105 : Tensor = prim::If(%1897) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.106 : Tensor = aten::hardtanh_(%1896, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.106)
        block1():
          %result.107 : Tensor = aten::hardtanh(%1896, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.107)
      %1901 : Tensor = aten::mul(%input.218, %result.105) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.219 : Tensor = aten::div(%1901, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %1903 : Tensor = prim::GetAttr[name="weight"](%1802)
      %1904 : Tensor? = prim::GetAttr[name="bias"](%1802)
      %input.220 : Tensor = aten::conv2d(%input.219, %1903, %1904, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1909 : bool = prim::GetAttr[name="training"](%1803)
       = prim::If(%1909) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1910 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1803)
          %1911 : Tensor = aten::add(%1910, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1803, %1911)
          -> ()
        block1():
          -> ()
      %1912 : bool = prim::GetAttr[name="training"](%1803)
      %1913 : Tensor = prim::GetAttr[name="running_mean"](%1803)
      %1914 : Tensor = prim::GetAttr[name="running_var"](%1803)
      %1915 : Tensor = prim::GetAttr[name="weight"](%1803)
      %1916 : Tensor = prim::GetAttr[name="bias"](%1803)
       = prim::If(%1912) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1917 : int[] = aten::size(%input.220) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.204 : int = aten::__getitem__(%1917, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1919 : int = aten::len(%1917) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1920 : int = aten::sub(%1919, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.205 : int = prim::Loop(%1920, %10, %size_prods.204) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.52 : int, %size_prods.206 : int):
              %1924 : int = aten::add(%i.52, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1925 : int = aten::__getitem__(%1917, %1924) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.207 : int = aten::mul(%size_prods.206, %1925) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.207)
          %1927 : bool = aten::eq(%size_prods.205, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1927) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1928 : str = aten::format(%8, %1917) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1928) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.221 : Tensor = aten::batch_norm(%input.220, %1915, %1916, %1913, %1914, %1912, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1930 : Tensor = aten::add(%input.45, %input.221, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:113:19
      -> (%1930)
    block1():
      %1931 : __torch__.torch.nn.modules.container.___torch_mangle_58.Sequential = prim::GetAttr[name="conv"](%35)
      %1932 : __torch__.torch.nn.modules.conv.___torch_mangle_50.Conv2d = prim::GetAttr[name="0"](%1931)
      %1933 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_51.BatchNorm2d = prim::GetAttr[name="1"](%1931)
      %1934 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%1931)
      %1935 : __torch__.torch.nn.modules.conv.___torch_mangle_52.Conv2d = prim::GetAttr[name="3"](%1931)
      %1936 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_51.BatchNorm2d = prim::GetAttr[name="4"](%1931)
      %1937 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_56.SEModule = prim::GetAttr[name="5"](%1931)
      %1938 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="6"](%1931)
      %1939 : __torch__.torch.nn.modules.conv.___torch_mangle_57.Conv2d = prim::GetAttr[name="7"](%1931)
      %1940 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_47.BatchNorm2d = prim::GetAttr[name="8"](%1931)
      %1941 : Tensor = prim::GetAttr[name="weight"](%1932)
      %1942 : Tensor? = prim::GetAttr[name="bias"](%1932)
      %input.222 : Tensor = aten::conv2d(%input.45, %1941, %1942, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1947 : bool = prim::GetAttr[name="training"](%1933)
       = prim::If(%1947) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1948 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1933)
          %1949 : Tensor = aten::add(%1948, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1933, %1949)
          -> ()
        block1():
          -> ()
      %1950 : bool = prim::GetAttr[name="training"](%1933)
      %1951 : Tensor = prim::GetAttr[name="running_mean"](%1933)
      %1952 : Tensor = prim::GetAttr[name="running_var"](%1933)
      %1953 : Tensor = prim::GetAttr[name="weight"](%1933)
      %1954 : Tensor = prim::GetAttr[name="bias"](%1933)
       = prim::If(%1950) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1955 : int[] = aten::size(%input.222) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.208 : int = aten::__getitem__(%1955, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1957 : int = aten::len(%1955) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1958 : int = aten::sub(%1957, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.209 : int = prim::Loop(%1958, %10, %size_prods.208) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.53 : int, %size_prods.210 : int):
              %1962 : int = aten::add(%i.53, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1963 : int = aten::__getitem__(%1955, %1962) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.211 : int = aten::mul(%size_prods.210, %1963) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.211)
          %1965 : bool = aten::eq(%size_prods.209, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1965) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1966 : str = aten::format(%8, %1955) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1966) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.223 : Tensor = aten::batch_norm(%input.222, %1953, %1954, %1951, %1952, %1950, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1968 : Tensor = aten::add(%input.223, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %1969 : bool = prim::GetAttr[name="inplace"](%1934)
      %result.108 : Tensor = prim::If(%1969) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.109 : Tensor = aten::hardtanh_(%1968, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.109)
        block1():
          %result.110 : Tensor = aten::hardtanh(%1968, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.110)
      %1973 : Tensor = aten::mul(%input.223, %result.108) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.224 : Tensor = aten::div(%1973, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %1975 : Tensor = prim::GetAttr[name="weight"](%1935)
      %1976 : Tensor? = prim::GetAttr[name="bias"](%1935)
      %input.225 : Tensor = aten::conv2d(%input.224, %1975, %1976, %2960, %2959, %2960, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1981 : bool = prim::GetAttr[name="training"](%1936)
       = prim::If(%1981) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1982 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1936)
          %1983 : Tensor = aten::add(%1982, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1936, %1983)
          -> ()
        block1():
          -> ()
      %1984 : bool = prim::GetAttr[name="training"](%1936)
      %1985 : Tensor = prim::GetAttr[name="running_mean"](%1936)
      %1986 : Tensor = prim::GetAttr[name="running_var"](%1936)
      %1987 : Tensor = prim::GetAttr[name="weight"](%1936)
      %1988 : Tensor = prim::GetAttr[name="bias"](%1936)
       = prim::If(%1984) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1989 : int[] = aten::size(%input.225) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.212 : int = aten::__getitem__(%1989, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1991 : int = aten::len(%1989) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1992 : int = aten::sub(%1991, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.213 : int = prim::Loop(%1992, %10, %size_prods.212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.54 : int, %size_prods.214 : int):
              %1996 : int = aten::add(%i.54, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1997 : int = aten::__getitem__(%1989, %1996) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.215 : int = aten::mul(%size_prods.214, %1997) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.215)
          %1999 : bool = aten::eq(%size_prods.213, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1999) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2000 : str = aten::format(%8, %1989) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2000) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.226 : Tensor = aten::batch_norm(%input.225, %1987, %1988, %1985, %1986, %1984, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2002 : int[] = aten::size(%input.226) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.14 : int, %c.14 : int, %2005 : int, %2006 : int = prim::ListUnpack(%2002)
      %2009 : int = aten::len(%2002) # <string>:5:9
      %2010 : bool = aten::gt(%2009, %22) # <string>:5:9
       = prim::If(%2010) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %2011 : Tensor = aten::adaptive_avg_pool2d(%input.226, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %2012 : int[] = prim::ListConstruct(%b.14, %c.14)
      %y.27 : Tensor = aten::view(%2011, %2012) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %2014 : __torch__.torch.nn.modules.container.___torch_mangle_55.Sequential = prim::GetAttr[name="fc"](%1937)
      %2015 : __torch__.torch.nn.modules.linear.___torch_mangle_53.Linear = prim::GetAttr[name="0"](%2014)
      %2016 : __torch__.torch.nn.modules.linear.___torch_mangle_54.Linear = prim::GetAttr[name="2"](%2014)
      %2017 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%2014)
      %2018 : Tensor = prim::GetAttr[name="weight"](%2015)
      %input.227 : Tensor = aten::linear(%y.27, %2018, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.228 : Tensor = aten::relu_(%input.227) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2021 : Tensor = prim::GetAttr[name="weight"](%2016)
      %input.229 : Tensor = aten::linear(%input.228, %2021, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %2023 : Tensor = aten::add(%input.229, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %2024 : bool = prim::GetAttr[name="inplace"](%2017)
      %result.111 : Tensor = prim::If(%2024) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.112 : Tensor = aten::hardtanh_(%2023, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.112)
        block1():
          %result.113 : Tensor = aten::hardtanh(%2023, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.113)
      %input.230 : Tensor = aten::div(%result.111, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %2029 : int[] = prim::ListConstruct(%b.14, %c.14, %11, %11)
      %y.28 : Tensor = aten::view(%input.230, %2029) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %2031 : Tensor = aten::expand_as(%y.28, %input.226) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.231 : Tensor = aten::mul(%input.226, %2031) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %2033 : Tensor = aten::add(%input.231, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %2034 : bool = prim::GetAttr[name="inplace"](%1938)
      %result.114 : Tensor = prim::If(%2034) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.115 : Tensor = aten::hardtanh_(%2033, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.115)
        block1():
          %result.116 : Tensor = aten::hardtanh(%2033, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.116)
      %2038 : Tensor = aten::mul(%input.231, %result.114) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.232 : Tensor = aten::div(%2038, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %2040 : Tensor = prim::GetAttr[name="weight"](%1939)
      %2041 : Tensor? = prim::GetAttr[name="bias"](%1939)
      %input.233 : Tensor = aten::conv2d(%input.232, %2040, %2041, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2046 : bool = prim::GetAttr[name="training"](%1940)
       = prim::If(%2046) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2047 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1940)
          %2048 : Tensor = aten::add(%2047, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1940, %2048)
          -> ()
        block1():
          -> ()
      %2049 : bool = prim::GetAttr[name="training"](%1940)
      %2050 : Tensor = prim::GetAttr[name="running_mean"](%1940)
      %2051 : Tensor = prim::GetAttr[name="running_var"](%1940)
      %2052 : Tensor = prim::GetAttr[name="weight"](%1940)
      %2053 : Tensor = prim::GetAttr[name="bias"](%1940)
       = prim::If(%2049) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2054 : int[] = aten::size(%input.233) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.216 : int = aten::__getitem__(%2054, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2056 : int = aten::len(%2054) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2057 : int = aten::sub(%2056, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.217 : int = prim::Loop(%2057, %10, %size_prods.216) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.55 : int, %size_prods.218 : int):
              %2061 : int = aten::add(%i.55, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2062 : int = aten::__getitem__(%2054, %2061) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.219 : int = aten::mul(%size_prods.218, %2062) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.219)
          %2064 : bool = aten::eq(%size_prods.217, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2064) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2065 : str = aten::format(%8, %2054) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2065) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.234 : Tensor = aten::batch_norm(%input.233, %2052, %2053, %2050, %2051, %2049, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.234)
  %2067 : bool = prim::GetAttr[name="use_res_connect"](%36)
  %input.35 : Tensor = prim::If(%2067) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:112:8
    block0():
      %2069 : __torch__.torch.nn.modules.container.___torch_mangle_68.Sequential = prim::GetAttr[name="conv"](%36)
      %2070 : __torch__.torch.nn.modules.conv.___torch_mangle_60.Conv2d = prim::GetAttr[name="0"](%2069)
      %2071 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_61.BatchNorm2d = prim::GetAttr[name="1"](%2069)
      %2072 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%2069)
      %2073 : __torch__.torch.nn.modules.conv.___torch_mangle_62.Conv2d = prim::GetAttr[name="3"](%2069)
      %2074 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_61.BatchNorm2d = prim::GetAttr[name="4"](%2069)
      %2075 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_66.SEModule = prim::GetAttr[name="5"](%2069)
      %2076 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="6"](%2069)
      %2077 : __torch__.torch.nn.modules.conv.___torch_mangle_67.Conv2d = prim::GetAttr[name="7"](%2069)
      %2078 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_19.BatchNorm2d = prim::GetAttr[name="8"](%2069)
      %2079 : Tensor = prim::GetAttr[name="weight"](%2070)
      %2080 : Tensor? = prim::GetAttr[name="bias"](%2070)
      %input.235 : Tensor = aten::conv2d(%input.46, %2079, %2080, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2085 : bool = prim::GetAttr[name="training"](%2071)
       = prim::If(%2085) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2086 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2071)
          %2087 : Tensor = aten::add(%2086, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2071, %2087)
          -> ()
        block1():
          -> ()
      %2088 : bool = prim::GetAttr[name="training"](%2071)
      %2089 : Tensor = prim::GetAttr[name="running_mean"](%2071)
      %2090 : Tensor = prim::GetAttr[name="running_var"](%2071)
      %2091 : Tensor = prim::GetAttr[name="weight"](%2071)
      %2092 : Tensor = prim::GetAttr[name="bias"](%2071)
       = prim::If(%2088) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2093 : int[] = aten::size(%input.235) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.220 : int = aten::__getitem__(%2093, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2095 : int = aten::len(%2093) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2096 : int = aten::sub(%2095, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.221 : int = prim::Loop(%2096, %10, %size_prods.220) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.56 : int, %size_prods.222 : int):
              %2100 : int = aten::add(%i.56, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2101 : int = aten::__getitem__(%2093, %2100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.223 : int = aten::mul(%size_prods.222, %2101) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.223)
          %2103 : bool = aten::eq(%size_prods.221, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2103) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2104 : str = aten::format(%8, %2093) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.236 : Tensor = aten::batch_norm(%input.235, %2091, %2092, %2089, %2090, %2088, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2106 : Tensor = aten::add(%input.236, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %2107 : bool = prim::GetAttr[name="inplace"](%2072)
      %result.117 : Tensor = prim::If(%2107) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.118 : Tensor = aten::hardtanh_(%2106, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.118)
        block1():
          %result.119 : Tensor = aten::hardtanh(%2106, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.119)
      %2111 : Tensor = aten::mul(%input.236, %result.117) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.237 : Tensor = aten::div(%2111, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %2113 : Tensor = prim::GetAttr[name="weight"](%2073)
      %2114 : Tensor? = prim::GetAttr[name="bias"](%2073)
      %input.238 : Tensor = aten::conv2d(%input.237, %2113, %2114, %2959, %2959, %2960, %20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2119 : bool = prim::GetAttr[name="training"](%2074)
       = prim::If(%2119) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2120 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2074)
          %2121 : Tensor = aten::add(%2120, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2074, %2121)
          -> ()
        block1():
          -> ()
      %2122 : bool = prim::GetAttr[name="training"](%2074)
      %2123 : Tensor = prim::GetAttr[name="running_mean"](%2074)
      %2124 : Tensor = prim::GetAttr[name="running_var"](%2074)
      %2125 : Tensor = prim::GetAttr[name="weight"](%2074)
      %2126 : Tensor = prim::GetAttr[name="bias"](%2074)
       = prim::If(%2122) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2127 : int[] = aten::size(%input.238) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.224 : int = aten::__getitem__(%2127, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2129 : int = aten::len(%2127) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2130 : int = aten::sub(%2129, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.225 : int = prim::Loop(%2130, %10, %size_prods.224) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.57 : int, %size_prods.226 : int):
              %2134 : int = aten::add(%i.57, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2135 : int = aten::__getitem__(%2127, %2134) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.227 : int = aten::mul(%size_prods.226, %2135) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.227)
          %2137 : bool = aten::eq(%size_prods.225, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2137) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2138 : str = aten::format(%8, %2127) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2138) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.239 : Tensor = aten::batch_norm(%input.238, %2125, %2126, %2123, %2124, %2122, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2140 : int[] = aten::size(%input.239) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.15 : int, %c.15 : int, %2143 : int, %2144 : int = prim::ListUnpack(%2140)
      %2147 : int = aten::len(%2140) # <string>:5:9
      %2148 : bool = aten::gt(%2147, %22) # <string>:5:9
       = prim::If(%2148) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %2149 : Tensor = aten::adaptive_avg_pool2d(%input.239, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %2150 : int[] = prim::ListConstruct(%b.15, %c.15)
      %y.29 : Tensor = aten::view(%2149, %2150) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %2152 : __torch__.torch.nn.modules.container.___torch_mangle_65.Sequential = prim::GetAttr[name="fc"](%2075)
      %2153 : __torch__.torch.nn.modules.linear.___torch_mangle_63.Linear = prim::GetAttr[name="0"](%2152)
      %2154 : __torch__.torch.nn.modules.linear.___torch_mangle_64.Linear = prim::GetAttr[name="2"](%2152)
      %2155 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%2152)
      %2156 : Tensor = prim::GetAttr[name="weight"](%2153)
      %input.240 : Tensor = aten::linear(%y.29, %2156, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.241 : Tensor = aten::relu_(%input.240) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2159 : Tensor = prim::GetAttr[name="weight"](%2154)
      %input.242 : Tensor = aten::linear(%input.241, %2159, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %2161 : Tensor = aten::add(%input.242, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %2162 : bool = prim::GetAttr[name="inplace"](%2155)
      %result.120 : Tensor = prim::If(%2162) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.121 : Tensor = aten::hardtanh_(%2161, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.121)
        block1():
          %result.122 : Tensor = aten::hardtanh(%2161, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.122)
      %input.243 : Tensor = aten::div(%result.120, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %2167 : int[] = prim::ListConstruct(%b.15, %c.15, %11, %11)
      %y.30 : Tensor = aten::view(%input.243, %2167) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %2169 : Tensor = aten::expand_as(%y.30, %input.239) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.244 : Tensor = aten::mul(%input.239, %2169) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %2171 : Tensor = aten::add(%input.244, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %2172 : bool = prim::GetAttr[name="inplace"](%2076)
      %result.123 : Tensor = prim::If(%2172) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.124 : Tensor = aten::hardtanh_(%2171, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.124)
        block1():
          %result.125 : Tensor = aten::hardtanh(%2171, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.125)
      %2176 : Tensor = aten::mul(%input.244, %result.123) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.245 : Tensor = aten::div(%2176, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %2178 : Tensor = prim::GetAttr[name="weight"](%2077)
      %2179 : Tensor? = prim::GetAttr[name="bias"](%2077)
      %input.246 : Tensor = aten::conv2d(%input.245, %2178, %2179, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2184 : bool = prim::GetAttr[name="training"](%2078)
       = prim::If(%2184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2185 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2078)
          %2186 : Tensor = aten::add(%2185, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2078, %2186)
          -> ()
        block1():
          -> ()
      %2187 : bool = prim::GetAttr[name="training"](%2078)
      %2188 : Tensor = prim::GetAttr[name="running_mean"](%2078)
      %2189 : Tensor = prim::GetAttr[name="running_var"](%2078)
      %2190 : Tensor = prim::GetAttr[name="weight"](%2078)
      %2191 : Tensor = prim::GetAttr[name="bias"](%2078)
       = prim::If(%2187) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2192 : int[] = aten::size(%input.246) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.228 : int = aten::__getitem__(%2192, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2194 : int = aten::len(%2192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2195 : int = aten::sub(%2194, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.229 : int = prim::Loop(%2195, %10, %size_prods.228) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.58 : int, %size_prods.230 : int):
              %2199 : int = aten::add(%i.58, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2200 : int = aten::__getitem__(%2192, %2199) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.231 : int = aten::mul(%size_prods.230, %2200) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.231)
          %2202 : bool = aten::eq(%size_prods.229, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2202) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2203 : str = aten::format(%8, %2192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2203) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.247 : Tensor = aten::batch_norm(%input.246, %2190, %2191, %2188, %2189, %2187, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2205 : Tensor = aten::add(%input.46, %input.247, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:113:19
      -> (%2205)
    block1():
      %2206 : __torch__.torch.nn.modules.container.___torch_mangle_68.Sequential = prim::GetAttr[name="conv"](%36)
      %2207 : __torch__.torch.nn.modules.conv.___torch_mangle_60.Conv2d = prim::GetAttr[name="0"](%2206)
      %2208 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_61.BatchNorm2d = prim::GetAttr[name="1"](%2206)
      %2209 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%2206)
      %2210 : __torch__.torch.nn.modules.conv.___torch_mangle_62.Conv2d = prim::GetAttr[name="3"](%2206)
      %2211 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_61.BatchNorm2d = prim::GetAttr[name="4"](%2206)
      %2212 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_66.SEModule = prim::GetAttr[name="5"](%2206)
      %2213 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="6"](%2206)
      %2214 : __torch__.torch.nn.modules.conv.___torch_mangle_67.Conv2d = prim::GetAttr[name="7"](%2206)
      %2215 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_19.BatchNorm2d = prim::GetAttr[name="8"](%2206)
      %2216 : Tensor = prim::GetAttr[name="weight"](%2207)
      %2217 : Tensor? = prim::GetAttr[name="bias"](%2207)
      %input.248 : Tensor = aten::conv2d(%input.46, %2216, %2217, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2222 : bool = prim::GetAttr[name="training"](%2208)
       = prim::If(%2222) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2223 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2208)
          %2224 : Tensor = aten::add(%2223, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2208, %2224)
          -> ()
        block1():
          -> ()
      %2225 : bool = prim::GetAttr[name="training"](%2208)
      %2226 : Tensor = prim::GetAttr[name="running_mean"](%2208)
      %2227 : Tensor = prim::GetAttr[name="running_var"](%2208)
      %2228 : Tensor = prim::GetAttr[name="weight"](%2208)
      %2229 : Tensor = prim::GetAttr[name="bias"](%2208)
       = prim::If(%2225) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2230 : int[] = aten::size(%input.248) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.232 : int = aten::__getitem__(%2230, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2232 : int = aten::len(%2230) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2233 : int = aten::sub(%2232, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.233 : int = prim::Loop(%2233, %10, %size_prods.232) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.59 : int, %size_prods.234 : int):
              %2237 : int = aten::add(%i.59, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2238 : int = aten::__getitem__(%2230, %2237) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.235 : int = aten::mul(%size_prods.234, %2238) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.235)
          %2240 : bool = aten::eq(%size_prods.233, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2240) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2241 : str = aten::format(%8, %2230) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2241) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.249 : Tensor = aten::batch_norm(%input.248, %2228, %2229, %2226, %2227, %2225, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2243 : Tensor = aten::add(%input.249, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %2244 : bool = prim::GetAttr[name="inplace"](%2209)
      %result.126 : Tensor = prim::If(%2244) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.127 : Tensor = aten::hardtanh_(%2243, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.127)
        block1():
          %result.128 : Tensor = aten::hardtanh(%2243, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.128)
      %2248 : Tensor = aten::mul(%input.249, %result.126) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.250 : Tensor = aten::div(%2248, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %2250 : Tensor = prim::GetAttr[name="weight"](%2210)
      %2251 : Tensor? = prim::GetAttr[name="bias"](%2210)
      %input.251 : Tensor = aten::conv2d(%input.250, %2250, %2251, %2959, %2959, %2960, %20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2256 : bool = prim::GetAttr[name="training"](%2211)
       = prim::If(%2256) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2257 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2211)
          %2258 : Tensor = aten::add(%2257, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2211, %2258)
          -> ()
        block1():
          -> ()
      %2259 : bool = prim::GetAttr[name="training"](%2211)
      %2260 : Tensor = prim::GetAttr[name="running_mean"](%2211)
      %2261 : Tensor = prim::GetAttr[name="running_var"](%2211)
      %2262 : Tensor = prim::GetAttr[name="weight"](%2211)
      %2263 : Tensor = prim::GetAttr[name="bias"](%2211)
       = prim::If(%2259) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2264 : int[] = aten::size(%input.251) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.236 : int = aten::__getitem__(%2264, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2266 : int = aten::len(%2264) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2267 : int = aten::sub(%2266, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.237 : int = prim::Loop(%2267, %10, %size_prods.236) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.60 : int, %size_prods.238 : int):
              %2271 : int = aten::add(%i.60, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2272 : int = aten::__getitem__(%2264, %2271) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.239 : int = aten::mul(%size_prods.238, %2272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.239)
          %2274 : bool = aten::eq(%size_prods.237, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2274) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2275 : str = aten::format(%8, %2264) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2275) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.252 : Tensor = aten::batch_norm(%input.251, %2262, %2263, %2260, %2261, %2259, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2277 : int[] = aten::size(%input.252) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.16 : int, %c.16 : int, %2280 : int, %2281 : int = prim::ListUnpack(%2277)
      %2284 : int = aten::len(%2277) # <string>:5:9
      %2285 : bool = aten::gt(%2284, %22) # <string>:5:9
       = prim::If(%2285) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %2286 : Tensor = aten::adaptive_avg_pool2d(%input.252, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %2287 : int[] = prim::ListConstruct(%b.16, %c.16)
      %y.31 : Tensor = aten::view(%2286, %2287) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %2289 : __torch__.torch.nn.modules.container.___torch_mangle_65.Sequential = prim::GetAttr[name="fc"](%2212)
      %2290 : __torch__.torch.nn.modules.linear.___torch_mangle_63.Linear = prim::GetAttr[name="0"](%2289)
      %2291 : __torch__.torch.nn.modules.linear.___torch_mangle_64.Linear = prim::GetAttr[name="2"](%2289)
      %2292 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%2289)
      %2293 : Tensor = prim::GetAttr[name="weight"](%2290)
      %input.253 : Tensor = aten::linear(%y.31, %2293, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.254 : Tensor = aten::relu_(%input.253) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2296 : Tensor = prim::GetAttr[name="weight"](%2291)
      %input.255 : Tensor = aten::linear(%input.254, %2296, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %2298 : Tensor = aten::add(%input.255, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %2299 : bool = prim::GetAttr[name="inplace"](%2292)
      %result.129 : Tensor = prim::If(%2299) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.130 : Tensor = aten::hardtanh_(%2298, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.130)
        block1():
          %result.131 : Tensor = aten::hardtanh(%2298, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.131)
      %input.256 : Tensor = aten::div(%result.129, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %2304 : int[] = prim::ListConstruct(%b.16, %c.16, %11, %11)
      %y.32 : Tensor = aten::view(%input.256, %2304) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %2306 : Tensor = aten::expand_as(%y.32, %input.252) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.257 : Tensor = aten::mul(%input.252, %2306) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %2308 : Tensor = aten::add(%input.257, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %2309 : bool = prim::GetAttr[name="inplace"](%2213)
      %result.132 : Tensor = prim::If(%2309) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.133 : Tensor = aten::hardtanh_(%2308, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.133)
        block1():
          %result.134 : Tensor = aten::hardtanh(%2308, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.134)
      %2313 : Tensor = aten::mul(%input.257, %result.132) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.258 : Tensor = aten::div(%2313, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %2315 : Tensor = prim::GetAttr[name="weight"](%2214)
      %2316 : Tensor? = prim::GetAttr[name="bias"](%2214)
      %input.259 : Tensor = aten::conv2d(%input.258, %2315, %2316, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2321 : bool = prim::GetAttr[name="training"](%2215)
       = prim::If(%2321) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2322 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2215)
          %2323 : Tensor = aten::add(%2322, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2215, %2323)
          -> ()
        block1():
          -> ()
      %2324 : bool = prim::GetAttr[name="training"](%2215)
      %2325 : Tensor = prim::GetAttr[name="running_mean"](%2215)
      %2326 : Tensor = prim::GetAttr[name="running_var"](%2215)
      %2327 : Tensor = prim::GetAttr[name="weight"](%2215)
      %2328 : Tensor = prim::GetAttr[name="bias"](%2215)
       = prim::If(%2324) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2329 : int[] = aten::size(%input.259) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.240 : int = aten::__getitem__(%2329, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2331 : int = aten::len(%2329) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2332 : int = aten::sub(%2331, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.241 : int = prim::Loop(%2332, %10, %size_prods.240) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.61 : int, %size_prods.242 : int):
              %2336 : int = aten::add(%i.61, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2337 : int = aten::__getitem__(%2329, %2336) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.243 : int = aten::mul(%size_prods.242, %2337) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.243)
          %2339 : bool = aten::eq(%size_prods.241, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2339) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2340 : str = aten::format(%8, %2329) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2340) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.260 : Tensor = aten::batch_norm(%input.259, %2327, %2328, %2325, %2326, %2324, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.260)
  %2342 : bool = prim::GetAttr[name="use_res_connect"](%37)
  %input.32 : Tensor = prim::If(%2342) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:112:8
    block0():
      %2344 : __torch__.torch.nn.modules.container.___torch_mangle_78.Sequential = prim::GetAttr[name="conv"](%37)
      %2345 : __torch__.torch.nn.modules.conv.___torch_mangle_70.Conv2d = prim::GetAttr[name="0"](%2344)
      %2346 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_71.BatchNorm2d = prim::GetAttr[name="1"](%2344)
      %2347 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%2344)
      %2348 : __torch__.torch.nn.modules.conv.___torch_mangle_72.Conv2d = prim::GetAttr[name="3"](%2344)
      %2349 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_71.BatchNorm2d = prim::GetAttr[name="4"](%2344)
      %2350 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_76.SEModule = prim::GetAttr[name="5"](%2344)
      %2351 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="6"](%2344)
      %2352 : __torch__.torch.nn.modules.conv.___torch_mangle_77.Conv2d = prim::GetAttr[name="7"](%2344)
      %2353 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_19.BatchNorm2d = prim::GetAttr[name="8"](%2344)
      %2354 : Tensor = prim::GetAttr[name="weight"](%2345)
      %2355 : Tensor? = prim::GetAttr[name="bias"](%2345)
      %input.261 : Tensor = aten::conv2d(%input.35, %2354, %2355, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2360 : bool = prim::GetAttr[name="training"](%2346)
       = prim::If(%2360) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2361 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2346)
          %2362 : Tensor = aten::add(%2361, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2346, %2362)
          -> ()
        block1():
          -> ()
      %2363 : bool = prim::GetAttr[name="training"](%2346)
      %2364 : Tensor = prim::GetAttr[name="running_mean"](%2346)
      %2365 : Tensor = prim::GetAttr[name="running_var"](%2346)
      %2366 : Tensor = prim::GetAttr[name="weight"](%2346)
      %2367 : Tensor = prim::GetAttr[name="bias"](%2346)
       = prim::If(%2363) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2368 : int[] = aten::size(%input.261) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.244 : int = aten::__getitem__(%2368, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2370 : int = aten::len(%2368) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2371 : int = aten::sub(%2370, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.245 : int = prim::Loop(%2371, %10, %size_prods.244) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.62 : int, %size_prods.246 : int):
              %2375 : int = aten::add(%i.62, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2376 : int = aten::__getitem__(%2368, %2375) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.247 : int = aten::mul(%size_prods.246, %2376) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.247)
          %2378 : bool = aten::eq(%size_prods.245, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2378) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2379 : str = aten::format(%8, %2368) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2379) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.262 : Tensor = aten::batch_norm(%input.261, %2366, %2367, %2364, %2365, %2363, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2381 : Tensor = aten::add(%input.262, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %2382 : bool = prim::GetAttr[name="inplace"](%2347)
      %result.135 : Tensor = prim::If(%2382) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.136 : Tensor = aten::hardtanh_(%2381, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.136)
        block1():
          %result.137 : Tensor = aten::hardtanh(%2381, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.137)
      %2386 : Tensor = aten::mul(%input.262, %result.135) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.263 : Tensor = aten::div(%2386, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %2388 : Tensor = prim::GetAttr[name="weight"](%2348)
      %2389 : Tensor? = prim::GetAttr[name="bias"](%2348)
      %input.264 : Tensor = aten::conv2d(%input.263, %2388, %2389, %2960, %2959, %2960, %21) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2394 : bool = prim::GetAttr[name="training"](%2349)
       = prim::If(%2394) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2395 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2349)
          %2396 : Tensor = aten::add(%2395, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2349, %2396)
          -> ()
        block1():
          -> ()
      %2397 : bool = prim::GetAttr[name="training"](%2349)
      %2398 : Tensor = prim::GetAttr[name="running_mean"](%2349)
      %2399 : Tensor = prim::GetAttr[name="running_var"](%2349)
      %2400 : Tensor = prim::GetAttr[name="weight"](%2349)
      %2401 : Tensor = prim::GetAttr[name="bias"](%2349)
       = prim::If(%2397) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2402 : int[] = aten::size(%input.264) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.248 : int = aten::__getitem__(%2402, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2404 : int = aten::len(%2402) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2405 : int = aten::sub(%2404, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.249 : int = prim::Loop(%2405, %10, %size_prods.248) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.63 : int, %size_prods.250 : int):
              %2409 : int = aten::add(%i.63, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2410 : int = aten::__getitem__(%2402, %2409) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.251 : int = aten::mul(%size_prods.250, %2410) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.251)
          %2412 : bool = aten::eq(%size_prods.249, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2412) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2413 : str = aten::format(%8, %2402) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2413) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.265 : Tensor = aten::batch_norm(%input.264, %2400, %2401, %2398, %2399, %2397, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2415 : int[] = aten::size(%input.265) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.17 : int, %c.17 : int, %2418 : int, %2419 : int = prim::ListUnpack(%2415)
      %2422 : int = aten::len(%2415) # <string>:5:9
      %2423 : bool = aten::gt(%2422, %22) # <string>:5:9
       = prim::If(%2423) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %2424 : Tensor = aten::adaptive_avg_pool2d(%input.265, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %2425 : int[] = prim::ListConstruct(%b.17, %c.17)
      %y.33 : Tensor = aten::view(%2424, %2425) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %2427 : __torch__.torch.nn.modules.container.___torch_mangle_75.Sequential = prim::GetAttr[name="fc"](%2350)
      %2428 : __torch__.torch.nn.modules.linear.___torch_mangle_73.Linear = prim::GetAttr[name="0"](%2427)
      %2429 : __torch__.torch.nn.modules.linear.___torch_mangle_74.Linear = prim::GetAttr[name="2"](%2427)
      %2430 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%2427)
      %2431 : Tensor = prim::GetAttr[name="weight"](%2428)
      %input.266 : Tensor = aten::linear(%y.33, %2431, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.267 : Tensor = aten::relu_(%input.266) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2434 : Tensor = prim::GetAttr[name="weight"](%2429)
      %input.268 : Tensor = aten::linear(%input.267, %2434, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %2436 : Tensor = aten::add(%input.268, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %2437 : bool = prim::GetAttr[name="inplace"](%2430)
      %result.138 : Tensor = prim::If(%2437) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.139 : Tensor = aten::hardtanh_(%2436, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.139)
        block1():
          %result.140 : Tensor = aten::hardtanh(%2436, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.140)
      %input.269 : Tensor = aten::div(%result.138, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %2442 : int[] = prim::ListConstruct(%b.17, %c.17, %11, %11)
      %y.34 : Tensor = aten::view(%input.269, %2442) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %2444 : Tensor = aten::expand_as(%y.34, %input.265) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.270 : Tensor = aten::mul(%input.265, %2444) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %2446 : Tensor = aten::add(%input.270, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %2447 : bool = prim::GetAttr[name="inplace"](%2351)
      %result.141 : Tensor = prim::If(%2447) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.142 : Tensor = aten::hardtanh_(%2446, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.142)
        block1():
          %result.143 : Tensor = aten::hardtanh(%2446, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.143)
      %2451 : Tensor = aten::mul(%input.270, %result.141) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.271 : Tensor = aten::div(%2451, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %2453 : Tensor = prim::GetAttr[name="weight"](%2352)
      %2454 : Tensor? = prim::GetAttr[name="bias"](%2352)
      %input.272 : Tensor = aten::conv2d(%input.271, %2453, %2454, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2459 : bool = prim::GetAttr[name="training"](%2353)
       = prim::If(%2459) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2460 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2353)
          %2461 : Tensor = aten::add(%2460, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2353, %2461)
          -> ()
        block1():
          -> ()
      %2462 : bool = prim::GetAttr[name="training"](%2353)
      %2463 : Tensor = prim::GetAttr[name="running_mean"](%2353)
      %2464 : Tensor = prim::GetAttr[name="running_var"](%2353)
      %2465 : Tensor = prim::GetAttr[name="weight"](%2353)
      %2466 : Tensor = prim::GetAttr[name="bias"](%2353)
       = prim::If(%2462) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2467 : int[] = aten::size(%input.272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.252 : int = aten::__getitem__(%2467, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2469 : int = aten::len(%2467) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2470 : int = aten::sub(%2469, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.253 : int = prim::Loop(%2470, %10, %size_prods.252) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.64 : int, %size_prods.254 : int):
              %2474 : int = aten::add(%i.64, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2475 : int = aten::__getitem__(%2467, %2474) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.255 : int = aten::mul(%size_prods.254, %2475) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.255)
          %2477 : bool = aten::eq(%size_prods.253, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2477) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2478 : str = aten::format(%8, %2467) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2478) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.273 : Tensor = aten::batch_norm(%input.272, %2465, %2466, %2463, %2464, %2462, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2480 : Tensor = aten::add(%input.35, %input.273, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:113:19
      -> (%2480)
    block1():
      %2481 : __torch__.torch.nn.modules.container.___torch_mangle_78.Sequential = prim::GetAttr[name="conv"](%37)
      %2482 : __torch__.torch.nn.modules.conv.___torch_mangle_70.Conv2d = prim::GetAttr[name="0"](%2481)
      %2483 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_71.BatchNorm2d = prim::GetAttr[name="1"](%2481)
      %2484 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%2481)
      %2485 : __torch__.torch.nn.modules.conv.___torch_mangle_72.Conv2d = prim::GetAttr[name="3"](%2481)
      %2486 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_71.BatchNorm2d = prim::GetAttr[name="4"](%2481)
      %2487 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_76.SEModule = prim::GetAttr[name="5"](%2481)
      %2488 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="6"](%2481)
      %2489 : __torch__.torch.nn.modules.conv.___torch_mangle_77.Conv2d = prim::GetAttr[name="7"](%2481)
      %2490 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_19.BatchNorm2d = prim::GetAttr[name="8"](%2481)
      %2491 : Tensor = prim::GetAttr[name="weight"](%2482)
      %2492 : Tensor? = prim::GetAttr[name="bias"](%2482)
      %input.274 : Tensor = aten::conv2d(%input.35, %2491, %2492, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2497 : bool = prim::GetAttr[name="training"](%2483)
       = prim::If(%2497) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2498 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2483)
          %2499 : Tensor = aten::add(%2498, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2483, %2499)
          -> ()
        block1():
          -> ()
      %2500 : bool = prim::GetAttr[name="training"](%2483)
      %2501 : Tensor = prim::GetAttr[name="running_mean"](%2483)
      %2502 : Tensor = prim::GetAttr[name="running_var"](%2483)
      %2503 : Tensor = prim::GetAttr[name="weight"](%2483)
      %2504 : Tensor = prim::GetAttr[name="bias"](%2483)
       = prim::If(%2500) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2505 : int[] = aten::size(%input.274) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.256 : int = aten::__getitem__(%2505, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2507 : int = aten::len(%2505) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2508 : int = aten::sub(%2507, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.257 : int = prim::Loop(%2508, %10, %size_prods.256) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.65 : int, %size_prods.258 : int):
              %2512 : int = aten::add(%i.65, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2513 : int = aten::__getitem__(%2505, %2512) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.259 : int = aten::mul(%size_prods.258, %2513) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.259)
          %2515 : bool = aten::eq(%size_prods.257, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2515) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2516 : str = aten::format(%8, %2505) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2516) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.275 : Tensor = aten::batch_norm(%input.274, %2503, %2504, %2501, %2502, %2500, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2518 : Tensor = aten::add(%input.275, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %2519 : bool = prim::GetAttr[name="inplace"](%2484)
      %result.144 : Tensor = prim::If(%2519) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.145 : Tensor = aten::hardtanh_(%2518, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.145)
        block1():
          %result.146 : Tensor = aten::hardtanh(%2518, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.146)
      %2523 : Tensor = aten::mul(%input.275, %result.144) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.276 : Tensor = aten::div(%2523, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %2525 : Tensor = prim::GetAttr[name="weight"](%2485)
      %2526 : Tensor? = prim::GetAttr[name="bias"](%2485)
      %input.277 : Tensor = aten::conv2d(%input.276, %2525, %2526, %2960, %2959, %2960, %21) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2531 : bool = prim::GetAttr[name="training"](%2486)
       = prim::If(%2531) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2532 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2486)
          %2533 : Tensor = aten::add(%2532, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2486, %2533)
          -> ()
        block1():
          -> ()
      %2534 : bool = prim::GetAttr[name="training"](%2486)
      %2535 : Tensor = prim::GetAttr[name="running_mean"](%2486)
      %2536 : Tensor = prim::GetAttr[name="running_var"](%2486)
      %2537 : Tensor = prim::GetAttr[name="weight"](%2486)
      %2538 : Tensor = prim::GetAttr[name="bias"](%2486)
       = prim::If(%2534) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2539 : int[] = aten::size(%input.277) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.260 : int = aten::__getitem__(%2539, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2541 : int = aten::len(%2539) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2542 : int = aten::sub(%2541, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.261 : int = prim::Loop(%2542, %10, %size_prods.260) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.66 : int, %size_prods.262 : int):
              %2546 : int = aten::add(%i.66, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2547 : int = aten::__getitem__(%2539, %2546) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.263 : int = aten::mul(%size_prods.262, %2547) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.263)
          %2549 : bool = aten::eq(%size_prods.261, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2549) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2550 : str = aten::format(%8, %2539) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2550) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.278 : Tensor = aten::batch_norm(%input.277, %2537, %2538, %2535, %2536, %2534, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2552 : int[] = aten::size(%input.278) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.18 : int, %c.18 : int, %2555 : int, %2556 : int = prim::ListUnpack(%2552)
      %2559 : int = aten::len(%2552) # <string>:5:9
      %2560 : bool = aten::gt(%2559, %22) # <string>:5:9
       = prim::If(%2560) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %2561 : Tensor = aten::adaptive_avg_pool2d(%input.278, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %2562 : int[] = prim::ListConstruct(%b.18, %c.18)
      %y.35 : Tensor = aten::view(%2561, %2562) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %2564 : __torch__.torch.nn.modules.container.___torch_mangle_75.Sequential = prim::GetAttr[name="fc"](%2487)
      %2565 : __torch__.torch.nn.modules.linear.___torch_mangle_73.Linear = prim::GetAttr[name="0"](%2564)
      %2566 : __torch__.torch.nn.modules.linear.___torch_mangle_74.Linear = prim::GetAttr[name="2"](%2564)
      %2567 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%2564)
      %2568 : Tensor = prim::GetAttr[name="weight"](%2565)
      %input.279 : Tensor = aten::linear(%y.35, %2568, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.280 : Tensor = aten::relu_(%input.279) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2571 : Tensor = prim::GetAttr[name="weight"](%2566)
      %input.281 : Tensor = aten::linear(%input.280, %2571, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %2573 : Tensor = aten::add(%input.281, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %2574 : bool = prim::GetAttr[name="inplace"](%2567)
      %result.147 : Tensor = prim::If(%2574) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.148 : Tensor = aten::hardtanh_(%2573, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.148)
        block1():
          %result.149 : Tensor = aten::hardtanh(%2573, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.149)
      %input.282 : Tensor = aten::div(%result.147, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %2579 : int[] = prim::ListConstruct(%b.18, %c.18, %11, %11)
      %y.36 : Tensor = aten::view(%input.282, %2579) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %2581 : Tensor = aten::expand_as(%y.36, %input.278) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.283 : Tensor = aten::mul(%input.278, %2581) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %2583 : Tensor = aten::add(%input.283, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %2584 : bool = prim::GetAttr[name="inplace"](%2488)
      %result.150 : Tensor = prim::If(%2584) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.151 : Tensor = aten::hardtanh_(%2583, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.151)
        block1():
          %result.152 : Tensor = aten::hardtanh(%2583, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.152)
      %2588 : Tensor = aten::mul(%input.283, %result.150) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.284 : Tensor = aten::div(%2588, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %2590 : Tensor = prim::GetAttr[name="weight"](%2489)
      %2591 : Tensor? = prim::GetAttr[name="bias"](%2489)
      %input.285 : Tensor = aten::conv2d(%input.284, %2590, %2591, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2596 : bool = prim::GetAttr[name="training"](%2490)
       = prim::If(%2596) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2597 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2490)
          %2598 : Tensor = aten::add(%2597, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2490, %2598)
          -> ()
        block1():
          -> ()
      %2599 : bool = prim::GetAttr[name="training"](%2490)
      %2600 : Tensor = prim::GetAttr[name="running_mean"](%2490)
      %2601 : Tensor = prim::GetAttr[name="running_var"](%2490)
      %2602 : Tensor = prim::GetAttr[name="weight"](%2490)
      %2603 : Tensor = prim::GetAttr[name="bias"](%2490)
       = prim::If(%2599) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2604 : int[] = aten::size(%input.285) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.264 : int = aten::__getitem__(%2604, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2606 : int = aten::len(%2604) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2607 : int = aten::sub(%2606, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.265 : int = prim::Loop(%2607, %10, %size_prods.264) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.67 : int, %size_prods.266 : int):
              %2611 : int = aten::add(%i.67, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2612 : int = aten::__getitem__(%2604, %2611) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.267 : int = aten::mul(%size_prods.266, %2612) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.267)
          %2614 : bool = aten::eq(%size_prods.265, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2614) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2615 : str = aten::format(%8, %2604) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2615) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.286 : Tensor = aten::batch_norm(%input.285, %2602, %2603, %2600, %2601, %2599, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.286)
  %2617 : bool = prim::GetAttr[name="use_res_connect"](%38)
  %input.30 : Tensor = prim::If(%2617) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:112:8
    block0():
      %2619 : __torch__.torch.nn.modules.container.___torch_mangle_78.Sequential = prim::GetAttr[name="conv"](%38)
      %2620 : __torch__.torch.nn.modules.conv.___torch_mangle_70.Conv2d = prim::GetAttr[name="0"](%2619)
      %2621 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_71.BatchNorm2d = prim::GetAttr[name="1"](%2619)
      %2622 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%2619)
      %2623 : __torch__.torch.nn.modules.conv.___torch_mangle_72.Conv2d = prim::GetAttr[name="3"](%2619)
      %2624 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_71.BatchNorm2d = prim::GetAttr[name="4"](%2619)
      %2625 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_76.SEModule = prim::GetAttr[name="5"](%2619)
      %2626 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="6"](%2619)
      %2627 : __torch__.torch.nn.modules.conv.___torch_mangle_77.Conv2d = prim::GetAttr[name="7"](%2619)
      %2628 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_19.BatchNorm2d = prim::GetAttr[name="8"](%2619)
      %2629 : Tensor = prim::GetAttr[name="weight"](%2620)
      %2630 : Tensor? = prim::GetAttr[name="bias"](%2620)
      %input.12 : Tensor = aten::conv2d(%input.32, %2629, %2630, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2635 : bool = prim::GetAttr[name="training"](%2621)
       = prim::If(%2635) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2636 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2621)
          %2637 : Tensor = aten::add(%2636, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2621, %2637)
          -> ()
        block1():
          -> ()
      %2638 : bool = prim::GetAttr[name="training"](%2621)
      %2639 : Tensor = prim::GetAttr[name="running_mean"](%2621)
      %2640 : Tensor = prim::GetAttr[name="running_var"](%2621)
      %2641 : Tensor = prim::GetAttr[name="weight"](%2621)
      %2642 : Tensor = prim::GetAttr[name="bias"](%2621)
       = prim::If(%2638) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2643 : int[] = aten::size(%input.12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.12 : int = aten::__getitem__(%2643, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2645 : int = aten::len(%2643) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2646 : int = aten::sub(%2645, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.13 : int = prim::Loop(%2646, %10, %size_prods.12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.4 : int, %size_prods.14 : int):
              %2650 : int = aten::add(%i.4, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2651 : int = aten::__getitem__(%2643, %2650) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.15 : int = aten::mul(%size_prods.14, %2651) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.15)
          %2653 : bool = aten::eq(%size_prods.13, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2653) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2654 : str = aten::format(%8, %2643) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2654) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.14 : Tensor = aten::batch_norm(%input.12, %2641, %2642, %2639, %2640, %2638, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2656 : Tensor = aten::add(%input.14, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %2657 : bool = prim::GetAttr[name="inplace"](%2622)
      %result.9 : Tensor = prim::If(%2657) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.10 : Tensor = aten::hardtanh_(%2656, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.10)
        block1():
          %result.11 : Tensor = aten::hardtanh(%2656, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.11)
      %2661 : Tensor = aten::mul(%input.14, %result.9) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.16 : Tensor = aten::div(%2661, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %2663 : Tensor = prim::GetAttr[name="weight"](%2623)
      %2664 : Tensor? = prim::GetAttr[name="bias"](%2623)
      %input.18 : Tensor = aten::conv2d(%input.16, %2663, %2664, %2960, %2959, %2960, %21) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2669 : bool = prim::GetAttr[name="training"](%2624)
       = prim::If(%2669) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2670 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2624)
          %2671 : Tensor = aten::add(%2670, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2624, %2671)
          -> ()
        block1():
          -> ()
      %2672 : bool = prim::GetAttr[name="training"](%2624)
      %2673 : Tensor = prim::GetAttr[name="running_mean"](%2624)
      %2674 : Tensor = prim::GetAttr[name="running_var"](%2624)
      %2675 : Tensor = prim::GetAttr[name="weight"](%2624)
      %2676 : Tensor = prim::GetAttr[name="bias"](%2624)
       = prim::If(%2672) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2677 : int[] = aten::size(%input.18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.16 : int = aten::__getitem__(%2677, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2679 : int = aten::len(%2677) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2680 : int = aten::sub(%2679, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.17 : int = prim::Loop(%2680, %10, %size_prods.16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.5 : int, %size_prods.18 : int):
              %2684 : int = aten::add(%i.5, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2685 : int = aten::__getitem__(%2677, %2684) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.19 : int = aten::mul(%size_prods.18, %2685) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.19)
          %2687 : bool = aten::eq(%size_prods.17, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2687) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2688 : str = aten::format(%8, %2677) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2688) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.20 : Tensor = aten::batch_norm(%input.18, %2675, %2676, %2673, %2674, %2672, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2690 : int[] = aten::size(%input.20) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.2 : int, %c.2 : int, %2693 : int, %2694 : int = prim::ListUnpack(%2690)
      %2697 : int = aten::len(%2690) # <string>:5:9
      %2698 : bool = aten::gt(%2697, %22) # <string>:5:9
       = prim::If(%2698) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %2699 : Tensor = aten::adaptive_avg_pool2d(%input.20, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %2700 : int[] = prim::ListConstruct(%b.2, %c.2)
      %y.2 : Tensor = aten::view(%2699, %2700) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %2702 : __torch__.torch.nn.modules.container.___torch_mangle_75.Sequential = prim::GetAttr[name="fc"](%2625)
      %2703 : __torch__.torch.nn.modules.linear.___torch_mangle_73.Linear = prim::GetAttr[name="0"](%2702)
      %2704 : __torch__.torch.nn.modules.linear.___torch_mangle_74.Linear = prim::GetAttr[name="2"](%2702)
      %2705 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%2702)
      %2706 : Tensor = prim::GetAttr[name="weight"](%2703)
      %input.21 : Tensor = aten::linear(%y.2, %2706, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.22 : Tensor = aten::relu_(%input.21) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2709 : Tensor = prim::GetAttr[name="weight"](%2704)
      %input.23 : Tensor = aten::linear(%input.22, %2709, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %2711 : Tensor = aten::add(%input.23, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %2712 : bool = prim::GetAttr[name="inplace"](%2705)
      %result.12 : Tensor = prim::If(%2712) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.13 : Tensor = aten::hardtanh_(%2711, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.13)
        block1():
          %result.14 : Tensor = aten::hardtanh(%2711, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.14)
      %input.24 : Tensor = aten::div(%result.12, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %2717 : int[] = prim::ListConstruct(%b.2, %c.2, %11, %11)
      %y.4 : Tensor = aten::view(%input.24, %2717) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %2719 : Tensor = aten::expand_as(%y.4, %input.20) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.25 : Tensor = aten::mul(%input.20, %2719) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %2721 : Tensor = aten::add(%input.25, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %2722 : bool = prim::GetAttr[name="inplace"](%2626)
      %result.15 : Tensor = prim::If(%2722) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.16 : Tensor = aten::hardtanh_(%2721, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.16)
        block1():
          %result.17 : Tensor = aten::hardtanh(%2721, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.17)
      %2726 : Tensor = aten::mul(%input.25, %result.15) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.26 : Tensor = aten::div(%2726, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %2728 : Tensor = prim::GetAttr[name="weight"](%2627)
      %2729 : Tensor? = prim::GetAttr[name="bias"](%2627)
      %input.27 : Tensor = aten::conv2d(%input.26, %2728, %2729, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2734 : bool = prim::GetAttr[name="training"](%2628)
       = prim::If(%2734) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2735 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2628)
          %2736 : Tensor = aten::add(%2735, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2628, %2736)
          -> ()
        block1():
          -> ()
      %2737 : bool = prim::GetAttr[name="training"](%2628)
      %2738 : Tensor = prim::GetAttr[name="running_mean"](%2628)
      %2739 : Tensor = prim::GetAttr[name="running_var"](%2628)
      %2740 : Tensor = prim::GetAttr[name="weight"](%2628)
      %2741 : Tensor = prim::GetAttr[name="bias"](%2628)
       = prim::If(%2737) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2742 : int[] = aten::size(%input.27) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.20 : int = aten::__getitem__(%2742, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2744 : int = aten::len(%2742) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2745 : int = aten::sub(%2744, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.21 : int = prim::Loop(%2745, %10, %size_prods.20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.6 : int, %size_prods.22 : int):
              %2749 : int = aten::add(%i.6, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2750 : int = aten::__getitem__(%2742, %2749) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.23 : int = aten::mul(%size_prods.22, %2750) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.23)
          %2752 : bool = aten::eq(%size_prods.21, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2752) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2753 : str = aten::format(%8, %2742) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2753) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.28 : Tensor = aten::batch_norm(%input.27, %2740, %2741, %2738, %2739, %2737, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2755 : Tensor = aten::add(%input.32, %input.28, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:113:19
      -> (%2755)
    block1():
      %2756 : __torch__.torch.nn.modules.container.___torch_mangle_78.Sequential = prim::GetAttr[name="conv"](%38)
      %2757 : __torch__.torch.nn.modules.conv.___torch_mangle_70.Conv2d = prim::GetAttr[name="0"](%2756)
      %2758 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_71.BatchNorm2d = prim::GetAttr[name="1"](%2756)
      %2759 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%2756)
      %2760 : __torch__.torch.nn.modules.conv.___torch_mangle_72.Conv2d = prim::GetAttr[name="3"](%2756)
      %2761 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_71.BatchNorm2d = prim::GetAttr[name="4"](%2756)
      %2762 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.___torch_mangle_76.SEModule = prim::GetAttr[name="5"](%2756)
      %2763 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="6"](%2756)
      %2764 : __torch__.torch.nn.modules.conv.___torch_mangle_77.Conv2d = prim::GetAttr[name="7"](%2756)
      %2765 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_19.BatchNorm2d = prim::GetAttr[name="8"](%2756)
      %2766 : Tensor = prim::GetAttr[name="weight"](%2757)
      %2767 : Tensor? = prim::GetAttr[name="bias"](%2757)
      %input.4 : Tensor = aten::conv2d(%input.32, %2766, %2767, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2772 : bool = prim::GetAttr[name="training"](%2758)
       = prim::If(%2772) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2773 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2758)
          %2774 : Tensor = aten::add(%2773, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2758, %2774)
          -> ()
        block1():
          -> ()
      %2775 : bool = prim::GetAttr[name="training"](%2758)
      %2776 : Tensor = prim::GetAttr[name="running_mean"](%2758)
      %2777 : Tensor = prim::GetAttr[name="running_var"](%2758)
      %2778 : Tensor = prim::GetAttr[name="weight"](%2758)
      %2779 : Tensor = prim::GetAttr[name="bias"](%2758)
       = prim::If(%2775) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2780 : int[] = aten::size(%input.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.2 : int = aten::__getitem__(%2780, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2782 : int = aten::len(%2780) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2783 : int = aten::sub(%2782, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.4 : int = prim::Loop(%2783, %10, %size_prods.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.2 : int, %size_prods.7 : int):
              %2787 : int = aten::add(%i.2, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2788 : int = aten::__getitem__(%2780, %2787) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.5 : int = aten::mul(%size_prods.7, %2788) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.5)
          %2790 : bool = aten::eq(%size_prods.4, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2790) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2791 : str = aten::format(%8, %2780) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2791) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.6 : Tensor = aten::batch_norm(%input.4, %2778, %2779, %2776, %2777, %2775, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2793 : Tensor = aten::add(%input.6, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %2794 : bool = prim::GetAttr[name="inplace"](%2759)
      %result.3 : Tensor = prim::If(%2794) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.4 : Tensor = aten::hardtanh_(%2793, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.4)
        block1():
          %result.5 : Tensor = aten::hardtanh(%2793, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.5)
      %2798 : Tensor = aten::mul(%input.6, %result.3) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.8 : Tensor = aten::div(%2798, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %2800 : Tensor = prim::GetAttr[name="weight"](%2760)
      %2801 : Tensor? = prim::GetAttr[name="bias"](%2760)
      %input.10 : Tensor = aten::conv2d(%input.8, %2800, %2801, %2960, %2959, %2960, %21) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2806 : bool = prim::GetAttr[name="training"](%2761)
       = prim::If(%2806) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2807 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2761)
          %2808 : Tensor = aten::add(%2807, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2761, %2808)
          -> ()
        block1():
          -> ()
      %2809 : bool = prim::GetAttr[name="training"](%2761)
      %2810 : Tensor = prim::GetAttr[name="running_mean"](%2761)
      %2811 : Tensor = prim::GetAttr[name="running_var"](%2761)
      %2812 : Tensor = prim::GetAttr[name="weight"](%2761)
      %2813 : Tensor = prim::GetAttr[name="bias"](%2761)
       = prim::If(%2809) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2814 : int[] = aten::size(%input.10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.8 : int = aten::__getitem__(%2814, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2816 : int = aten::len(%2814) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2817 : int = aten::sub(%2816, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.9 : int = prim::Loop(%2817, %10, %size_prods.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.3 : int, %size_prods.10 : int):
              %2821 : int = aten::add(%i.3, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2822 : int = aten::__getitem__(%2814, %2821) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.11 : int = aten::mul(%size_prods.10, %2822) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.11)
          %2824 : bool = aten::eq(%size_prods.9, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2824) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2825 : str = aten::format(%8, %2814) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2825) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.11 : Tensor = aten::batch_norm(%input.10, %2812, %2813, %2810, %2811, %2809, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2827 : int[] = aten::size(%input.11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:56:21
      %b.1 : int, %c.1 : int, %2830 : int, %2831 : int = prim::ListUnpack(%2827)
      %2834 : int = aten::len(%2827) # <string>:5:9
      %2835 : bool = aten::gt(%2834, %22) # <string>:5:9
       = prim::If(%2835) # <string>:5:2
        block0():
          -> ()
        block1():
           = prim::RaiseException(%13) # <string>:5:2
          -> ()
      %2836 : Tensor = aten::adaptive_avg_pool2d(%input.11, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
      %2837 : int[] = prim::ListConstruct(%b.1, %c.1)
      %y.1 : Tensor = aten::view(%2836, %2837) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:57:12
      %2839 : __torch__.torch.nn.modules.container.___torch_mangle_75.Sequential = prim::GetAttr[name="fc"](%2762)
      %2840 : __torch__.torch.nn.modules.linear.___torch_mangle_73.Linear = prim::GetAttr[name="0"](%2839)
      %2841 : __torch__.torch.nn.modules.linear.___torch_mangle_74.Linear = prim::GetAttr[name="2"](%2839)
      %2842 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hsigmoid = prim::GetAttr[name="3"](%2839)
      %2843 : Tensor = prim::GetAttr[name="weight"](%2840)
      %input.287 : Tensor = aten::linear(%y.1, %2843, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %input.288 : Tensor = aten::relu_(%input.287) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2846 : Tensor = prim::GetAttr[name="weight"](%2841)
      %input.289 : Tensor = aten::linear(%input.288, %2846, %25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
      %2848 : Tensor = aten::add(%input.289, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:23
      %2849 : bool = prim::GetAttr[name="inplace"](%2842)
      %result.6 : Tensor = prim::If(%2849) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.7 : Tensor = aten::hardtanh_(%2848, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.7)
        block1():
          %result.8 : Tensor = aten::hardtanh(%2848, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.8)
      %input.9 : Tensor = aten::div(%result.6, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:40:15
      %2854 : int[] = prim::ListConstruct(%b.1, %c.1, %11, %11)
      %y.3 : Tensor = aten::view(%input.9, %2854) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:58:12
      %2856 : Tensor = aten::expand_as(%y.3, %input.11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:19
      %input.13 : Tensor = aten::mul(%input.11, %2856) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:59:15
      %2858 : Tensor = aten::add(%input.13, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
      %2859 : bool = prim::GetAttr[name="inplace"](%2763)
      %result.153 : Tensor = prim::If(%2859) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
        block0():
          %result.154 : Tensor = aten::hardtanh_(%2858, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
          -> (%result.154)
        block1():
          %result.155 : Tensor = aten::hardtanh(%2858, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
          -> (%result.155)
      %2863 : Tensor = aten::mul(%input.13, %result.153) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %input.15 : Tensor = aten::div(%2863, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
      %2865 : Tensor = prim::GetAttr[name="weight"](%2764)
      %2866 : Tensor? = prim::GetAttr[name="bias"](%2764)
      %input.17 : Tensor = aten::conv2d(%input.15, %2865, %2866, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2871 : bool = prim::GetAttr[name="training"](%2765)
       = prim::If(%2871) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2872 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2765)
          %2873 : Tensor = aten::add(%2872, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2765, %2873)
          -> ()
        block1():
          -> ()
      %2874 : bool = prim::GetAttr[name="training"](%2765)
      %2875 : Tensor = prim::GetAttr[name="running_mean"](%2765)
      %2876 : Tensor = prim::GetAttr[name="running_var"](%2765)
      %2877 : Tensor = prim::GetAttr[name="weight"](%2765)
      %2878 : Tensor = prim::GetAttr[name="bias"](%2765)
       = prim::If(%2874) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2879 : int[] = aten::size(%input.17) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.268 : int = aten::__getitem__(%2879, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2881 : int = aten::len(%2879) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2882 : int = aten::sub(%2881, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.269 : int = prim::Loop(%2882, %10, %size_prods.268) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.68 : int, %size_prods.270 : int):
              %2886 : int = aten::add(%i.68, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2887 : int = aten::__getitem__(%2879, %2886) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.271 : int = aten::mul(%size_prods.270, %2887) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.271)
          %2889 : bool = aten::eq(%size_prods.269, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2889) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2890 : str = aten::format(%8, %2879) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2890) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.19 : Tensor = aten::batch_norm(%input.17, %2877, %2878, %2875, %2876, %2874, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.19)
  %2892 : __torch__.torch.nn.modules.conv.___torch_mangle_70.Conv2d = prim::GetAttr[name="0"](%39)
  %2893 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_71.BatchNorm2d = prim::GetAttr[name="1"](%39)
  %2894 : __torch__.torchbenchmark.models.pytorch_mobilenet_v3.mobilenetv3.Hswish = prim::GetAttr[name="2"](%39)
  %2895 : Tensor = prim::GetAttr[name="weight"](%2892)
  %2896 : Tensor? = prim::GetAttr[name="bias"](%2892)
  %input.7 : Tensor = aten::conv2d(%input.30, %2895, %2896, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %2901 : bool = prim::GetAttr[name="training"](%2893)
   = prim::If(%2901) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %2902 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2893)
      %2903 : Tensor = aten::add(%2902, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%2893, %2903)
      -> ()
    block1():
      -> ()
  %2904 : bool = prim::GetAttr[name="training"](%2893)
  %2905 : Tensor = prim::GetAttr[name="running_mean"](%2893)
  %2906 : Tensor = prim::GetAttr[name="running_var"](%2893)
  %2907 : Tensor = prim::GetAttr[name="weight"](%2893)
  %2908 : Tensor = prim::GetAttr[name="bias"](%2893)
   = prim::If(%2904) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %2909 : int[] = aten::size(%input.7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.1 : int = aten::__getitem__(%2909, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %2911 : int = aten::len(%2909) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %2912 : int = aten::sub(%2911, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods : int = prim::Loop(%2912, %10, %size_prods.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.1 : int, %size_prods.6 : int):
          %2916 : int = aten::add(%i.1, %22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %2917 : int = aten::__getitem__(%2909, %2916) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.3 : int = aten::mul(%size_prods.6, %2917) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%10, %size_prods.3)
      %2919 : bool = aten::eq(%size_prods, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%2919) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %2920 : str = aten::format(%8, %2909) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%2920) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.33 : Tensor = aten::batch_norm(%input.7, %2907, %2908, %2905, %2906, %2904, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %2922 : Tensor = aten::add(%input.33, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
  %2923 : bool = prim::GetAttr[name="inplace"](%2894)
  %result.156 : Tensor = prim::If(%2923) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
    block0():
      %result.157 : Tensor = aten::hardtanh_(%2922, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      -> (%result.157)
    block1():
      %result.158 : Tensor = aten::hardtanh(%2922, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
      -> (%result.158)
  %2927 : Tensor = aten::mul(%input.33, %result.156) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
  %input.34 : Tensor = aten::div(%2927, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
  %2930 : int[] = aten::size(%input.34) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1036:51
  %2931 : int = aten::len(%2930) # <string>:5:9
  %2932 : bool = aten::gt(%2931, %22) # <string>:5:9
   = prim::If(%2932) # <string>:5:2
    block0():
      -> ()
    block1():
       = prim::RaiseException(%13) # <string>:5:2
      -> ()
  %input.29 : Tensor = aten::adaptive_avg_pool2d(%input.34, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
  %2934 : Tensor = prim::GetAttr[name="weight"](%40)
  %2935 : Tensor? = prim::GetAttr[name="bias"](%40)
  %input.31 : Tensor = aten::conv2d(%input.29, %2934, %2935, %2960, %2963, %2960, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %2940 : Tensor = aten::add(%input.31, %3, %11) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:27
  %2941 : bool = prim::GetAttr[name="inplace"](%41)
  %result : Tensor = prim::If(%2941) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1254:4
    block0():
      %result.1 : Tensor = aten::hardtanh_(%2940, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      -> (%result.1)
    block1():
      %result.2 : Tensor = aten::hardtanh(%2940, %5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1257:17
      -> (%result.2)
  %2945 : Tensor = aten::mul(%input.31, %result) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
  %x.3 : Tensor = aten::div(%2945, %4) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:31:15
  %2948 : Tensor = aten::mean(%x.3, %3185, %24, %25) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:205:12
  %x.5 : Tensor = aten::mean(%2948, %3186, %24, %25) # /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/pytorch_mobilenet_v3/mobilenetv3.py:205:12
  %2951 : __torch__.torch.nn.modules.container.___torch_mangle_84.Sequential = prim::GetAttr[name="classifier"](%self)
  %2952 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="0"](%2951)
  %2953 : __torch__.torch.nn.modules.linear.___torch_mangle_83.Linear = prim::GetAttr[name="1"](%2951)
  %2954 : bool = prim::GetAttr[name="training"](%2952)
  %input.3 : Tensor = aten::dropout(%x.5, %2, %2954) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
  %2956 : Tensor = prim::GetAttr[name="weight"](%2953)
  %2957 : Tensor = prim::GetAttr[name="bias"](%2953)
  %x.7 : Tensor = aten::linear(%input.3, %2956, %2957) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
  return (%x.7)

