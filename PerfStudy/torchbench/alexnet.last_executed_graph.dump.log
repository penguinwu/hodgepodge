Dump Graph IR for alexnet using example inputs:
graph(%self : __torch__.torchvision.models.alexnet.AlexNet,
      %x.1 : Tensor):
  %122 : int[] = prim::Constant[value=[6, 6]]()
  %100 : int[] = prim::Constant[value=[0, 0]]()
  %98 : int[] = prim::Constant[value=[3, 3]]()
  %97 : int[] = prim::Constant[value=[1, 1]]()
  %96 : int[] = prim::Constant[value=[2, 2]]()
  %95 : int[] = prim::Constant[value=[4, 4]]()
  %11 : int = prim::Constant[value=-1]()
  %10 : int = prim::Constant[value=1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/alexnet.py:48:29
  %9 : bool = prim::Constant[value=0]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/pooling.py:163:57
  %5 : int = prim::Constant[value=2]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:24
  %4 : str = prim::Constant[value="AssertionError: "]()
  %2 : float = prim::Constant[value=0.5]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/dropout.py:58:32
  %12 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="features"](%self)
  %13 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name="0"](%12)
  %14 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="3"](%12)
  %15 : __torch__.torch.nn.modules.conv.___torch_mangle_1.Conv2d = prim::GetAttr[name="6"](%12)
  %16 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="8"](%12)
  %17 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv2d = prim::GetAttr[name="10"](%12)
  %18 : Tensor = prim::GetAttr[name="weight"](%13)
  %19 : Tensor? = prim::GetAttr[name="bias"](%13)
  %input.4 : Tensor = aten::conv2d(%x.1, %18, %19, %95, %96, %97, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %input.6 : Tensor = aten::relu_(%input.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %input.8 : Tensor = aten::max_pool2d(%input.6, %98, %96, %100, %97, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:659:11
  %30 : Tensor = prim::GetAttr[name="weight"](%14)
  %31 : Tensor? = prim::GetAttr[name="bias"](%14)
  %input.10 : Tensor = aten::conv2d(%input.8, %30, %31, %97, %96, %97, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %input.12 : Tensor = aten::relu_(%input.10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %input.14 : Tensor = aten::max_pool2d(%input.12, %98, %96, %100, %97, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:659:11
  %42 : Tensor = prim::GetAttr[name="weight"](%15)
  %43 : Tensor? = prim::GetAttr[name="bias"](%15)
  %input.16 : Tensor = aten::conv2d(%input.14, %42, %43, %97, %97, %97, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %input.17 : Tensor = aten::relu_(%input.16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %49 : Tensor = prim::GetAttr[name="weight"](%16)
  %50 : Tensor? = prim::GetAttr[name="bias"](%16)
  %input.19 : Tensor = aten::conv2d(%input.17, %49, %50, %97, %97, %97, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %input.21 : Tensor = aten::relu_(%input.19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %56 : Tensor = prim::GetAttr[name="weight"](%17)
  %57 : Tensor? = prim::GetAttr[name="bias"](%17)
  %input.23 : Tensor = aten::conv2d(%input.21, %56, %57, %97, %97, %97, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %input.25 : Tensor = aten::relu_(%input.23) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %x.3 : Tensor = aten::max_pool2d(%input.25, %98, %96, %100, %97, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:659:11
  %69 : int[] = aten::size(%x.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1036:51
  %70 : int = aten::len(%69) # <string>:5:9
  %71 : bool = aten::gt(%70, %5) # <string>:5:9
   = prim::If(%71) # <string>:5:2
    block0():
      -> ()
    block1():
       = prim::RaiseException(%4) # <string>:5:2
      -> ()
  %x.5 : Tensor = aten::adaptive_avg_pool2d(%x.3, %122) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
  %x.7 : Tensor = aten::flatten(%x.5, %10, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/alexnet.py:48:12
  %74 : __torch__.torch.nn.modules.container.___torch_mangle_6.Sequential = prim::GetAttr[name="classifier"](%self)
  %75 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="0"](%74)
  %76 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="1"](%74)
  %77 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="3"](%74)
  %78 : __torch__.torch.nn.modules.linear.___torch_mangle_4.Linear = prim::GetAttr[name="4"](%74)
  %79 : __torch__.torch.nn.modules.linear.___torch_mangle_5.Linear = prim::GetAttr[name="6"](%74)
  %80 : bool = prim::GetAttr[name="training"](%75)
  %input.3 : Tensor = aten::dropout(%x.7, %2, %80) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
  %82 : Tensor = prim::GetAttr[name="weight"](%76)
  %83 : Tensor = prim::GetAttr[name="bias"](%76)
  %input.5 : Tensor = aten::linear(%input.3, %82, %83) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
  %input.7 : Tensor = aten::relu_(%input.5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %86 : bool = prim::GetAttr[name="training"](%77)
  %input.9 : Tensor = aten::dropout(%input.7, %2, %86) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
  %88 : Tensor = prim::GetAttr[name="weight"](%78)
  %89 : Tensor = prim::GetAttr[name="bias"](%78)
  %input.11 : Tensor = aten::linear(%input.9, %88, %89) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
  %input.13 : Tensor = aten::relu_(%input.11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %92 : Tensor = prim::GetAttr[name="weight"](%79)
  %93 : Tensor = prim::GetAttr[name="bias"](%79)
  %x.9 : Tensor = aten::linear(%input.13, %92, %93) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
  return (%x.9)

