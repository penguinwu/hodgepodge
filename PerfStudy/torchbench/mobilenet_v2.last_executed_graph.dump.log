Dump Graph IR for mobilenet_v2 using example inputs:
graph(%self : __torch__.torchvision.models.mobilenetv2.MobileNetV2,
      %x.1 : Tensor):
  %3242 : int[] = prim::Constant[value=[0, 0]]()
  %3236 : int[] = prim::Constant[value=[1, 1]]()
  %3235 : int[] = prim::Constant[value=[2, 2]]()
  %20 : float = prim::Constant[value=0.20000000000000001]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/dropout.py:58:32
  %19 : str = prim::Constant[value="AssertionError: "]()
  %18 : float = prim::Constant[value=6.]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:237:47
  %17 : float = prim::Constant[value=0.]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:237:33
  %16 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:140:77
  %15 : float = prim::Constant[value=0.10000000000000001]()
  %14 : str = prim::Constant[value="Expected more than 1 value per channel when training, got input size {}"]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
  %13 : bool = prim::Constant[value=1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2147:81
  %12 : int = prim::Constant[value=2]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:45
  %11 : int = prim::Constant[value=32]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %10 : int = prim::Constant[value=96]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %9 : int = prim::Constant[value=144]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %8 : int = prim::Constant[value=192]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %7 : int = prim::Constant[value=384]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %6 : int = prim::Constant[value=576]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %5 : int = prim::Constant[value=960]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %4 : int = prim::Constant[value=0]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:195:73
  %3 : int = prim::Constant[value=1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:195:50
  %2 : int = prim::Constant[value=-1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:195:77
  %21 : __torch__.torch.nn.modules.container.___torch_mangle_80.Sequential = prim::GetAttr[name="features"](%self)
  %22 : __torch__.torchvision.models.mobilenetv2.ConvBNActivation = prim::GetAttr[name="0"](%21)
  %23 : __torch__.torchvision.models.mobilenetv2.InvertedResidual = prim::GetAttr[name="1"](%21)
  %24 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_12.InvertedResidual = prim::GetAttr[name="2"](%21)
  %25 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_20.InvertedResidual = prim::GetAttr[name="3"](%21)
  %26 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_25.InvertedResidual = prim::GetAttr[name="4"](%21)
  %27 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_33.InvertedResidual = prim::GetAttr[name="5"](%21)
  %28 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_33.InvertedResidual = prim::GetAttr[name="6"](%21)
  %29 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_39.InvertedResidual = prim::GetAttr[name="7"](%21)
  %30 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_47.InvertedResidual = prim::GetAttr[name="8"](%21)
  %31 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_47.InvertedResidual = prim::GetAttr[name="9"](%21)
  %32 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_47.InvertedResidual = prim::GetAttr[name="10"](%21)
  %33 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_50.InvertedResidual = prim::GetAttr[name="11"](%21)
  %34 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_58.InvertedResidual = prim::GetAttr[name="12"](%21)
  %35 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_58.InvertedResidual = prim::GetAttr[name="13"](%21)
  %36 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_64.InvertedResidual = prim::GetAttr[name="14"](%21)
  %37 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_72.InvertedResidual = prim::GetAttr[name="15"](%21)
  %38 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_72.InvertedResidual = prim::GetAttr[name="16"](%21)
  %39 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_76.InvertedResidual = prim::GetAttr[name="17"](%21)
  %40 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_79.ConvBNActivation = prim::GetAttr[name="18"](%21)
  %41 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name="0"](%22)
  %42 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%22)
  %43 : Tensor = prim::GetAttr[name="weight"](%41)
  %44 : Tensor? = prim::GetAttr[name="bias"](%41)
  %input.41 : Tensor = aten::conv2d(%x.1, %43, %44, %3235, %3236, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %49 : bool = prim::GetAttr[name="training"](%42)
   = prim::If(%49) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %50 : Tensor = prim::GetAttr[name="num_batches_tracked"](%42)
      %51 : Tensor = aten::add(%50, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%42, %51)
      -> ()
    block1():
      -> ()
  %52 : bool = prim::GetAttr[name="training"](%42)
  %53 : Tensor = prim::GetAttr[name="running_mean"](%42)
  %54 : Tensor = prim::GetAttr[name="running_var"](%42)
  %55 : Tensor = prim::GetAttr[name="weight"](%42)
  %56 : Tensor = prim::GetAttr[name="bias"](%42)
   = prim::If(%52) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %57 : int[] = aten::size(%input.41) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.24 : int = aten::__getitem__(%57, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %59 : int = aten::len(%57) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %60 : int = aten::sub(%59, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.25 : int = prim::Loop(%60, %13, %size_prods.24) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.7 : int, %size_prods.26 : int):
          %64 : int = aten::add(%i.7, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %65 : int = aten::__getitem__(%57, %64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.27 : int = aten::mul(%size_prods.26, %65) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%13, %size_prods.27)
      %67 : bool = aten::eq(%size_prods.25, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%67) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %68 : str = aten::format(%14, %57) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%68) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.20 : Tensor = aten::batch_norm(%input.41, %55, %56, %53, %54, %52, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %input.22 : Tensor = aten::hardtanh_(%input.20, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
  %71 : bool = prim::GetAttr[name="use_res_connect"](%23)
  %input.24 : Tensor = prim::If(%71) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:98:8
    block0():
      %73 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="conv"](%23)
      %74 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_1.ConvBNActivation = prim::GetAttr[name="0"](%73)
      %75 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="1"](%73)
      %76 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="2"](%73)
      %77 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="0"](%74)
      %78 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%74)
      %79 : Tensor = prim::GetAttr[name="weight"](%77)
      %80 : Tensor? = prim::GetAttr[name="bias"](%77)
      %input.32 : Tensor = aten::conv2d(%input.22, %79, %80, %3236, %3236, %3236, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %85 : bool = prim::GetAttr[name="training"](%78)
       = prim::If(%85) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %86 : Tensor = prim::GetAttr[name="num_batches_tracked"](%78)
          %87 : Tensor = aten::add(%86, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%78, %87)
          -> ()
        block1():
          -> ()
      %88 : bool = prim::GetAttr[name="training"](%78)
      %89 : Tensor = prim::GetAttr[name="running_mean"](%78)
      %90 : Tensor = prim::GetAttr[name="running_var"](%78)
      %91 : Tensor = prim::GetAttr[name="weight"](%78)
      %92 : Tensor = prim::GetAttr[name="bias"](%78)
       = prim::If(%88) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %93 : int[] = aten::size(%input.32) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.36 : int = aten::__getitem__(%93, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %95 : int = aten::len(%93) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %96 : int = aten::sub(%95, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.37 : int = prim::Loop(%96, %13, %size_prods.36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.10 : int, %size_prods.38 : int):
              %100 : int = aten::add(%i.10, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %101 : int = aten::__getitem__(%93, %100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.39 : int = aten::mul(%size_prods.38, %101) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.39)
          %103 : bool = aten::eq(%size_prods.37, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%103) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %104 : str = aten::format(%14, %93) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.49 : Tensor = aten::batch_norm(%input.32, %91, %92, %89, %90, %88, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.43 : Tensor = aten::hardtanh_(%input.49, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %107 : Tensor = prim::GetAttr[name="weight"](%75)
      %108 : Tensor? = prim::GetAttr[name="bias"](%75)
      %input.42 : Tensor = aten::conv2d(%input.43, %107, %108, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %113 : bool = prim::GetAttr[name="training"](%76)
       = prim::If(%113) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %114 : Tensor = prim::GetAttr[name="num_batches_tracked"](%76)
          %115 : Tensor = aten::add(%114, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%76, %115)
          -> ()
        block1():
          -> ()
      %116 : bool = prim::GetAttr[name="training"](%76)
      %117 : Tensor = prim::GetAttr[name="running_mean"](%76)
      %118 : Tensor = prim::GetAttr[name="running_var"](%76)
      %119 : Tensor = prim::GetAttr[name="weight"](%76)
      %120 : Tensor = prim::GetAttr[name="bias"](%76)
       = prim::If(%116) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %121 : int[] = aten::size(%input.42) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.28 : int = aten::__getitem__(%121, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %123 : int = aten::len(%121) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %124 : int = aten::sub(%123, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.29 : int = prim::Loop(%124, %13, %size_prods.28) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.8 : int, %size_prods.30 : int):
              %128 : int = aten::add(%i.8, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %129 : int = aten::__getitem__(%121, %128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.31 : int = aten::mul(%size_prods.30, %129) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.31)
          %131 : bool = aten::eq(%size_prods.29, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%131) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %132 : str = aten::format(%14, %121) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%132) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.28 : Tensor = aten::batch_norm(%input.42, %119, %120, %117, %118, %116, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %134 : Tensor = aten::add(%input.22, %input.28, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:99:19
      -> (%134)
    block1():
      %135 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="conv"](%23)
      %136 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_1.ConvBNActivation = prim::GetAttr[name="0"](%135)
      %137 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="1"](%135)
      %138 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="2"](%135)
      %139 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="0"](%136)
      %140 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%136)
      %141 : Tensor = prim::GetAttr[name="weight"](%139)
      %142 : Tensor? = prim::GetAttr[name="bias"](%139)
      %input.45 : Tensor = aten::conv2d(%input.22, %141, %142, %3236, %3236, %3236, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %147 : bool = prim::GetAttr[name="training"](%140)
       = prim::If(%147) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %148 : Tensor = prim::GetAttr[name="num_batches_tracked"](%140)
          %149 : Tensor = aten::add(%148, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%140, %149)
          -> ()
        block1():
          -> ()
      %150 : bool = prim::GetAttr[name="training"](%140)
      %151 : Tensor = prim::GetAttr[name="running_mean"](%140)
      %152 : Tensor = prim::GetAttr[name="running_var"](%140)
      %153 : Tensor = prim::GetAttr[name="weight"](%140)
      %154 : Tensor = prim::GetAttr[name="bias"](%140)
       = prim::If(%150) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %155 : int[] = aten::size(%input.45) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.32 : int = aten::__getitem__(%155, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %157 : int = aten::len(%155) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %158 : int = aten::sub(%157, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.33 : int = prim::Loop(%158, %13, %size_prods.32) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.9 : int, %size_prods.34 : int):
              %162 : int = aten::add(%i.9, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %163 : int = aten::__getitem__(%155, %162) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.35 : int = aten::mul(%size_prods.34, %163) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.35)
          %165 : bool = aten::eq(%size_prods.33, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%165) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %166 : str = aten::format(%14, %155) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%166) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.46 : Tensor = aten::batch_norm(%input.45, %153, %154, %151, %152, %150, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.44 : Tensor = aten::hardtanh_(%input.46, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %169 : Tensor = prim::GetAttr[name="weight"](%137)
      %170 : Tensor? = prim::GetAttr[name="bias"](%137)
      %input.47 : Tensor = aten::conv2d(%input.44, %169, %170, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %175 : bool = prim::GetAttr[name="training"](%138)
       = prim::If(%175) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %176 : Tensor = prim::GetAttr[name="num_batches_tracked"](%138)
          %177 : Tensor = aten::add(%176, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%138, %177)
          -> ()
        block1():
          -> ()
      %178 : bool = prim::GetAttr[name="training"](%138)
      %179 : Tensor = prim::GetAttr[name="running_mean"](%138)
      %180 : Tensor = prim::GetAttr[name="running_var"](%138)
      %181 : Tensor = prim::GetAttr[name="weight"](%138)
      %182 : Tensor = prim::GetAttr[name="bias"](%138)
       = prim::If(%178) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %183 : int[] = aten::size(%input.47) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.40 : int = aten::__getitem__(%183, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %185 : int = aten::len(%183) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %186 : int = aten::sub(%185, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.41 : int = prim::Loop(%186, %13, %size_prods.40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.11 : int, %size_prods.42 : int):
              %190 : int = aten::add(%i.11, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %191 : int = aten::__getitem__(%183, %190) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.43 : int = aten::mul(%size_prods.42, %191) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.43)
          %193 : bool = aten::eq(%size_prods.41, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%193) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %194 : str = aten::format(%14, %183) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%194) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.48 : Tensor = aten::batch_norm(%input.47, %181, %182, %179, %180, %178, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.48)
  %196 : bool = prim::GetAttr[name="use_res_connect"](%24)
  %input.26 : Tensor = prim::If(%196) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:98:8
    block0():
      %198 : __torch__.torch.nn.modules.container.___torch_mangle_11.Sequential = prim::GetAttr[name="conv"](%24)
      %199 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_6.ConvBNActivation = prim::GetAttr[name="0"](%198)
      %200 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_8.ConvBNActivation = prim::GetAttr[name="1"](%198)
      %201 : __torch__.torch.nn.modules.conv.___torch_mangle_9.Conv2d = prim::GetAttr[name="2"](%198)
      %202 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_10.BatchNorm2d = prim::GetAttr[name="3"](%198)
      %203 : __torch__.torch.nn.modules.conv.___torch_mangle_4.Conv2d = prim::GetAttr[name="0"](%199)
      %204 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_5.BatchNorm2d = prim::GetAttr[name="1"](%199)
      %205 : Tensor = prim::GetAttr[name="weight"](%203)
      %206 : Tensor? = prim::GetAttr[name="bias"](%203)
      %input.50 : Tensor = aten::conv2d(%input.24, %205, %206, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %211 : bool = prim::GetAttr[name="training"](%204)
       = prim::If(%211) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %212 : Tensor = prim::GetAttr[name="num_batches_tracked"](%204)
          %213 : Tensor = aten::add(%212, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%204, %213)
          -> ()
        block1():
          -> ()
      %214 : bool = prim::GetAttr[name="training"](%204)
      %215 : Tensor = prim::GetAttr[name="running_mean"](%204)
      %216 : Tensor = prim::GetAttr[name="running_var"](%204)
      %217 : Tensor = prim::GetAttr[name="weight"](%204)
      %218 : Tensor = prim::GetAttr[name="bias"](%204)
       = prim::If(%214) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %219 : int[] = aten::size(%input.50) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.44 : int = aten::__getitem__(%219, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %221 : int = aten::len(%219) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %222 : int = aten::sub(%221, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.45 : int = prim::Loop(%222, %13, %size_prods.44) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.12 : int, %size_prods.46 : int):
              %226 : int = aten::add(%i.12, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %227 : int = aten::__getitem__(%219, %226) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.47 : int = aten::mul(%size_prods.46, %227) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.47)
          %229 : bool = aten::eq(%size_prods.45, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%229) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %230 : str = aten::format(%14, %219) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%230) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.51 : Tensor = aten::batch_norm(%input.50, %217, %218, %215, %216, %214, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.52 : Tensor = aten::hardtanh_(%input.51, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %233 : __torch__.torch.nn.modules.conv.___torch_mangle_7.Conv2d = prim::GetAttr[name="0"](%200)
      %234 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_5.BatchNorm2d = prim::GetAttr[name="1"](%200)
      %235 : Tensor = prim::GetAttr[name="weight"](%233)
      %236 : Tensor? = prim::GetAttr[name="bias"](%233)
      %input.53 : Tensor = aten::conv2d(%input.52, %235, %236, %3235, %3236, %3236, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %241 : bool = prim::GetAttr[name="training"](%234)
       = prim::If(%241) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %242 : Tensor = prim::GetAttr[name="num_batches_tracked"](%234)
          %243 : Tensor = aten::add(%242, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%234, %243)
          -> ()
        block1():
          -> ()
      %244 : bool = prim::GetAttr[name="training"](%234)
      %245 : Tensor = prim::GetAttr[name="running_mean"](%234)
      %246 : Tensor = prim::GetAttr[name="running_var"](%234)
      %247 : Tensor = prim::GetAttr[name="weight"](%234)
      %248 : Tensor = prim::GetAttr[name="bias"](%234)
       = prim::If(%244) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %249 : int[] = aten::size(%input.53) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.48 : int = aten::__getitem__(%249, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %251 : int = aten::len(%249) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %252 : int = aten::sub(%251, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.49 : int = prim::Loop(%252, %13, %size_prods.48) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.13 : int, %size_prods.50 : int):
              %256 : int = aten::add(%i.13, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %257 : int = aten::__getitem__(%249, %256) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.51 : int = aten::mul(%size_prods.50, %257) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.51)
          %259 : bool = aten::eq(%size_prods.49, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%259) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %260 : str = aten::format(%14, %249) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%260) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.54 : Tensor = aten::batch_norm(%input.53, %247, %248, %245, %246, %244, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.55 : Tensor = aten::hardtanh_(%input.54, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %263 : Tensor = prim::GetAttr[name="weight"](%201)
      %264 : Tensor? = prim::GetAttr[name="bias"](%201)
      %input.56 : Tensor = aten::conv2d(%input.55, %263, %264, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %269 : bool = prim::GetAttr[name="training"](%202)
       = prim::If(%269) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %270 : Tensor = prim::GetAttr[name="num_batches_tracked"](%202)
          %271 : Tensor = aten::add(%270, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%202, %271)
          -> ()
        block1():
          -> ()
      %272 : bool = prim::GetAttr[name="training"](%202)
      %273 : Tensor = prim::GetAttr[name="running_mean"](%202)
      %274 : Tensor = prim::GetAttr[name="running_var"](%202)
      %275 : Tensor = prim::GetAttr[name="weight"](%202)
      %276 : Tensor = prim::GetAttr[name="bias"](%202)
       = prim::If(%272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %277 : int[] = aten::size(%input.56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.52 : int = aten::__getitem__(%277, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %279 : int = aten::len(%277) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %280 : int = aten::sub(%279, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.53 : int = prim::Loop(%280, %13, %size_prods.52) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.14 : int, %size_prods.54 : int):
              %284 : int = aten::add(%i.14, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %285 : int = aten::__getitem__(%277, %284) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.55 : int = aten::mul(%size_prods.54, %285) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.55)
          %287 : bool = aten::eq(%size_prods.53, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%287) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %288 : str = aten::format(%14, %277) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%288) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.57 : Tensor = aten::batch_norm(%input.56, %275, %276, %273, %274, %272, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %290 : Tensor = aten::add(%input.24, %input.57, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:99:19
      -> (%290)
    block1():
      %291 : __torch__.torch.nn.modules.container.___torch_mangle_11.Sequential = prim::GetAttr[name="conv"](%24)
      %292 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_6.ConvBNActivation = prim::GetAttr[name="0"](%291)
      %293 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_8.ConvBNActivation = prim::GetAttr[name="1"](%291)
      %294 : __torch__.torch.nn.modules.conv.___torch_mangle_9.Conv2d = prim::GetAttr[name="2"](%291)
      %295 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_10.BatchNorm2d = prim::GetAttr[name="3"](%291)
      %296 : __torch__.torch.nn.modules.conv.___torch_mangle_4.Conv2d = prim::GetAttr[name="0"](%292)
      %297 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_5.BatchNorm2d = prim::GetAttr[name="1"](%292)
      %298 : Tensor = prim::GetAttr[name="weight"](%296)
      %299 : Tensor? = prim::GetAttr[name="bias"](%296)
      %input.58 : Tensor = aten::conv2d(%input.24, %298, %299, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %304 : bool = prim::GetAttr[name="training"](%297)
       = prim::If(%304) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %305 : Tensor = prim::GetAttr[name="num_batches_tracked"](%297)
          %306 : Tensor = aten::add(%305, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%297, %306)
          -> ()
        block1():
          -> ()
      %307 : bool = prim::GetAttr[name="training"](%297)
      %308 : Tensor = prim::GetAttr[name="running_mean"](%297)
      %309 : Tensor = prim::GetAttr[name="running_var"](%297)
      %310 : Tensor = prim::GetAttr[name="weight"](%297)
      %311 : Tensor = prim::GetAttr[name="bias"](%297)
       = prim::If(%307) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %312 : int[] = aten::size(%input.58) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.56 : int = aten::__getitem__(%312, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %314 : int = aten::len(%312) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %315 : int = aten::sub(%314, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.57 : int = prim::Loop(%315, %13, %size_prods.56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.15 : int, %size_prods.58 : int):
              %319 : int = aten::add(%i.15, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %320 : int = aten::__getitem__(%312, %319) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.59 : int = aten::mul(%size_prods.58, %320) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.59)
          %322 : bool = aten::eq(%size_prods.57, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%322) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %323 : str = aten::format(%14, %312) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%323) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.59 : Tensor = aten::batch_norm(%input.58, %310, %311, %308, %309, %307, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.60 : Tensor = aten::hardtanh_(%input.59, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %326 : __torch__.torch.nn.modules.conv.___torch_mangle_7.Conv2d = prim::GetAttr[name="0"](%293)
      %327 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_5.BatchNorm2d = prim::GetAttr[name="1"](%293)
      %328 : Tensor = prim::GetAttr[name="weight"](%326)
      %329 : Tensor? = prim::GetAttr[name="bias"](%326)
      %input.61 : Tensor = aten::conv2d(%input.60, %328, %329, %3235, %3236, %3236, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %334 : bool = prim::GetAttr[name="training"](%327)
       = prim::If(%334) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %335 : Tensor = prim::GetAttr[name="num_batches_tracked"](%327)
          %336 : Tensor = aten::add(%335, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%327, %336)
          -> ()
        block1():
          -> ()
      %337 : bool = prim::GetAttr[name="training"](%327)
      %338 : Tensor = prim::GetAttr[name="running_mean"](%327)
      %339 : Tensor = prim::GetAttr[name="running_var"](%327)
      %340 : Tensor = prim::GetAttr[name="weight"](%327)
      %341 : Tensor = prim::GetAttr[name="bias"](%327)
       = prim::If(%337) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %342 : int[] = aten::size(%input.61) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.60 : int = aten::__getitem__(%342, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %344 : int = aten::len(%342) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %345 : int = aten::sub(%344, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.61 : int = prim::Loop(%345, %13, %size_prods.60) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.16 : int, %size_prods.62 : int):
              %349 : int = aten::add(%i.16, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %350 : int = aten::__getitem__(%342, %349) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.63 : int = aten::mul(%size_prods.62, %350) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.63)
          %352 : bool = aten::eq(%size_prods.61, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%352) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %353 : str = aten::format(%14, %342) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%353) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.62 : Tensor = aten::batch_norm(%input.61, %340, %341, %338, %339, %337, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.63 : Tensor = aten::hardtanh_(%input.62, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %356 : Tensor = prim::GetAttr[name="weight"](%294)
      %357 : Tensor? = prim::GetAttr[name="bias"](%294)
      %input.64 : Tensor = aten::conv2d(%input.63, %356, %357, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %362 : bool = prim::GetAttr[name="training"](%295)
       = prim::If(%362) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %363 : Tensor = prim::GetAttr[name="num_batches_tracked"](%295)
          %364 : Tensor = aten::add(%363, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%295, %364)
          -> ()
        block1():
          -> ()
      %365 : bool = prim::GetAttr[name="training"](%295)
      %366 : Tensor = prim::GetAttr[name="running_mean"](%295)
      %367 : Tensor = prim::GetAttr[name="running_var"](%295)
      %368 : Tensor = prim::GetAttr[name="weight"](%295)
      %369 : Tensor = prim::GetAttr[name="bias"](%295)
       = prim::If(%365) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %370 : int[] = aten::size(%input.64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.64 : int = aten::__getitem__(%370, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %372 : int = aten::len(%370) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %373 : int = aten::sub(%372, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.65 : int = prim::Loop(%373, %13, %size_prods.64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.17 : int, %size_prods.66 : int):
              %377 : int = aten::add(%i.17, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %378 : int = aten::__getitem__(%370, %377) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.67 : int = aten::mul(%size_prods.66, %378) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.67)
          %380 : bool = aten::eq(%size_prods.65, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%380) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %381 : str = aten::format(%14, %370) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%381) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.65 : Tensor = aten::batch_norm(%input.64, %368, %369, %366, %367, %365, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.65)
  %383 : bool = prim::GetAttr[name="use_res_connect"](%25)
  %input.38 : Tensor = prim::If(%383) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:98:8
    block0():
      %385 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="conv"](%25)
      %386 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_15.ConvBNActivation = prim::GetAttr[name="0"](%385)
      %387 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_17.ConvBNActivation = prim::GetAttr[name="1"](%385)
      %388 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="2"](%385)
      %389 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_10.BatchNorm2d = prim::GetAttr[name="3"](%385)
      %390 : __torch__.torch.nn.modules.conv.___torch_mangle_13.Conv2d = prim::GetAttr[name="0"](%386)
      %391 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_14.BatchNorm2d = prim::GetAttr[name="1"](%386)
      %392 : Tensor = prim::GetAttr[name="weight"](%390)
      %393 : Tensor? = prim::GetAttr[name="bias"](%390)
      %input.66 : Tensor = aten::conv2d(%input.26, %392, %393, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %398 : bool = prim::GetAttr[name="training"](%391)
       = prim::If(%398) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %399 : Tensor = prim::GetAttr[name="num_batches_tracked"](%391)
          %400 : Tensor = aten::add(%399, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%391, %400)
          -> ()
        block1():
          -> ()
      %401 : bool = prim::GetAttr[name="training"](%391)
      %402 : Tensor = prim::GetAttr[name="running_mean"](%391)
      %403 : Tensor = prim::GetAttr[name="running_var"](%391)
      %404 : Tensor = prim::GetAttr[name="weight"](%391)
      %405 : Tensor = prim::GetAttr[name="bias"](%391)
       = prim::If(%401) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %406 : int[] = aten::size(%input.66) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.68 : int = aten::__getitem__(%406, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %408 : int = aten::len(%406) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %409 : int = aten::sub(%408, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.69 : int = prim::Loop(%409, %13, %size_prods.68) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.18 : int, %size_prods.70 : int):
              %413 : int = aten::add(%i.18, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %414 : int = aten::__getitem__(%406, %413) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.71 : int = aten::mul(%size_prods.70, %414) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.71)
          %416 : bool = aten::eq(%size_prods.69, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%416) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %417 : str = aten::format(%14, %406) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%417) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.67 : Tensor = aten::batch_norm(%input.66, %404, %405, %402, %403, %401, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.68 : Tensor = aten::hardtanh_(%input.67, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %420 : __torch__.torch.nn.modules.conv.___torch_mangle_16.Conv2d = prim::GetAttr[name="0"](%387)
      %421 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_14.BatchNorm2d = prim::GetAttr[name="1"](%387)
      %422 : Tensor = prim::GetAttr[name="weight"](%420)
      %423 : Tensor? = prim::GetAttr[name="bias"](%420)
      %input.69 : Tensor = aten::conv2d(%input.68, %422, %423, %3236, %3236, %3236, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %428 : bool = prim::GetAttr[name="training"](%421)
       = prim::If(%428) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %429 : Tensor = prim::GetAttr[name="num_batches_tracked"](%421)
          %430 : Tensor = aten::add(%429, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%421, %430)
          -> ()
        block1():
          -> ()
      %431 : bool = prim::GetAttr[name="training"](%421)
      %432 : Tensor = prim::GetAttr[name="running_mean"](%421)
      %433 : Tensor = prim::GetAttr[name="running_var"](%421)
      %434 : Tensor = prim::GetAttr[name="weight"](%421)
      %435 : Tensor = prim::GetAttr[name="bias"](%421)
       = prim::If(%431) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %436 : int[] = aten::size(%input.69) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.72 : int = aten::__getitem__(%436, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %438 : int = aten::len(%436) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %439 : int = aten::sub(%438, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.73 : int = prim::Loop(%439, %13, %size_prods.72) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.19 : int, %size_prods.74 : int):
              %443 : int = aten::add(%i.19, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %444 : int = aten::__getitem__(%436, %443) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.75 : int = aten::mul(%size_prods.74, %444) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.75)
          %446 : bool = aten::eq(%size_prods.73, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%446) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %447 : str = aten::format(%14, %436) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%447) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.70 : Tensor = aten::batch_norm(%input.69, %434, %435, %432, %433, %431, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.71 : Tensor = aten::hardtanh_(%input.70, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %450 : Tensor = prim::GetAttr[name="weight"](%388)
      %451 : Tensor? = prim::GetAttr[name="bias"](%388)
      %input.72 : Tensor = aten::conv2d(%input.71, %450, %451, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %456 : bool = prim::GetAttr[name="training"](%389)
       = prim::If(%456) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %457 : Tensor = prim::GetAttr[name="num_batches_tracked"](%389)
          %458 : Tensor = aten::add(%457, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%389, %458)
          -> ()
        block1():
          -> ()
      %459 : bool = prim::GetAttr[name="training"](%389)
      %460 : Tensor = prim::GetAttr[name="running_mean"](%389)
      %461 : Tensor = prim::GetAttr[name="running_var"](%389)
      %462 : Tensor = prim::GetAttr[name="weight"](%389)
      %463 : Tensor = prim::GetAttr[name="bias"](%389)
       = prim::If(%459) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %464 : int[] = aten::size(%input.72) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.76 : int = aten::__getitem__(%464, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %466 : int = aten::len(%464) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %467 : int = aten::sub(%466, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.77 : int = prim::Loop(%467, %13, %size_prods.76) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.20 : int, %size_prods.78 : int):
              %471 : int = aten::add(%i.20, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %472 : int = aten::__getitem__(%464, %471) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.79 : int = aten::mul(%size_prods.78, %472) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.79)
          %474 : bool = aten::eq(%size_prods.77, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%474) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %475 : str = aten::format(%14, %464) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%475) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.73 : Tensor = aten::batch_norm(%input.72, %462, %463, %460, %461, %459, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %477 : Tensor = aten::add(%input.26, %input.73, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:99:19
      -> (%477)
    block1():
      %478 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="conv"](%25)
      %479 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_15.ConvBNActivation = prim::GetAttr[name="0"](%478)
      %480 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_17.ConvBNActivation = prim::GetAttr[name="1"](%478)
      %481 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="2"](%478)
      %482 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_10.BatchNorm2d = prim::GetAttr[name="3"](%478)
      %483 : __torch__.torch.nn.modules.conv.___torch_mangle_13.Conv2d = prim::GetAttr[name="0"](%479)
      %484 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_14.BatchNorm2d = prim::GetAttr[name="1"](%479)
      %485 : Tensor = prim::GetAttr[name="weight"](%483)
      %486 : Tensor? = prim::GetAttr[name="bias"](%483)
      %input.74 : Tensor = aten::conv2d(%input.26, %485, %486, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %491 : bool = prim::GetAttr[name="training"](%484)
       = prim::If(%491) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %492 : Tensor = prim::GetAttr[name="num_batches_tracked"](%484)
          %493 : Tensor = aten::add(%492, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%484, %493)
          -> ()
        block1():
          -> ()
      %494 : bool = prim::GetAttr[name="training"](%484)
      %495 : Tensor = prim::GetAttr[name="running_mean"](%484)
      %496 : Tensor = prim::GetAttr[name="running_var"](%484)
      %497 : Tensor = prim::GetAttr[name="weight"](%484)
      %498 : Tensor = prim::GetAttr[name="bias"](%484)
       = prim::If(%494) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %499 : int[] = aten::size(%input.74) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.80 : int = aten::__getitem__(%499, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %501 : int = aten::len(%499) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %502 : int = aten::sub(%501, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.81 : int = prim::Loop(%502, %13, %size_prods.80) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.21 : int, %size_prods.82 : int):
              %506 : int = aten::add(%i.21, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %507 : int = aten::__getitem__(%499, %506) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.83 : int = aten::mul(%size_prods.82, %507) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.83)
          %509 : bool = aten::eq(%size_prods.81, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%509) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %510 : str = aten::format(%14, %499) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%510) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.75 : Tensor = aten::batch_norm(%input.74, %497, %498, %495, %496, %494, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.76 : Tensor = aten::hardtanh_(%input.75, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %513 : __torch__.torch.nn.modules.conv.___torch_mangle_16.Conv2d = prim::GetAttr[name="0"](%480)
      %514 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_14.BatchNorm2d = prim::GetAttr[name="1"](%480)
      %515 : Tensor = prim::GetAttr[name="weight"](%513)
      %516 : Tensor? = prim::GetAttr[name="bias"](%513)
      %input.77 : Tensor = aten::conv2d(%input.76, %515, %516, %3236, %3236, %3236, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %521 : bool = prim::GetAttr[name="training"](%514)
       = prim::If(%521) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %522 : Tensor = prim::GetAttr[name="num_batches_tracked"](%514)
          %523 : Tensor = aten::add(%522, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%514, %523)
          -> ()
        block1():
          -> ()
      %524 : bool = prim::GetAttr[name="training"](%514)
      %525 : Tensor = prim::GetAttr[name="running_mean"](%514)
      %526 : Tensor = prim::GetAttr[name="running_var"](%514)
      %527 : Tensor = prim::GetAttr[name="weight"](%514)
      %528 : Tensor = prim::GetAttr[name="bias"](%514)
       = prim::If(%524) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %529 : int[] = aten::size(%input.77) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.84 : int = aten::__getitem__(%529, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %531 : int = aten::len(%529) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %532 : int = aten::sub(%531, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.85 : int = prim::Loop(%532, %13, %size_prods.84) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.22 : int, %size_prods.86 : int):
              %536 : int = aten::add(%i.22, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %537 : int = aten::__getitem__(%529, %536) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.87 : int = aten::mul(%size_prods.86, %537) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.87)
          %539 : bool = aten::eq(%size_prods.85, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%539) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %540 : str = aten::format(%14, %529) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%540) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.78 : Tensor = aten::batch_norm(%input.77, %527, %528, %525, %526, %524, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.79 : Tensor = aten::hardtanh_(%input.78, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %543 : Tensor = prim::GetAttr[name="weight"](%481)
      %544 : Tensor? = prim::GetAttr[name="bias"](%481)
      %input.80 : Tensor = aten::conv2d(%input.79, %543, %544, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %549 : bool = prim::GetAttr[name="training"](%482)
       = prim::If(%549) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %550 : Tensor = prim::GetAttr[name="num_batches_tracked"](%482)
          %551 : Tensor = aten::add(%550, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%482, %551)
          -> ()
        block1():
          -> ()
      %552 : bool = prim::GetAttr[name="training"](%482)
      %553 : Tensor = prim::GetAttr[name="running_mean"](%482)
      %554 : Tensor = prim::GetAttr[name="running_var"](%482)
      %555 : Tensor = prim::GetAttr[name="weight"](%482)
      %556 : Tensor = prim::GetAttr[name="bias"](%482)
       = prim::If(%552) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %557 : int[] = aten::size(%input.80) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.88 : int = aten::__getitem__(%557, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %559 : int = aten::len(%557) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %560 : int = aten::sub(%559, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.89 : int = prim::Loop(%560, %13, %size_prods.88) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.23 : int, %size_prods.90 : int):
              %564 : int = aten::add(%i.23, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %565 : int = aten::__getitem__(%557, %564) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.91 : int = aten::mul(%size_prods.90, %565) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.91)
          %567 : bool = aten::eq(%size_prods.89, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%567) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %568 : str = aten::format(%14, %557) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%568) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.81 : Tensor = aten::batch_norm(%input.80, %555, %556, %553, %554, %552, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.81)
  %570 : bool = prim::GetAttr[name="use_res_connect"](%26)
  %input.34 : Tensor = prim::If(%570) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:98:8
    block0():
      %572 : __torch__.torch.nn.modules.container.___torch_mangle_24.Sequential = prim::GetAttr[name="conv"](%26)
      %573 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_15.ConvBNActivation = prim::GetAttr[name="0"](%572)
      %574 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_22.ConvBNActivation = prim::GetAttr[name="1"](%572)
      %575 : __torch__.torch.nn.modules.conv.___torch_mangle_23.Conv2d = prim::GetAttr[name="2"](%572)
      %576 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="3"](%572)
      %577 : __torch__.torch.nn.modules.conv.___torch_mangle_13.Conv2d = prim::GetAttr[name="0"](%573)
      %578 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_14.BatchNorm2d = prim::GetAttr[name="1"](%573)
      %579 : Tensor = prim::GetAttr[name="weight"](%577)
      %580 : Tensor? = prim::GetAttr[name="bias"](%577)
      %input.82 : Tensor = aten::conv2d(%input.38, %579, %580, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %585 : bool = prim::GetAttr[name="training"](%578)
       = prim::If(%585) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %586 : Tensor = prim::GetAttr[name="num_batches_tracked"](%578)
          %587 : Tensor = aten::add(%586, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%578, %587)
          -> ()
        block1():
          -> ()
      %588 : bool = prim::GetAttr[name="training"](%578)
      %589 : Tensor = prim::GetAttr[name="running_mean"](%578)
      %590 : Tensor = prim::GetAttr[name="running_var"](%578)
      %591 : Tensor = prim::GetAttr[name="weight"](%578)
      %592 : Tensor = prim::GetAttr[name="bias"](%578)
       = prim::If(%588) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %593 : int[] = aten::size(%input.82) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.92 : int = aten::__getitem__(%593, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %595 : int = aten::len(%593) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %596 : int = aten::sub(%595, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.93 : int = prim::Loop(%596, %13, %size_prods.92) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.24 : int, %size_prods.94 : int):
              %600 : int = aten::add(%i.24, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %601 : int = aten::__getitem__(%593, %600) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.95 : int = aten::mul(%size_prods.94, %601) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.95)
          %603 : bool = aten::eq(%size_prods.93, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%603) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %604 : str = aten::format(%14, %593) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%604) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.83 : Tensor = aten::batch_norm(%input.82, %591, %592, %589, %590, %588, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.84 : Tensor = aten::hardtanh_(%input.83, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %607 : __torch__.torch.nn.modules.conv.___torch_mangle_21.Conv2d = prim::GetAttr[name="0"](%574)
      %608 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_14.BatchNorm2d = prim::GetAttr[name="1"](%574)
      %609 : Tensor = prim::GetAttr[name="weight"](%607)
      %610 : Tensor? = prim::GetAttr[name="bias"](%607)
      %input.85 : Tensor = aten::conv2d(%input.84, %609, %610, %3235, %3236, %3236, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %615 : bool = prim::GetAttr[name="training"](%608)
       = prim::If(%615) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %616 : Tensor = prim::GetAttr[name="num_batches_tracked"](%608)
          %617 : Tensor = aten::add(%616, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%608, %617)
          -> ()
        block1():
          -> ()
      %618 : bool = prim::GetAttr[name="training"](%608)
      %619 : Tensor = prim::GetAttr[name="running_mean"](%608)
      %620 : Tensor = prim::GetAttr[name="running_var"](%608)
      %621 : Tensor = prim::GetAttr[name="weight"](%608)
      %622 : Tensor = prim::GetAttr[name="bias"](%608)
       = prim::If(%618) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %623 : int[] = aten::size(%input.85) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.96 : int = aten::__getitem__(%623, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %625 : int = aten::len(%623) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %626 : int = aten::sub(%625, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.97 : int = prim::Loop(%626, %13, %size_prods.96) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.25 : int, %size_prods.98 : int):
              %630 : int = aten::add(%i.25, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %631 : int = aten::__getitem__(%623, %630) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.99 : int = aten::mul(%size_prods.98, %631) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.99)
          %633 : bool = aten::eq(%size_prods.97, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%633) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %634 : str = aten::format(%14, %623) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%634) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.86 : Tensor = aten::batch_norm(%input.85, %621, %622, %619, %620, %618, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.87 : Tensor = aten::hardtanh_(%input.86, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %637 : Tensor = prim::GetAttr[name="weight"](%575)
      %638 : Tensor? = prim::GetAttr[name="bias"](%575)
      %input.88 : Tensor = aten::conv2d(%input.87, %637, %638, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %643 : bool = prim::GetAttr[name="training"](%576)
       = prim::If(%643) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %644 : Tensor = prim::GetAttr[name="num_batches_tracked"](%576)
          %645 : Tensor = aten::add(%644, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%576, %645)
          -> ()
        block1():
          -> ()
      %646 : bool = prim::GetAttr[name="training"](%576)
      %647 : Tensor = prim::GetAttr[name="running_mean"](%576)
      %648 : Tensor = prim::GetAttr[name="running_var"](%576)
      %649 : Tensor = prim::GetAttr[name="weight"](%576)
      %650 : Tensor = prim::GetAttr[name="bias"](%576)
       = prim::If(%646) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %651 : int[] = aten::size(%input.88) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.100 : int = aten::__getitem__(%651, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %653 : int = aten::len(%651) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %654 : int = aten::sub(%653, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.101 : int = prim::Loop(%654, %13, %size_prods.100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.26 : int, %size_prods.102 : int):
              %658 : int = aten::add(%i.26, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %659 : int = aten::__getitem__(%651, %658) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.103 : int = aten::mul(%size_prods.102, %659) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.103)
          %661 : bool = aten::eq(%size_prods.101, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%661) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %662 : str = aten::format(%14, %651) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%662) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.89 : Tensor = aten::batch_norm(%input.88, %649, %650, %647, %648, %646, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %664 : Tensor = aten::add(%input.38, %input.89, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:99:19
      -> (%664)
    block1():
      %665 : __torch__.torch.nn.modules.container.___torch_mangle_24.Sequential = prim::GetAttr[name="conv"](%26)
      %666 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_15.ConvBNActivation = prim::GetAttr[name="0"](%665)
      %667 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_22.ConvBNActivation = prim::GetAttr[name="1"](%665)
      %668 : __torch__.torch.nn.modules.conv.___torch_mangle_23.Conv2d = prim::GetAttr[name="2"](%665)
      %669 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="3"](%665)
      %670 : __torch__.torch.nn.modules.conv.___torch_mangle_13.Conv2d = prim::GetAttr[name="0"](%666)
      %671 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_14.BatchNorm2d = prim::GetAttr[name="1"](%666)
      %672 : Tensor = prim::GetAttr[name="weight"](%670)
      %673 : Tensor? = prim::GetAttr[name="bias"](%670)
      %input.90 : Tensor = aten::conv2d(%input.38, %672, %673, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %678 : bool = prim::GetAttr[name="training"](%671)
       = prim::If(%678) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %679 : Tensor = prim::GetAttr[name="num_batches_tracked"](%671)
          %680 : Tensor = aten::add(%679, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%671, %680)
          -> ()
        block1():
          -> ()
      %681 : bool = prim::GetAttr[name="training"](%671)
      %682 : Tensor = prim::GetAttr[name="running_mean"](%671)
      %683 : Tensor = prim::GetAttr[name="running_var"](%671)
      %684 : Tensor = prim::GetAttr[name="weight"](%671)
      %685 : Tensor = prim::GetAttr[name="bias"](%671)
       = prim::If(%681) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %686 : int[] = aten::size(%input.90) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.104 : int = aten::__getitem__(%686, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %688 : int = aten::len(%686) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %689 : int = aten::sub(%688, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.105 : int = prim::Loop(%689, %13, %size_prods.104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.27 : int, %size_prods.106 : int):
              %693 : int = aten::add(%i.27, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %694 : int = aten::__getitem__(%686, %693) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.107 : int = aten::mul(%size_prods.106, %694) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.107)
          %696 : bool = aten::eq(%size_prods.105, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%696) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %697 : str = aten::format(%14, %686) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%697) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.91 : Tensor = aten::batch_norm(%input.90, %684, %685, %682, %683, %681, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.92 : Tensor = aten::hardtanh_(%input.91, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %700 : __torch__.torch.nn.modules.conv.___torch_mangle_21.Conv2d = prim::GetAttr[name="0"](%667)
      %701 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_14.BatchNorm2d = prim::GetAttr[name="1"](%667)
      %702 : Tensor = prim::GetAttr[name="weight"](%700)
      %703 : Tensor? = prim::GetAttr[name="bias"](%700)
      %input.93 : Tensor = aten::conv2d(%input.92, %702, %703, %3235, %3236, %3236, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %708 : bool = prim::GetAttr[name="training"](%701)
       = prim::If(%708) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %709 : Tensor = prim::GetAttr[name="num_batches_tracked"](%701)
          %710 : Tensor = aten::add(%709, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%701, %710)
          -> ()
        block1():
          -> ()
      %711 : bool = prim::GetAttr[name="training"](%701)
      %712 : Tensor = prim::GetAttr[name="running_mean"](%701)
      %713 : Tensor = prim::GetAttr[name="running_var"](%701)
      %714 : Tensor = prim::GetAttr[name="weight"](%701)
      %715 : Tensor = prim::GetAttr[name="bias"](%701)
       = prim::If(%711) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %716 : int[] = aten::size(%input.93) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.108 : int = aten::__getitem__(%716, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %718 : int = aten::len(%716) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %719 : int = aten::sub(%718, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.109 : int = prim::Loop(%719, %13, %size_prods.108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.28 : int, %size_prods.110 : int):
              %723 : int = aten::add(%i.28, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %724 : int = aten::__getitem__(%716, %723) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.111 : int = aten::mul(%size_prods.110, %724) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.111)
          %726 : bool = aten::eq(%size_prods.109, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%726) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %727 : str = aten::format(%14, %716) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%727) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.94 : Tensor = aten::batch_norm(%input.93, %714, %715, %712, %713, %711, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.95 : Tensor = aten::hardtanh_(%input.94, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %730 : Tensor = prim::GetAttr[name="weight"](%668)
      %731 : Tensor? = prim::GetAttr[name="bias"](%668)
      %input.96 : Tensor = aten::conv2d(%input.95, %730, %731, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %736 : bool = prim::GetAttr[name="training"](%669)
       = prim::If(%736) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %737 : Tensor = prim::GetAttr[name="num_batches_tracked"](%669)
          %738 : Tensor = aten::add(%737, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%669, %738)
          -> ()
        block1():
          -> ()
      %739 : bool = prim::GetAttr[name="training"](%669)
      %740 : Tensor = prim::GetAttr[name="running_mean"](%669)
      %741 : Tensor = prim::GetAttr[name="running_var"](%669)
      %742 : Tensor = prim::GetAttr[name="weight"](%669)
      %743 : Tensor = prim::GetAttr[name="bias"](%669)
       = prim::If(%739) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %744 : int[] = aten::size(%input.96) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.112 : int = aten::__getitem__(%744, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %746 : int = aten::len(%744) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %747 : int = aten::sub(%746, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.113 : int = prim::Loop(%747, %13, %size_prods.112) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.29 : int, %size_prods.114 : int):
              %751 : int = aten::add(%i.29, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %752 : int = aten::__getitem__(%744, %751) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.115 : int = aten::mul(%size_prods.114, %752) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.115)
          %754 : bool = aten::eq(%size_prods.113, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%754) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %755 : str = aten::format(%14, %744) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%755) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.97 : Tensor = aten::batch_norm(%input.96, %742, %743, %740, %741, %739, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.97)
  %757 : bool = prim::GetAttr[name="use_res_connect"](%27)
  %input.30 : Tensor = prim::If(%757) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:98:8
    block0():
      %759 : __torch__.torch.nn.modules.container.___torch_mangle_32.Sequential = prim::GetAttr[name="conv"](%27)
      %760 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_28.ConvBNActivation = prim::GetAttr[name="0"](%759)
      %761 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_30.ConvBNActivation = prim::GetAttr[name="1"](%759)
      %762 : __torch__.torch.nn.modules.conv.___torch_mangle_31.Conv2d = prim::GetAttr[name="2"](%759)
      %763 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="3"](%759)
      %764 : __torch__.torch.nn.modules.conv.___torch_mangle_26.Conv2d = prim::GetAttr[name="0"](%760)
      %765 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_27.BatchNorm2d = prim::GetAttr[name="1"](%760)
      %766 : Tensor = prim::GetAttr[name="weight"](%764)
      %767 : Tensor? = prim::GetAttr[name="bias"](%764)
      %input.98 : Tensor = aten::conv2d(%input.34, %766, %767, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %772 : bool = prim::GetAttr[name="training"](%765)
       = prim::If(%772) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %773 : Tensor = prim::GetAttr[name="num_batches_tracked"](%765)
          %774 : Tensor = aten::add(%773, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%765, %774)
          -> ()
        block1():
          -> ()
      %775 : bool = prim::GetAttr[name="training"](%765)
      %776 : Tensor = prim::GetAttr[name="running_mean"](%765)
      %777 : Tensor = prim::GetAttr[name="running_var"](%765)
      %778 : Tensor = prim::GetAttr[name="weight"](%765)
      %779 : Tensor = prim::GetAttr[name="bias"](%765)
       = prim::If(%775) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %780 : int[] = aten::size(%input.98) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.116 : int = aten::__getitem__(%780, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %782 : int = aten::len(%780) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %783 : int = aten::sub(%782, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.117 : int = prim::Loop(%783, %13, %size_prods.116) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.30 : int, %size_prods.118 : int):
              %787 : int = aten::add(%i.30, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %788 : int = aten::__getitem__(%780, %787) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.119 : int = aten::mul(%size_prods.118, %788) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.119)
          %790 : bool = aten::eq(%size_prods.117, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%790) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %791 : str = aten::format(%14, %780) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%791) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.99 : Tensor = aten::batch_norm(%input.98, %778, %779, %776, %777, %775, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.100 : Tensor = aten::hardtanh_(%input.99, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %794 : __torch__.torch.nn.modules.conv.___torch_mangle_29.Conv2d = prim::GetAttr[name="0"](%761)
      %795 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_27.BatchNorm2d = prim::GetAttr[name="1"](%761)
      %796 : Tensor = prim::GetAttr[name="weight"](%794)
      %797 : Tensor? = prim::GetAttr[name="bias"](%794)
      %input.101 : Tensor = aten::conv2d(%input.100, %796, %797, %3236, %3236, %3236, %8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %802 : bool = prim::GetAttr[name="training"](%795)
       = prim::If(%802) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %803 : Tensor = prim::GetAttr[name="num_batches_tracked"](%795)
          %804 : Tensor = aten::add(%803, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%795, %804)
          -> ()
        block1():
          -> ()
      %805 : bool = prim::GetAttr[name="training"](%795)
      %806 : Tensor = prim::GetAttr[name="running_mean"](%795)
      %807 : Tensor = prim::GetAttr[name="running_var"](%795)
      %808 : Tensor = prim::GetAttr[name="weight"](%795)
      %809 : Tensor = prim::GetAttr[name="bias"](%795)
       = prim::If(%805) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %810 : int[] = aten::size(%input.101) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.120 : int = aten::__getitem__(%810, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %812 : int = aten::len(%810) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %813 : int = aten::sub(%812, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.121 : int = prim::Loop(%813, %13, %size_prods.120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.31 : int, %size_prods.122 : int):
              %817 : int = aten::add(%i.31, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %818 : int = aten::__getitem__(%810, %817) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.123 : int = aten::mul(%size_prods.122, %818) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.123)
          %820 : bool = aten::eq(%size_prods.121, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%820) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %821 : str = aten::format(%14, %810) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%821) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.102 : Tensor = aten::batch_norm(%input.101, %808, %809, %806, %807, %805, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.103 : Tensor = aten::hardtanh_(%input.102, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %824 : Tensor = prim::GetAttr[name="weight"](%762)
      %825 : Tensor? = prim::GetAttr[name="bias"](%762)
      %input.104 : Tensor = aten::conv2d(%input.103, %824, %825, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %830 : bool = prim::GetAttr[name="training"](%763)
       = prim::If(%830) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %831 : Tensor = prim::GetAttr[name="num_batches_tracked"](%763)
          %832 : Tensor = aten::add(%831, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%763, %832)
          -> ()
        block1():
          -> ()
      %833 : bool = prim::GetAttr[name="training"](%763)
      %834 : Tensor = prim::GetAttr[name="running_mean"](%763)
      %835 : Tensor = prim::GetAttr[name="running_var"](%763)
      %836 : Tensor = prim::GetAttr[name="weight"](%763)
      %837 : Tensor = prim::GetAttr[name="bias"](%763)
       = prim::If(%833) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %838 : int[] = aten::size(%input.104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.124 : int = aten::__getitem__(%838, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %840 : int = aten::len(%838) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %841 : int = aten::sub(%840, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.125 : int = prim::Loop(%841, %13, %size_prods.124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.32 : int, %size_prods.126 : int):
              %845 : int = aten::add(%i.32, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %846 : int = aten::__getitem__(%838, %845) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.127 : int = aten::mul(%size_prods.126, %846) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.127)
          %848 : bool = aten::eq(%size_prods.125, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%848) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %849 : str = aten::format(%14, %838) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%849) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.105 : Tensor = aten::batch_norm(%input.104, %836, %837, %834, %835, %833, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %851 : Tensor = aten::add(%input.34, %input.105, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:99:19
      -> (%851)
    block1():
      %852 : __torch__.torch.nn.modules.container.___torch_mangle_32.Sequential = prim::GetAttr[name="conv"](%27)
      %853 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_28.ConvBNActivation = prim::GetAttr[name="0"](%852)
      %854 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_30.ConvBNActivation = prim::GetAttr[name="1"](%852)
      %855 : __torch__.torch.nn.modules.conv.___torch_mangle_31.Conv2d = prim::GetAttr[name="2"](%852)
      %856 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="3"](%852)
      %857 : __torch__.torch.nn.modules.conv.___torch_mangle_26.Conv2d = prim::GetAttr[name="0"](%853)
      %858 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_27.BatchNorm2d = prim::GetAttr[name="1"](%853)
      %859 : Tensor = prim::GetAttr[name="weight"](%857)
      %860 : Tensor? = prim::GetAttr[name="bias"](%857)
      %input.106 : Tensor = aten::conv2d(%input.34, %859, %860, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %865 : bool = prim::GetAttr[name="training"](%858)
       = prim::If(%865) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %866 : Tensor = prim::GetAttr[name="num_batches_tracked"](%858)
          %867 : Tensor = aten::add(%866, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%858, %867)
          -> ()
        block1():
          -> ()
      %868 : bool = prim::GetAttr[name="training"](%858)
      %869 : Tensor = prim::GetAttr[name="running_mean"](%858)
      %870 : Tensor = prim::GetAttr[name="running_var"](%858)
      %871 : Tensor = prim::GetAttr[name="weight"](%858)
      %872 : Tensor = prim::GetAttr[name="bias"](%858)
       = prim::If(%868) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %873 : int[] = aten::size(%input.106) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.128 : int = aten::__getitem__(%873, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %875 : int = aten::len(%873) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %876 : int = aten::sub(%875, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.129 : int = prim::Loop(%876, %13, %size_prods.128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.33 : int, %size_prods.130 : int):
              %880 : int = aten::add(%i.33, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %881 : int = aten::__getitem__(%873, %880) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.131 : int = aten::mul(%size_prods.130, %881) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.131)
          %883 : bool = aten::eq(%size_prods.129, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%883) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %884 : str = aten::format(%14, %873) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%884) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.107 : Tensor = aten::batch_norm(%input.106, %871, %872, %869, %870, %868, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.108 : Tensor = aten::hardtanh_(%input.107, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %887 : __torch__.torch.nn.modules.conv.___torch_mangle_29.Conv2d = prim::GetAttr[name="0"](%854)
      %888 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_27.BatchNorm2d = prim::GetAttr[name="1"](%854)
      %889 : Tensor = prim::GetAttr[name="weight"](%887)
      %890 : Tensor? = prim::GetAttr[name="bias"](%887)
      %input.109 : Tensor = aten::conv2d(%input.108, %889, %890, %3236, %3236, %3236, %8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %895 : bool = prim::GetAttr[name="training"](%888)
       = prim::If(%895) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %896 : Tensor = prim::GetAttr[name="num_batches_tracked"](%888)
          %897 : Tensor = aten::add(%896, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%888, %897)
          -> ()
        block1():
          -> ()
      %898 : bool = prim::GetAttr[name="training"](%888)
      %899 : Tensor = prim::GetAttr[name="running_mean"](%888)
      %900 : Tensor = prim::GetAttr[name="running_var"](%888)
      %901 : Tensor = prim::GetAttr[name="weight"](%888)
      %902 : Tensor = prim::GetAttr[name="bias"](%888)
       = prim::If(%898) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %903 : int[] = aten::size(%input.109) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.132 : int = aten::__getitem__(%903, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %905 : int = aten::len(%903) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %906 : int = aten::sub(%905, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.133 : int = prim::Loop(%906, %13, %size_prods.132) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.34 : int, %size_prods.134 : int):
              %910 : int = aten::add(%i.34, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %911 : int = aten::__getitem__(%903, %910) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.135 : int = aten::mul(%size_prods.134, %911) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.135)
          %913 : bool = aten::eq(%size_prods.133, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%913) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %914 : str = aten::format(%14, %903) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%914) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.110 : Tensor = aten::batch_norm(%input.109, %901, %902, %899, %900, %898, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.111 : Tensor = aten::hardtanh_(%input.110, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %917 : Tensor = prim::GetAttr[name="weight"](%855)
      %918 : Tensor? = prim::GetAttr[name="bias"](%855)
      %input.112 : Tensor = aten::conv2d(%input.111, %917, %918, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %923 : bool = prim::GetAttr[name="training"](%856)
       = prim::If(%923) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %924 : Tensor = prim::GetAttr[name="num_batches_tracked"](%856)
          %925 : Tensor = aten::add(%924, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%856, %925)
          -> ()
        block1():
          -> ()
      %926 : bool = prim::GetAttr[name="training"](%856)
      %927 : Tensor = prim::GetAttr[name="running_mean"](%856)
      %928 : Tensor = prim::GetAttr[name="running_var"](%856)
      %929 : Tensor = prim::GetAttr[name="weight"](%856)
      %930 : Tensor = prim::GetAttr[name="bias"](%856)
       = prim::If(%926) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %931 : int[] = aten::size(%input.112) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.136 : int = aten::__getitem__(%931, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %933 : int = aten::len(%931) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %934 : int = aten::sub(%933, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.137 : int = prim::Loop(%934, %13, %size_prods.136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.35 : int, %size_prods.138 : int):
              %938 : int = aten::add(%i.35, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %939 : int = aten::__getitem__(%931, %938) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.139 : int = aten::mul(%size_prods.138, %939) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.139)
          %941 : bool = aten::eq(%size_prods.137, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%941) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %942 : str = aten::format(%14, %931) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%942) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.113 : Tensor = aten::batch_norm(%input.112, %929, %930, %927, %928, %926, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.113)
  %944 : bool = prim::GetAttr[name="use_res_connect"](%28)
  %input.36 : Tensor = prim::If(%944) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:98:8
    block0():
      %946 : __torch__.torch.nn.modules.container.___torch_mangle_32.Sequential = prim::GetAttr[name="conv"](%28)
      %947 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_28.ConvBNActivation = prim::GetAttr[name="0"](%946)
      %948 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_30.ConvBNActivation = prim::GetAttr[name="1"](%946)
      %949 : __torch__.torch.nn.modules.conv.___torch_mangle_31.Conv2d = prim::GetAttr[name="2"](%946)
      %950 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="3"](%946)
      %951 : __torch__.torch.nn.modules.conv.___torch_mangle_26.Conv2d = prim::GetAttr[name="0"](%947)
      %952 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_27.BatchNorm2d = prim::GetAttr[name="1"](%947)
      %953 : Tensor = prim::GetAttr[name="weight"](%951)
      %954 : Tensor? = prim::GetAttr[name="bias"](%951)
      %input.114 : Tensor = aten::conv2d(%input.30, %953, %954, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %959 : bool = prim::GetAttr[name="training"](%952)
       = prim::If(%959) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %960 : Tensor = prim::GetAttr[name="num_batches_tracked"](%952)
          %961 : Tensor = aten::add(%960, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%952, %961)
          -> ()
        block1():
          -> ()
      %962 : bool = prim::GetAttr[name="training"](%952)
      %963 : Tensor = prim::GetAttr[name="running_mean"](%952)
      %964 : Tensor = prim::GetAttr[name="running_var"](%952)
      %965 : Tensor = prim::GetAttr[name="weight"](%952)
      %966 : Tensor = prim::GetAttr[name="bias"](%952)
       = prim::If(%962) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %967 : int[] = aten::size(%input.114) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.140 : int = aten::__getitem__(%967, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %969 : int = aten::len(%967) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %970 : int = aten::sub(%969, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.141 : int = prim::Loop(%970, %13, %size_prods.140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.36 : int, %size_prods.142 : int):
              %974 : int = aten::add(%i.36, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %975 : int = aten::__getitem__(%967, %974) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.143 : int = aten::mul(%size_prods.142, %975) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.143)
          %977 : bool = aten::eq(%size_prods.141, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%977) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %978 : str = aten::format(%14, %967) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%978) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.115 : Tensor = aten::batch_norm(%input.114, %965, %966, %963, %964, %962, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.116 : Tensor = aten::hardtanh_(%input.115, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %981 : __torch__.torch.nn.modules.conv.___torch_mangle_29.Conv2d = prim::GetAttr[name="0"](%948)
      %982 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_27.BatchNorm2d = prim::GetAttr[name="1"](%948)
      %983 : Tensor = prim::GetAttr[name="weight"](%981)
      %984 : Tensor? = prim::GetAttr[name="bias"](%981)
      %input.117 : Tensor = aten::conv2d(%input.116, %983, %984, %3236, %3236, %3236, %8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %989 : bool = prim::GetAttr[name="training"](%982)
       = prim::If(%989) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %990 : Tensor = prim::GetAttr[name="num_batches_tracked"](%982)
          %991 : Tensor = aten::add(%990, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%982, %991)
          -> ()
        block1():
          -> ()
      %992 : bool = prim::GetAttr[name="training"](%982)
      %993 : Tensor = prim::GetAttr[name="running_mean"](%982)
      %994 : Tensor = prim::GetAttr[name="running_var"](%982)
      %995 : Tensor = prim::GetAttr[name="weight"](%982)
      %996 : Tensor = prim::GetAttr[name="bias"](%982)
       = prim::If(%992) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %997 : int[] = aten::size(%input.117) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.144 : int = aten::__getitem__(%997, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %999 : int = aten::len(%997) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1000 : int = aten::sub(%999, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.145 : int = prim::Loop(%1000, %13, %size_prods.144) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.37 : int, %size_prods.146 : int):
              %1004 : int = aten::add(%i.37, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1005 : int = aten::__getitem__(%997, %1004) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.147 : int = aten::mul(%size_prods.146, %1005) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.147)
          %1007 : bool = aten::eq(%size_prods.145, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1007) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1008 : str = aten::format(%14, %997) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1008) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.118 : Tensor = aten::batch_norm(%input.117, %995, %996, %993, %994, %992, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.119 : Tensor = aten::hardtanh_(%input.118, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1011 : Tensor = prim::GetAttr[name="weight"](%949)
      %1012 : Tensor? = prim::GetAttr[name="bias"](%949)
      %input.120 : Tensor = aten::conv2d(%input.119, %1011, %1012, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1017 : bool = prim::GetAttr[name="training"](%950)
       = prim::If(%1017) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1018 : Tensor = prim::GetAttr[name="num_batches_tracked"](%950)
          %1019 : Tensor = aten::add(%1018, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%950, %1019)
          -> ()
        block1():
          -> ()
      %1020 : bool = prim::GetAttr[name="training"](%950)
      %1021 : Tensor = prim::GetAttr[name="running_mean"](%950)
      %1022 : Tensor = prim::GetAttr[name="running_var"](%950)
      %1023 : Tensor = prim::GetAttr[name="weight"](%950)
      %1024 : Tensor = prim::GetAttr[name="bias"](%950)
       = prim::If(%1020) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1025 : int[] = aten::size(%input.120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.148 : int = aten::__getitem__(%1025, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1027 : int = aten::len(%1025) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1028 : int = aten::sub(%1027, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.149 : int = prim::Loop(%1028, %13, %size_prods.148) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.38 : int, %size_prods.150 : int):
              %1032 : int = aten::add(%i.38, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1033 : int = aten::__getitem__(%1025, %1032) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.151 : int = aten::mul(%size_prods.150, %1033) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.151)
          %1035 : bool = aten::eq(%size_prods.149, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1035) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1036 : str = aten::format(%14, %1025) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1036) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.121 : Tensor = aten::batch_norm(%input.120, %1023, %1024, %1021, %1022, %1020, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1038 : Tensor = aten::add(%input.30, %input.121, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:99:19
      -> (%1038)
    block1():
      %1039 : __torch__.torch.nn.modules.container.___torch_mangle_32.Sequential = prim::GetAttr[name="conv"](%28)
      %1040 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_28.ConvBNActivation = prim::GetAttr[name="0"](%1039)
      %1041 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_30.ConvBNActivation = prim::GetAttr[name="1"](%1039)
      %1042 : __torch__.torch.nn.modules.conv.___torch_mangle_31.Conv2d = prim::GetAttr[name="2"](%1039)
      %1043 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="3"](%1039)
      %1044 : __torch__.torch.nn.modules.conv.___torch_mangle_26.Conv2d = prim::GetAttr[name="0"](%1040)
      %1045 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_27.BatchNorm2d = prim::GetAttr[name="1"](%1040)
      %1046 : Tensor = prim::GetAttr[name="weight"](%1044)
      %1047 : Tensor? = prim::GetAttr[name="bias"](%1044)
      %input.122 : Tensor = aten::conv2d(%input.30, %1046, %1047, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1052 : bool = prim::GetAttr[name="training"](%1045)
       = prim::If(%1052) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1053 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1045)
          %1054 : Tensor = aten::add(%1053, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1045, %1054)
          -> ()
        block1():
          -> ()
      %1055 : bool = prim::GetAttr[name="training"](%1045)
      %1056 : Tensor = prim::GetAttr[name="running_mean"](%1045)
      %1057 : Tensor = prim::GetAttr[name="running_var"](%1045)
      %1058 : Tensor = prim::GetAttr[name="weight"](%1045)
      %1059 : Tensor = prim::GetAttr[name="bias"](%1045)
       = prim::If(%1055) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1060 : int[] = aten::size(%input.122) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.152 : int = aten::__getitem__(%1060, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1062 : int = aten::len(%1060) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1063 : int = aten::sub(%1062, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.153 : int = prim::Loop(%1063, %13, %size_prods.152) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.39 : int, %size_prods.154 : int):
              %1067 : int = aten::add(%i.39, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1068 : int = aten::__getitem__(%1060, %1067) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.155 : int = aten::mul(%size_prods.154, %1068) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.155)
          %1070 : bool = aten::eq(%size_prods.153, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1070) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1071 : str = aten::format(%14, %1060) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1071) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.123 : Tensor = aten::batch_norm(%input.122, %1058, %1059, %1056, %1057, %1055, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.124 : Tensor = aten::hardtanh_(%input.123, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1074 : __torch__.torch.nn.modules.conv.___torch_mangle_29.Conv2d = prim::GetAttr[name="0"](%1041)
      %1075 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_27.BatchNorm2d = prim::GetAttr[name="1"](%1041)
      %1076 : Tensor = prim::GetAttr[name="weight"](%1074)
      %1077 : Tensor? = prim::GetAttr[name="bias"](%1074)
      %input.125 : Tensor = aten::conv2d(%input.124, %1076, %1077, %3236, %3236, %3236, %8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1082 : bool = prim::GetAttr[name="training"](%1075)
       = prim::If(%1082) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1083 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1075)
          %1084 : Tensor = aten::add(%1083, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1075, %1084)
          -> ()
        block1():
          -> ()
      %1085 : bool = prim::GetAttr[name="training"](%1075)
      %1086 : Tensor = prim::GetAttr[name="running_mean"](%1075)
      %1087 : Tensor = prim::GetAttr[name="running_var"](%1075)
      %1088 : Tensor = prim::GetAttr[name="weight"](%1075)
      %1089 : Tensor = prim::GetAttr[name="bias"](%1075)
       = prim::If(%1085) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1090 : int[] = aten::size(%input.125) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.156 : int = aten::__getitem__(%1090, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1092 : int = aten::len(%1090) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1093 : int = aten::sub(%1092, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.157 : int = prim::Loop(%1093, %13, %size_prods.156) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.40 : int, %size_prods.158 : int):
              %1097 : int = aten::add(%i.40, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1098 : int = aten::__getitem__(%1090, %1097) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.159 : int = aten::mul(%size_prods.158, %1098) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.159)
          %1100 : bool = aten::eq(%size_prods.157, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1101 : str = aten::format(%14, %1090) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1101) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.126 : Tensor = aten::batch_norm(%input.125, %1088, %1089, %1086, %1087, %1085, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.127 : Tensor = aten::hardtanh_(%input.126, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1104 : Tensor = prim::GetAttr[name="weight"](%1042)
      %1105 : Tensor? = prim::GetAttr[name="bias"](%1042)
      %input.128 : Tensor = aten::conv2d(%input.127, %1104, %1105, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1110 : bool = prim::GetAttr[name="training"](%1043)
       = prim::If(%1110) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1111 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1043)
          %1112 : Tensor = aten::add(%1111, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1043, %1112)
          -> ()
        block1():
          -> ()
      %1113 : bool = prim::GetAttr[name="training"](%1043)
      %1114 : Tensor = prim::GetAttr[name="running_mean"](%1043)
      %1115 : Tensor = prim::GetAttr[name="running_var"](%1043)
      %1116 : Tensor = prim::GetAttr[name="weight"](%1043)
      %1117 : Tensor = prim::GetAttr[name="bias"](%1043)
       = prim::If(%1113) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1118 : int[] = aten::size(%input.128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.160 : int = aten::__getitem__(%1118, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1120 : int = aten::len(%1118) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1121 : int = aten::sub(%1120, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.161 : int = prim::Loop(%1121, %13, %size_prods.160) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.41 : int, %size_prods.162 : int):
              %1125 : int = aten::add(%i.41, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1126 : int = aten::__getitem__(%1118, %1125) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.163 : int = aten::mul(%size_prods.162, %1126) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.163)
          %1128 : bool = aten::eq(%size_prods.161, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1129 : str = aten::format(%14, %1118) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1129) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.129 : Tensor = aten::batch_norm(%input.128, %1116, %1117, %1114, %1115, %1113, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.129)
  %1131 : bool = prim::GetAttr[name="use_res_connect"](%29)
  %input.40 : Tensor = prim::If(%1131) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:98:8
    block0():
      %1133 : __torch__.torch.nn.modules.container.___torch_mangle_38.Sequential = prim::GetAttr[name="conv"](%29)
      %1134 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_28.ConvBNActivation = prim::GetAttr[name="0"](%1133)
      %1135 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_35.ConvBNActivation = prim::GetAttr[name="1"](%1133)
      %1136 : __torch__.torch.nn.modules.conv.___torch_mangle_36.Conv2d = prim::GetAttr[name="2"](%1133)
      %1137 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_37.BatchNorm2d = prim::GetAttr[name="3"](%1133)
      %1138 : __torch__.torch.nn.modules.conv.___torch_mangle_26.Conv2d = prim::GetAttr[name="0"](%1134)
      %1139 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_27.BatchNorm2d = prim::GetAttr[name="1"](%1134)
      %1140 : Tensor = prim::GetAttr[name="weight"](%1138)
      %1141 : Tensor? = prim::GetAttr[name="bias"](%1138)
      %input.130 : Tensor = aten::conv2d(%input.36, %1140, %1141, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1146 : bool = prim::GetAttr[name="training"](%1139)
       = prim::If(%1146) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1147 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1139)
          %1148 : Tensor = aten::add(%1147, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1139, %1148)
          -> ()
        block1():
          -> ()
      %1149 : bool = prim::GetAttr[name="training"](%1139)
      %1150 : Tensor = prim::GetAttr[name="running_mean"](%1139)
      %1151 : Tensor = prim::GetAttr[name="running_var"](%1139)
      %1152 : Tensor = prim::GetAttr[name="weight"](%1139)
      %1153 : Tensor = prim::GetAttr[name="bias"](%1139)
       = prim::If(%1149) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1154 : int[] = aten::size(%input.130) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.164 : int = aten::__getitem__(%1154, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1156 : int = aten::len(%1154) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1157 : int = aten::sub(%1156, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.165 : int = prim::Loop(%1157, %13, %size_prods.164) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.42 : int, %size_prods.166 : int):
              %1161 : int = aten::add(%i.42, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1162 : int = aten::__getitem__(%1154, %1161) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.167 : int = aten::mul(%size_prods.166, %1162) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.167)
          %1164 : bool = aten::eq(%size_prods.165, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1164) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1165 : str = aten::format(%14, %1154) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1165) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.131 : Tensor = aten::batch_norm(%input.130, %1152, %1153, %1150, %1151, %1149, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.132 : Tensor = aten::hardtanh_(%input.131, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1168 : __torch__.torch.nn.modules.conv.___torch_mangle_34.Conv2d = prim::GetAttr[name="0"](%1135)
      %1169 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_27.BatchNorm2d = prim::GetAttr[name="1"](%1135)
      %1170 : Tensor = prim::GetAttr[name="weight"](%1168)
      %1171 : Tensor? = prim::GetAttr[name="bias"](%1168)
      %input.133 : Tensor = aten::conv2d(%input.132, %1170, %1171, %3235, %3236, %3236, %8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1176 : bool = prim::GetAttr[name="training"](%1169)
       = prim::If(%1176) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1177 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1169)
          %1178 : Tensor = aten::add(%1177, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1169, %1178)
          -> ()
        block1():
          -> ()
      %1179 : bool = prim::GetAttr[name="training"](%1169)
      %1180 : Tensor = prim::GetAttr[name="running_mean"](%1169)
      %1181 : Tensor = prim::GetAttr[name="running_var"](%1169)
      %1182 : Tensor = prim::GetAttr[name="weight"](%1169)
      %1183 : Tensor = prim::GetAttr[name="bias"](%1169)
       = prim::If(%1179) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1184 : int[] = aten::size(%input.133) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.168 : int = aten::__getitem__(%1184, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1186 : int = aten::len(%1184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1187 : int = aten::sub(%1186, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.169 : int = prim::Loop(%1187, %13, %size_prods.168) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.43 : int, %size_prods.170 : int):
              %1191 : int = aten::add(%i.43, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1192 : int = aten::__getitem__(%1184, %1191) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.171 : int = aten::mul(%size_prods.170, %1192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.171)
          %1194 : bool = aten::eq(%size_prods.169, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1194) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1195 : str = aten::format(%14, %1184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1195) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.134 : Tensor = aten::batch_norm(%input.133, %1182, %1183, %1180, %1181, %1179, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.135 : Tensor = aten::hardtanh_(%input.134, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1198 : Tensor = prim::GetAttr[name="weight"](%1136)
      %1199 : Tensor? = prim::GetAttr[name="bias"](%1136)
      %input.136 : Tensor = aten::conv2d(%input.135, %1198, %1199, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1204 : bool = prim::GetAttr[name="training"](%1137)
       = prim::If(%1204) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1205 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1137)
          %1206 : Tensor = aten::add(%1205, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1137, %1206)
          -> ()
        block1():
          -> ()
      %1207 : bool = prim::GetAttr[name="training"](%1137)
      %1208 : Tensor = prim::GetAttr[name="running_mean"](%1137)
      %1209 : Tensor = prim::GetAttr[name="running_var"](%1137)
      %1210 : Tensor = prim::GetAttr[name="weight"](%1137)
      %1211 : Tensor = prim::GetAttr[name="bias"](%1137)
       = prim::If(%1207) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1212 : int[] = aten::size(%input.136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.172 : int = aten::__getitem__(%1212, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1214 : int = aten::len(%1212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1215 : int = aten::sub(%1214, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.173 : int = prim::Loop(%1215, %13, %size_prods.172) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.44 : int, %size_prods.174 : int):
              %1219 : int = aten::add(%i.44, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1220 : int = aten::__getitem__(%1212, %1219) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.175 : int = aten::mul(%size_prods.174, %1220) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.175)
          %1222 : bool = aten::eq(%size_prods.173, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1222) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1223 : str = aten::format(%14, %1212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1223) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.137 : Tensor = aten::batch_norm(%input.136, %1210, %1211, %1208, %1209, %1207, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1225 : Tensor = aten::add(%input.36, %input.137, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:99:19
      -> (%1225)
    block1():
      %1226 : __torch__.torch.nn.modules.container.___torch_mangle_38.Sequential = prim::GetAttr[name="conv"](%29)
      %1227 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_28.ConvBNActivation = prim::GetAttr[name="0"](%1226)
      %1228 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_35.ConvBNActivation = prim::GetAttr[name="1"](%1226)
      %1229 : __torch__.torch.nn.modules.conv.___torch_mangle_36.Conv2d = prim::GetAttr[name="2"](%1226)
      %1230 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_37.BatchNorm2d = prim::GetAttr[name="3"](%1226)
      %1231 : __torch__.torch.nn.modules.conv.___torch_mangle_26.Conv2d = prim::GetAttr[name="0"](%1227)
      %1232 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_27.BatchNorm2d = prim::GetAttr[name="1"](%1227)
      %1233 : Tensor = prim::GetAttr[name="weight"](%1231)
      %1234 : Tensor? = prim::GetAttr[name="bias"](%1231)
      %input.138 : Tensor = aten::conv2d(%input.36, %1233, %1234, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1239 : bool = prim::GetAttr[name="training"](%1232)
       = prim::If(%1239) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1240 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1232)
          %1241 : Tensor = aten::add(%1240, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1232, %1241)
          -> ()
        block1():
          -> ()
      %1242 : bool = prim::GetAttr[name="training"](%1232)
      %1243 : Tensor = prim::GetAttr[name="running_mean"](%1232)
      %1244 : Tensor = prim::GetAttr[name="running_var"](%1232)
      %1245 : Tensor = prim::GetAttr[name="weight"](%1232)
      %1246 : Tensor = prim::GetAttr[name="bias"](%1232)
       = prim::If(%1242) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1247 : int[] = aten::size(%input.138) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.176 : int = aten::__getitem__(%1247, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1249 : int = aten::len(%1247) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1250 : int = aten::sub(%1249, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.177 : int = prim::Loop(%1250, %13, %size_prods.176) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.45 : int, %size_prods.178 : int):
              %1254 : int = aten::add(%i.45, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1255 : int = aten::__getitem__(%1247, %1254) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.179 : int = aten::mul(%size_prods.178, %1255) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.179)
          %1257 : bool = aten::eq(%size_prods.177, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1257) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1258 : str = aten::format(%14, %1247) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1258) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.139 : Tensor = aten::batch_norm(%input.138, %1245, %1246, %1243, %1244, %1242, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.140 : Tensor = aten::hardtanh_(%input.139, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1261 : __torch__.torch.nn.modules.conv.___torch_mangle_34.Conv2d = prim::GetAttr[name="0"](%1228)
      %1262 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_27.BatchNorm2d = prim::GetAttr[name="1"](%1228)
      %1263 : Tensor = prim::GetAttr[name="weight"](%1261)
      %1264 : Tensor? = prim::GetAttr[name="bias"](%1261)
      %input.141 : Tensor = aten::conv2d(%input.140, %1263, %1264, %3235, %3236, %3236, %8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1269 : bool = prim::GetAttr[name="training"](%1262)
       = prim::If(%1269) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1270 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1262)
          %1271 : Tensor = aten::add(%1270, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1262, %1271)
          -> ()
        block1():
          -> ()
      %1272 : bool = prim::GetAttr[name="training"](%1262)
      %1273 : Tensor = prim::GetAttr[name="running_mean"](%1262)
      %1274 : Tensor = prim::GetAttr[name="running_var"](%1262)
      %1275 : Tensor = prim::GetAttr[name="weight"](%1262)
      %1276 : Tensor = prim::GetAttr[name="bias"](%1262)
       = prim::If(%1272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1277 : int[] = aten::size(%input.141) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.180 : int = aten::__getitem__(%1277, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1279 : int = aten::len(%1277) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1280 : int = aten::sub(%1279, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.181 : int = prim::Loop(%1280, %13, %size_prods.180) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.46 : int, %size_prods.182 : int):
              %1284 : int = aten::add(%i.46, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1285 : int = aten::__getitem__(%1277, %1284) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.183 : int = aten::mul(%size_prods.182, %1285) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.183)
          %1287 : bool = aten::eq(%size_prods.181, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1287) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1288 : str = aten::format(%14, %1277) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1288) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.142 : Tensor = aten::batch_norm(%input.141, %1275, %1276, %1273, %1274, %1272, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.143 : Tensor = aten::hardtanh_(%input.142, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1291 : Tensor = prim::GetAttr[name="weight"](%1229)
      %1292 : Tensor? = prim::GetAttr[name="bias"](%1229)
      %input.144 : Tensor = aten::conv2d(%input.143, %1291, %1292, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1297 : bool = prim::GetAttr[name="training"](%1230)
       = prim::If(%1297) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1298 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1230)
          %1299 : Tensor = aten::add(%1298, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1230, %1299)
          -> ()
        block1():
          -> ()
      %1300 : bool = prim::GetAttr[name="training"](%1230)
      %1301 : Tensor = prim::GetAttr[name="running_mean"](%1230)
      %1302 : Tensor = prim::GetAttr[name="running_var"](%1230)
      %1303 : Tensor = prim::GetAttr[name="weight"](%1230)
      %1304 : Tensor = prim::GetAttr[name="bias"](%1230)
       = prim::If(%1300) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1305 : int[] = aten::size(%input.144) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.184 : int = aten::__getitem__(%1305, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1307 : int = aten::len(%1305) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1308 : int = aten::sub(%1307, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.185 : int = prim::Loop(%1308, %13, %size_prods.184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.47 : int, %size_prods.186 : int):
              %1312 : int = aten::add(%i.47, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1313 : int = aten::__getitem__(%1305, %1312) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.187 : int = aten::mul(%size_prods.186, %1313) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.187)
          %1315 : bool = aten::eq(%size_prods.185, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1315) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1316 : str = aten::format(%14, %1305) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1316) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.145 : Tensor = aten::batch_norm(%input.144, %1303, %1304, %1301, %1302, %1300, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.145)
  %1318 : bool = prim::GetAttr[name="use_res_connect"](%30)
  %input.19 : Tensor = prim::If(%1318) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:98:8
    block0():
      %1320 : __torch__.torch.nn.modules.container.___torch_mangle_46.Sequential = prim::GetAttr[name="conv"](%30)
      %1321 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_42.ConvBNActivation = prim::GetAttr[name="0"](%1320)
      %1322 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_44.ConvBNActivation = prim::GetAttr[name="1"](%1320)
      %1323 : __torch__.torch.nn.modules.conv.___torch_mangle_45.Conv2d = prim::GetAttr[name="2"](%1320)
      %1324 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_37.BatchNorm2d = prim::GetAttr[name="3"](%1320)
      %1325 : __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d = prim::GetAttr[name="0"](%1321)
      %1326 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_41.BatchNorm2d = prim::GetAttr[name="1"](%1321)
      %1327 : Tensor = prim::GetAttr[name="weight"](%1325)
      %1328 : Tensor? = prim::GetAttr[name="bias"](%1325)
      %input.146 : Tensor = aten::conv2d(%input.40, %1327, %1328, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1333 : bool = prim::GetAttr[name="training"](%1326)
       = prim::If(%1333) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1334 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1326)
          %1335 : Tensor = aten::add(%1334, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1326, %1335)
          -> ()
        block1():
          -> ()
      %1336 : bool = prim::GetAttr[name="training"](%1326)
      %1337 : Tensor = prim::GetAttr[name="running_mean"](%1326)
      %1338 : Tensor = prim::GetAttr[name="running_var"](%1326)
      %1339 : Tensor = prim::GetAttr[name="weight"](%1326)
      %1340 : Tensor = prim::GetAttr[name="bias"](%1326)
       = prim::If(%1336) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1341 : int[] = aten::size(%input.146) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.188 : int = aten::__getitem__(%1341, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1343 : int = aten::len(%1341) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1344 : int = aten::sub(%1343, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.189 : int = prim::Loop(%1344, %13, %size_prods.188) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.48 : int, %size_prods.190 : int):
              %1348 : int = aten::add(%i.48, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1349 : int = aten::__getitem__(%1341, %1348) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.191 : int = aten::mul(%size_prods.190, %1349) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.191)
          %1351 : bool = aten::eq(%size_prods.189, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1351) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1352 : str = aten::format(%14, %1341) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1352) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.147 : Tensor = aten::batch_norm(%input.146, %1339, %1340, %1337, %1338, %1336, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.148 : Tensor = aten::hardtanh_(%input.147, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1355 : __torch__.torch.nn.modules.conv.___torch_mangle_43.Conv2d = prim::GetAttr[name="0"](%1322)
      %1356 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_41.BatchNorm2d = prim::GetAttr[name="1"](%1322)
      %1357 : Tensor = prim::GetAttr[name="weight"](%1355)
      %1358 : Tensor? = prim::GetAttr[name="bias"](%1355)
      %input.149 : Tensor = aten::conv2d(%input.148, %1357, %1358, %3236, %3236, %3236, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1363 : bool = prim::GetAttr[name="training"](%1356)
       = prim::If(%1363) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1364 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1356)
          %1365 : Tensor = aten::add(%1364, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1356, %1365)
          -> ()
        block1():
          -> ()
      %1366 : bool = prim::GetAttr[name="training"](%1356)
      %1367 : Tensor = prim::GetAttr[name="running_mean"](%1356)
      %1368 : Tensor = prim::GetAttr[name="running_var"](%1356)
      %1369 : Tensor = prim::GetAttr[name="weight"](%1356)
      %1370 : Tensor = prim::GetAttr[name="bias"](%1356)
       = prim::If(%1366) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1371 : int[] = aten::size(%input.149) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.192 : int = aten::__getitem__(%1371, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1373 : int = aten::len(%1371) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1374 : int = aten::sub(%1373, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.193 : int = prim::Loop(%1374, %13, %size_prods.192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.49 : int, %size_prods.194 : int):
              %1378 : int = aten::add(%i.49, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1379 : int = aten::__getitem__(%1371, %1378) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.195 : int = aten::mul(%size_prods.194, %1379) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.195)
          %1381 : bool = aten::eq(%size_prods.193, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1381) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1382 : str = aten::format(%14, %1371) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1382) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.150 : Tensor = aten::batch_norm(%input.149, %1369, %1370, %1367, %1368, %1366, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.151 : Tensor = aten::hardtanh_(%input.150, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1385 : Tensor = prim::GetAttr[name="weight"](%1323)
      %1386 : Tensor? = prim::GetAttr[name="bias"](%1323)
      %input.152 : Tensor = aten::conv2d(%input.151, %1385, %1386, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1391 : bool = prim::GetAttr[name="training"](%1324)
       = prim::If(%1391) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1392 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1324)
          %1393 : Tensor = aten::add(%1392, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1324, %1393)
          -> ()
        block1():
          -> ()
      %1394 : bool = prim::GetAttr[name="training"](%1324)
      %1395 : Tensor = prim::GetAttr[name="running_mean"](%1324)
      %1396 : Tensor = prim::GetAttr[name="running_var"](%1324)
      %1397 : Tensor = prim::GetAttr[name="weight"](%1324)
      %1398 : Tensor = prim::GetAttr[name="bias"](%1324)
       = prim::If(%1394) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1399 : int[] = aten::size(%input.152) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.196 : int = aten::__getitem__(%1399, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1401 : int = aten::len(%1399) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1402 : int = aten::sub(%1401, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.197 : int = prim::Loop(%1402, %13, %size_prods.196) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.50 : int, %size_prods.198 : int):
              %1406 : int = aten::add(%i.50, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1407 : int = aten::__getitem__(%1399, %1406) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.199 : int = aten::mul(%size_prods.198, %1407) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.199)
          %1409 : bool = aten::eq(%size_prods.197, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1409) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1410 : str = aten::format(%14, %1399) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1410) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.153 : Tensor = aten::batch_norm(%input.152, %1397, %1398, %1395, %1396, %1394, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1412 : Tensor = aten::add(%input.40, %input.153, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:99:19
      -> (%1412)
    block1():
      %1413 : __torch__.torch.nn.modules.container.___torch_mangle_46.Sequential = prim::GetAttr[name="conv"](%30)
      %1414 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_42.ConvBNActivation = prim::GetAttr[name="0"](%1413)
      %1415 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_44.ConvBNActivation = prim::GetAttr[name="1"](%1413)
      %1416 : __torch__.torch.nn.modules.conv.___torch_mangle_45.Conv2d = prim::GetAttr[name="2"](%1413)
      %1417 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_37.BatchNorm2d = prim::GetAttr[name="3"](%1413)
      %1418 : __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d = prim::GetAttr[name="0"](%1414)
      %1419 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_41.BatchNorm2d = prim::GetAttr[name="1"](%1414)
      %1420 : Tensor = prim::GetAttr[name="weight"](%1418)
      %1421 : Tensor? = prim::GetAttr[name="bias"](%1418)
      %input.154 : Tensor = aten::conv2d(%input.40, %1420, %1421, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1426 : bool = prim::GetAttr[name="training"](%1419)
       = prim::If(%1426) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1427 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1419)
          %1428 : Tensor = aten::add(%1427, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1419, %1428)
          -> ()
        block1():
          -> ()
      %1429 : bool = prim::GetAttr[name="training"](%1419)
      %1430 : Tensor = prim::GetAttr[name="running_mean"](%1419)
      %1431 : Tensor = prim::GetAttr[name="running_var"](%1419)
      %1432 : Tensor = prim::GetAttr[name="weight"](%1419)
      %1433 : Tensor = prim::GetAttr[name="bias"](%1419)
       = prim::If(%1429) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1434 : int[] = aten::size(%input.154) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.200 : int = aten::__getitem__(%1434, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1436 : int = aten::len(%1434) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1437 : int = aten::sub(%1436, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.201 : int = prim::Loop(%1437, %13, %size_prods.200) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.51 : int, %size_prods.202 : int):
              %1441 : int = aten::add(%i.51, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1442 : int = aten::__getitem__(%1434, %1441) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.203 : int = aten::mul(%size_prods.202, %1442) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.203)
          %1444 : bool = aten::eq(%size_prods.201, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1444) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1445 : str = aten::format(%14, %1434) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1445) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.155 : Tensor = aten::batch_norm(%input.154, %1432, %1433, %1430, %1431, %1429, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.156 : Tensor = aten::hardtanh_(%input.155, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1448 : __torch__.torch.nn.modules.conv.___torch_mangle_43.Conv2d = prim::GetAttr[name="0"](%1415)
      %1449 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_41.BatchNorm2d = prim::GetAttr[name="1"](%1415)
      %1450 : Tensor = prim::GetAttr[name="weight"](%1448)
      %1451 : Tensor? = prim::GetAttr[name="bias"](%1448)
      %input.157 : Tensor = aten::conv2d(%input.156, %1450, %1451, %3236, %3236, %3236, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1456 : bool = prim::GetAttr[name="training"](%1449)
       = prim::If(%1456) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1457 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1449)
          %1458 : Tensor = aten::add(%1457, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1449, %1458)
          -> ()
        block1():
          -> ()
      %1459 : bool = prim::GetAttr[name="training"](%1449)
      %1460 : Tensor = prim::GetAttr[name="running_mean"](%1449)
      %1461 : Tensor = prim::GetAttr[name="running_var"](%1449)
      %1462 : Tensor = prim::GetAttr[name="weight"](%1449)
      %1463 : Tensor = prim::GetAttr[name="bias"](%1449)
       = prim::If(%1459) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1464 : int[] = aten::size(%input.157) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.204 : int = aten::__getitem__(%1464, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1466 : int = aten::len(%1464) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1467 : int = aten::sub(%1466, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.205 : int = prim::Loop(%1467, %13, %size_prods.204) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.52 : int, %size_prods.206 : int):
              %1471 : int = aten::add(%i.52, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1472 : int = aten::__getitem__(%1464, %1471) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.207 : int = aten::mul(%size_prods.206, %1472) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.207)
          %1474 : bool = aten::eq(%size_prods.205, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1474) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1475 : str = aten::format(%14, %1464) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1475) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.158 : Tensor = aten::batch_norm(%input.157, %1462, %1463, %1460, %1461, %1459, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.159 : Tensor = aten::hardtanh_(%input.158, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1478 : Tensor = prim::GetAttr[name="weight"](%1416)
      %1479 : Tensor? = prim::GetAttr[name="bias"](%1416)
      %input.160 : Tensor = aten::conv2d(%input.159, %1478, %1479, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1484 : bool = prim::GetAttr[name="training"](%1417)
       = prim::If(%1484) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1485 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1417)
          %1486 : Tensor = aten::add(%1485, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1417, %1486)
          -> ()
        block1():
          -> ()
      %1487 : bool = prim::GetAttr[name="training"](%1417)
      %1488 : Tensor = prim::GetAttr[name="running_mean"](%1417)
      %1489 : Tensor = prim::GetAttr[name="running_var"](%1417)
      %1490 : Tensor = prim::GetAttr[name="weight"](%1417)
      %1491 : Tensor = prim::GetAttr[name="bias"](%1417)
       = prim::If(%1487) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1492 : int[] = aten::size(%input.160) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.208 : int = aten::__getitem__(%1492, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1494 : int = aten::len(%1492) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1495 : int = aten::sub(%1494, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.209 : int = prim::Loop(%1495, %13, %size_prods.208) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.53 : int, %size_prods.210 : int):
              %1499 : int = aten::add(%i.53, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1500 : int = aten::__getitem__(%1492, %1499) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.211 : int = aten::mul(%size_prods.210, %1500) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.211)
          %1502 : bool = aten::eq(%size_prods.209, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1502) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1503 : str = aten::format(%14, %1492) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1503) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.161 : Tensor = aten::batch_norm(%input.160, %1490, %1491, %1488, %1489, %1487, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.161)
  %1505 : bool = prim::GetAttr[name="use_res_connect"](%31)
  %input.21 : Tensor = prim::If(%1505) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:98:8
    block0():
      %1507 : __torch__.torch.nn.modules.container.___torch_mangle_46.Sequential = prim::GetAttr[name="conv"](%31)
      %1508 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_42.ConvBNActivation = prim::GetAttr[name="0"](%1507)
      %1509 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_44.ConvBNActivation = prim::GetAttr[name="1"](%1507)
      %1510 : __torch__.torch.nn.modules.conv.___torch_mangle_45.Conv2d = prim::GetAttr[name="2"](%1507)
      %1511 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_37.BatchNorm2d = prim::GetAttr[name="3"](%1507)
      %1512 : __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d = prim::GetAttr[name="0"](%1508)
      %1513 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_41.BatchNorm2d = prim::GetAttr[name="1"](%1508)
      %1514 : Tensor = prim::GetAttr[name="weight"](%1512)
      %1515 : Tensor? = prim::GetAttr[name="bias"](%1512)
      %input.162 : Tensor = aten::conv2d(%input.19, %1514, %1515, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1520 : bool = prim::GetAttr[name="training"](%1513)
       = prim::If(%1520) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1521 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1513)
          %1522 : Tensor = aten::add(%1521, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1513, %1522)
          -> ()
        block1():
          -> ()
      %1523 : bool = prim::GetAttr[name="training"](%1513)
      %1524 : Tensor = prim::GetAttr[name="running_mean"](%1513)
      %1525 : Tensor = prim::GetAttr[name="running_var"](%1513)
      %1526 : Tensor = prim::GetAttr[name="weight"](%1513)
      %1527 : Tensor = prim::GetAttr[name="bias"](%1513)
       = prim::If(%1523) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1528 : int[] = aten::size(%input.162) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.212 : int = aten::__getitem__(%1528, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1530 : int = aten::len(%1528) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1531 : int = aten::sub(%1530, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.213 : int = prim::Loop(%1531, %13, %size_prods.212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.54 : int, %size_prods.214 : int):
              %1535 : int = aten::add(%i.54, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1536 : int = aten::__getitem__(%1528, %1535) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.215 : int = aten::mul(%size_prods.214, %1536) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.215)
          %1538 : bool = aten::eq(%size_prods.213, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1538) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1539 : str = aten::format(%14, %1528) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1539) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.163 : Tensor = aten::batch_norm(%input.162, %1526, %1527, %1524, %1525, %1523, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.164 : Tensor = aten::hardtanh_(%input.163, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1542 : __torch__.torch.nn.modules.conv.___torch_mangle_43.Conv2d = prim::GetAttr[name="0"](%1509)
      %1543 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_41.BatchNorm2d = prim::GetAttr[name="1"](%1509)
      %1544 : Tensor = prim::GetAttr[name="weight"](%1542)
      %1545 : Tensor? = prim::GetAttr[name="bias"](%1542)
      %input.165 : Tensor = aten::conv2d(%input.164, %1544, %1545, %3236, %3236, %3236, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1550 : bool = prim::GetAttr[name="training"](%1543)
       = prim::If(%1550) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1551 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1543)
          %1552 : Tensor = aten::add(%1551, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1543, %1552)
          -> ()
        block1():
          -> ()
      %1553 : bool = prim::GetAttr[name="training"](%1543)
      %1554 : Tensor = prim::GetAttr[name="running_mean"](%1543)
      %1555 : Tensor = prim::GetAttr[name="running_var"](%1543)
      %1556 : Tensor = prim::GetAttr[name="weight"](%1543)
      %1557 : Tensor = prim::GetAttr[name="bias"](%1543)
       = prim::If(%1553) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1558 : int[] = aten::size(%input.165) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.216 : int = aten::__getitem__(%1558, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1560 : int = aten::len(%1558) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1561 : int = aten::sub(%1560, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.217 : int = prim::Loop(%1561, %13, %size_prods.216) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.55 : int, %size_prods.218 : int):
              %1565 : int = aten::add(%i.55, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1566 : int = aten::__getitem__(%1558, %1565) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.219 : int = aten::mul(%size_prods.218, %1566) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.219)
          %1568 : bool = aten::eq(%size_prods.217, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1568) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1569 : str = aten::format(%14, %1558) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1569) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.166 : Tensor = aten::batch_norm(%input.165, %1556, %1557, %1554, %1555, %1553, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.167 : Tensor = aten::hardtanh_(%input.166, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1572 : Tensor = prim::GetAttr[name="weight"](%1510)
      %1573 : Tensor? = prim::GetAttr[name="bias"](%1510)
      %input.168 : Tensor = aten::conv2d(%input.167, %1572, %1573, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1578 : bool = prim::GetAttr[name="training"](%1511)
       = prim::If(%1578) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1579 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1511)
          %1580 : Tensor = aten::add(%1579, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1511, %1580)
          -> ()
        block1():
          -> ()
      %1581 : bool = prim::GetAttr[name="training"](%1511)
      %1582 : Tensor = prim::GetAttr[name="running_mean"](%1511)
      %1583 : Tensor = prim::GetAttr[name="running_var"](%1511)
      %1584 : Tensor = prim::GetAttr[name="weight"](%1511)
      %1585 : Tensor = prim::GetAttr[name="bias"](%1511)
       = prim::If(%1581) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1586 : int[] = aten::size(%input.168) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.220 : int = aten::__getitem__(%1586, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1588 : int = aten::len(%1586) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1589 : int = aten::sub(%1588, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.221 : int = prim::Loop(%1589, %13, %size_prods.220) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.56 : int, %size_prods.222 : int):
              %1593 : int = aten::add(%i.56, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1594 : int = aten::__getitem__(%1586, %1593) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.223 : int = aten::mul(%size_prods.222, %1594) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.223)
          %1596 : bool = aten::eq(%size_prods.221, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1596) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1597 : str = aten::format(%14, %1586) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1597) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.169 : Tensor = aten::batch_norm(%input.168, %1584, %1585, %1582, %1583, %1581, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1599 : Tensor = aten::add(%input.19, %input.169, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:99:19
      -> (%1599)
    block1():
      %1600 : __torch__.torch.nn.modules.container.___torch_mangle_46.Sequential = prim::GetAttr[name="conv"](%31)
      %1601 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_42.ConvBNActivation = prim::GetAttr[name="0"](%1600)
      %1602 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_44.ConvBNActivation = prim::GetAttr[name="1"](%1600)
      %1603 : __torch__.torch.nn.modules.conv.___torch_mangle_45.Conv2d = prim::GetAttr[name="2"](%1600)
      %1604 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_37.BatchNorm2d = prim::GetAttr[name="3"](%1600)
      %1605 : __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d = prim::GetAttr[name="0"](%1601)
      %1606 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_41.BatchNorm2d = prim::GetAttr[name="1"](%1601)
      %1607 : Tensor = prim::GetAttr[name="weight"](%1605)
      %1608 : Tensor? = prim::GetAttr[name="bias"](%1605)
      %input.170 : Tensor = aten::conv2d(%input.19, %1607, %1608, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1613 : bool = prim::GetAttr[name="training"](%1606)
       = prim::If(%1613) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1614 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1606)
          %1615 : Tensor = aten::add(%1614, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1606, %1615)
          -> ()
        block1():
          -> ()
      %1616 : bool = prim::GetAttr[name="training"](%1606)
      %1617 : Tensor = prim::GetAttr[name="running_mean"](%1606)
      %1618 : Tensor = prim::GetAttr[name="running_var"](%1606)
      %1619 : Tensor = prim::GetAttr[name="weight"](%1606)
      %1620 : Tensor = prim::GetAttr[name="bias"](%1606)
       = prim::If(%1616) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1621 : int[] = aten::size(%input.170) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.224 : int = aten::__getitem__(%1621, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1623 : int = aten::len(%1621) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1624 : int = aten::sub(%1623, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.225 : int = prim::Loop(%1624, %13, %size_prods.224) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.57 : int, %size_prods.226 : int):
              %1628 : int = aten::add(%i.57, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1629 : int = aten::__getitem__(%1621, %1628) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.227 : int = aten::mul(%size_prods.226, %1629) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.227)
          %1631 : bool = aten::eq(%size_prods.225, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1631) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1632 : str = aten::format(%14, %1621) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1632) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.171 : Tensor = aten::batch_norm(%input.170, %1619, %1620, %1617, %1618, %1616, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.172 : Tensor = aten::hardtanh_(%input.171, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1635 : __torch__.torch.nn.modules.conv.___torch_mangle_43.Conv2d = prim::GetAttr[name="0"](%1602)
      %1636 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_41.BatchNorm2d = prim::GetAttr[name="1"](%1602)
      %1637 : Tensor = prim::GetAttr[name="weight"](%1635)
      %1638 : Tensor? = prim::GetAttr[name="bias"](%1635)
      %input.173 : Tensor = aten::conv2d(%input.172, %1637, %1638, %3236, %3236, %3236, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1643 : bool = prim::GetAttr[name="training"](%1636)
       = prim::If(%1643) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1644 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1636)
          %1645 : Tensor = aten::add(%1644, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1636, %1645)
          -> ()
        block1():
          -> ()
      %1646 : bool = prim::GetAttr[name="training"](%1636)
      %1647 : Tensor = prim::GetAttr[name="running_mean"](%1636)
      %1648 : Tensor = prim::GetAttr[name="running_var"](%1636)
      %1649 : Tensor = prim::GetAttr[name="weight"](%1636)
      %1650 : Tensor = prim::GetAttr[name="bias"](%1636)
       = prim::If(%1646) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1651 : int[] = aten::size(%input.173) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.228 : int = aten::__getitem__(%1651, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1653 : int = aten::len(%1651) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1654 : int = aten::sub(%1653, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.229 : int = prim::Loop(%1654, %13, %size_prods.228) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.58 : int, %size_prods.230 : int):
              %1658 : int = aten::add(%i.58, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1659 : int = aten::__getitem__(%1651, %1658) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.231 : int = aten::mul(%size_prods.230, %1659) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.231)
          %1661 : bool = aten::eq(%size_prods.229, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1661) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1662 : str = aten::format(%14, %1651) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1662) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.174 : Tensor = aten::batch_norm(%input.173, %1649, %1650, %1647, %1648, %1646, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.175 : Tensor = aten::hardtanh_(%input.174, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1665 : Tensor = prim::GetAttr[name="weight"](%1603)
      %1666 : Tensor? = prim::GetAttr[name="bias"](%1603)
      %input.176 : Tensor = aten::conv2d(%input.175, %1665, %1666, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1671 : bool = prim::GetAttr[name="training"](%1604)
       = prim::If(%1671) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1672 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1604)
          %1673 : Tensor = aten::add(%1672, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1604, %1673)
          -> ()
        block1():
          -> ()
      %1674 : bool = prim::GetAttr[name="training"](%1604)
      %1675 : Tensor = prim::GetAttr[name="running_mean"](%1604)
      %1676 : Tensor = prim::GetAttr[name="running_var"](%1604)
      %1677 : Tensor = prim::GetAttr[name="weight"](%1604)
      %1678 : Tensor = prim::GetAttr[name="bias"](%1604)
       = prim::If(%1674) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1679 : int[] = aten::size(%input.176) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.232 : int = aten::__getitem__(%1679, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1681 : int = aten::len(%1679) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1682 : int = aten::sub(%1681, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.233 : int = prim::Loop(%1682, %13, %size_prods.232) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.59 : int, %size_prods.234 : int):
              %1686 : int = aten::add(%i.59, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1687 : int = aten::__getitem__(%1679, %1686) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.235 : int = aten::mul(%size_prods.234, %1687) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.235)
          %1689 : bool = aten::eq(%size_prods.233, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1689) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1690 : str = aten::format(%14, %1679) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1690) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.177 : Tensor = aten::batch_norm(%input.176, %1677, %1678, %1675, %1676, %1674, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.177)
  %1692 : bool = prim::GetAttr[name="use_res_connect"](%32)
  %input.23 : Tensor = prim::If(%1692) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:98:8
    block0():
      %1694 : __torch__.torch.nn.modules.container.___torch_mangle_46.Sequential = prim::GetAttr[name="conv"](%32)
      %1695 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_42.ConvBNActivation = prim::GetAttr[name="0"](%1694)
      %1696 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_44.ConvBNActivation = prim::GetAttr[name="1"](%1694)
      %1697 : __torch__.torch.nn.modules.conv.___torch_mangle_45.Conv2d = prim::GetAttr[name="2"](%1694)
      %1698 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_37.BatchNorm2d = prim::GetAttr[name="3"](%1694)
      %1699 : __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d = prim::GetAttr[name="0"](%1695)
      %1700 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_41.BatchNorm2d = prim::GetAttr[name="1"](%1695)
      %1701 : Tensor = prim::GetAttr[name="weight"](%1699)
      %1702 : Tensor? = prim::GetAttr[name="bias"](%1699)
      %input.178 : Tensor = aten::conv2d(%input.21, %1701, %1702, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1707 : bool = prim::GetAttr[name="training"](%1700)
       = prim::If(%1707) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1708 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1700)
          %1709 : Tensor = aten::add(%1708, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1700, %1709)
          -> ()
        block1():
          -> ()
      %1710 : bool = prim::GetAttr[name="training"](%1700)
      %1711 : Tensor = prim::GetAttr[name="running_mean"](%1700)
      %1712 : Tensor = prim::GetAttr[name="running_var"](%1700)
      %1713 : Tensor = prim::GetAttr[name="weight"](%1700)
      %1714 : Tensor = prim::GetAttr[name="bias"](%1700)
       = prim::If(%1710) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1715 : int[] = aten::size(%input.178) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.236 : int = aten::__getitem__(%1715, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1717 : int = aten::len(%1715) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1718 : int = aten::sub(%1717, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.237 : int = prim::Loop(%1718, %13, %size_prods.236) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.60 : int, %size_prods.238 : int):
              %1722 : int = aten::add(%i.60, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1723 : int = aten::__getitem__(%1715, %1722) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.239 : int = aten::mul(%size_prods.238, %1723) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.239)
          %1725 : bool = aten::eq(%size_prods.237, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1725) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1726 : str = aten::format(%14, %1715) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1726) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.179 : Tensor = aten::batch_norm(%input.178, %1713, %1714, %1711, %1712, %1710, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.180 : Tensor = aten::hardtanh_(%input.179, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1729 : __torch__.torch.nn.modules.conv.___torch_mangle_43.Conv2d = prim::GetAttr[name="0"](%1696)
      %1730 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_41.BatchNorm2d = prim::GetAttr[name="1"](%1696)
      %1731 : Tensor = prim::GetAttr[name="weight"](%1729)
      %1732 : Tensor? = prim::GetAttr[name="bias"](%1729)
      %input.181 : Tensor = aten::conv2d(%input.180, %1731, %1732, %3236, %3236, %3236, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1737 : bool = prim::GetAttr[name="training"](%1730)
       = prim::If(%1737) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1738 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1730)
          %1739 : Tensor = aten::add(%1738, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1730, %1739)
          -> ()
        block1():
          -> ()
      %1740 : bool = prim::GetAttr[name="training"](%1730)
      %1741 : Tensor = prim::GetAttr[name="running_mean"](%1730)
      %1742 : Tensor = prim::GetAttr[name="running_var"](%1730)
      %1743 : Tensor = prim::GetAttr[name="weight"](%1730)
      %1744 : Tensor = prim::GetAttr[name="bias"](%1730)
       = prim::If(%1740) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1745 : int[] = aten::size(%input.181) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.240 : int = aten::__getitem__(%1745, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1747 : int = aten::len(%1745) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1748 : int = aten::sub(%1747, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.241 : int = prim::Loop(%1748, %13, %size_prods.240) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.61 : int, %size_prods.242 : int):
              %1752 : int = aten::add(%i.61, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1753 : int = aten::__getitem__(%1745, %1752) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.243 : int = aten::mul(%size_prods.242, %1753) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.243)
          %1755 : bool = aten::eq(%size_prods.241, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1755) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1756 : str = aten::format(%14, %1745) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1756) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.182 : Tensor = aten::batch_norm(%input.181, %1743, %1744, %1741, %1742, %1740, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.183 : Tensor = aten::hardtanh_(%input.182, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1759 : Tensor = prim::GetAttr[name="weight"](%1697)
      %1760 : Tensor? = prim::GetAttr[name="bias"](%1697)
      %input.184 : Tensor = aten::conv2d(%input.183, %1759, %1760, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1765 : bool = prim::GetAttr[name="training"](%1698)
       = prim::If(%1765) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1766 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1698)
          %1767 : Tensor = aten::add(%1766, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1698, %1767)
          -> ()
        block1():
          -> ()
      %1768 : bool = prim::GetAttr[name="training"](%1698)
      %1769 : Tensor = prim::GetAttr[name="running_mean"](%1698)
      %1770 : Tensor = prim::GetAttr[name="running_var"](%1698)
      %1771 : Tensor = prim::GetAttr[name="weight"](%1698)
      %1772 : Tensor = prim::GetAttr[name="bias"](%1698)
       = prim::If(%1768) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1773 : int[] = aten::size(%input.184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.244 : int = aten::__getitem__(%1773, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1775 : int = aten::len(%1773) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1776 : int = aten::sub(%1775, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.245 : int = prim::Loop(%1776, %13, %size_prods.244) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.62 : int, %size_prods.246 : int):
              %1780 : int = aten::add(%i.62, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1781 : int = aten::__getitem__(%1773, %1780) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.247 : int = aten::mul(%size_prods.246, %1781) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.247)
          %1783 : bool = aten::eq(%size_prods.245, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1783) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1784 : str = aten::format(%14, %1773) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1784) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.185 : Tensor = aten::batch_norm(%input.184, %1771, %1772, %1769, %1770, %1768, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1786 : Tensor = aten::add(%input.21, %input.185, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:99:19
      -> (%1786)
    block1():
      %1787 : __torch__.torch.nn.modules.container.___torch_mangle_46.Sequential = prim::GetAttr[name="conv"](%32)
      %1788 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_42.ConvBNActivation = prim::GetAttr[name="0"](%1787)
      %1789 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_44.ConvBNActivation = prim::GetAttr[name="1"](%1787)
      %1790 : __torch__.torch.nn.modules.conv.___torch_mangle_45.Conv2d = prim::GetAttr[name="2"](%1787)
      %1791 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_37.BatchNorm2d = prim::GetAttr[name="3"](%1787)
      %1792 : __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d = prim::GetAttr[name="0"](%1788)
      %1793 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_41.BatchNorm2d = prim::GetAttr[name="1"](%1788)
      %1794 : Tensor = prim::GetAttr[name="weight"](%1792)
      %1795 : Tensor? = prim::GetAttr[name="bias"](%1792)
      %input.186 : Tensor = aten::conv2d(%input.21, %1794, %1795, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1800 : bool = prim::GetAttr[name="training"](%1793)
       = prim::If(%1800) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1801 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1793)
          %1802 : Tensor = aten::add(%1801, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1793, %1802)
          -> ()
        block1():
          -> ()
      %1803 : bool = prim::GetAttr[name="training"](%1793)
      %1804 : Tensor = prim::GetAttr[name="running_mean"](%1793)
      %1805 : Tensor = prim::GetAttr[name="running_var"](%1793)
      %1806 : Tensor = prim::GetAttr[name="weight"](%1793)
      %1807 : Tensor = prim::GetAttr[name="bias"](%1793)
       = prim::If(%1803) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1808 : int[] = aten::size(%input.186) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.248 : int = aten::__getitem__(%1808, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1810 : int = aten::len(%1808) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1811 : int = aten::sub(%1810, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.249 : int = prim::Loop(%1811, %13, %size_prods.248) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.63 : int, %size_prods.250 : int):
              %1815 : int = aten::add(%i.63, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1816 : int = aten::__getitem__(%1808, %1815) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.251 : int = aten::mul(%size_prods.250, %1816) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.251)
          %1818 : bool = aten::eq(%size_prods.249, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1818) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1819 : str = aten::format(%14, %1808) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1819) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.187 : Tensor = aten::batch_norm(%input.186, %1806, %1807, %1804, %1805, %1803, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.188 : Tensor = aten::hardtanh_(%input.187, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1822 : __torch__.torch.nn.modules.conv.___torch_mangle_43.Conv2d = prim::GetAttr[name="0"](%1789)
      %1823 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_41.BatchNorm2d = prim::GetAttr[name="1"](%1789)
      %1824 : Tensor = prim::GetAttr[name="weight"](%1822)
      %1825 : Tensor? = prim::GetAttr[name="bias"](%1822)
      %input.189 : Tensor = aten::conv2d(%input.188, %1824, %1825, %3236, %3236, %3236, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1830 : bool = prim::GetAttr[name="training"](%1823)
       = prim::If(%1830) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1831 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1823)
          %1832 : Tensor = aten::add(%1831, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1823, %1832)
          -> ()
        block1():
          -> ()
      %1833 : bool = prim::GetAttr[name="training"](%1823)
      %1834 : Tensor = prim::GetAttr[name="running_mean"](%1823)
      %1835 : Tensor = prim::GetAttr[name="running_var"](%1823)
      %1836 : Tensor = prim::GetAttr[name="weight"](%1823)
      %1837 : Tensor = prim::GetAttr[name="bias"](%1823)
       = prim::If(%1833) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1838 : int[] = aten::size(%input.189) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.252 : int = aten::__getitem__(%1838, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1840 : int = aten::len(%1838) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1841 : int = aten::sub(%1840, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.253 : int = prim::Loop(%1841, %13, %size_prods.252) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.64 : int, %size_prods.254 : int):
              %1845 : int = aten::add(%i.64, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1846 : int = aten::__getitem__(%1838, %1845) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.255 : int = aten::mul(%size_prods.254, %1846) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.255)
          %1848 : bool = aten::eq(%size_prods.253, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1848) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1849 : str = aten::format(%14, %1838) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1849) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.190 : Tensor = aten::batch_norm(%input.189, %1836, %1837, %1834, %1835, %1833, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.191 : Tensor = aten::hardtanh_(%input.190, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1852 : Tensor = prim::GetAttr[name="weight"](%1790)
      %1853 : Tensor? = prim::GetAttr[name="bias"](%1790)
      %input.192 : Tensor = aten::conv2d(%input.191, %1852, %1853, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1858 : bool = prim::GetAttr[name="training"](%1791)
       = prim::If(%1858) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1859 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1791)
          %1860 : Tensor = aten::add(%1859, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1791, %1860)
          -> ()
        block1():
          -> ()
      %1861 : bool = prim::GetAttr[name="training"](%1791)
      %1862 : Tensor = prim::GetAttr[name="running_mean"](%1791)
      %1863 : Tensor = prim::GetAttr[name="running_var"](%1791)
      %1864 : Tensor = prim::GetAttr[name="weight"](%1791)
      %1865 : Tensor = prim::GetAttr[name="bias"](%1791)
       = prim::If(%1861) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1866 : int[] = aten::size(%input.192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.256 : int = aten::__getitem__(%1866, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1868 : int = aten::len(%1866) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1869 : int = aten::sub(%1868, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.257 : int = prim::Loop(%1869, %13, %size_prods.256) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.65 : int, %size_prods.258 : int):
              %1873 : int = aten::add(%i.65, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1874 : int = aten::__getitem__(%1866, %1873) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.259 : int = aten::mul(%size_prods.258, %1874) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.259)
          %1876 : bool = aten::eq(%size_prods.257, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1876) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1877 : str = aten::format(%14, %1866) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1877) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.193 : Tensor = aten::batch_norm(%input.192, %1864, %1865, %1862, %1863, %1861, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.193)
  %1879 : bool = prim::GetAttr[name="use_res_connect"](%33)
  %input.25 : Tensor = prim::If(%1879) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:98:8
    block0():
      %1881 : __torch__.torch.nn.modules.container.___torch_mangle_49.Sequential = prim::GetAttr[name="conv"](%33)
      %1882 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_42.ConvBNActivation = prim::GetAttr[name="0"](%1881)
      %1883 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_44.ConvBNActivation = prim::GetAttr[name="1"](%1881)
      %1884 : __torch__.torch.nn.modules.conv.___torch_mangle_48.Conv2d = prim::GetAttr[name="2"](%1881)
      %1885 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_5.BatchNorm2d = prim::GetAttr[name="3"](%1881)
      %1886 : __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d = prim::GetAttr[name="0"](%1882)
      %1887 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_41.BatchNorm2d = prim::GetAttr[name="1"](%1882)
      %1888 : Tensor = prim::GetAttr[name="weight"](%1886)
      %1889 : Tensor? = prim::GetAttr[name="bias"](%1886)
      %input.194 : Tensor = aten::conv2d(%input.23, %1888, %1889, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1894 : bool = prim::GetAttr[name="training"](%1887)
       = prim::If(%1894) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1895 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1887)
          %1896 : Tensor = aten::add(%1895, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1887, %1896)
          -> ()
        block1():
          -> ()
      %1897 : bool = prim::GetAttr[name="training"](%1887)
      %1898 : Tensor = prim::GetAttr[name="running_mean"](%1887)
      %1899 : Tensor = prim::GetAttr[name="running_var"](%1887)
      %1900 : Tensor = prim::GetAttr[name="weight"](%1887)
      %1901 : Tensor = prim::GetAttr[name="bias"](%1887)
       = prim::If(%1897) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1902 : int[] = aten::size(%input.194) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.260 : int = aten::__getitem__(%1902, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1904 : int = aten::len(%1902) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1905 : int = aten::sub(%1904, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.261 : int = prim::Loop(%1905, %13, %size_prods.260) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.66 : int, %size_prods.262 : int):
              %1909 : int = aten::add(%i.66, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1910 : int = aten::__getitem__(%1902, %1909) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.263 : int = aten::mul(%size_prods.262, %1910) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.263)
          %1912 : bool = aten::eq(%size_prods.261, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1912) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1913 : str = aten::format(%14, %1902) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1913) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.195 : Tensor = aten::batch_norm(%input.194, %1900, %1901, %1898, %1899, %1897, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.196 : Tensor = aten::hardtanh_(%input.195, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1916 : __torch__.torch.nn.modules.conv.___torch_mangle_43.Conv2d = prim::GetAttr[name="0"](%1883)
      %1917 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_41.BatchNorm2d = prim::GetAttr[name="1"](%1883)
      %1918 : Tensor = prim::GetAttr[name="weight"](%1916)
      %1919 : Tensor? = prim::GetAttr[name="bias"](%1916)
      %input.197 : Tensor = aten::conv2d(%input.196, %1918, %1919, %3236, %3236, %3236, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1924 : bool = prim::GetAttr[name="training"](%1917)
       = prim::If(%1924) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1925 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1917)
          %1926 : Tensor = aten::add(%1925, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1917, %1926)
          -> ()
        block1():
          -> ()
      %1927 : bool = prim::GetAttr[name="training"](%1917)
      %1928 : Tensor = prim::GetAttr[name="running_mean"](%1917)
      %1929 : Tensor = prim::GetAttr[name="running_var"](%1917)
      %1930 : Tensor = prim::GetAttr[name="weight"](%1917)
      %1931 : Tensor = prim::GetAttr[name="bias"](%1917)
       = prim::If(%1927) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1932 : int[] = aten::size(%input.197) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.264 : int = aten::__getitem__(%1932, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1934 : int = aten::len(%1932) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1935 : int = aten::sub(%1934, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.265 : int = prim::Loop(%1935, %13, %size_prods.264) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.67 : int, %size_prods.266 : int):
              %1939 : int = aten::add(%i.67, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1940 : int = aten::__getitem__(%1932, %1939) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.267 : int = aten::mul(%size_prods.266, %1940) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.267)
          %1942 : bool = aten::eq(%size_prods.265, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1942) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1943 : str = aten::format(%14, %1932) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1943) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.198 : Tensor = aten::batch_norm(%input.197, %1930, %1931, %1928, %1929, %1927, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.199 : Tensor = aten::hardtanh_(%input.198, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %1946 : Tensor = prim::GetAttr[name="weight"](%1884)
      %1947 : Tensor? = prim::GetAttr[name="bias"](%1884)
      %input.200 : Tensor = aten::conv2d(%input.199, %1946, %1947, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1952 : bool = prim::GetAttr[name="training"](%1885)
       = prim::If(%1952) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1953 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1885)
          %1954 : Tensor = aten::add(%1953, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1885, %1954)
          -> ()
        block1():
          -> ()
      %1955 : bool = prim::GetAttr[name="training"](%1885)
      %1956 : Tensor = prim::GetAttr[name="running_mean"](%1885)
      %1957 : Tensor = prim::GetAttr[name="running_var"](%1885)
      %1958 : Tensor = prim::GetAttr[name="weight"](%1885)
      %1959 : Tensor = prim::GetAttr[name="bias"](%1885)
       = prim::If(%1955) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1960 : int[] = aten::size(%input.200) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.268 : int = aten::__getitem__(%1960, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1962 : int = aten::len(%1960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1963 : int = aten::sub(%1962, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.269 : int = prim::Loop(%1963, %13, %size_prods.268) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.68 : int, %size_prods.270 : int):
              %1967 : int = aten::add(%i.68, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1968 : int = aten::__getitem__(%1960, %1967) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.271 : int = aten::mul(%size_prods.270, %1968) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.271)
          %1970 : bool = aten::eq(%size_prods.269, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1970) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1971 : str = aten::format(%14, %1960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1971) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.201 : Tensor = aten::batch_norm(%input.200, %1958, %1959, %1956, %1957, %1955, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1973 : Tensor = aten::add(%input.23, %input.201, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:99:19
      -> (%1973)
    block1():
      %1974 : __torch__.torch.nn.modules.container.___torch_mangle_49.Sequential = prim::GetAttr[name="conv"](%33)
      %1975 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_42.ConvBNActivation = prim::GetAttr[name="0"](%1974)
      %1976 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_44.ConvBNActivation = prim::GetAttr[name="1"](%1974)
      %1977 : __torch__.torch.nn.modules.conv.___torch_mangle_48.Conv2d = prim::GetAttr[name="2"](%1974)
      %1978 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_5.BatchNorm2d = prim::GetAttr[name="3"](%1974)
      %1979 : __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d = prim::GetAttr[name="0"](%1975)
      %1980 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_41.BatchNorm2d = prim::GetAttr[name="1"](%1975)
      %1981 : Tensor = prim::GetAttr[name="weight"](%1979)
      %1982 : Tensor? = prim::GetAttr[name="bias"](%1979)
      %input.202 : Tensor = aten::conv2d(%input.23, %1981, %1982, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1987 : bool = prim::GetAttr[name="training"](%1980)
       = prim::If(%1987) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1988 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1980)
          %1989 : Tensor = aten::add(%1988, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1980, %1989)
          -> ()
        block1():
          -> ()
      %1990 : bool = prim::GetAttr[name="training"](%1980)
      %1991 : Tensor = prim::GetAttr[name="running_mean"](%1980)
      %1992 : Tensor = prim::GetAttr[name="running_var"](%1980)
      %1993 : Tensor = prim::GetAttr[name="weight"](%1980)
      %1994 : Tensor = prim::GetAttr[name="bias"](%1980)
       = prim::If(%1990) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1995 : int[] = aten::size(%input.202) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.272 : int = aten::__getitem__(%1995, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1997 : int = aten::len(%1995) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1998 : int = aten::sub(%1997, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.273 : int = prim::Loop(%1998, %13, %size_prods.272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.69 : int, %size_prods.274 : int):
              %2002 : int = aten::add(%i.69, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2003 : int = aten::__getitem__(%1995, %2002) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.275 : int = aten::mul(%size_prods.274, %2003) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.275)
          %2005 : bool = aten::eq(%size_prods.273, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2005) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2006 : str = aten::format(%14, %1995) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2006) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.203 : Tensor = aten::batch_norm(%input.202, %1993, %1994, %1991, %1992, %1990, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.204 : Tensor = aten::hardtanh_(%input.203, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2009 : __torch__.torch.nn.modules.conv.___torch_mangle_43.Conv2d = prim::GetAttr[name="0"](%1976)
      %2010 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_41.BatchNorm2d = prim::GetAttr[name="1"](%1976)
      %2011 : Tensor = prim::GetAttr[name="weight"](%2009)
      %2012 : Tensor? = prim::GetAttr[name="bias"](%2009)
      %input.205 : Tensor = aten::conv2d(%input.204, %2011, %2012, %3236, %3236, %3236, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2017 : bool = prim::GetAttr[name="training"](%2010)
       = prim::If(%2017) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2018 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2010)
          %2019 : Tensor = aten::add(%2018, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2010, %2019)
          -> ()
        block1():
          -> ()
      %2020 : bool = prim::GetAttr[name="training"](%2010)
      %2021 : Tensor = prim::GetAttr[name="running_mean"](%2010)
      %2022 : Tensor = prim::GetAttr[name="running_var"](%2010)
      %2023 : Tensor = prim::GetAttr[name="weight"](%2010)
      %2024 : Tensor = prim::GetAttr[name="bias"](%2010)
       = prim::If(%2020) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2025 : int[] = aten::size(%input.205) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.276 : int = aten::__getitem__(%2025, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2027 : int = aten::len(%2025) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2028 : int = aten::sub(%2027, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.277 : int = prim::Loop(%2028, %13, %size_prods.276) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.70 : int, %size_prods.278 : int):
              %2032 : int = aten::add(%i.70, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2033 : int = aten::__getitem__(%2025, %2032) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.279 : int = aten::mul(%size_prods.278, %2033) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.279)
          %2035 : bool = aten::eq(%size_prods.277, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2035) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2036 : str = aten::format(%14, %2025) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2036) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.206 : Tensor = aten::batch_norm(%input.205, %2023, %2024, %2021, %2022, %2020, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.207 : Tensor = aten::hardtanh_(%input.206, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2039 : Tensor = prim::GetAttr[name="weight"](%1977)
      %2040 : Tensor? = prim::GetAttr[name="bias"](%1977)
      %input.208 : Tensor = aten::conv2d(%input.207, %2039, %2040, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2045 : bool = prim::GetAttr[name="training"](%1978)
       = prim::If(%2045) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2046 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1978)
          %2047 : Tensor = aten::add(%2046, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1978, %2047)
          -> ()
        block1():
          -> ()
      %2048 : bool = prim::GetAttr[name="training"](%1978)
      %2049 : Tensor = prim::GetAttr[name="running_mean"](%1978)
      %2050 : Tensor = prim::GetAttr[name="running_var"](%1978)
      %2051 : Tensor = prim::GetAttr[name="weight"](%1978)
      %2052 : Tensor = prim::GetAttr[name="bias"](%1978)
       = prim::If(%2048) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2053 : int[] = aten::size(%input.208) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.280 : int = aten::__getitem__(%2053, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2055 : int = aten::len(%2053) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2056 : int = aten::sub(%2055, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.281 : int = prim::Loop(%2056, %13, %size_prods.280) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.71 : int, %size_prods.282 : int):
              %2060 : int = aten::add(%i.71, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2061 : int = aten::__getitem__(%2053, %2060) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.283 : int = aten::mul(%size_prods.282, %2061) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.283)
          %2063 : bool = aten::eq(%size_prods.281, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2063) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2064 : str = aten::format(%14, %2053) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2064) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.209 : Tensor = aten::batch_norm(%input.208, %2051, %2052, %2049, %2050, %2048, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.209)
  %2066 : bool = prim::GetAttr[name="use_res_connect"](%34)
  %input.27 : Tensor = prim::If(%2066) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:98:8
    block0():
      %2068 : __torch__.torch.nn.modules.container.___torch_mangle_57.Sequential = prim::GetAttr[name="conv"](%34)
      %2069 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_53.ConvBNActivation = prim::GetAttr[name="0"](%2068)
      %2070 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_55.ConvBNActivation = prim::GetAttr[name="1"](%2068)
      %2071 : __torch__.torch.nn.modules.conv.___torch_mangle_56.Conv2d = prim::GetAttr[name="2"](%2068)
      %2072 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_5.BatchNorm2d = prim::GetAttr[name="3"](%2068)
      %2073 : __torch__.torch.nn.modules.conv.___torch_mangle_51.Conv2d = prim::GetAttr[name="0"](%2069)
      %2074 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_52.BatchNorm2d = prim::GetAttr[name="1"](%2069)
      %2075 : Tensor = prim::GetAttr[name="weight"](%2073)
      %2076 : Tensor? = prim::GetAttr[name="bias"](%2073)
      %input.210 : Tensor = aten::conv2d(%input.25, %2075, %2076, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2081 : bool = prim::GetAttr[name="training"](%2074)
       = prim::If(%2081) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2082 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2074)
          %2083 : Tensor = aten::add(%2082, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2074, %2083)
          -> ()
        block1():
          -> ()
      %2084 : bool = prim::GetAttr[name="training"](%2074)
      %2085 : Tensor = prim::GetAttr[name="running_mean"](%2074)
      %2086 : Tensor = prim::GetAttr[name="running_var"](%2074)
      %2087 : Tensor = prim::GetAttr[name="weight"](%2074)
      %2088 : Tensor = prim::GetAttr[name="bias"](%2074)
       = prim::If(%2084) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2089 : int[] = aten::size(%input.210) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.284 : int = aten::__getitem__(%2089, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2091 : int = aten::len(%2089) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2092 : int = aten::sub(%2091, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.285 : int = prim::Loop(%2092, %13, %size_prods.284) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.72 : int, %size_prods.286 : int):
              %2096 : int = aten::add(%i.72, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2097 : int = aten::__getitem__(%2089, %2096) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.287 : int = aten::mul(%size_prods.286, %2097) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.287)
          %2099 : bool = aten::eq(%size_prods.285, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2099) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2100 : str = aten::format(%14, %2089) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.211 : Tensor = aten::batch_norm(%input.210, %2087, %2088, %2085, %2086, %2084, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.212 : Tensor = aten::hardtanh_(%input.211, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2103 : __torch__.torch.nn.modules.conv.___torch_mangle_54.Conv2d = prim::GetAttr[name="0"](%2070)
      %2104 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_52.BatchNorm2d = prim::GetAttr[name="1"](%2070)
      %2105 : Tensor = prim::GetAttr[name="weight"](%2103)
      %2106 : Tensor? = prim::GetAttr[name="bias"](%2103)
      %input.213 : Tensor = aten::conv2d(%input.212, %2105, %2106, %3236, %3236, %3236, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2111 : bool = prim::GetAttr[name="training"](%2104)
       = prim::If(%2111) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2112 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2104)
          %2113 : Tensor = aten::add(%2112, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2104, %2113)
          -> ()
        block1():
          -> ()
      %2114 : bool = prim::GetAttr[name="training"](%2104)
      %2115 : Tensor = prim::GetAttr[name="running_mean"](%2104)
      %2116 : Tensor = prim::GetAttr[name="running_var"](%2104)
      %2117 : Tensor = prim::GetAttr[name="weight"](%2104)
      %2118 : Tensor = prim::GetAttr[name="bias"](%2104)
       = prim::If(%2114) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2119 : int[] = aten::size(%input.213) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.288 : int = aten::__getitem__(%2119, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2121 : int = aten::len(%2119) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2122 : int = aten::sub(%2121, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.289 : int = prim::Loop(%2122, %13, %size_prods.288) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.73 : int, %size_prods.290 : int):
              %2126 : int = aten::add(%i.73, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2127 : int = aten::__getitem__(%2119, %2126) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.291 : int = aten::mul(%size_prods.290, %2127) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.291)
          %2129 : bool = aten::eq(%size_prods.289, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2129) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2130 : str = aten::format(%14, %2119) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2130) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.214 : Tensor = aten::batch_norm(%input.213, %2117, %2118, %2115, %2116, %2114, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.215 : Tensor = aten::hardtanh_(%input.214, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2133 : Tensor = prim::GetAttr[name="weight"](%2071)
      %2134 : Tensor? = prim::GetAttr[name="bias"](%2071)
      %input.216 : Tensor = aten::conv2d(%input.215, %2133, %2134, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2139 : bool = prim::GetAttr[name="training"](%2072)
       = prim::If(%2139) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2140 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2072)
          %2141 : Tensor = aten::add(%2140, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2072, %2141)
          -> ()
        block1():
          -> ()
      %2142 : bool = prim::GetAttr[name="training"](%2072)
      %2143 : Tensor = prim::GetAttr[name="running_mean"](%2072)
      %2144 : Tensor = prim::GetAttr[name="running_var"](%2072)
      %2145 : Tensor = prim::GetAttr[name="weight"](%2072)
      %2146 : Tensor = prim::GetAttr[name="bias"](%2072)
       = prim::If(%2142) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2147 : int[] = aten::size(%input.216) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.292 : int = aten::__getitem__(%2147, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2149 : int = aten::len(%2147) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2150 : int = aten::sub(%2149, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.293 : int = prim::Loop(%2150, %13, %size_prods.292) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.74 : int, %size_prods.294 : int):
              %2154 : int = aten::add(%i.74, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2155 : int = aten::__getitem__(%2147, %2154) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.295 : int = aten::mul(%size_prods.294, %2155) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.295)
          %2157 : bool = aten::eq(%size_prods.293, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2157) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2158 : str = aten::format(%14, %2147) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2158) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.217 : Tensor = aten::batch_norm(%input.216, %2145, %2146, %2143, %2144, %2142, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2160 : Tensor = aten::add(%input.25, %input.217, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:99:19
      -> (%2160)
    block1():
      %2161 : __torch__.torch.nn.modules.container.___torch_mangle_57.Sequential = prim::GetAttr[name="conv"](%34)
      %2162 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_53.ConvBNActivation = prim::GetAttr[name="0"](%2161)
      %2163 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_55.ConvBNActivation = prim::GetAttr[name="1"](%2161)
      %2164 : __torch__.torch.nn.modules.conv.___torch_mangle_56.Conv2d = prim::GetAttr[name="2"](%2161)
      %2165 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_5.BatchNorm2d = prim::GetAttr[name="3"](%2161)
      %2166 : __torch__.torch.nn.modules.conv.___torch_mangle_51.Conv2d = prim::GetAttr[name="0"](%2162)
      %2167 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_52.BatchNorm2d = prim::GetAttr[name="1"](%2162)
      %2168 : Tensor = prim::GetAttr[name="weight"](%2166)
      %2169 : Tensor? = prim::GetAttr[name="bias"](%2166)
      %input.218 : Tensor = aten::conv2d(%input.25, %2168, %2169, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2174 : bool = prim::GetAttr[name="training"](%2167)
       = prim::If(%2174) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2175 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2167)
          %2176 : Tensor = aten::add(%2175, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2167, %2176)
          -> ()
        block1():
          -> ()
      %2177 : bool = prim::GetAttr[name="training"](%2167)
      %2178 : Tensor = prim::GetAttr[name="running_mean"](%2167)
      %2179 : Tensor = prim::GetAttr[name="running_var"](%2167)
      %2180 : Tensor = prim::GetAttr[name="weight"](%2167)
      %2181 : Tensor = prim::GetAttr[name="bias"](%2167)
       = prim::If(%2177) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2182 : int[] = aten::size(%input.218) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.296 : int = aten::__getitem__(%2182, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2184 : int = aten::len(%2182) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2185 : int = aten::sub(%2184, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.297 : int = prim::Loop(%2185, %13, %size_prods.296) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.75 : int, %size_prods.298 : int):
              %2189 : int = aten::add(%i.75, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2190 : int = aten::__getitem__(%2182, %2189) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.299 : int = aten::mul(%size_prods.298, %2190) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.299)
          %2192 : bool = aten::eq(%size_prods.297, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2193 : str = aten::format(%14, %2182) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2193) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.219 : Tensor = aten::batch_norm(%input.218, %2180, %2181, %2178, %2179, %2177, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.220 : Tensor = aten::hardtanh_(%input.219, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2196 : __torch__.torch.nn.modules.conv.___torch_mangle_54.Conv2d = prim::GetAttr[name="0"](%2163)
      %2197 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_52.BatchNorm2d = prim::GetAttr[name="1"](%2163)
      %2198 : Tensor = prim::GetAttr[name="weight"](%2196)
      %2199 : Tensor? = prim::GetAttr[name="bias"](%2196)
      %input.221 : Tensor = aten::conv2d(%input.220, %2198, %2199, %3236, %3236, %3236, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2204 : bool = prim::GetAttr[name="training"](%2197)
       = prim::If(%2204) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2205 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2197)
          %2206 : Tensor = aten::add(%2205, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2197, %2206)
          -> ()
        block1():
          -> ()
      %2207 : bool = prim::GetAttr[name="training"](%2197)
      %2208 : Tensor = prim::GetAttr[name="running_mean"](%2197)
      %2209 : Tensor = prim::GetAttr[name="running_var"](%2197)
      %2210 : Tensor = prim::GetAttr[name="weight"](%2197)
      %2211 : Tensor = prim::GetAttr[name="bias"](%2197)
       = prim::If(%2207) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2212 : int[] = aten::size(%input.221) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.300 : int = aten::__getitem__(%2212, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2214 : int = aten::len(%2212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2215 : int = aten::sub(%2214, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.301 : int = prim::Loop(%2215, %13, %size_prods.300) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.76 : int, %size_prods.302 : int):
              %2219 : int = aten::add(%i.76, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2220 : int = aten::__getitem__(%2212, %2219) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.303 : int = aten::mul(%size_prods.302, %2220) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.303)
          %2222 : bool = aten::eq(%size_prods.301, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2222) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2223 : str = aten::format(%14, %2212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2223) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.222 : Tensor = aten::batch_norm(%input.221, %2210, %2211, %2208, %2209, %2207, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.223 : Tensor = aten::hardtanh_(%input.222, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2226 : Tensor = prim::GetAttr[name="weight"](%2164)
      %2227 : Tensor? = prim::GetAttr[name="bias"](%2164)
      %input.224 : Tensor = aten::conv2d(%input.223, %2226, %2227, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2232 : bool = prim::GetAttr[name="training"](%2165)
       = prim::If(%2232) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2233 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2165)
          %2234 : Tensor = aten::add(%2233, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2165, %2234)
          -> ()
        block1():
          -> ()
      %2235 : bool = prim::GetAttr[name="training"](%2165)
      %2236 : Tensor = prim::GetAttr[name="running_mean"](%2165)
      %2237 : Tensor = prim::GetAttr[name="running_var"](%2165)
      %2238 : Tensor = prim::GetAttr[name="weight"](%2165)
      %2239 : Tensor = prim::GetAttr[name="bias"](%2165)
       = prim::If(%2235) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2240 : int[] = aten::size(%input.224) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.304 : int = aten::__getitem__(%2240, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2242 : int = aten::len(%2240) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2243 : int = aten::sub(%2242, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.305 : int = prim::Loop(%2243, %13, %size_prods.304) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.77 : int, %size_prods.306 : int):
              %2247 : int = aten::add(%i.77, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2248 : int = aten::__getitem__(%2240, %2247) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.307 : int = aten::mul(%size_prods.306, %2248) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.307)
          %2250 : bool = aten::eq(%size_prods.305, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2250) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2251 : str = aten::format(%14, %2240) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2251) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.225 : Tensor = aten::batch_norm(%input.224, %2238, %2239, %2236, %2237, %2235, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.225)
  %2253 : bool = prim::GetAttr[name="use_res_connect"](%35)
  %input.29 : Tensor = prim::If(%2253) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:98:8
    block0():
      %2255 : __torch__.torch.nn.modules.container.___torch_mangle_57.Sequential = prim::GetAttr[name="conv"](%35)
      %2256 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_53.ConvBNActivation = prim::GetAttr[name="0"](%2255)
      %2257 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_55.ConvBNActivation = prim::GetAttr[name="1"](%2255)
      %2258 : __torch__.torch.nn.modules.conv.___torch_mangle_56.Conv2d = prim::GetAttr[name="2"](%2255)
      %2259 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_5.BatchNorm2d = prim::GetAttr[name="3"](%2255)
      %2260 : __torch__.torch.nn.modules.conv.___torch_mangle_51.Conv2d = prim::GetAttr[name="0"](%2256)
      %2261 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_52.BatchNorm2d = prim::GetAttr[name="1"](%2256)
      %2262 : Tensor = prim::GetAttr[name="weight"](%2260)
      %2263 : Tensor? = prim::GetAttr[name="bias"](%2260)
      %input.226 : Tensor = aten::conv2d(%input.27, %2262, %2263, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2268 : bool = prim::GetAttr[name="training"](%2261)
       = prim::If(%2268) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2269 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2261)
          %2270 : Tensor = aten::add(%2269, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2261, %2270)
          -> ()
        block1():
          -> ()
      %2271 : bool = prim::GetAttr[name="training"](%2261)
      %2272 : Tensor = prim::GetAttr[name="running_mean"](%2261)
      %2273 : Tensor = prim::GetAttr[name="running_var"](%2261)
      %2274 : Tensor = prim::GetAttr[name="weight"](%2261)
      %2275 : Tensor = prim::GetAttr[name="bias"](%2261)
       = prim::If(%2271) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2276 : int[] = aten::size(%input.226) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.308 : int = aten::__getitem__(%2276, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2278 : int = aten::len(%2276) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2279 : int = aten::sub(%2278, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.309 : int = prim::Loop(%2279, %13, %size_prods.308) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.78 : int, %size_prods.310 : int):
              %2283 : int = aten::add(%i.78, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2284 : int = aten::__getitem__(%2276, %2283) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.311 : int = aten::mul(%size_prods.310, %2284) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.311)
          %2286 : bool = aten::eq(%size_prods.309, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2286) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2287 : str = aten::format(%14, %2276) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2287) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.227 : Tensor = aten::batch_norm(%input.226, %2274, %2275, %2272, %2273, %2271, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.228 : Tensor = aten::hardtanh_(%input.227, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2290 : __torch__.torch.nn.modules.conv.___torch_mangle_54.Conv2d = prim::GetAttr[name="0"](%2257)
      %2291 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_52.BatchNorm2d = prim::GetAttr[name="1"](%2257)
      %2292 : Tensor = prim::GetAttr[name="weight"](%2290)
      %2293 : Tensor? = prim::GetAttr[name="bias"](%2290)
      %input.229 : Tensor = aten::conv2d(%input.228, %2292, %2293, %3236, %3236, %3236, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2298 : bool = prim::GetAttr[name="training"](%2291)
       = prim::If(%2298) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2299 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2291)
          %2300 : Tensor = aten::add(%2299, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2291, %2300)
          -> ()
        block1():
          -> ()
      %2301 : bool = prim::GetAttr[name="training"](%2291)
      %2302 : Tensor = prim::GetAttr[name="running_mean"](%2291)
      %2303 : Tensor = prim::GetAttr[name="running_var"](%2291)
      %2304 : Tensor = prim::GetAttr[name="weight"](%2291)
      %2305 : Tensor = prim::GetAttr[name="bias"](%2291)
       = prim::If(%2301) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2306 : int[] = aten::size(%input.229) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.312 : int = aten::__getitem__(%2306, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2308 : int = aten::len(%2306) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2309 : int = aten::sub(%2308, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.313 : int = prim::Loop(%2309, %13, %size_prods.312) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.79 : int, %size_prods.314 : int):
              %2313 : int = aten::add(%i.79, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2314 : int = aten::__getitem__(%2306, %2313) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.315 : int = aten::mul(%size_prods.314, %2314) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.315)
          %2316 : bool = aten::eq(%size_prods.313, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2316) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2317 : str = aten::format(%14, %2306) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2317) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.230 : Tensor = aten::batch_norm(%input.229, %2304, %2305, %2302, %2303, %2301, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.231 : Tensor = aten::hardtanh_(%input.230, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2320 : Tensor = prim::GetAttr[name="weight"](%2258)
      %2321 : Tensor? = prim::GetAttr[name="bias"](%2258)
      %input.232 : Tensor = aten::conv2d(%input.231, %2320, %2321, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2326 : bool = prim::GetAttr[name="training"](%2259)
       = prim::If(%2326) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2327 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2259)
          %2328 : Tensor = aten::add(%2327, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2259, %2328)
          -> ()
        block1():
          -> ()
      %2329 : bool = prim::GetAttr[name="training"](%2259)
      %2330 : Tensor = prim::GetAttr[name="running_mean"](%2259)
      %2331 : Tensor = prim::GetAttr[name="running_var"](%2259)
      %2332 : Tensor = prim::GetAttr[name="weight"](%2259)
      %2333 : Tensor = prim::GetAttr[name="bias"](%2259)
       = prim::If(%2329) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2334 : int[] = aten::size(%input.232) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.316 : int = aten::__getitem__(%2334, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2336 : int = aten::len(%2334) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2337 : int = aten::sub(%2336, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.317 : int = prim::Loop(%2337, %13, %size_prods.316) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.80 : int, %size_prods.318 : int):
              %2341 : int = aten::add(%i.80, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2342 : int = aten::__getitem__(%2334, %2341) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.319 : int = aten::mul(%size_prods.318, %2342) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.319)
          %2344 : bool = aten::eq(%size_prods.317, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2344) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2345 : str = aten::format(%14, %2334) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2345) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.233 : Tensor = aten::batch_norm(%input.232, %2332, %2333, %2330, %2331, %2329, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2347 : Tensor = aten::add(%input.27, %input.233, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:99:19
      -> (%2347)
    block1():
      %2348 : __torch__.torch.nn.modules.container.___torch_mangle_57.Sequential = prim::GetAttr[name="conv"](%35)
      %2349 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_53.ConvBNActivation = prim::GetAttr[name="0"](%2348)
      %2350 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_55.ConvBNActivation = prim::GetAttr[name="1"](%2348)
      %2351 : __torch__.torch.nn.modules.conv.___torch_mangle_56.Conv2d = prim::GetAttr[name="2"](%2348)
      %2352 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_5.BatchNorm2d = prim::GetAttr[name="3"](%2348)
      %2353 : __torch__.torch.nn.modules.conv.___torch_mangle_51.Conv2d = prim::GetAttr[name="0"](%2349)
      %2354 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_52.BatchNorm2d = prim::GetAttr[name="1"](%2349)
      %2355 : Tensor = prim::GetAttr[name="weight"](%2353)
      %2356 : Tensor? = prim::GetAttr[name="bias"](%2353)
      %input.234 : Tensor = aten::conv2d(%input.27, %2355, %2356, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2361 : bool = prim::GetAttr[name="training"](%2354)
       = prim::If(%2361) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2362 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2354)
          %2363 : Tensor = aten::add(%2362, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2354, %2363)
          -> ()
        block1():
          -> ()
      %2364 : bool = prim::GetAttr[name="training"](%2354)
      %2365 : Tensor = prim::GetAttr[name="running_mean"](%2354)
      %2366 : Tensor = prim::GetAttr[name="running_var"](%2354)
      %2367 : Tensor = prim::GetAttr[name="weight"](%2354)
      %2368 : Tensor = prim::GetAttr[name="bias"](%2354)
       = prim::If(%2364) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2369 : int[] = aten::size(%input.234) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.320 : int = aten::__getitem__(%2369, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2371 : int = aten::len(%2369) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2372 : int = aten::sub(%2371, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.321 : int = prim::Loop(%2372, %13, %size_prods.320) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.81 : int, %size_prods.322 : int):
              %2376 : int = aten::add(%i.81, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2377 : int = aten::__getitem__(%2369, %2376) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.323 : int = aten::mul(%size_prods.322, %2377) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.323)
          %2379 : bool = aten::eq(%size_prods.321, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2379) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2380 : str = aten::format(%14, %2369) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2380) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.235 : Tensor = aten::batch_norm(%input.234, %2367, %2368, %2365, %2366, %2364, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.236 : Tensor = aten::hardtanh_(%input.235, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2383 : __torch__.torch.nn.modules.conv.___torch_mangle_54.Conv2d = prim::GetAttr[name="0"](%2350)
      %2384 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_52.BatchNorm2d = prim::GetAttr[name="1"](%2350)
      %2385 : Tensor = prim::GetAttr[name="weight"](%2383)
      %2386 : Tensor? = prim::GetAttr[name="bias"](%2383)
      %input.237 : Tensor = aten::conv2d(%input.236, %2385, %2386, %3236, %3236, %3236, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2391 : bool = prim::GetAttr[name="training"](%2384)
       = prim::If(%2391) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2392 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2384)
          %2393 : Tensor = aten::add(%2392, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2384, %2393)
          -> ()
        block1():
          -> ()
      %2394 : bool = prim::GetAttr[name="training"](%2384)
      %2395 : Tensor = prim::GetAttr[name="running_mean"](%2384)
      %2396 : Tensor = prim::GetAttr[name="running_var"](%2384)
      %2397 : Tensor = prim::GetAttr[name="weight"](%2384)
      %2398 : Tensor = prim::GetAttr[name="bias"](%2384)
       = prim::If(%2394) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2399 : int[] = aten::size(%input.237) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.324 : int = aten::__getitem__(%2399, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2401 : int = aten::len(%2399) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2402 : int = aten::sub(%2401, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.325 : int = prim::Loop(%2402, %13, %size_prods.324) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.82 : int, %size_prods.326 : int):
              %2406 : int = aten::add(%i.82, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2407 : int = aten::__getitem__(%2399, %2406) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.327 : int = aten::mul(%size_prods.326, %2407) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.327)
          %2409 : bool = aten::eq(%size_prods.325, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2409) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2410 : str = aten::format(%14, %2399) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2410) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.238 : Tensor = aten::batch_norm(%input.237, %2397, %2398, %2395, %2396, %2394, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.239 : Tensor = aten::hardtanh_(%input.238, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2413 : Tensor = prim::GetAttr[name="weight"](%2351)
      %2414 : Tensor? = prim::GetAttr[name="bias"](%2351)
      %input.240 : Tensor = aten::conv2d(%input.239, %2413, %2414, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2419 : bool = prim::GetAttr[name="training"](%2352)
       = prim::If(%2419) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2420 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2352)
          %2421 : Tensor = aten::add(%2420, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2352, %2421)
          -> ()
        block1():
          -> ()
      %2422 : bool = prim::GetAttr[name="training"](%2352)
      %2423 : Tensor = prim::GetAttr[name="running_mean"](%2352)
      %2424 : Tensor = prim::GetAttr[name="running_var"](%2352)
      %2425 : Tensor = prim::GetAttr[name="weight"](%2352)
      %2426 : Tensor = prim::GetAttr[name="bias"](%2352)
       = prim::If(%2422) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2427 : int[] = aten::size(%input.240) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.328 : int = aten::__getitem__(%2427, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2429 : int = aten::len(%2427) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2430 : int = aten::sub(%2429, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.329 : int = prim::Loop(%2430, %13, %size_prods.328) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.83 : int, %size_prods.330 : int):
              %2434 : int = aten::add(%i.83, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2435 : int = aten::__getitem__(%2427, %2434) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.331 : int = aten::mul(%size_prods.330, %2435) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.331)
          %2437 : bool = aten::eq(%size_prods.329, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2437) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2438 : str = aten::format(%14, %2427) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2438) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.241 : Tensor = aten::batch_norm(%input.240, %2425, %2426, %2423, %2424, %2422, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.241)
  %2440 : bool = prim::GetAttr[name="use_res_connect"](%36)
  %input.31 : Tensor = prim::If(%2440) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:98:8
    block0():
      %2442 : __torch__.torch.nn.modules.container.___torch_mangle_63.Sequential = prim::GetAttr[name="conv"](%36)
      %2443 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_53.ConvBNActivation = prim::GetAttr[name="0"](%2442)
      %2444 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_60.ConvBNActivation = prim::GetAttr[name="1"](%2442)
      %2445 : __torch__.torch.nn.modules.conv.___torch_mangle_61.Conv2d = prim::GetAttr[name="2"](%2442)
      %2446 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_62.BatchNorm2d = prim::GetAttr[name="3"](%2442)
      %2447 : __torch__.torch.nn.modules.conv.___torch_mangle_51.Conv2d = prim::GetAttr[name="0"](%2443)
      %2448 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_52.BatchNorm2d = prim::GetAttr[name="1"](%2443)
      %2449 : Tensor = prim::GetAttr[name="weight"](%2447)
      %2450 : Tensor? = prim::GetAttr[name="bias"](%2447)
      %input.242 : Tensor = aten::conv2d(%input.29, %2449, %2450, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2455 : bool = prim::GetAttr[name="training"](%2448)
       = prim::If(%2455) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2456 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2448)
          %2457 : Tensor = aten::add(%2456, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2448, %2457)
          -> ()
        block1():
          -> ()
      %2458 : bool = prim::GetAttr[name="training"](%2448)
      %2459 : Tensor = prim::GetAttr[name="running_mean"](%2448)
      %2460 : Tensor = prim::GetAttr[name="running_var"](%2448)
      %2461 : Tensor = prim::GetAttr[name="weight"](%2448)
      %2462 : Tensor = prim::GetAttr[name="bias"](%2448)
       = prim::If(%2458) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2463 : int[] = aten::size(%input.242) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.332 : int = aten::__getitem__(%2463, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2465 : int = aten::len(%2463) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2466 : int = aten::sub(%2465, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.333 : int = prim::Loop(%2466, %13, %size_prods.332) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.84 : int, %size_prods.334 : int):
              %2470 : int = aten::add(%i.84, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2471 : int = aten::__getitem__(%2463, %2470) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.335 : int = aten::mul(%size_prods.334, %2471) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.335)
          %2473 : bool = aten::eq(%size_prods.333, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2473) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2474 : str = aten::format(%14, %2463) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2474) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.243 : Tensor = aten::batch_norm(%input.242, %2461, %2462, %2459, %2460, %2458, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.244 : Tensor = aten::hardtanh_(%input.243, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2477 : __torch__.torch.nn.modules.conv.___torch_mangle_59.Conv2d = prim::GetAttr[name="0"](%2444)
      %2478 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_52.BatchNorm2d = prim::GetAttr[name="1"](%2444)
      %2479 : Tensor = prim::GetAttr[name="weight"](%2477)
      %2480 : Tensor? = prim::GetAttr[name="bias"](%2477)
      %input.245 : Tensor = aten::conv2d(%input.244, %2479, %2480, %3235, %3236, %3236, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2485 : bool = prim::GetAttr[name="training"](%2478)
       = prim::If(%2485) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2486 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2478)
          %2487 : Tensor = aten::add(%2486, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2478, %2487)
          -> ()
        block1():
          -> ()
      %2488 : bool = prim::GetAttr[name="training"](%2478)
      %2489 : Tensor = prim::GetAttr[name="running_mean"](%2478)
      %2490 : Tensor = prim::GetAttr[name="running_var"](%2478)
      %2491 : Tensor = prim::GetAttr[name="weight"](%2478)
      %2492 : Tensor = prim::GetAttr[name="bias"](%2478)
       = prim::If(%2488) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2493 : int[] = aten::size(%input.245) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.336 : int = aten::__getitem__(%2493, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2495 : int = aten::len(%2493) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2496 : int = aten::sub(%2495, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.337 : int = prim::Loop(%2496, %13, %size_prods.336) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.85 : int, %size_prods.338 : int):
              %2500 : int = aten::add(%i.85, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2501 : int = aten::__getitem__(%2493, %2500) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.339 : int = aten::mul(%size_prods.338, %2501) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.339)
          %2503 : bool = aten::eq(%size_prods.337, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2503) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2504 : str = aten::format(%14, %2493) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2504) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.246 : Tensor = aten::batch_norm(%input.245, %2491, %2492, %2489, %2490, %2488, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.247 : Tensor = aten::hardtanh_(%input.246, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2507 : Tensor = prim::GetAttr[name="weight"](%2445)
      %2508 : Tensor? = prim::GetAttr[name="bias"](%2445)
      %input.248 : Tensor = aten::conv2d(%input.247, %2507, %2508, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2513 : bool = prim::GetAttr[name="training"](%2446)
       = prim::If(%2513) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2514 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2446)
          %2515 : Tensor = aten::add(%2514, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2446, %2515)
          -> ()
        block1():
          -> ()
      %2516 : bool = prim::GetAttr[name="training"](%2446)
      %2517 : Tensor = prim::GetAttr[name="running_mean"](%2446)
      %2518 : Tensor = prim::GetAttr[name="running_var"](%2446)
      %2519 : Tensor = prim::GetAttr[name="weight"](%2446)
      %2520 : Tensor = prim::GetAttr[name="bias"](%2446)
       = prim::If(%2516) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2521 : int[] = aten::size(%input.248) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.340 : int = aten::__getitem__(%2521, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2523 : int = aten::len(%2521) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2524 : int = aten::sub(%2523, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.341 : int = prim::Loop(%2524, %13, %size_prods.340) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.86 : int, %size_prods.342 : int):
              %2528 : int = aten::add(%i.86, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2529 : int = aten::__getitem__(%2521, %2528) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.343 : int = aten::mul(%size_prods.342, %2529) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.343)
          %2531 : bool = aten::eq(%size_prods.341, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2531) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2532 : str = aten::format(%14, %2521) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2532) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.249 : Tensor = aten::batch_norm(%input.248, %2519, %2520, %2517, %2518, %2516, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2534 : Tensor = aten::add(%input.29, %input.249, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:99:19
      -> (%2534)
    block1():
      %2535 : __torch__.torch.nn.modules.container.___torch_mangle_63.Sequential = prim::GetAttr[name="conv"](%36)
      %2536 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_53.ConvBNActivation = prim::GetAttr[name="0"](%2535)
      %2537 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_60.ConvBNActivation = prim::GetAttr[name="1"](%2535)
      %2538 : __torch__.torch.nn.modules.conv.___torch_mangle_61.Conv2d = prim::GetAttr[name="2"](%2535)
      %2539 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_62.BatchNorm2d = prim::GetAttr[name="3"](%2535)
      %2540 : __torch__.torch.nn.modules.conv.___torch_mangle_51.Conv2d = prim::GetAttr[name="0"](%2536)
      %2541 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_52.BatchNorm2d = prim::GetAttr[name="1"](%2536)
      %2542 : Tensor = prim::GetAttr[name="weight"](%2540)
      %2543 : Tensor? = prim::GetAttr[name="bias"](%2540)
      %input.250 : Tensor = aten::conv2d(%input.29, %2542, %2543, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2548 : bool = prim::GetAttr[name="training"](%2541)
       = prim::If(%2548) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2549 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2541)
          %2550 : Tensor = aten::add(%2549, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2541, %2550)
          -> ()
        block1():
          -> ()
      %2551 : bool = prim::GetAttr[name="training"](%2541)
      %2552 : Tensor = prim::GetAttr[name="running_mean"](%2541)
      %2553 : Tensor = prim::GetAttr[name="running_var"](%2541)
      %2554 : Tensor = prim::GetAttr[name="weight"](%2541)
      %2555 : Tensor = prim::GetAttr[name="bias"](%2541)
       = prim::If(%2551) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2556 : int[] = aten::size(%input.250) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.344 : int = aten::__getitem__(%2556, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2558 : int = aten::len(%2556) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2559 : int = aten::sub(%2558, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.345 : int = prim::Loop(%2559, %13, %size_prods.344) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.87 : int, %size_prods.346 : int):
              %2563 : int = aten::add(%i.87, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2564 : int = aten::__getitem__(%2556, %2563) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.347 : int = aten::mul(%size_prods.346, %2564) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.347)
          %2566 : bool = aten::eq(%size_prods.345, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2566) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2567 : str = aten::format(%14, %2556) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2567) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.251 : Tensor = aten::batch_norm(%input.250, %2554, %2555, %2552, %2553, %2551, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.252 : Tensor = aten::hardtanh_(%input.251, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2570 : __torch__.torch.nn.modules.conv.___torch_mangle_59.Conv2d = prim::GetAttr[name="0"](%2537)
      %2571 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_52.BatchNorm2d = prim::GetAttr[name="1"](%2537)
      %2572 : Tensor = prim::GetAttr[name="weight"](%2570)
      %2573 : Tensor? = prim::GetAttr[name="bias"](%2570)
      %input.253 : Tensor = aten::conv2d(%input.252, %2572, %2573, %3235, %3236, %3236, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2578 : bool = prim::GetAttr[name="training"](%2571)
       = prim::If(%2578) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2579 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2571)
          %2580 : Tensor = aten::add(%2579, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2571, %2580)
          -> ()
        block1():
          -> ()
      %2581 : bool = prim::GetAttr[name="training"](%2571)
      %2582 : Tensor = prim::GetAttr[name="running_mean"](%2571)
      %2583 : Tensor = prim::GetAttr[name="running_var"](%2571)
      %2584 : Tensor = prim::GetAttr[name="weight"](%2571)
      %2585 : Tensor = prim::GetAttr[name="bias"](%2571)
       = prim::If(%2581) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2586 : int[] = aten::size(%input.253) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.348 : int = aten::__getitem__(%2586, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2588 : int = aten::len(%2586) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2589 : int = aten::sub(%2588, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.349 : int = prim::Loop(%2589, %13, %size_prods.348) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.88 : int, %size_prods.350 : int):
              %2593 : int = aten::add(%i.88, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2594 : int = aten::__getitem__(%2586, %2593) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.351 : int = aten::mul(%size_prods.350, %2594) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.351)
          %2596 : bool = aten::eq(%size_prods.349, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2596) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2597 : str = aten::format(%14, %2586) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2597) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.254 : Tensor = aten::batch_norm(%input.253, %2584, %2585, %2582, %2583, %2581, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.255 : Tensor = aten::hardtanh_(%input.254, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2600 : Tensor = prim::GetAttr[name="weight"](%2538)
      %2601 : Tensor? = prim::GetAttr[name="bias"](%2538)
      %input.256 : Tensor = aten::conv2d(%input.255, %2600, %2601, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2606 : bool = prim::GetAttr[name="training"](%2539)
       = prim::If(%2606) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2607 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2539)
          %2608 : Tensor = aten::add(%2607, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2539, %2608)
          -> ()
        block1():
          -> ()
      %2609 : bool = prim::GetAttr[name="training"](%2539)
      %2610 : Tensor = prim::GetAttr[name="running_mean"](%2539)
      %2611 : Tensor = prim::GetAttr[name="running_var"](%2539)
      %2612 : Tensor = prim::GetAttr[name="weight"](%2539)
      %2613 : Tensor = prim::GetAttr[name="bias"](%2539)
       = prim::If(%2609) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2614 : int[] = aten::size(%input.256) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.352 : int = aten::__getitem__(%2614, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2616 : int = aten::len(%2614) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2617 : int = aten::sub(%2616, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.353 : int = prim::Loop(%2617, %13, %size_prods.352) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.89 : int, %size_prods.354 : int):
              %2621 : int = aten::add(%i.89, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2622 : int = aten::__getitem__(%2614, %2621) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.355 : int = aten::mul(%size_prods.354, %2622) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.355)
          %2624 : bool = aten::eq(%size_prods.353, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2624) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2625 : str = aten::format(%14, %2614) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2625) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.257 : Tensor = aten::batch_norm(%input.256, %2612, %2613, %2610, %2611, %2609, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.257)
  %2627 : bool = prim::GetAttr[name="use_res_connect"](%37)
  %input.33 : Tensor = prim::If(%2627) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:98:8
    block0():
      %2629 : __torch__.torch.nn.modules.container.___torch_mangle_71.Sequential = prim::GetAttr[name="conv"](%37)
      %2630 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_67.ConvBNActivation = prim::GetAttr[name="0"](%2629)
      %2631 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_69.ConvBNActivation = prim::GetAttr[name="1"](%2629)
      %2632 : __torch__.torch.nn.modules.conv.___torch_mangle_70.Conv2d = prim::GetAttr[name="2"](%2629)
      %2633 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_62.BatchNorm2d = prim::GetAttr[name="3"](%2629)
      %2634 : __torch__.torch.nn.modules.conv.___torch_mangle_65.Conv2d = prim::GetAttr[name="0"](%2630)
      %2635 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_66.BatchNorm2d = prim::GetAttr[name="1"](%2630)
      %2636 : Tensor = prim::GetAttr[name="weight"](%2634)
      %2637 : Tensor? = prim::GetAttr[name="bias"](%2634)
      %input.258 : Tensor = aten::conv2d(%input.31, %2636, %2637, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2642 : bool = prim::GetAttr[name="training"](%2635)
       = prim::If(%2642) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2643 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2635)
          %2644 : Tensor = aten::add(%2643, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2635, %2644)
          -> ()
        block1():
          -> ()
      %2645 : bool = prim::GetAttr[name="training"](%2635)
      %2646 : Tensor = prim::GetAttr[name="running_mean"](%2635)
      %2647 : Tensor = prim::GetAttr[name="running_var"](%2635)
      %2648 : Tensor = prim::GetAttr[name="weight"](%2635)
      %2649 : Tensor = prim::GetAttr[name="bias"](%2635)
       = prim::If(%2645) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2650 : int[] = aten::size(%input.258) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.356 : int = aten::__getitem__(%2650, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2652 : int = aten::len(%2650) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2653 : int = aten::sub(%2652, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.357 : int = prim::Loop(%2653, %13, %size_prods.356) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.90 : int, %size_prods.358 : int):
              %2657 : int = aten::add(%i.90, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2658 : int = aten::__getitem__(%2650, %2657) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.359 : int = aten::mul(%size_prods.358, %2658) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.359)
          %2660 : bool = aten::eq(%size_prods.357, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2660) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2661 : str = aten::format(%14, %2650) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2661) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.259 : Tensor = aten::batch_norm(%input.258, %2648, %2649, %2646, %2647, %2645, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.260 : Tensor = aten::hardtanh_(%input.259, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2664 : __torch__.torch.nn.modules.conv.___torch_mangle_68.Conv2d = prim::GetAttr[name="0"](%2631)
      %2665 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_66.BatchNorm2d = prim::GetAttr[name="1"](%2631)
      %2666 : Tensor = prim::GetAttr[name="weight"](%2664)
      %2667 : Tensor? = prim::GetAttr[name="bias"](%2664)
      %input.261 : Tensor = aten::conv2d(%input.260, %2666, %2667, %3236, %3236, %3236, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2672 : bool = prim::GetAttr[name="training"](%2665)
       = prim::If(%2672) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2673 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2665)
          %2674 : Tensor = aten::add(%2673, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2665, %2674)
          -> ()
        block1():
          -> ()
      %2675 : bool = prim::GetAttr[name="training"](%2665)
      %2676 : Tensor = prim::GetAttr[name="running_mean"](%2665)
      %2677 : Tensor = prim::GetAttr[name="running_var"](%2665)
      %2678 : Tensor = prim::GetAttr[name="weight"](%2665)
      %2679 : Tensor = prim::GetAttr[name="bias"](%2665)
       = prim::If(%2675) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2680 : int[] = aten::size(%input.261) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.360 : int = aten::__getitem__(%2680, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2682 : int = aten::len(%2680) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2683 : int = aten::sub(%2682, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.361 : int = prim::Loop(%2683, %13, %size_prods.360) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.91 : int, %size_prods.362 : int):
              %2687 : int = aten::add(%i.91, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2688 : int = aten::__getitem__(%2680, %2687) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.363 : int = aten::mul(%size_prods.362, %2688) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.363)
          %2690 : bool = aten::eq(%size_prods.361, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2690) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2691 : str = aten::format(%14, %2680) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2691) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.262 : Tensor = aten::batch_norm(%input.261, %2678, %2679, %2676, %2677, %2675, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.263 : Tensor = aten::hardtanh_(%input.262, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2694 : Tensor = prim::GetAttr[name="weight"](%2632)
      %2695 : Tensor? = prim::GetAttr[name="bias"](%2632)
      %input.264 : Tensor = aten::conv2d(%input.263, %2694, %2695, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2700 : bool = prim::GetAttr[name="training"](%2633)
       = prim::If(%2700) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2701 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2633)
          %2702 : Tensor = aten::add(%2701, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2633, %2702)
          -> ()
        block1():
          -> ()
      %2703 : bool = prim::GetAttr[name="training"](%2633)
      %2704 : Tensor = prim::GetAttr[name="running_mean"](%2633)
      %2705 : Tensor = prim::GetAttr[name="running_var"](%2633)
      %2706 : Tensor = prim::GetAttr[name="weight"](%2633)
      %2707 : Tensor = prim::GetAttr[name="bias"](%2633)
       = prim::If(%2703) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2708 : int[] = aten::size(%input.264) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.364 : int = aten::__getitem__(%2708, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2710 : int = aten::len(%2708) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2711 : int = aten::sub(%2710, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.365 : int = prim::Loop(%2711, %13, %size_prods.364) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.92 : int, %size_prods.366 : int):
              %2715 : int = aten::add(%i.92, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2716 : int = aten::__getitem__(%2708, %2715) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.367 : int = aten::mul(%size_prods.366, %2716) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.367)
          %2718 : bool = aten::eq(%size_prods.365, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2718) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2719 : str = aten::format(%14, %2708) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2719) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.265 : Tensor = aten::batch_norm(%input.264, %2706, %2707, %2704, %2705, %2703, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2721 : Tensor = aten::add(%input.31, %input.265, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:99:19
      -> (%2721)
    block1():
      %2722 : __torch__.torch.nn.modules.container.___torch_mangle_71.Sequential = prim::GetAttr[name="conv"](%37)
      %2723 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_67.ConvBNActivation = prim::GetAttr[name="0"](%2722)
      %2724 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_69.ConvBNActivation = prim::GetAttr[name="1"](%2722)
      %2725 : __torch__.torch.nn.modules.conv.___torch_mangle_70.Conv2d = prim::GetAttr[name="2"](%2722)
      %2726 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_62.BatchNorm2d = prim::GetAttr[name="3"](%2722)
      %2727 : __torch__.torch.nn.modules.conv.___torch_mangle_65.Conv2d = prim::GetAttr[name="0"](%2723)
      %2728 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_66.BatchNorm2d = prim::GetAttr[name="1"](%2723)
      %2729 : Tensor = prim::GetAttr[name="weight"](%2727)
      %2730 : Tensor? = prim::GetAttr[name="bias"](%2727)
      %input.266 : Tensor = aten::conv2d(%input.31, %2729, %2730, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2735 : bool = prim::GetAttr[name="training"](%2728)
       = prim::If(%2735) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2736 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2728)
          %2737 : Tensor = aten::add(%2736, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2728, %2737)
          -> ()
        block1():
          -> ()
      %2738 : bool = prim::GetAttr[name="training"](%2728)
      %2739 : Tensor = prim::GetAttr[name="running_mean"](%2728)
      %2740 : Tensor = prim::GetAttr[name="running_var"](%2728)
      %2741 : Tensor = prim::GetAttr[name="weight"](%2728)
      %2742 : Tensor = prim::GetAttr[name="bias"](%2728)
       = prim::If(%2738) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2743 : int[] = aten::size(%input.266) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.368 : int = aten::__getitem__(%2743, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2745 : int = aten::len(%2743) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2746 : int = aten::sub(%2745, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.369 : int = prim::Loop(%2746, %13, %size_prods.368) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.93 : int, %size_prods.370 : int):
              %2750 : int = aten::add(%i.93, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2751 : int = aten::__getitem__(%2743, %2750) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.371 : int = aten::mul(%size_prods.370, %2751) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.371)
          %2753 : bool = aten::eq(%size_prods.369, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2753) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2754 : str = aten::format(%14, %2743) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2754) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.267 : Tensor = aten::batch_norm(%input.266, %2741, %2742, %2739, %2740, %2738, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.268 : Tensor = aten::hardtanh_(%input.267, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2757 : __torch__.torch.nn.modules.conv.___torch_mangle_68.Conv2d = prim::GetAttr[name="0"](%2724)
      %2758 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_66.BatchNorm2d = prim::GetAttr[name="1"](%2724)
      %2759 : Tensor = prim::GetAttr[name="weight"](%2757)
      %2760 : Tensor? = prim::GetAttr[name="bias"](%2757)
      %input.269 : Tensor = aten::conv2d(%input.268, %2759, %2760, %3236, %3236, %3236, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2765 : bool = prim::GetAttr[name="training"](%2758)
       = prim::If(%2765) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2766 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2758)
          %2767 : Tensor = aten::add(%2766, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2758, %2767)
          -> ()
        block1():
          -> ()
      %2768 : bool = prim::GetAttr[name="training"](%2758)
      %2769 : Tensor = prim::GetAttr[name="running_mean"](%2758)
      %2770 : Tensor = prim::GetAttr[name="running_var"](%2758)
      %2771 : Tensor = prim::GetAttr[name="weight"](%2758)
      %2772 : Tensor = prim::GetAttr[name="bias"](%2758)
       = prim::If(%2768) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2773 : int[] = aten::size(%input.269) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.372 : int = aten::__getitem__(%2773, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2775 : int = aten::len(%2773) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2776 : int = aten::sub(%2775, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.373 : int = prim::Loop(%2776, %13, %size_prods.372) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.94 : int, %size_prods.374 : int):
              %2780 : int = aten::add(%i.94, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2781 : int = aten::__getitem__(%2773, %2780) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.375 : int = aten::mul(%size_prods.374, %2781) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.375)
          %2783 : bool = aten::eq(%size_prods.373, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2783) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2784 : str = aten::format(%14, %2773) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2784) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.270 : Tensor = aten::batch_norm(%input.269, %2771, %2772, %2769, %2770, %2768, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.271 : Tensor = aten::hardtanh_(%input.270, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2787 : Tensor = prim::GetAttr[name="weight"](%2725)
      %2788 : Tensor? = prim::GetAttr[name="bias"](%2725)
      %input.272 : Tensor = aten::conv2d(%input.271, %2787, %2788, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2793 : bool = prim::GetAttr[name="training"](%2726)
       = prim::If(%2793) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2794 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2726)
          %2795 : Tensor = aten::add(%2794, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2726, %2795)
          -> ()
        block1():
          -> ()
      %2796 : bool = prim::GetAttr[name="training"](%2726)
      %2797 : Tensor = prim::GetAttr[name="running_mean"](%2726)
      %2798 : Tensor = prim::GetAttr[name="running_var"](%2726)
      %2799 : Tensor = prim::GetAttr[name="weight"](%2726)
      %2800 : Tensor = prim::GetAttr[name="bias"](%2726)
       = prim::If(%2796) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2801 : int[] = aten::size(%input.272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.376 : int = aten::__getitem__(%2801, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2803 : int = aten::len(%2801) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2804 : int = aten::sub(%2803, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.377 : int = prim::Loop(%2804, %13, %size_prods.376) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.95 : int, %size_prods.378 : int):
              %2808 : int = aten::add(%i.95, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2809 : int = aten::__getitem__(%2801, %2808) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.379 : int = aten::mul(%size_prods.378, %2809) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.379)
          %2811 : bool = aten::eq(%size_prods.377, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2811) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2812 : str = aten::format(%14, %2801) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2812) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.273 : Tensor = aten::batch_norm(%input.272, %2799, %2800, %2797, %2798, %2796, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.273)
  %2814 : bool = prim::GetAttr[name="use_res_connect"](%38)
  %input.35 : Tensor = prim::If(%2814) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:98:8
    block0():
      %2816 : __torch__.torch.nn.modules.container.___torch_mangle_71.Sequential = prim::GetAttr[name="conv"](%38)
      %2817 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_67.ConvBNActivation = prim::GetAttr[name="0"](%2816)
      %2818 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_69.ConvBNActivation = prim::GetAttr[name="1"](%2816)
      %2819 : __torch__.torch.nn.modules.conv.___torch_mangle_70.Conv2d = prim::GetAttr[name="2"](%2816)
      %2820 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_62.BatchNorm2d = prim::GetAttr[name="3"](%2816)
      %2821 : __torch__.torch.nn.modules.conv.___torch_mangle_65.Conv2d = prim::GetAttr[name="0"](%2817)
      %2822 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_66.BatchNorm2d = prim::GetAttr[name="1"](%2817)
      %2823 : Tensor = prim::GetAttr[name="weight"](%2821)
      %2824 : Tensor? = prim::GetAttr[name="bias"](%2821)
      %input.274 : Tensor = aten::conv2d(%input.33, %2823, %2824, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2829 : bool = prim::GetAttr[name="training"](%2822)
       = prim::If(%2829) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2830 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2822)
          %2831 : Tensor = aten::add(%2830, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2822, %2831)
          -> ()
        block1():
          -> ()
      %2832 : bool = prim::GetAttr[name="training"](%2822)
      %2833 : Tensor = prim::GetAttr[name="running_mean"](%2822)
      %2834 : Tensor = prim::GetAttr[name="running_var"](%2822)
      %2835 : Tensor = prim::GetAttr[name="weight"](%2822)
      %2836 : Tensor = prim::GetAttr[name="bias"](%2822)
       = prim::If(%2832) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2837 : int[] = aten::size(%input.274) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.380 : int = aten::__getitem__(%2837, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2839 : int = aten::len(%2837) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2840 : int = aten::sub(%2839, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.381 : int = prim::Loop(%2840, %13, %size_prods.380) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.96 : int, %size_prods.382 : int):
              %2844 : int = aten::add(%i.96, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2845 : int = aten::__getitem__(%2837, %2844) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.383 : int = aten::mul(%size_prods.382, %2845) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.383)
          %2847 : bool = aten::eq(%size_prods.381, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2847) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2848 : str = aten::format(%14, %2837) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2848) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.275 : Tensor = aten::batch_norm(%input.274, %2835, %2836, %2833, %2834, %2832, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.276 : Tensor = aten::hardtanh_(%input.275, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2851 : __torch__.torch.nn.modules.conv.___torch_mangle_68.Conv2d = prim::GetAttr[name="0"](%2818)
      %2852 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_66.BatchNorm2d = prim::GetAttr[name="1"](%2818)
      %2853 : Tensor = prim::GetAttr[name="weight"](%2851)
      %2854 : Tensor? = prim::GetAttr[name="bias"](%2851)
      %input.277 : Tensor = aten::conv2d(%input.276, %2853, %2854, %3236, %3236, %3236, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2859 : bool = prim::GetAttr[name="training"](%2852)
       = prim::If(%2859) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2860 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2852)
          %2861 : Tensor = aten::add(%2860, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2852, %2861)
          -> ()
        block1():
          -> ()
      %2862 : bool = prim::GetAttr[name="training"](%2852)
      %2863 : Tensor = prim::GetAttr[name="running_mean"](%2852)
      %2864 : Tensor = prim::GetAttr[name="running_var"](%2852)
      %2865 : Tensor = prim::GetAttr[name="weight"](%2852)
      %2866 : Tensor = prim::GetAttr[name="bias"](%2852)
       = prim::If(%2862) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2867 : int[] = aten::size(%input.277) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.384 : int = aten::__getitem__(%2867, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2869 : int = aten::len(%2867) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2870 : int = aten::sub(%2869, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.385 : int = prim::Loop(%2870, %13, %size_prods.384) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.97 : int, %size_prods.386 : int):
              %2874 : int = aten::add(%i.97, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2875 : int = aten::__getitem__(%2867, %2874) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.387 : int = aten::mul(%size_prods.386, %2875) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.387)
          %2877 : bool = aten::eq(%size_prods.385, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2877) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2878 : str = aten::format(%14, %2867) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2878) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.278 : Tensor = aten::batch_norm(%input.277, %2865, %2866, %2863, %2864, %2862, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.279 : Tensor = aten::hardtanh_(%input.278, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2881 : Tensor = prim::GetAttr[name="weight"](%2819)
      %2882 : Tensor? = prim::GetAttr[name="bias"](%2819)
      %input.280 : Tensor = aten::conv2d(%input.279, %2881, %2882, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2887 : bool = prim::GetAttr[name="training"](%2820)
       = prim::If(%2887) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2888 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2820)
          %2889 : Tensor = aten::add(%2888, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2820, %2889)
          -> ()
        block1():
          -> ()
      %2890 : bool = prim::GetAttr[name="training"](%2820)
      %2891 : Tensor = prim::GetAttr[name="running_mean"](%2820)
      %2892 : Tensor = prim::GetAttr[name="running_var"](%2820)
      %2893 : Tensor = prim::GetAttr[name="weight"](%2820)
      %2894 : Tensor = prim::GetAttr[name="bias"](%2820)
       = prim::If(%2890) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2895 : int[] = aten::size(%input.280) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.388 : int = aten::__getitem__(%2895, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2897 : int = aten::len(%2895) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2898 : int = aten::sub(%2897, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.389 : int = prim::Loop(%2898, %13, %size_prods.388) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.98 : int, %size_prods.390 : int):
              %2902 : int = aten::add(%i.98, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2903 : int = aten::__getitem__(%2895, %2902) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.391 : int = aten::mul(%size_prods.390, %2903) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.391)
          %2905 : bool = aten::eq(%size_prods.389, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2905) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2906 : str = aten::format(%14, %2895) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2906) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.281 : Tensor = aten::batch_norm(%input.280, %2893, %2894, %2891, %2892, %2890, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2908 : Tensor = aten::add(%input.33, %input.281, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:99:19
      -> (%2908)
    block1():
      %2909 : __torch__.torch.nn.modules.container.___torch_mangle_71.Sequential = prim::GetAttr[name="conv"](%38)
      %2910 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_67.ConvBNActivation = prim::GetAttr[name="0"](%2909)
      %2911 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_69.ConvBNActivation = prim::GetAttr[name="1"](%2909)
      %2912 : __torch__.torch.nn.modules.conv.___torch_mangle_70.Conv2d = prim::GetAttr[name="2"](%2909)
      %2913 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_62.BatchNorm2d = prim::GetAttr[name="3"](%2909)
      %2914 : __torch__.torch.nn.modules.conv.___torch_mangle_65.Conv2d = prim::GetAttr[name="0"](%2910)
      %2915 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_66.BatchNorm2d = prim::GetAttr[name="1"](%2910)
      %2916 : Tensor = prim::GetAttr[name="weight"](%2914)
      %2917 : Tensor? = prim::GetAttr[name="bias"](%2914)
      %input.282 : Tensor = aten::conv2d(%input.33, %2916, %2917, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2922 : bool = prim::GetAttr[name="training"](%2915)
       = prim::If(%2922) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2923 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2915)
          %2924 : Tensor = aten::add(%2923, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2915, %2924)
          -> ()
        block1():
          -> ()
      %2925 : bool = prim::GetAttr[name="training"](%2915)
      %2926 : Tensor = prim::GetAttr[name="running_mean"](%2915)
      %2927 : Tensor = prim::GetAttr[name="running_var"](%2915)
      %2928 : Tensor = prim::GetAttr[name="weight"](%2915)
      %2929 : Tensor = prim::GetAttr[name="bias"](%2915)
       = prim::If(%2925) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2930 : int[] = aten::size(%input.282) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.392 : int = aten::__getitem__(%2930, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2932 : int = aten::len(%2930) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2933 : int = aten::sub(%2932, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.393 : int = prim::Loop(%2933, %13, %size_prods.392) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.99 : int, %size_prods.394 : int):
              %2937 : int = aten::add(%i.99, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2938 : int = aten::__getitem__(%2930, %2937) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.395 : int = aten::mul(%size_prods.394, %2938) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.395)
          %2940 : bool = aten::eq(%size_prods.393, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2940) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2941 : str = aten::format(%14, %2930) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2941) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.283 : Tensor = aten::batch_norm(%input.282, %2928, %2929, %2926, %2927, %2925, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.284 : Tensor = aten::hardtanh_(%input.283, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2944 : __torch__.torch.nn.modules.conv.___torch_mangle_68.Conv2d = prim::GetAttr[name="0"](%2911)
      %2945 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_66.BatchNorm2d = prim::GetAttr[name="1"](%2911)
      %2946 : Tensor = prim::GetAttr[name="weight"](%2944)
      %2947 : Tensor? = prim::GetAttr[name="bias"](%2944)
      %input.285 : Tensor = aten::conv2d(%input.284, %2946, %2947, %3236, %3236, %3236, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2952 : bool = prim::GetAttr[name="training"](%2945)
       = prim::If(%2952) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2953 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2945)
          %2954 : Tensor = aten::add(%2953, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2945, %2954)
          -> ()
        block1():
          -> ()
      %2955 : bool = prim::GetAttr[name="training"](%2945)
      %2956 : Tensor = prim::GetAttr[name="running_mean"](%2945)
      %2957 : Tensor = prim::GetAttr[name="running_var"](%2945)
      %2958 : Tensor = prim::GetAttr[name="weight"](%2945)
      %2959 : Tensor = prim::GetAttr[name="bias"](%2945)
       = prim::If(%2955) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2960 : int[] = aten::size(%input.285) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.396 : int = aten::__getitem__(%2960, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2962 : int = aten::len(%2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2963 : int = aten::sub(%2962, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.397 : int = prim::Loop(%2963, %13, %size_prods.396) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.100 : int, %size_prods.398 : int):
              %2967 : int = aten::add(%i.100, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2968 : int = aten::__getitem__(%2960, %2967) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.399 : int = aten::mul(%size_prods.398, %2968) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.399)
          %2970 : bool = aten::eq(%size_prods.397, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2970) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2971 : str = aten::format(%14, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2971) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.286 : Tensor = aten::batch_norm(%input.285, %2958, %2959, %2956, %2957, %2955, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.287 : Tensor = aten::hardtanh_(%input.286, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %2974 : Tensor = prim::GetAttr[name="weight"](%2912)
      %2975 : Tensor? = prim::GetAttr[name="bias"](%2912)
      %input.288 : Tensor = aten::conv2d(%input.287, %2974, %2975, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2980 : bool = prim::GetAttr[name="training"](%2913)
       = prim::If(%2980) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2981 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2913)
          %2982 : Tensor = aten::add(%2981, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2913, %2982)
          -> ()
        block1():
          -> ()
      %2983 : bool = prim::GetAttr[name="training"](%2913)
      %2984 : Tensor = prim::GetAttr[name="running_mean"](%2913)
      %2985 : Tensor = prim::GetAttr[name="running_var"](%2913)
      %2986 : Tensor = prim::GetAttr[name="weight"](%2913)
      %2987 : Tensor = prim::GetAttr[name="bias"](%2913)
       = prim::If(%2983) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2988 : int[] = aten::size(%input.288) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.400 : int = aten::__getitem__(%2988, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2990 : int = aten::len(%2988) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2991 : int = aten::sub(%2990, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.401 : int = prim::Loop(%2991, %13, %size_prods.400) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.101 : int, %size_prods.402 : int):
              %2995 : int = aten::add(%i.101, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2996 : int = aten::__getitem__(%2988, %2995) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.403 : int = aten::mul(%size_prods.402, %2996) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.403)
          %2998 : bool = aten::eq(%size_prods.401, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2998) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2999 : str = aten::format(%14, %2988) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2999) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.289 : Tensor = aten::batch_norm(%input.288, %2986, %2987, %2984, %2985, %2983, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.289)
  %3001 : bool = prim::GetAttr[name="use_res_connect"](%39)
  %input.37 : Tensor = prim::If(%3001) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:98:8
    block0():
      %3003 : __torch__.torch.nn.modules.container.___torch_mangle_75.Sequential = prim::GetAttr[name="conv"](%39)
      %3004 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_67.ConvBNActivation = prim::GetAttr[name="0"](%3003)
      %3005 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_69.ConvBNActivation = prim::GetAttr[name="1"](%3003)
      %3006 : __torch__.torch.nn.modules.conv.___torch_mangle_73.Conv2d = prim::GetAttr[name="2"](%3003)
      %3007 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_74.BatchNorm2d = prim::GetAttr[name="3"](%3003)
      %3008 : __torch__.torch.nn.modules.conv.___torch_mangle_65.Conv2d = prim::GetAttr[name="0"](%3004)
      %3009 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_66.BatchNorm2d = prim::GetAttr[name="1"](%3004)
      %3010 : Tensor = prim::GetAttr[name="weight"](%3008)
      %3011 : Tensor? = prim::GetAttr[name="bias"](%3008)
      %input.12 : Tensor = aten::conv2d(%input.35, %3010, %3011, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3016 : bool = prim::GetAttr[name="training"](%3009)
       = prim::If(%3016) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3017 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3009)
          %3018 : Tensor = aten::add(%3017, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3009, %3018)
          -> ()
        block1():
          -> ()
      %3019 : bool = prim::GetAttr[name="training"](%3009)
      %3020 : Tensor = prim::GetAttr[name="running_mean"](%3009)
      %3021 : Tensor = prim::GetAttr[name="running_var"](%3009)
      %3022 : Tensor = prim::GetAttr[name="weight"](%3009)
      %3023 : Tensor = prim::GetAttr[name="bias"](%3009)
       = prim::If(%3019) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3024 : int[] = aten::size(%input.12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.12 : int = aten::__getitem__(%3024, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3026 : int = aten::len(%3024) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3027 : int = aten::sub(%3026, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.13 : int = prim::Loop(%3027, %13, %size_prods.12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.4 : int, %size_prods.14 : int):
              %3031 : int = aten::add(%i.4, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3032 : int = aten::__getitem__(%3024, %3031) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.15 : int = aten::mul(%size_prods.14, %3032) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.15)
          %3034 : bool = aten::eq(%size_prods.13, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3034) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3035 : str = aten::format(%14, %3024) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3035) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.13 : Tensor = aten::batch_norm(%input.12, %3022, %3023, %3020, %3021, %3019, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.292 : Tensor = aten::hardtanh_(%input.13, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %3038 : __torch__.torch.nn.modules.conv.___torch_mangle_68.Conv2d = prim::GetAttr[name="0"](%3005)
      %3039 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_66.BatchNorm2d = prim::GetAttr[name="1"](%3005)
      %3040 : Tensor = prim::GetAttr[name="weight"](%3038)
      %3041 : Tensor? = prim::GetAttr[name="bias"](%3038)
      %input.14 : Tensor = aten::conv2d(%input.292, %3040, %3041, %3236, %3236, %3236, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3046 : bool = prim::GetAttr[name="training"](%3039)
       = prim::If(%3046) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3047 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3039)
          %3048 : Tensor = aten::add(%3047, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3039, %3048)
          -> ()
        block1():
          -> ()
      %3049 : bool = prim::GetAttr[name="training"](%3039)
      %3050 : Tensor = prim::GetAttr[name="running_mean"](%3039)
      %3051 : Tensor = prim::GetAttr[name="running_var"](%3039)
      %3052 : Tensor = prim::GetAttr[name="weight"](%3039)
      %3053 : Tensor = prim::GetAttr[name="bias"](%3039)
       = prim::If(%3049) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3054 : int[] = aten::size(%input.14) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.16 : int = aten::__getitem__(%3054, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3056 : int = aten::len(%3054) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3057 : int = aten::sub(%3056, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.17 : int = prim::Loop(%3057, %13, %size_prods.16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.5 : int, %size_prods.18 : int):
              %3061 : int = aten::add(%i.5, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3062 : int = aten::__getitem__(%3054, %3061) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.19 : int = aten::mul(%size_prods.18, %3062) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.19)
          %3064 : bool = aten::eq(%size_prods.17, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3064) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3065 : str = aten::format(%14, %3054) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3065) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.15 : Tensor = aten::batch_norm(%input.14, %3052, %3053, %3050, %3051, %3049, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.16 : Tensor = aten::hardtanh_(%input.15, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %3068 : Tensor = prim::GetAttr[name="weight"](%3006)
      %3069 : Tensor? = prim::GetAttr[name="bias"](%3006)
      %input.17 : Tensor = aten::conv2d(%input.16, %3068, %3069, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3074 : bool = prim::GetAttr[name="training"](%3007)
       = prim::If(%3074) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3075 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3007)
          %3076 : Tensor = aten::add(%3075, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3007, %3076)
          -> ()
        block1():
          -> ()
      %3077 : bool = prim::GetAttr[name="training"](%3007)
      %3078 : Tensor = prim::GetAttr[name="running_mean"](%3007)
      %3079 : Tensor = prim::GetAttr[name="running_var"](%3007)
      %3080 : Tensor = prim::GetAttr[name="weight"](%3007)
      %3081 : Tensor = prim::GetAttr[name="bias"](%3007)
       = prim::If(%3077) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3082 : int[] = aten::size(%input.17) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.20 : int = aten::__getitem__(%3082, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3084 : int = aten::len(%3082) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3085 : int = aten::sub(%3084, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.21 : int = prim::Loop(%3085, %13, %size_prods.20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.6 : int, %size_prods.22 : int):
              %3089 : int = aten::add(%i.6, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3090 : int = aten::__getitem__(%3082, %3089) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.23 : int = aten::mul(%size_prods.22, %3090) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.23)
          %3092 : bool = aten::eq(%size_prods.21, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3092) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3093 : str = aten::format(%14, %3082) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3093) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.18 : Tensor = aten::batch_norm(%input.17, %3080, %3081, %3078, %3079, %3077, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %3095 : Tensor = aten::add(%input.35, %input.18, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:99:19
      -> (%3095)
    block1():
      %3096 : __torch__.torch.nn.modules.container.___torch_mangle_75.Sequential = prim::GetAttr[name="conv"](%39)
      %3097 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_67.ConvBNActivation = prim::GetAttr[name="0"](%3096)
      %3098 : __torch__.torchvision.models.mobilenetv2.___torch_mangle_69.ConvBNActivation = prim::GetAttr[name="1"](%3096)
      %3099 : __torch__.torch.nn.modules.conv.___torch_mangle_73.Conv2d = prim::GetAttr[name="2"](%3096)
      %3100 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_74.BatchNorm2d = prim::GetAttr[name="3"](%3096)
      %3101 : __torch__.torch.nn.modules.conv.___torch_mangle_65.Conv2d = prim::GetAttr[name="0"](%3097)
      %3102 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_66.BatchNorm2d = prim::GetAttr[name="1"](%3097)
      %3103 : Tensor = prim::GetAttr[name="weight"](%3101)
      %3104 : Tensor? = prim::GetAttr[name="bias"](%3101)
      %input.11 : Tensor = aten::conv2d(%input.35, %3103, %3104, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3109 : bool = prim::GetAttr[name="training"](%3102)
       = prim::If(%3109) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3110 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3102)
          %3111 : Tensor = aten::add(%3110, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3102, %3111)
          -> ()
        block1():
          -> ()
      %3112 : bool = prim::GetAttr[name="training"](%3102)
      %3113 : Tensor = prim::GetAttr[name="running_mean"](%3102)
      %3114 : Tensor = prim::GetAttr[name="running_var"](%3102)
      %3115 : Tensor = prim::GetAttr[name="weight"](%3102)
      %3116 : Tensor = prim::GetAttr[name="bias"](%3102)
       = prim::If(%3112) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3117 : int[] = aten::size(%input.11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.2 : int = aten::__getitem__(%3117, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3119 : int = aten::len(%3117) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3120 : int = aten::sub(%3119, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.4 : int = prim::Loop(%3120, %13, %size_prods.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.2 : int, %size_prods.7 : int):
              %3124 : int = aten::add(%i.2, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3125 : int = aten::__getitem__(%3117, %3124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.5 : int = aten::mul(%size_prods.7, %3125) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.5)
          %3127 : bool = aten::eq(%size_prods.4, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3127) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3128 : str = aten::format(%14, %3117) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.10 : Tensor = aten::batch_norm(%input.11, %3115, %3116, %3113, %3114, %3112, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.4 : Tensor = aten::hardtanh_(%input.10, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %3131 : __torch__.torch.nn.modules.conv.___torch_mangle_68.Conv2d = prim::GetAttr[name="0"](%3098)
      %3132 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_66.BatchNorm2d = prim::GetAttr[name="1"](%3098)
      %3133 : Tensor = prim::GetAttr[name="weight"](%3131)
      %3134 : Tensor? = prim::GetAttr[name="bias"](%3131)
      %input.290 : Tensor = aten::conv2d(%input.4, %3133, %3134, %3236, %3236, %3236, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3139 : bool = prim::GetAttr[name="training"](%3132)
       = prim::If(%3139) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3140 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3132)
          %3141 : Tensor = aten::add(%3140, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3132, %3141)
          -> ()
        block1():
          -> ()
      %3142 : bool = prim::GetAttr[name="training"](%3132)
      %3143 : Tensor = prim::GetAttr[name="running_mean"](%3132)
      %3144 : Tensor = prim::GetAttr[name="running_var"](%3132)
      %3145 : Tensor = prim::GetAttr[name="weight"](%3132)
      %3146 : Tensor = prim::GetAttr[name="bias"](%3132)
       = prim::If(%3142) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3147 : int[] = aten::size(%input.290) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.8 : int = aten::__getitem__(%3147, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3149 : int = aten::len(%3147) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3150 : int = aten::sub(%3149, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.9 : int = prim::Loop(%3150, %13, %size_prods.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.3 : int, %size_prods.10 : int):
              %3154 : int = aten::add(%i.3, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3155 : int = aten::__getitem__(%3147, %3154) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.11 : int = aten::mul(%size_prods.10, %3155) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.11)
          %3157 : bool = aten::eq(%size_prods.9, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3157) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3158 : str = aten::format(%14, %3147) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3158) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.291 : Tensor = aten::batch_norm(%input.290, %3145, %3146, %3143, %3144, %3142, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.6 : Tensor = aten::hardtanh_(%input.291, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
      %3161 : Tensor = prim::GetAttr[name="weight"](%3099)
      %3162 : Tensor? = prim::GetAttr[name="bias"](%3099)
      %input.8 : Tensor = aten::conv2d(%input.6, %3161, %3162, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3167 : bool = prim::GetAttr[name="training"](%3100)
       = prim::If(%3167) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3168 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3100)
          %3169 : Tensor = aten::add(%3168, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3100, %3169)
          -> ()
        block1():
          -> ()
      %3170 : bool = prim::GetAttr[name="training"](%3100)
      %3171 : Tensor = prim::GetAttr[name="running_mean"](%3100)
      %3172 : Tensor = prim::GetAttr[name="running_var"](%3100)
      %3173 : Tensor = prim::GetAttr[name="weight"](%3100)
      %3174 : Tensor = prim::GetAttr[name="bias"](%3100)
       = prim::If(%3170) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3175 : int[] = aten::size(%input.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.404 : int = aten::__getitem__(%3175, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3177 : int = aten::len(%3175) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3178 : int = aten::sub(%3177, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.405 : int = prim::Loop(%3178, %13, %size_prods.404) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.102 : int, %size_prods.406 : int):
              %3182 : int = aten::add(%i.102, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3183 : int = aten::__getitem__(%3175, %3182) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.407 : int = aten::mul(%size_prods.406, %3183) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%13, %size_prods.407)
          %3185 : bool = aten::eq(%size_prods.405, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3185) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3186 : str = aten::format(%14, %3175) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3186) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.9 : Tensor = aten::batch_norm(%input.8, %3173, %3174, %3171, %3172, %3170, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      -> (%input.9)
  %3188 : __torch__.torch.nn.modules.conv.___torch_mangle_77.Conv2d = prim::GetAttr[name="0"](%40)
  %3189 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_78.BatchNorm2d = prim::GetAttr[name="1"](%40)
  %3190 : Tensor = prim::GetAttr[name="weight"](%3188)
  %3191 : Tensor? = prim::GetAttr[name="bias"](%3188)
  %input.7 : Tensor = aten::conv2d(%input.37, %3190, %3191, %3236, %3242, %3236, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %3196 : bool = prim::GetAttr[name="training"](%3189)
   = prim::If(%3196) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %3197 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3189)
      %3198 : Tensor = aten::add(%3197, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%3189, %3198)
      -> ()
    block1():
      -> ()
  %3199 : bool = prim::GetAttr[name="training"](%3189)
  %3200 : Tensor = prim::GetAttr[name="running_mean"](%3189)
  %3201 : Tensor = prim::GetAttr[name="running_var"](%3189)
  %3202 : Tensor = prim::GetAttr[name="weight"](%3189)
  %3203 : Tensor = prim::GetAttr[name="bias"](%3189)
   = prim::If(%3199) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %3204 : int[] = aten::size(%input.7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.1 : int = aten::__getitem__(%3204, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %3206 : int = aten::len(%3204) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %3207 : int = aten::sub(%3206, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods : int = prim::Loop(%3207, %13, %size_prods.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.1 : int, %size_prods.6 : int):
          %3211 : int = aten::add(%i.1, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %3212 : int = aten::__getitem__(%3204, %3211) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.3 : int = aten::mul(%size_prods.6, %3212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%13, %size_prods.3)
      %3214 : bool = aten::eq(%size_prods, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%3214) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %3215 : str = aten::format(%14, %3204) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%3215) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.39 : Tensor = aten::batch_norm(%input.7, %3202, %3203, %3200, %3201, %3199, %15, %16, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %x.3 : Tensor = aten::hardtanh_(%input.39, %17, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1255:17
  %3219 : int[] = aten::size(%x.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1036:51
  %3220 : int = aten::len(%3219) # <string>:5:9
  %3221 : bool = aten::gt(%3220, %12) # <string>:5:9
   = prim::If(%3221) # <string>:5:2
    block0():
      -> ()
    block1():
       = prim::RaiseException(%19) # <string>:5:2
      -> ()
  %3222 : Tensor = aten::adaptive_avg_pool2d(%x.3, %3236) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
  %3223 : int[] = aten::size(%x.3) # <string>:7:9
  %3224 : int = aten::__getitem__(%3223, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:195:65
  %3225 : int[] = prim::ListConstruct(%3224, %2)
  %x.6 : Tensor = aten::reshape(%3222, %3225) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/mobilenetv2.py:195:12
  %3227 : __torch__.torch.nn.modules.container.___torch_mangle_81.Sequential = prim::GetAttr[name="classifier"](%self)
  %3228 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="0"](%3227)
  %3229 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="1"](%3227)
  %3230 : bool = prim::GetAttr[name="training"](%3228)
  %input.3 : Tensor = aten::dropout(%x.6, %20, %3230) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
  %3232 : Tensor = prim::GetAttr[name="weight"](%3229)
  %3233 : Tensor = prim::GetAttr[name="bias"](%3229)
  %x.8 : Tensor = aten::linear(%input.3, %3232, %3233) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
  return (%x.8)

