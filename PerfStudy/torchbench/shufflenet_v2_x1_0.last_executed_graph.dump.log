Dump Graph IR for shufflenet_v2_x1_0 using example inputs:
graph(%self : __torch__.torchvision.models.shufflenetv2.ShuffleNetV2,
      %x.1 : Tensor):
  %3869 : int[] = prim::Constant[value=[2, 3]]()
  %3561 : int[] = prim::Constant[value=[0, 0]]()
  %3556 : int[] = prim::Constant[value=[3, 3]]()
  %3554 : int[] = prim::Constant[value=[1, 1]]()
  %3553 : int[] = prim::Constant[value=[2, 2]]()
  %16 : int = prim::Constant[value=232]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %15 : int = prim::Constant[value=116]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %14 : int = prim::Constant[value=-1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:32:26
  %13 : int = prim::Constant[value=24]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %12 : int = prim::Constant[value=58]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %11 : int = prim::Constant[value=1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:24
  %10 : bool = prim::Constant[value=1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2147:81
  %9 : int = prim::Constant[value=0]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:22
  %8 : str = prim::Constant[value="Expected more than 1 value per channel when training, got input size {}"]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
  %7 : float = prim::Constant[value=0.10000000000000001]()
  %6 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:140:77
  %4 : int = prim::Constant[value=2]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:156:20
  %3 : bool = prim::Constant[value=0]()
  %2 : None = prim::Constant()
  %17 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="conv1"](%self)
  %18 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name="0"](%17)
  %19 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%17)
  %20 : Tensor = prim::GetAttr[name="weight"](%18)
  %21 : Tensor? = prim::GetAttr[name="bias"](%18)
  %input.185 : Tensor = aten::conv2d(%x.1, %20, %21, %3553, %3554, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %26 : bool = prim::GetAttr[name="training"](%19)
   = prim::If(%26) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %27 : Tensor = prim::GetAttr[name="num_batches_tracked"](%19)
      %28 : Tensor = aten::add(%27, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%19, %28)
      -> ()
    block1():
      -> ()
  %29 : bool = prim::GetAttr[name="training"](%19)
  %30 : Tensor = prim::GetAttr[name="running_mean"](%19)
  %31 : Tensor = prim::GetAttr[name="running_var"](%19)
  %32 : Tensor = prim::GetAttr[name="weight"](%19)
  %33 : Tensor = prim::GetAttr[name="bias"](%19)
   = prim::If(%29) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %34 : int[] = aten::size(%input.185) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.272 : int = aten::__getitem__(%34, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %36 : int = aten::len(%34) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %37 : int = aten::sub(%36, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.273 : int = prim::Loop(%37, %10, %size_prods.272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.69 : int, %size_prods.274 : int):
          %41 : int = aten::add(%i.69, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %42 : int = aten::__getitem__(%34, %41) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.275 : int = aten::mul(%size_prods.274, %42) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%10, %size_prods.275)
      %44 : bool = aten::eq(%size_prods.273, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%44) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %45 : str = aten::format(%8, %34) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%45) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.184 : Tensor = aten::batch_norm(%input.185, %32, %33, %30, %31, %29, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %x.3 : Tensor = aten::relu_(%input.184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %x.31 : Tensor = aten::max_pool2d(%x.3, %3556, %3553, %3554, %3554, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:659:11
  %53 : __torch__.torch.nn.modules.container.___torch_mangle_11.Sequential = prim::GetAttr[name="stage2"](%self)
  %54 : __torch__.torchvision.models.shufflenetv2.InvertedResidual = prim::GetAttr[name="0"](%53)
  %55 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_10.InvertedResidual = prim::GetAttr[name="1"](%53)
  %56 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_10.InvertedResidual = prim::GetAttr[name="2"](%53)
  %57 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_10.InvertedResidual = prim::GetAttr[name="3"](%53)
  %58 : int = prim::GetAttr[name="stride"](%54)
  %59 : bool = aten::eq(%58, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:11
  %out.8 : Tensor = prim::If(%59) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:8
    block0():
      %3521 : Tensor, %3522 : Tensor = prim::ConstantChunk[chunks=2, dim=1](%x.31)
      %64 : __torch__.torch.nn.modules.container.___torch_mangle_6.Sequential = prim::GetAttr[name="branch2"](%54)
      %65 : __torch__.torch.nn.modules.conv.___torch_mangle_1.Conv2d = prim::GetAttr[name="0"](%64)
      %66 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="1"](%64)
      %67 : __torch__.torch.nn.modules.conv.___torch_mangle_4.Conv2d = prim::GetAttr[name="3"](%64)
      %68 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="4"](%64)
      %69 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="5"](%64)
      %70 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="6"](%64)
      %71 : Tensor = prim::GetAttr[name="weight"](%65)
      %72 : Tensor? = prim::GetAttr[name="bias"](%65)
      %input.166 : Tensor = aten::conv2d(%3522, %71, %72, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %77 : bool = prim::GetAttr[name="training"](%66)
       = prim::If(%77) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %78 : Tensor = prim::GetAttr[name="num_batches_tracked"](%66)
          %79 : Tensor = aten::add(%78, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%66, %79)
          -> ()
        block1():
          -> ()
      %80 : bool = prim::GetAttr[name="training"](%66)
      %81 : Tensor = prim::GetAttr[name="running_mean"](%66)
      %82 : Tensor = prim::GetAttr[name="running_var"](%66)
      %83 : Tensor = prim::GetAttr[name="weight"](%66)
      %84 : Tensor = prim::GetAttr[name="bias"](%66)
       = prim::If(%80) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %85 : int[] = aten::size(%input.166) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.276 : int = aten::__getitem__(%85, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %87 : int = aten::len(%85) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %88 : int = aten::sub(%87, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.277 : int = prim::Loop(%88, %10, %size_prods.276) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.70 : int, %size_prods.278 : int):
              %92 : int = aten::add(%i.70, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %93 : int = aten::__getitem__(%85, %92) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.279 : int = aten::mul(%size_prods.278, %93) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.279)
          %95 : bool = aten::eq(%size_prods.277, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%95) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %96 : str = aten::format(%8, %85) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%96) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.183 : Tensor = aten::batch_norm(%input.166, %83, %84, %81, %82, %80, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.200 : Tensor = aten::relu_(%input.183) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %99 : Tensor = prim::GetAttr[name="weight"](%67)
      %100 : Tensor? = prim::GetAttr[name="bias"](%67)
      %input.217 : Tensor = aten::conv2d(%input.200, %99, %100, %3553, %3554, %3554, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %105 : bool = prim::GetAttr[name="training"](%68)
       = prim::If(%105) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %106 : Tensor = prim::GetAttr[name="num_batches_tracked"](%68)
          %107 : Tensor = aten::add(%106, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%68, %107)
          -> ()
        block1():
          -> ()
      %108 : bool = prim::GetAttr[name="training"](%68)
      %109 : Tensor = prim::GetAttr[name="running_mean"](%68)
      %110 : Tensor = prim::GetAttr[name="running_var"](%68)
      %111 : Tensor = prim::GetAttr[name="weight"](%68)
      %112 : Tensor = prim::GetAttr[name="bias"](%68)
       = prim::If(%108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %113 : int[] = aten::size(%input.217) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.280 : int = aten::__getitem__(%113, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %115 : int = aten::len(%113) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %116 : int = aten::sub(%115, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.281 : int = prim::Loop(%116, %10, %size_prods.280) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.71 : int, %size_prods.282 : int):
              %120 : int = aten::add(%i.71, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %121 : int = aten::__getitem__(%113, %120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.283 : int = aten::mul(%size_prods.282, %121) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.283)
          %123 : bool = aten::eq(%size_prods.281, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%123) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %124 : str = aten::format(%8, %113) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.186 : Tensor = aten::batch_norm(%input.217, %111, %112, %109, %110, %108, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %126 : Tensor = prim::GetAttr[name="weight"](%69)
      %127 : Tensor? = prim::GetAttr[name="bias"](%69)
      %input.149 : Tensor = aten::conv2d(%input.186, %126, %127, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %132 : bool = prim::GetAttr[name="training"](%70)
       = prim::If(%132) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %133 : Tensor = prim::GetAttr[name="num_batches_tracked"](%70)
          %134 : Tensor = aten::add(%133, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%70, %134)
          -> ()
        block1():
          -> ()
      %135 : bool = prim::GetAttr[name="training"](%70)
      %136 : Tensor = prim::GetAttr[name="running_mean"](%70)
      %137 : Tensor = prim::GetAttr[name="running_var"](%70)
      %138 : Tensor = prim::GetAttr[name="weight"](%70)
      %139 : Tensor = prim::GetAttr[name="bias"](%70)
       = prim::If(%135) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %140 : int[] = aten::size(%input.149) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.200 : int = aten::__getitem__(%140, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %142 : int = aten::len(%140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %143 : int = aten::sub(%142, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.201 : int = prim::Loop(%143, %10, %size_prods.200) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.51 : int, %size_prods.202 : int):
              %147 : int = aten::add(%i.51, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %148 : int = aten::__getitem__(%140, %147) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.203 : int = aten::mul(%size_prods.202, %148) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.203)
          %150 : bool = aten::eq(%size_prods.201, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%150) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %151 : str = aten::format(%8, %140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%151) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.192 : Tensor = aten::batch_norm(%input.149, %138, %139, %136, %137, %135, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.193 : Tensor = aten::relu_(%input.192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %154 : Tensor[] = prim::ListConstruct(%3521, %input.193)
      %out.31 : Tensor = aten::cat(%154, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:90:18
      -> (%out.31)
    block1():
      %156 : __torch__.torch.nn.modules.container.___torch_mangle_3.Sequential = prim::GetAttr[name="branch1"](%54)
      %157 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="0"](%156)
      %158 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="1"](%156)
      %159 : __torch__.torch.nn.modules.conv.___torch_mangle_1.Conv2d = prim::GetAttr[name="2"](%156)
      %160 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="3"](%156)
      %161 : Tensor = prim::GetAttr[name="weight"](%157)
      %162 : Tensor? = prim::GetAttr[name="bias"](%157)
      %input.187 : Tensor = aten::conv2d(%x.31, %161, %162, %3553, %3554, %3554, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %167 : bool = prim::GetAttr[name="training"](%158)
       = prim::If(%167) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %168 : Tensor = prim::GetAttr[name="num_batches_tracked"](%158)
          %169 : Tensor = aten::add(%168, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%158, %169)
          -> ()
        block1():
          -> ()
      %170 : bool = prim::GetAttr[name="training"](%158)
      %171 : Tensor = prim::GetAttr[name="running_mean"](%158)
      %172 : Tensor = prim::GetAttr[name="running_var"](%158)
      %173 : Tensor = prim::GetAttr[name="weight"](%158)
      %174 : Tensor = prim::GetAttr[name="bias"](%158)
       = prim::If(%170) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %175 : int[] = aten::size(%input.187) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.204 : int = aten::__getitem__(%175, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %177 : int = aten::len(%175) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %178 : int = aten::sub(%177, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.205 : int = prim::Loop(%178, %10, %size_prods.204) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.52 : int, %size_prods.206 : int):
              %182 : int = aten::add(%i.52, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %183 : int = aten::__getitem__(%175, %182) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.207 : int = aten::mul(%size_prods.206, %183) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.207)
          %185 : bool = aten::eq(%size_prods.205, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%185) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %186 : str = aten::format(%8, %175) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%186) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.189 : Tensor = aten::batch_norm(%input.187, %173, %174, %171, %172, %170, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %188 : Tensor = prim::GetAttr[name="weight"](%159)
      %189 : Tensor? = prim::GetAttr[name="bias"](%159)
      %input.190 : Tensor = aten::conv2d(%input.189, %188, %189, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %194 : bool = prim::GetAttr[name="training"](%160)
       = prim::If(%194) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %195 : Tensor = prim::GetAttr[name="num_batches_tracked"](%160)
          %196 : Tensor = aten::add(%195, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%160, %196)
          -> ()
        block1():
          -> ()
      %197 : bool = prim::GetAttr[name="training"](%160)
      %198 : Tensor = prim::GetAttr[name="running_mean"](%160)
      %199 : Tensor = prim::GetAttr[name="running_var"](%160)
      %200 : Tensor = prim::GetAttr[name="weight"](%160)
      %201 : Tensor = prim::GetAttr[name="bias"](%160)
       = prim::If(%197) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %202 : int[] = aten::size(%input.190) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.208 : int = aten::__getitem__(%202, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %204 : int = aten::len(%202) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %205 : int = aten::sub(%204, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.209 : int = prim::Loop(%205, %10, %size_prods.208) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.53 : int, %size_prods.210 : int):
              %209 : int = aten::add(%i.53, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %210 : int = aten::__getitem__(%202, %209) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.211 : int = aten::mul(%size_prods.210, %210) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.211)
          %212 : bool = aten::eq(%size_prods.209, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %213 : str = aten::format(%8, %202) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%213) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.197 : Tensor = aten::batch_norm(%input.190, %200, %201, %198, %199, %197, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.198 : Tensor = aten::relu_(%input.197) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %216 : __torch__.torch.nn.modules.container.___torch_mangle_6.Sequential = prim::GetAttr[name="branch2"](%54)
      %217 : __torch__.torch.nn.modules.conv.___torch_mangle_1.Conv2d = prim::GetAttr[name="0"](%216)
      %218 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="1"](%216)
      %219 : __torch__.torch.nn.modules.conv.___torch_mangle_4.Conv2d = prim::GetAttr[name="3"](%216)
      %220 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="4"](%216)
      %221 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="5"](%216)
      %222 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="6"](%216)
      %223 : Tensor = prim::GetAttr[name="weight"](%217)
      %224 : Tensor? = prim::GetAttr[name="bias"](%217)
      %input.191 : Tensor = aten::conv2d(%x.31, %223, %224, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %229 : bool = prim::GetAttr[name="training"](%218)
       = prim::If(%229) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %230 : Tensor = prim::GetAttr[name="num_batches_tracked"](%218)
          %231 : Tensor = aten::add(%230, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%218, %231)
          -> ()
        block1():
          -> ()
      %232 : bool = prim::GetAttr[name="training"](%218)
      %233 : Tensor = prim::GetAttr[name="running_mean"](%218)
      %234 : Tensor = prim::GetAttr[name="running_var"](%218)
      %235 : Tensor = prim::GetAttr[name="weight"](%218)
      %236 : Tensor = prim::GetAttr[name="bias"](%218)
       = prim::If(%232) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %237 : int[] = aten::size(%input.191) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.212 : int = aten::__getitem__(%237, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %239 : int = aten::len(%237) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %240 : int = aten::sub(%239, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.213 : int = prim::Loop(%240, %10, %size_prods.212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.54 : int, %size_prods.214 : int):
              %244 : int = aten::add(%i.54, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %245 : int = aten::__getitem__(%237, %244) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.215 : int = aten::mul(%size_prods.214, %245) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.215)
          %247 : bool = aten::eq(%size_prods.213, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%247) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %248 : str = aten::format(%8, %237) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%248) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.194 : Tensor = aten::batch_norm(%input.191, %235, %236, %233, %234, %232, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.195 : Tensor = aten::relu_(%input.194) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %251 : Tensor = prim::GetAttr[name="weight"](%219)
      %252 : Tensor? = prim::GetAttr[name="bias"](%219)
      %input.196 : Tensor = aten::conv2d(%input.195, %251, %252, %3553, %3554, %3554, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %257 : bool = prim::GetAttr[name="training"](%220)
       = prim::If(%257) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %258 : Tensor = prim::GetAttr[name="num_batches_tracked"](%220)
          %259 : Tensor = aten::add(%258, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%220, %259)
          -> ()
        block1():
          -> ()
      %260 : bool = prim::GetAttr[name="training"](%220)
      %261 : Tensor = prim::GetAttr[name="running_mean"](%220)
      %262 : Tensor = prim::GetAttr[name="running_var"](%220)
      %263 : Tensor = prim::GetAttr[name="weight"](%220)
      %264 : Tensor = prim::GetAttr[name="bias"](%220)
       = prim::If(%260) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %265 : int[] = aten::size(%input.196) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.216 : int = aten::__getitem__(%265, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %267 : int = aten::len(%265) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %268 : int = aten::sub(%267, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.217 : int = prim::Loop(%268, %10, %size_prods.216) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.55 : int, %size_prods.218 : int):
              %272 : int = aten::add(%i.55, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %273 : int = aten::__getitem__(%265, %272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.219 : int = aten::mul(%size_prods.218, %273) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.219)
          %275 : bool = aten::eq(%size_prods.217, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%275) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %276 : str = aten::format(%8, %265) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%276) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.199 : Tensor = aten::batch_norm(%input.196, %263, %264, %261, %262, %260, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %278 : Tensor = prim::GetAttr[name="weight"](%221)
      %279 : Tensor? = prim::GetAttr[name="bias"](%221)
      %input.144 : Tensor = aten::conv2d(%input.199, %278, %279, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %284 : bool = prim::GetAttr[name="training"](%222)
       = prim::If(%284) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %285 : Tensor = prim::GetAttr[name="num_batches_tracked"](%222)
          %286 : Tensor = aten::add(%285, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%222, %286)
          -> ()
        block1():
          -> ()
      %287 : bool = prim::GetAttr[name="training"](%222)
      %288 : Tensor = prim::GetAttr[name="running_mean"](%222)
      %289 : Tensor = prim::GetAttr[name="running_var"](%222)
      %290 : Tensor = prim::GetAttr[name="weight"](%222)
      %291 : Tensor = prim::GetAttr[name="bias"](%222)
       = prim::If(%287) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %292 : int[] = aten::size(%input.144) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.220 : int = aten::__getitem__(%292, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %294 : int = aten::len(%292) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %295 : int = aten::sub(%294, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.221 : int = prim::Loop(%295, %10, %size_prods.220) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.56 : int, %size_prods.222 : int):
              %299 : int = aten::add(%i.56, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %300 : int = aten::__getitem__(%292, %299) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.223 : int = aten::mul(%size_prods.222, %300) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.223)
          %302 : bool = aten::eq(%size_prods.221, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%302) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %303 : str = aten::format(%8, %292) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%303) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.145 : Tensor = aten::batch_norm(%input.144, %290, %291, %288, %289, %287, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.146 : Tensor = aten::relu_(%input.145) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %306 : Tensor[] = prim::ListConstruct(%input.198, %input.146)
      %out.32 : Tensor = aten::cat(%306, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:92:18
      -> (%out.32)
  %308 : int[] = aten::size(%out.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:22:45
  %batchsize.11 : int, %num_channels.11 : int, %height.11 : int, %width.11 : int = prim::ListUnpack(%308)
  %channels_per_group.11 : int = aten::floordiv(%num_channels.11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:23:25
  %314 : int[] = prim::ListConstruct(%batchsize.11, %4, %channels_per_group.11, %height.11, %width.11)
  %x.32 : Tensor = aten::view(%out.8, %314) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:26:8
  %316 : Tensor = aten::transpose(%x.32, %11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %x.20 : Tensor = aten::contiguous(%316, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %318 : int[] = prim::ListConstruct(%batchsize.11, %14, %height.11, %width.11)
  %input.152 : Tensor = aten::view(%x.20, %318) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:32:8
  %320 : int = prim::GetAttr[name="stride"](%55)
  %321 : bool = aten::eq(%320, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:11
  %out.27 : Tensor = prim::If(%321) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:8
    block0():
      %3523 : Tensor, %3524 : Tensor = prim::ConstantChunk[chunks=2, dim=1](%input.152)
      %326 : __torch__.torch.nn.modules.container.___torch_mangle_9.Sequential = prim::GetAttr[name="branch2"](%55)
      %327 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="0"](%326)
      %328 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="1"](%326)
      %329 : __torch__.torch.nn.modules.conv.___torch_mangle_8.Conv2d = prim::GetAttr[name="3"](%326)
      %330 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="4"](%326)
      %331 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="5"](%326)
      %332 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="6"](%326)
      %333 : Tensor = prim::GetAttr[name="weight"](%327)
      %334 : Tensor? = prim::GetAttr[name="bias"](%327)
      %input.147 : Tensor = aten::conv2d(%3524, %333, %334, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %339 : bool = prim::GetAttr[name="training"](%328)
       = prim::If(%339) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %340 : Tensor = prim::GetAttr[name="num_batches_tracked"](%328)
          %341 : Tensor = aten::add(%340, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%328, %341)
          -> ()
        block1():
          -> ()
      %342 : bool = prim::GetAttr[name="training"](%328)
      %343 : Tensor = prim::GetAttr[name="running_mean"](%328)
      %344 : Tensor = prim::GetAttr[name="running_var"](%328)
      %345 : Tensor = prim::GetAttr[name="weight"](%328)
      %346 : Tensor = prim::GetAttr[name="bias"](%328)
       = prim::If(%342) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %347 : int[] = aten::size(%input.147) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.224 : int = aten::__getitem__(%347, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %349 : int = aten::len(%347) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %350 : int = aten::sub(%349, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.225 : int = prim::Loop(%350, %10, %size_prods.224) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.57 : int, %size_prods.226 : int):
              %354 : int = aten::add(%i.57, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %355 : int = aten::__getitem__(%347, %354) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.227 : int = aten::mul(%size_prods.226, %355) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.227)
          %357 : bool = aten::eq(%size_prods.225, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%357) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %358 : str = aten::format(%8, %347) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%358) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.148 : Tensor = aten::batch_norm(%input.147, %345, %346, %343, %344, %342, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.150 : Tensor = aten::relu_(%input.148) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %361 : Tensor = prim::GetAttr[name="weight"](%329)
      %362 : Tensor? = prim::GetAttr[name="bias"](%329)
      %input.151 : Tensor = aten::conv2d(%input.150, %361, %362, %3554, %3554, %3554, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %367 : bool = prim::GetAttr[name="training"](%330)
       = prim::If(%367) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %368 : Tensor = prim::GetAttr[name="num_batches_tracked"](%330)
          %369 : Tensor = aten::add(%368, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%330, %369)
          -> ()
        block1():
          -> ()
      %370 : bool = prim::GetAttr[name="training"](%330)
      %371 : Tensor = prim::GetAttr[name="running_mean"](%330)
      %372 : Tensor = prim::GetAttr[name="running_var"](%330)
      %373 : Tensor = prim::GetAttr[name="weight"](%330)
      %374 : Tensor = prim::GetAttr[name="bias"](%330)
       = prim::If(%370) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %375 : int[] = aten::size(%input.151) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.228 : int = aten::__getitem__(%375, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %377 : int = aten::len(%375) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %378 : int = aten::sub(%377, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.229 : int = prim::Loop(%378, %10, %size_prods.228) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.58 : int, %size_prods.230 : int):
              %382 : int = aten::add(%i.58, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %383 : int = aten::__getitem__(%375, %382) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.231 : int = aten::mul(%size_prods.230, %383) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.231)
          %385 : bool = aten::eq(%size_prods.229, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%385) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %386 : str = aten::format(%8, %375) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%386) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.153 : Tensor = aten::batch_norm(%input.151, %373, %374, %371, %372, %370, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %388 : Tensor = prim::GetAttr[name="weight"](%331)
      %389 : Tensor? = prim::GetAttr[name="bias"](%331)
      %input.154 : Tensor = aten::conv2d(%input.153, %388, %389, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %394 : bool = prim::GetAttr[name="training"](%332)
       = prim::If(%394) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %395 : Tensor = prim::GetAttr[name="num_batches_tracked"](%332)
          %396 : Tensor = aten::add(%395, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%332, %396)
          -> ()
        block1():
          -> ()
      %397 : bool = prim::GetAttr[name="training"](%332)
      %398 : Tensor = prim::GetAttr[name="running_mean"](%332)
      %399 : Tensor = prim::GetAttr[name="running_var"](%332)
      %400 : Tensor = prim::GetAttr[name="weight"](%332)
      %401 : Tensor = prim::GetAttr[name="bias"](%332)
       = prim::If(%397) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %402 : int[] = aten::size(%input.154) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.232 : int = aten::__getitem__(%402, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %404 : int = aten::len(%402) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %405 : int = aten::sub(%404, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.233 : int = prim::Loop(%405, %10, %size_prods.232) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.59 : int, %size_prods.234 : int):
              %409 : int = aten::add(%i.59, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %410 : int = aten::__getitem__(%402, %409) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.235 : int = aten::mul(%size_prods.234, %410) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.235)
          %412 : bool = aten::eq(%size_prods.233, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%412) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %413 : str = aten::format(%8, %402) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%413) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.155 : Tensor = aten::batch_norm(%input.154, %400, %401, %398, %399, %397, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.156 : Tensor = aten::relu_(%input.155) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %416 : Tensor[] = prim::ListConstruct(%3523, %input.156)
      %out.25 : Tensor = aten::cat(%416, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:90:18
      -> (%out.25)
    block1():
      %418 : __torch__.torch.nn.modules.container.___torch_mangle_9.Sequential = prim::GetAttr[name="branch2"](%55)
      %419 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="0"](%418)
      %420 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="1"](%418)
      %421 : __torch__.torch.nn.modules.conv.___torch_mangle_8.Conv2d = prim::GetAttr[name="3"](%418)
      %422 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="4"](%418)
      %423 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="5"](%418)
      %424 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="6"](%418)
      %425 : Tensor = prim::GetAttr[name="weight"](%419)
      %426 : Tensor? = prim::GetAttr[name="bias"](%419)
      %input.157 : Tensor = aten::conv2d(%input.152, %425, %426, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %431 : bool = prim::GetAttr[name="training"](%420)
       = prim::If(%431) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %432 : Tensor = prim::GetAttr[name="num_batches_tracked"](%420)
          %433 : Tensor = aten::add(%432, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%420, %433)
          -> ()
        block1():
          -> ()
      %434 : bool = prim::GetAttr[name="training"](%420)
      %435 : Tensor = prim::GetAttr[name="running_mean"](%420)
      %436 : Tensor = prim::GetAttr[name="running_var"](%420)
      %437 : Tensor = prim::GetAttr[name="weight"](%420)
      %438 : Tensor = prim::GetAttr[name="bias"](%420)
       = prim::If(%434) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %439 : int[] = aten::size(%input.157) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.236 : int = aten::__getitem__(%439, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %441 : int = aten::len(%439) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %442 : int = aten::sub(%441, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.237 : int = prim::Loop(%442, %10, %size_prods.236) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.60 : int, %size_prods.238 : int):
              %446 : int = aten::add(%i.60, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %447 : int = aten::__getitem__(%439, %446) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.239 : int = aten::mul(%size_prods.238, %447) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.239)
          %449 : bool = aten::eq(%size_prods.237, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%449) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %450 : str = aten::format(%8, %439) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%450) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.158 : Tensor = aten::batch_norm(%input.157, %437, %438, %435, %436, %434, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.159 : Tensor = aten::relu_(%input.158) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %453 : Tensor = prim::GetAttr[name="weight"](%421)
      %454 : Tensor? = prim::GetAttr[name="bias"](%421)
      %input.160 : Tensor = aten::conv2d(%input.159, %453, %454, %3554, %3554, %3554, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %459 : bool = prim::GetAttr[name="training"](%422)
       = prim::If(%459) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %460 : Tensor = prim::GetAttr[name="num_batches_tracked"](%422)
          %461 : Tensor = aten::add(%460, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%422, %461)
          -> ()
        block1():
          -> ()
      %462 : bool = prim::GetAttr[name="training"](%422)
      %463 : Tensor = prim::GetAttr[name="running_mean"](%422)
      %464 : Tensor = prim::GetAttr[name="running_var"](%422)
      %465 : Tensor = prim::GetAttr[name="weight"](%422)
      %466 : Tensor = prim::GetAttr[name="bias"](%422)
       = prim::If(%462) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %467 : int[] = aten::size(%input.160) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.240 : int = aten::__getitem__(%467, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %469 : int = aten::len(%467) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %470 : int = aten::sub(%469, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.241 : int = prim::Loop(%470, %10, %size_prods.240) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.61 : int, %size_prods.242 : int):
              %474 : int = aten::add(%i.61, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %475 : int = aten::__getitem__(%467, %474) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.243 : int = aten::mul(%size_prods.242, %475) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.243)
          %477 : bool = aten::eq(%size_prods.241, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%477) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %478 : str = aten::format(%8, %467) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%478) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.161 : Tensor = aten::batch_norm(%input.160, %465, %466, %463, %464, %462, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %480 : Tensor = prim::GetAttr[name="weight"](%423)
      %481 : Tensor? = prim::GetAttr[name="bias"](%423)
      %input.162 : Tensor = aten::conv2d(%input.161, %480, %481, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %486 : bool = prim::GetAttr[name="training"](%424)
       = prim::If(%486) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %487 : Tensor = prim::GetAttr[name="num_batches_tracked"](%424)
          %488 : Tensor = aten::add(%487, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%424, %488)
          -> ()
        block1():
          -> ()
      %489 : bool = prim::GetAttr[name="training"](%424)
      %490 : Tensor = prim::GetAttr[name="running_mean"](%424)
      %491 : Tensor = prim::GetAttr[name="running_var"](%424)
      %492 : Tensor = prim::GetAttr[name="weight"](%424)
      %493 : Tensor = prim::GetAttr[name="bias"](%424)
       = prim::If(%489) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %494 : int[] = aten::size(%input.162) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.244 : int = aten::__getitem__(%494, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %496 : int = aten::len(%494) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %497 : int = aten::sub(%496, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.245 : int = prim::Loop(%497, %10, %size_prods.244) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.62 : int, %size_prods.246 : int):
              %501 : int = aten::add(%i.62, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %502 : int = aten::__getitem__(%494, %501) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.247 : int = aten::mul(%size_prods.246, %502) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.247)
          %504 : bool = aten::eq(%size_prods.245, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%504) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %505 : str = aten::format(%8, %494) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%505) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.163 : Tensor = aten::batch_norm(%input.162, %492, %493, %490, %491, %489, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.164 : Tensor = aten::relu_(%input.163) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %508 : Tensor[] = prim::ListConstruct(%input.152, %input.164)
      %out.26 : Tensor = aten::cat(%508, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:92:18
      -> (%out.26)
  %510 : int[] = aten::size(%out.27) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:22:45
  %batchsize.9 : int, %num_channels.9 : int, %height.9 : int, %width.9 : int = prim::ListUnpack(%510)
  %channels_per_group.9 : int = aten::floordiv(%num_channels.9, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:23:25
  %516 : int[] = prim::ListConstruct(%batchsize.9, %4, %channels_per_group.9, %height.9, %width.9)
  %x.21 : Tensor = aten::view(%out.27, %516) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:26:8
  %518 : Tensor = aten::transpose(%x.21, %11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %x.22 : Tensor = aten::contiguous(%518, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %520 : int[] = prim::ListConstruct(%batchsize.9, %14, %height.9, %width.9)
  %input.170 : Tensor = aten::view(%x.22, %520) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:32:8
  %522 : int = prim::GetAttr[name="stride"](%56)
  %523 : bool = aten::eq(%522, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:11
  %out.30 : Tensor = prim::If(%523) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:8
    block0():
      %3525 : Tensor, %3526 : Tensor = prim::ConstantChunk[chunks=2, dim=1](%input.170)
      %528 : __torch__.torch.nn.modules.container.___torch_mangle_9.Sequential = prim::GetAttr[name="branch2"](%56)
      %529 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="0"](%528)
      %530 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="1"](%528)
      %531 : __torch__.torch.nn.modules.conv.___torch_mangle_8.Conv2d = prim::GetAttr[name="3"](%528)
      %532 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="4"](%528)
      %533 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="5"](%528)
      %534 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="6"](%528)
      %535 : Tensor = prim::GetAttr[name="weight"](%529)
      %536 : Tensor? = prim::GetAttr[name="bias"](%529)
      %input.165 : Tensor = aten::conv2d(%3526, %535, %536, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %541 : bool = prim::GetAttr[name="training"](%530)
       = prim::If(%541) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %542 : Tensor = prim::GetAttr[name="num_batches_tracked"](%530)
          %543 : Tensor = aten::add(%542, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%530, %543)
          -> ()
        block1():
          -> ()
      %544 : bool = prim::GetAttr[name="training"](%530)
      %545 : Tensor = prim::GetAttr[name="running_mean"](%530)
      %546 : Tensor = prim::GetAttr[name="running_var"](%530)
      %547 : Tensor = prim::GetAttr[name="weight"](%530)
      %548 : Tensor = prim::GetAttr[name="bias"](%530)
       = prim::If(%544) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %549 : int[] = aten::size(%input.165) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.248 : int = aten::__getitem__(%549, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %551 : int = aten::len(%549) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %552 : int = aten::sub(%551, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.249 : int = prim::Loop(%552, %10, %size_prods.248) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.63 : int, %size_prods.250 : int):
              %556 : int = aten::add(%i.63, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %557 : int = aten::__getitem__(%549, %556) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.251 : int = aten::mul(%size_prods.250, %557) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.251)
          %559 : bool = aten::eq(%size_prods.249, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%559) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %560 : str = aten::format(%8, %549) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%560) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.167 : Tensor = aten::batch_norm(%input.165, %547, %548, %545, %546, %544, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.168 : Tensor = aten::relu_(%input.167) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %563 : Tensor = prim::GetAttr[name="weight"](%531)
      %564 : Tensor? = prim::GetAttr[name="bias"](%531)
      %input.169 : Tensor = aten::conv2d(%input.168, %563, %564, %3554, %3554, %3554, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %569 : bool = prim::GetAttr[name="training"](%532)
       = prim::If(%569) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %570 : Tensor = prim::GetAttr[name="num_batches_tracked"](%532)
          %571 : Tensor = aten::add(%570, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%532, %571)
          -> ()
        block1():
          -> ()
      %572 : bool = prim::GetAttr[name="training"](%532)
      %573 : Tensor = prim::GetAttr[name="running_mean"](%532)
      %574 : Tensor = prim::GetAttr[name="running_var"](%532)
      %575 : Tensor = prim::GetAttr[name="weight"](%532)
      %576 : Tensor = prim::GetAttr[name="bias"](%532)
       = prim::If(%572) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %577 : int[] = aten::size(%input.169) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.252 : int = aten::__getitem__(%577, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %579 : int = aten::len(%577) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %580 : int = aten::sub(%579, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.253 : int = prim::Loop(%580, %10, %size_prods.252) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.64 : int, %size_prods.254 : int):
              %584 : int = aten::add(%i.64, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %585 : int = aten::__getitem__(%577, %584) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.255 : int = aten::mul(%size_prods.254, %585) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.255)
          %587 : bool = aten::eq(%size_prods.253, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%587) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %588 : str = aten::format(%8, %577) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%588) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.171 : Tensor = aten::batch_norm(%input.169, %575, %576, %573, %574, %572, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %590 : Tensor = prim::GetAttr[name="weight"](%533)
      %591 : Tensor? = prim::GetAttr[name="bias"](%533)
      %input.172 : Tensor = aten::conv2d(%input.171, %590, %591, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %596 : bool = prim::GetAttr[name="training"](%534)
       = prim::If(%596) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %597 : Tensor = prim::GetAttr[name="num_batches_tracked"](%534)
          %598 : Tensor = aten::add(%597, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%534, %598)
          -> ()
        block1():
          -> ()
      %599 : bool = prim::GetAttr[name="training"](%534)
      %600 : Tensor = prim::GetAttr[name="running_mean"](%534)
      %601 : Tensor = prim::GetAttr[name="running_var"](%534)
      %602 : Tensor = prim::GetAttr[name="weight"](%534)
      %603 : Tensor = prim::GetAttr[name="bias"](%534)
       = prim::If(%599) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %604 : int[] = aten::size(%input.172) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.256 : int = aten::__getitem__(%604, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %606 : int = aten::len(%604) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %607 : int = aten::sub(%606, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.257 : int = prim::Loop(%607, %10, %size_prods.256) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.65 : int, %size_prods.258 : int):
              %611 : int = aten::add(%i.65, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %612 : int = aten::__getitem__(%604, %611) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.259 : int = aten::mul(%size_prods.258, %612) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.259)
          %614 : bool = aten::eq(%size_prods.257, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%614) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %615 : str = aten::format(%8, %604) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%615) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.173 : Tensor = aten::batch_norm(%input.172, %602, %603, %600, %601, %599, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.174 : Tensor = aten::relu_(%input.173) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %618 : Tensor[] = prim::ListConstruct(%3525, %input.174)
      %out.28 : Tensor = aten::cat(%618, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:90:18
      -> (%out.28)
    block1():
      %620 : __torch__.torch.nn.modules.container.___torch_mangle_9.Sequential = prim::GetAttr[name="branch2"](%56)
      %621 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="0"](%620)
      %622 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="1"](%620)
      %623 : __torch__.torch.nn.modules.conv.___torch_mangle_8.Conv2d = prim::GetAttr[name="3"](%620)
      %624 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="4"](%620)
      %625 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="5"](%620)
      %626 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="6"](%620)
      %627 : Tensor = prim::GetAttr[name="weight"](%621)
      %628 : Tensor? = prim::GetAttr[name="bias"](%621)
      %input.175 : Tensor = aten::conv2d(%input.170, %627, %628, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %633 : bool = prim::GetAttr[name="training"](%622)
       = prim::If(%633) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %634 : Tensor = prim::GetAttr[name="num_batches_tracked"](%622)
          %635 : Tensor = aten::add(%634, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%622, %635)
          -> ()
        block1():
          -> ()
      %636 : bool = prim::GetAttr[name="training"](%622)
      %637 : Tensor = prim::GetAttr[name="running_mean"](%622)
      %638 : Tensor = prim::GetAttr[name="running_var"](%622)
      %639 : Tensor = prim::GetAttr[name="weight"](%622)
      %640 : Tensor = prim::GetAttr[name="bias"](%622)
       = prim::If(%636) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %641 : int[] = aten::size(%input.175) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.260 : int = aten::__getitem__(%641, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %643 : int = aten::len(%641) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %644 : int = aten::sub(%643, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.261 : int = prim::Loop(%644, %10, %size_prods.260) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.66 : int, %size_prods.262 : int):
              %648 : int = aten::add(%i.66, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %649 : int = aten::__getitem__(%641, %648) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.263 : int = aten::mul(%size_prods.262, %649) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.263)
          %651 : bool = aten::eq(%size_prods.261, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%651) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %652 : str = aten::format(%8, %641) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%652) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.176 : Tensor = aten::batch_norm(%input.175, %639, %640, %637, %638, %636, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.177 : Tensor = aten::relu_(%input.176) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %655 : Tensor = prim::GetAttr[name="weight"](%623)
      %656 : Tensor? = prim::GetAttr[name="bias"](%623)
      %input.178 : Tensor = aten::conv2d(%input.177, %655, %656, %3554, %3554, %3554, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %661 : bool = prim::GetAttr[name="training"](%624)
       = prim::If(%661) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %662 : Tensor = prim::GetAttr[name="num_batches_tracked"](%624)
          %663 : Tensor = aten::add(%662, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%624, %663)
          -> ()
        block1():
          -> ()
      %664 : bool = prim::GetAttr[name="training"](%624)
      %665 : Tensor = prim::GetAttr[name="running_mean"](%624)
      %666 : Tensor = prim::GetAttr[name="running_var"](%624)
      %667 : Tensor = prim::GetAttr[name="weight"](%624)
      %668 : Tensor = prim::GetAttr[name="bias"](%624)
       = prim::If(%664) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %669 : int[] = aten::size(%input.178) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.264 : int = aten::__getitem__(%669, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %671 : int = aten::len(%669) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %672 : int = aten::sub(%671, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.265 : int = prim::Loop(%672, %10, %size_prods.264) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.67 : int, %size_prods.266 : int):
              %676 : int = aten::add(%i.67, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %677 : int = aten::__getitem__(%669, %676) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.267 : int = aten::mul(%size_prods.266, %677) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.267)
          %679 : bool = aten::eq(%size_prods.265, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%679) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %680 : str = aten::format(%8, %669) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%680) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.179 : Tensor = aten::batch_norm(%input.178, %667, %668, %665, %666, %664, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %682 : Tensor = prim::GetAttr[name="weight"](%625)
      %683 : Tensor? = prim::GetAttr[name="bias"](%625)
      %input.180 : Tensor = aten::conv2d(%input.179, %682, %683, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %688 : bool = prim::GetAttr[name="training"](%626)
       = prim::If(%688) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %689 : Tensor = prim::GetAttr[name="num_batches_tracked"](%626)
          %690 : Tensor = aten::add(%689, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%626, %690)
          -> ()
        block1():
          -> ()
      %691 : bool = prim::GetAttr[name="training"](%626)
      %692 : Tensor = prim::GetAttr[name="running_mean"](%626)
      %693 : Tensor = prim::GetAttr[name="running_var"](%626)
      %694 : Tensor = prim::GetAttr[name="weight"](%626)
      %695 : Tensor = prim::GetAttr[name="bias"](%626)
       = prim::If(%691) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %696 : int[] = aten::size(%input.180) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.268 : int = aten::__getitem__(%696, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %698 : int = aten::len(%696) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %699 : int = aten::sub(%698, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.269 : int = prim::Loop(%699, %10, %size_prods.268) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.68 : int, %size_prods.270 : int):
              %703 : int = aten::add(%i.68, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %704 : int = aten::__getitem__(%696, %703) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.271 : int = aten::mul(%size_prods.270, %704) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.271)
          %706 : bool = aten::eq(%size_prods.269, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%706) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %707 : str = aten::format(%8, %696) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%707) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.181 : Tensor = aten::batch_norm(%input.180, %694, %695, %692, %693, %691, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.182 : Tensor = aten::relu_(%input.181) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %710 : Tensor[] = prim::ListConstruct(%input.170, %input.182)
      %out.29 : Tensor = aten::cat(%710, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:92:18
      -> (%out.29)
  %712 : int[] = aten::size(%out.30) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:22:45
  %batchsize.10 : int, %num_channels.10 : int, %height.10 : int, %width.10 : int = prim::ListUnpack(%712)
  %channels_per_group.10 : int = aten::floordiv(%num_channels.10, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:23:25
  %718 : int[] = prim::ListConstruct(%batchsize.10, %4, %channels_per_group.10, %height.10, %width.10)
  %x.23 : Tensor = aten::view(%out.30, %718) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:26:8
  %720 : Tensor = aten::transpose(%x.23, %11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %x.24 : Tensor = aten::contiguous(%720, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %722 : int[] = prim::ListConstruct(%batchsize.10, %14, %height.10, %width.10)
  %input.188 : Tensor = aten::view(%x.24, %722) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:32:8
  %724 : int = prim::GetAttr[name="stride"](%57)
  %725 : bool = aten::eq(%724, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:11
  %out.33 : Tensor = prim::If(%725) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:8
    block0():
      %3527 : Tensor, %3528 : Tensor = prim::ConstantChunk[chunks=2, dim=1](%input.188)
      %730 : __torch__.torch.nn.modules.container.___torch_mangle_9.Sequential = prim::GetAttr[name="branch2"](%57)
      %731 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="0"](%730)
      %732 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="1"](%730)
      %733 : __torch__.torch.nn.modules.conv.___torch_mangle_8.Conv2d = prim::GetAttr[name="3"](%730)
      %734 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="4"](%730)
      %735 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="5"](%730)
      %736 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="6"](%730)
      %737 : Tensor = prim::GetAttr[name="weight"](%731)
      %738 : Tensor? = prim::GetAttr[name="bias"](%731)
      %input.201 : Tensor = aten::conv2d(%3528, %737, %738, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %743 : bool = prim::GetAttr[name="training"](%732)
       = prim::If(%743) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %744 : Tensor = prim::GetAttr[name="num_batches_tracked"](%732)
          %745 : Tensor = aten::add(%744, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%732, %745)
          -> ()
        block1():
          -> ()
      %746 : bool = prim::GetAttr[name="training"](%732)
      %747 : Tensor = prim::GetAttr[name="running_mean"](%732)
      %748 : Tensor = prim::GetAttr[name="running_var"](%732)
      %749 : Tensor = prim::GetAttr[name="weight"](%732)
      %750 : Tensor = prim::GetAttr[name="bias"](%732)
       = prim::If(%746) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %751 : int[] = aten::size(%input.201) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.284 : int = aten::__getitem__(%751, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %753 : int = aten::len(%751) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %754 : int = aten::sub(%753, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.285 : int = prim::Loop(%754, %10, %size_prods.284) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.72 : int, %size_prods.286 : int):
              %758 : int = aten::add(%i.72, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %759 : int = aten::__getitem__(%751, %758) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.287 : int = aten::mul(%size_prods.286, %759) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.287)
          %761 : bool = aten::eq(%size_prods.285, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%761) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %762 : str = aten::format(%8, %751) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%762) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.202 : Tensor = aten::batch_norm(%input.201, %749, %750, %747, %748, %746, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.203 : Tensor = aten::relu_(%input.202) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %765 : Tensor = prim::GetAttr[name="weight"](%733)
      %766 : Tensor? = prim::GetAttr[name="bias"](%733)
      %input.204 : Tensor = aten::conv2d(%input.203, %765, %766, %3554, %3554, %3554, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %771 : bool = prim::GetAttr[name="training"](%734)
       = prim::If(%771) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %772 : Tensor = prim::GetAttr[name="num_batches_tracked"](%734)
          %773 : Tensor = aten::add(%772, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%734, %773)
          -> ()
        block1():
          -> ()
      %774 : bool = prim::GetAttr[name="training"](%734)
      %775 : Tensor = prim::GetAttr[name="running_mean"](%734)
      %776 : Tensor = prim::GetAttr[name="running_var"](%734)
      %777 : Tensor = prim::GetAttr[name="weight"](%734)
      %778 : Tensor = prim::GetAttr[name="bias"](%734)
       = prim::If(%774) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %779 : int[] = aten::size(%input.204) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.288 : int = aten::__getitem__(%779, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %781 : int = aten::len(%779) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %782 : int = aten::sub(%781, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.289 : int = prim::Loop(%782, %10, %size_prods.288) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.73 : int, %size_prods.290 : int):
              %786 : int = aten::add(%i.73, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %787 : int = aten::__getitem__(%779, %786) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.291 : int = aten::mul(%size_prods.290, %787) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.291)
          %789 : bool = aten::eq(%size_prods.289, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%789) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %790 : str = aten::format(%8, %779) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%790) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.205 : Tensor = aten::batch_norm(%input.204, %777, %778, %775, %776, %774, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %792 : Tensor = prim::GetAttr[name="weight"](%735)
      %793 : Tensor? = prim::GetAttr[name="bias"](%735)
      %input.206 : Tensor = aten::conv2d(%input.205, %792, %793, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %798 : bool = prim::GetAttr[name="training"](%736)
       = prim::If(%798) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %799 : Tensor = prim::GetAttr[name="num_batches_tracked"](%736)
          %800 : Tensor = aten::add(%799, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%736, %800)
          -> ()
        block1():
          -> ()
      %801 : bool = prim::GetAttr[name="training"](%736)
      %802 : Tensor = prim::GetAttr[name="running_mean"](%736)
      %803 : Tensor = prim::GetAttr[name="running_var"](%736)
      %804 : Tensor = prim::GetAttr[name="weight"](%736)
      %805 : Tensor = prim::GetAttr[name="bias"](%736)
       = prim::If(%801) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %806 : int[] = aten::size(%input.206) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.292 : int = aten::__getitem__(%806, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %808 : int = aten::len(%806) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %809 : int = aten::sub(%808, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.293 : int = prim::Loop(%809, %10, %size_prods.292) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.74 : int, %size_prods.294 : int):
              %813 : int = aten::add(%i.74, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %814 : int = aten::__getitem__(%806, %813) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.295 : int = aten::mul(%size_prods.294, %814) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.295)
          %816 : bool = aten::eq(%size_prods.293, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%816) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %817 : str = aten::format(%8, %806) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%817) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.207 : Tensor = aten::batch_norm(%input.206, %804, %805, %802, %803, %801, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.208 : Tensor = aten::relu_(%input.207) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %820 : Tensor[] = prim::ListConstruct(%3527, %input.208)
      %out.34 : Tensor = aten::cat(%820, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:90:18
      -> (%out.34)
    block1():
      %822 : __torch__.torch.nn.modules.container.___torch_mangle_9.Sequential = prim::GetAttr[name="branch2"](%57)
      %823 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="0"](%822)
      %824 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="1"](%822)
      %825 : __torch__.torch.nn.modules.conv.___torch_mangle_8.Conv2d = prim::GetAttr[name="3"](%822)
      %826 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="4"](%822)
      %827 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="5"](%822)
      %828 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_2.BatchNorm2d = prim::GetAttr[name="6"](%822)
      %829 : Tensor = prim::GetAttr[name="weight"](%823)
      %830 : Tensor? = prim::GetAttr[name="bias"](%823)
      %input.209 : Tensor = aten::conv2d(%input.188, %829, %830, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %835 : bool = prim::GetAttr[name="training"](%824)
       = prim::If(%835) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %836 : Tensor = prim::GetAttr[name="num_batches_tracked"](%824)
          %837 : Tensor = aten::add(%836, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%824, %837)
          -> ()
        block1():
          -> ()
      %838 : bool = prim::GetAttr[name="training"](%824)
      %839 : Tensor = prim::GetAttr[name="running_mean"](%824)
      %840 : Tensor = prim::GetAttr[name="running_var"](%824)
      %841 : Tensor = prim::GetAttr[name="weight"](%824)
      %842 : Tensor = prim::GetAttr[name="bias"](%824)
       = prim::If(%838) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %843 : int[] = aten::size(%input.209) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.296 : int = aten::__getitem__(%843, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %845 : int = aten::len(%843) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %846 : int = aten::sub(%845, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.297 : int = prim::Loop(%846, %10, %size_prods.296) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.75 : int, %size_prods.298 : int):
              %850 : int = aten::add(%i.75, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %851 : int = aten::__getitem__(%843, %850) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.299 : int = aten::mul(%size_prods.298, %851) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.299)
          %853 : bool = aten::eq(%size_prods.297, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%853) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %854 : str = aten::format(%8, %843) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%854) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.210 : Tensor = aten::batch_norm(%input.209, %841, %842, %839, %840, %838, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.211 : Tensor = aten::relu_(%input.210) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %857 : Tensor = prim::GetAttr[name="weight"](%825)
      %858 : Tensor? = prim::GetAttr[name="bias"](%825)
      %input.212 : Tensor = aten::conv2d(%input.211, %857, %858, %3554, %3554, %3554, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %863 : bool = prim::GetAttr[name="training"](%826)
       = prim::If(%863) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %864 : Tensor = prim::GetAttr[name="num_batches_tracked"](%826)
          %865 : Tensor = aten::add(%864, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%826, %865)
          -> ()
        block1():
          -> ()
      %866 : bool = prim::GetAttr[name="training"](%826)
      %867 : Tensor = prim::GetAttr[name="running_mean"](%826)
      %868 : Tensor = prim::GetAttr[name="running_var"](%826)
      %869 : Tensor = prim::GetAttr[name="weight"](%826)
      %870 : Tensor = prim::GetAttr[name="bias"](%826)
       = prim::If(%866) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %871 : int[] = aten::size(%input.212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.300 : int = aten::__getitem__(%871, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %873 : int = aten::len(%871) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %874 : int = aten::sub(%873, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.301 : int = prim::Loop(%874, %10, %size_prods.300) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.76 : int, %size_prods.302 : int):
              %878 : int = aten::add(%i.76, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %879 : int = aten::__getitem__(%871, %878) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.303 : int = aten::mul(%size_prods.302, %879) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.303)
          %881 : bool = aten::eq(%size_prods.301, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%881) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %882 : str = aten::format(%8, %871) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%882) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.213 : Tensor = aten::batch_norm(%input.212, %869, %870, %867, %868, %866, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %884 : Tensor = prim::GetAttr[name="weight"](%827)
      %885 : Tensor? = prim::GetAttr[name="bias"](%827)
      %input.214 : Tensor = aten::conv2d(%input.213, %884, %885, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %890 : bool = prim::GetAttr[name="training"](%828)
       = prim::If(%890) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %891 : Tensor = prim::GetAttr[name="num_batches_tracked"](%828)
          %892 : Tensor = aten::add(%891, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%828, %892)
          -> ()
        block1():
          -> ()
      %893 : bool = prim::GetAttr[name="training"](%828)
      %894 : Tensor = prim::GetAttr[name="running_mean"](%828)
      %895 : Tensor = prim::GetAttr[name="running_var"](%828)
      %896 : Tensor = prim::GetAttr[name="weight"](%828)
      %897 : Tensor = prim::GetAttr[name="bias"](%828)
       = prim::If(%893) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %898 : int[] = aten::size(%input.214) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.304 : int = aten::__getitem__(%898, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %900 : int = aten::len(%898) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %901 : int = aten::sub(%900, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.305 : int = prim::Loop(%901, %10, %size_prods.304) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.77 : int, %size_prods.306 : int):
              %905 : int = aten::add(%i.77, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %906 : int = aten::__getitem__(%898, %905) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.307 : int = aten::mul(%size_prods.306, %906) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.307)
          %908 : bool = aten::eq(%size_prods.305, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%908) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %909 : str = aten::format(%8, %898) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%909) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.215 : Tensor = aten::batch_norm(%input.214, %896, %897, %894, %895, %893, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.216 : Tensor = aten::relu_(%input.215) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %912 : Tensor[] = prim::ListConstruct(%input.188, %input.216)
      %out.35 : Tensor = aten::cat(%912, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:92:18
      -> (%out.35)
  %914 : int[] = aten::size(%out.33) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:22:45
  %batchsize.12 : int, %num_channels.12 : int, %height.12 : int, %width.12 : int = prim::ListUnpack(%914)
  %channels_per_group.12 : int = aten::floordiv(%num_channels.12, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:23:25
  %920 : int[] = prim::ListConstruct(%batchsize.12, %4, %channels_per_group.12, %height.12, %width.12)
  %x.33 : Tensor = aten::view(%out.33, %920) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:26:8
  %922 : Tensor = aten::transpose(%x.33, %11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %x.34 : Tensor = aten::contiguous(%922, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %924 : int[] = prim::ListConstruct(%batchsize.12, %14, %height.12, %width.12)
  %x.27 : Tensor = aten::view(%x.34, %924) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:32:8
  %926 : __torch__.torch.nn.modules.container.___torch_mangle_21.Sequential = prim::GetAttr[name="stage3"](%self)
  %927 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_17.InvertedResidual = prim::GetAttr[name="0"](%926)
  %928 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_20.InvertedResidual = prim::GetAttr[name="1"](%926)
  %929 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_20.InvertedResidual = prim::GetAttr[name="2"](%926)
  %930 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_20.InvertedResidual = prim::GetAttr[name="3"](%926)
  %931 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_20.InvertedResidual = prim::GetAttr[name="4"](%926)
  %932 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_20.InvertedResidual = prim::GetAttr[name="5"](%926)
  %933 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_20.InvertedResidual = prim::GetAttr[name="6"](%926)
  %934 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_20.InvertedResidual = prim::GetAttr[name="7"](%926)
  %935 : int = prim::GetAttr[name="stride"](%927)
  %936 : bool = aten::eq(%935, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:11
  %out.36 : Tensor = prim::If(%936) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:8
    block0():
      %3529 : Tensor, %3530 : Tensor = prim::ConstantChunk[chunks=2, dim=1](%x.27)
      %941 : __torch__.torch.nn.modules.container.___torch_mangle_16.Sequential = prim::GetAttr[name="branch2"](%927)
      %942 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="0"](%941)
      %943 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%941)
      %944 : __torch__.torch.nn.modules.conv.___torch_mangle_12.Conv2d = prim::GetAttr[name="3"](%941)
      %945 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%941)
      %946 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="5"](%941)
      %947 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="6"](%941)
      %948 : Tensor = prim::GetAttr[name="weight"](%942)
      %949 : Tensor? = prim::GetAttr[name="bias"](%942)
      %input.221 : Tensor = aten::conv2d(%3530, %948, %949, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %954 : bool = prim::GetAttr[name="training"](%943)
       = prim::If(%954) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %955 : Tensor = prim::GetAttr[name="num_batches_tracked"](%943)
          %956 : Tensor = aten::add(%955, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%943, %956)
          -> ()
        block1():
          -> ()
      %957 : bool = prim::GetAttr[name="training"](%943)
      %958 : Tensor = prim::GetAttr[name="running_mean"](%943)
      %959 : Tensor = prim::GetAttr[name="running_var"](%943)
      %960 : Tensor = prim::GetAttr[name="weight"](%943)
      %961 : Tensor = prim::GetAttr[name="bias"](%943)
       = prim::If(%957) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %962 : int[] = aten::size(%input.221) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.308 : int = aten::__getitem__(%962, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %964 : int = aten::len(%962) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %965 : int = aten::sub(%964, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.309 : int = prim::Loop(%965, %10, %size_prods.308) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.78 : int, %size_prods.310 : int):
              %969 : int = aten::add(%i.78, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %970 : int = aten::__getitem__(%962, %969) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.311 : int = aten::mul(%size_prods.310, %970) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.311)
          %972 : bool = aten::eq(%size_prods.309, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%972) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %973 : str = aten::format(%8, %962) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%973) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.225 : Tensor = aten::batch_norm(%input.221, %960, %961, %958, %959, %957, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.226 : Tensor = aten::relu_(%input.225) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %976 : Tensor = prim::GetAttr[name="weight"](%944)
      %977 : Tensor? = prim::GetAttr[name="bias"](%944)
      %input.227 : Tensor = aten::conv2d(%input.226, %976, %977, %3553, %3554, %3554, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %982 : bool = prim::GetAttr[name="training"](%945)
       = prim::If(%982) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %983 : Tensor = prim::GetAttr[name="num_batches_tracked"](%945)
          %984 : Tensor = aten::add(%983, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%945, %984)
          -> ()
        block1():
          -> ()
      %985 : bool = prim::GetAttr[name="training"](%945)
      %986 : Tensor = prim::GetAttr[name="running_mean"](%945)
      %987 : Tensor = prim::GetAttr[name="running_var"](%945)
      %988 : Tensor = prim::GetAttr[name="weight"](%945)
      %989 : Tensor = prim::GetAttr[name="bias"](%945)
       = prim::If(%985) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %990 : int[] = aten::size(%input.227) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.312 : int = aten::__getitem__(%990, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %992 : int = aten::len(%990) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %993 : int = aten::sub(%992, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.313 : int = prim::Loop(%993, %10, %size_prods.312) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.79 : int, %size_prods.314 : int):
              %997 : int = aten::add(%i.79, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %998 : int = aten::__getitem__(%990, %997) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.315 : int = aten::mul(%size_prods.314, %998) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.315)
          %1000 : bool = aten::eq(%size_prods.313, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1000) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1001 : str = aten::format(%8, %990) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1001) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.230 : Tensor = aten::batch_norm(%input.227, %988, %989, %986, %987, %985, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1003 : Tensor = prim::GetAttr[name="weight"](%946)
      %1004 : Tensor? = prim::GetAttr[name="bias"](%946)
      %input.222 : Tensor = aten::conv2d(%input.230, %1003, %1004, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1009 : bool = prim::GetAttr[name="training"](%947)
       = prim::If(%1009) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1010 : Tensor = prim::GetAttr[name="num_batches_tracked"](%947)
          %1011 : Tensor = aten::add(%1010, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%947, %1011)
          -> ()
        block1():
          -> ()
      %1012 : bool = prim::GetAttr[name="training"](%947)
      %1013 : Tensor = prim::GetAttr[name="running_mean"](%947)
      %1014 : Tensor = prim::GetAttr[name="running_var"](%947)
      %1015 : Tensor = prim::GetAttr[name="weight"](%947)
      %1016 : Tensor = prim::GetAttr[name="bias"](%947)
       = prim::If(%1012) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1017 : int[] = aten::size(%input.222) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.316 : int = aten::__getitem__(%1017, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1019 : int = aten::len(%1017) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1020 : int = aten::sub(%1019, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.317 : int = prim::Loop(%1020, %10, %size_prods.316) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.80 : int, %size_prods.318 : int):
              %1024 : int = aten::add(%i.80, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1025 : int = aten::__getitem__(%1017, %1024) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.319 : int = aten::mul(%size_prods.318, %1025) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.319)
          %1027 : bool = aten::eq(%size_prods.317, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1027) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1028 : str = aten::format(%8, %1017) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1028) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.223 : Tensor = aten::batch_norm(%input.222, %1015, %1016, %1013, %1014, %1012, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.224 : Tensor = aten::relu_(%input.223) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1031 : Tensor[] = prim::ListConstruct(%3529, %input.224)
      %out.37 : Tensor = aten::cat(%1031, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:90:18
      -> (%out.37)
    block1():
      %1033 : __torch__.torch.nn.modules.container.___torch_mangle_15.Sequential = prim::GetAttr[name="branch1"](%927)
      %1034 : __torch__.torch.nn.modules.conv.___torch_mangle_12.Conv2d = prim::GetAttr[name="0"](%1033)
      %1035 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%1033)
      %1036 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="2"](%1033)
      %1037 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="3"](%1033)
      %1038 : Tensor = prim::GetAttr[name="weight"](%1034)
      %1039 : Tensor? = prim::GetAttr[name="bias"](%1034)
      %input.231 : Tensor = aten::conv2d(%x.27, %1038, %1039, %3553, %3554, %3554, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1044 : bool = prim::GetAttr[name="training"](%1035)
       = prim::If(%1044) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1045 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1035)
          %1046 : Tensor = aten::add(%1045, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1035, %1046)
          -> ()
        block1():
          -> ()
      %1047 : bool = prim::GetAttr[name="training"](%1035)
      %1048 : Tensor = prim::GetAttr[name="running_mean"](%1035)
      %1049 : Tensor = prim::GetAttr[name="running_var"](%1035)
      %1050 : Tensor = prim::GetAttr[name="weight"](%1035)
      %1051 : Tensor = prim::GetAttr[name="bias"](%1035)
       = prim::If(%1047) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1052 : int[] = aten::size(%input.231) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.320 : int = aten::__getitem__(%1052, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1054 : int = aten::len(%1052) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1055 : int = aten::sub(%1054, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.321 : int = prim::Loop(%1055, %10, %size_prods.320) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.81 : int, %size_prods.322 : int):
              %1059 : int = aten::add(%i.81, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1060 : int = aten::__getitem__(%1052, %1059) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.323 : int = aten::mul(%size_prods.322, %1060) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.323)
          %1062 : bool = aten::eq(%size_prods.321, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1062) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1063 : str = aten::format(%8, %1052) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1063) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.232 : Tensor = aten::batch_norm(%input.231, %1050, %1051, %1048, %1049, %1047, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1065 : Tensor = prim::GetAttr[name="weight"](%1036)
      %1066 : Tensor? = prim::GetAttr[name="bias"](%1036)
      %input.233 : Tensor = aten::conv2d(%input.232, %1065, %1066, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1071 : bool = prim::GetAttr[name="training"](%1037)
       = prim::If(%1071) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1072 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1037)
          %1073 : Tensor = aten::add(%1072, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1037, %1073)
          -> ()
        block1():
          -> ()
      %1074 : bool = prim::GetAttr[name="training"](%1037)
      %1075 : Tensor = prim::GetAttr[name="running_mean"](%1037)
      %1076 : Tensor = prim::GetAttr[name="running_var"](%1037)
      %1077 : Tensor = prim::GetAttr[name="weight"](%1037)
      %1078 : Tensor = prim::GetAttr[name="bias"](%1037)
       = prim::If(%1074) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1079 : int[] = aten::size(%input.233) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.324 : int = aten::__getitem__(%1079, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1081 : int = aten::len(%1079) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1082 : int = aten::sub(%1081, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.325 : int = prim::Loop(%1082, %10, %size_prods.324) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.82 : int, %size_prods.326 : int):
              %1086 : int = aten::add(%i.82, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1087 : int = aten::__getitem__(%1079, %1086) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.327 : int = aten::mul(%size_prods.326, %1087) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.327)
          %1089 : bool = aten::eq(%size_prods.325, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1089) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1090 : str = aten::format(%8, %1079) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1090) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.228 : Tensor = aten::batch_norm(%input.233, %1077, %1078, %1075, %1076, %1074, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.229 : Tensor = aten::relu_(%input.228) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1093 : __torch__.torch.nn.modules.container.___torch_mangle_16.Sequential = prim::GetAttr[name="branch2"](%927)
      %1094 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="0"](%1093)
      %1095 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%1093)
      %1096 : __torch__.torch.nn.modules.conv.___torch_mangle_12.Conv2d = prim::GetAttr[name="3"](%1093)
      %1097 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%1093)
      %1098 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="5"](%1093)
      %1099 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="6"](%1093)
      %1100 : Tensor = prim::GetAttr[name="weight"](%1094)
      %1101 : Tensor? = prim::GetAttr[name="bias"](%1094)
      %input.234 : Tensor = aten::conv2d(%x.27, %1100, %1101, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1106 : bool = prim::GetAttr[name="training"](%1095)
       = prim::If(%1106) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1107 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1095)
          %1108 : Tensor = aten::add(%1107, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1095, %1108)
          -> ()
        block1():
          -> ()
      %1109 : bool = prim::GetAttr[name="training"](%1095)
      %1110 : Tensor = prim::GetAttr[name="running_mean"](%1095)
      %1111 : Tensor = prim::GetAttr[name="running_var"](%1095)
      %1112 : Tensor = prim::GetAttr[name="weight"](%1095)
      %1113 : Tensor = prim::GetAttr[name="bias"](%1095)
       = prim::If(%1109) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1114 : int[] = aten::size(%input.234) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.328 : int = aten::__getitem__(%1114, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1116 : int = aten::len(%1114) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1117 : int = aten::sub(%1116, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.329 : int = prim::Loop(%1117, %10, %size_prods.328) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.83 : int, %size_prods.330 : int):
              %1121 : int = aten::add(%i.83, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1122 : int = aten::__getitem__(%1114, %1121) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.331 : int = aten::mul(%size_prods.330, %1122) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.331)
          %1124 : bool = aten::eq(%size_prods.329, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1125 : str = aten::format(%8, %1114) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1125) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.235 : Tensor = aten::batch_norm(%input.234, %1112, %1113, %1110, %1111, %1109, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.236 : Tensor = aten::relu_(%input.235) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1128 : Tensor = prim::GetAttr[name="weight"](%1096)
      %1129 : Tensor? = prim::GetAttr[name="bias"](%1096)
      %input.237 : Tensor = aten::conv2d(%input.236, %1128, %1129, %3553, %3554, %3554, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1134 : bool = prim::GetAttr[name="training"](%1097)
       = prim::If(%1134) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1135 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1097)
          %1136 : Tensor = aten::add(%1135, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1097, %1136)
          -> ()
        block1():
          -> ()
      %1137 : bool = prim::GetAttr[name="training"](%1097)
      %1138 : Tensor = prim::GetAttr[name="running_mean"](%1097)
      %1139 : Tensor = prim::GetAttr[name="running_var"](%1097)
      %1140 : Tensor = prim::GetAttr[name="weight"](%1097)
      %1141 : Tensor = prim::GetAttr[name="bias"](%1097)
       = prim::If(%1137) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1142 : int[] = aten::size(%input.237) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.332 : int = aten::__getitem__(%1142, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1144 : int = aten::len(%1142) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1145 : int = aten::sub(%1144, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.333 : int = prim::Loop(%1145, %10, %size_prods.332) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.84 : int, %size_prods.334 : int):
              %1149 : int = aten::add(%i.84, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1150 : int = aten::__getitem__(%1142, %1149) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.335 : int = aten::mul(%size_prods.334, %1150) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.335)
          %1152 : bool = aten::eq(%size_prods.333, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1152) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1153 : str = aten::format(%8, %1142) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1153) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.239 : Tensor = aten::batch_norm(%input.237, %1140, %1141, %1138, %1139, %1137, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1155 : Tensor = prim::GetAttr[name="weight"](%1098)
      %1156 : Tensor? = prim::GetAttr[name="bias"](%1098)
      %input.240 : Tensor = aten::conv2d(%input.239, %1155, %1156, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1161 : bool = prim::GetAttr[name="training"](%1099)
       = prim::If(%1161) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1162 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1099)
          %1163 : Tensor = aten::add(%1162, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1099, %1163)
          -> ()
        block1():
          -> ()
      %1164 : bool = prim::GetAttr[name="training"](%1099)
      %1165 : Tensor = prim::GetAttr[name="running_mean"](%1099)
      %1166 : Tensor = prim::GetAttr[name="running_var"](%1099)
      %1167 : Tensor = prim::GetAttr[name="weight"](%1099)
      %1168 : Tensor = prim::GetAttr[name="bias"](%1099)
       = prim::If(%1164) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1169 : int[] = aten::size(%input.240) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.336 : int = aten::__getitem__(%1169, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1171 : int = aten::len(%1169) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1172 : int = aten::sub(%1171, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.337 : int = prim::Loop(%1172, %10, %size_prods.336) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.85 : int, %size_prods.338 : int):
              %1176 : int = aten::add(%i.85, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1177 : int = aten::__getitem__(%1169, %1176) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.339 : int = aten::mul(%size_prods.338, %1177) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.339)
          %1179 : bool = aten::eq(%size_prods.337, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1179) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1180 : str = aten::format(%8, %1169) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1180) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.241 : Tensor = aten::batch_norm(%input.240, %1167, %1168, %1165, %1166, %1164, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.242 : Tensor = aten::relu_(%input.241) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1183 : Tensor[] = prim::ListConstruct(%input.229, %input.242)
      %out.38 : Tensor = aten::cat(%1183, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:92:18
      -> (%out.38)
  %1185 : int[] = aten::size(%out.36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:22:45
  %batchsize.13 : int, %num_channels.13 : int, %height.13 : int, %width.13 : int = prim::ListUnpack(%1185)
  %channels_per_group.13 : int = aten::floordiv(%num_channels.13, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:23:25
  %1191 : int[] = prim::ListConstruct(%batchsize.13, %4, %channels_per_group.13, %height.13, %width.13)
  %x.35 : Tensor = aten::view(%out.36, %1191) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:26:8
  %1193 : Tensor = aten::transpose(%x.35, %11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %x.36 : Tensor = aten::contiguous(%1193, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %1195 : int[] = prim::ListConstruct(%batchsize.13, %14, %height.13, %width.13)
  %input.238 : Tensor = aten::view(%x.36, %1195) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:32:8
  %1197 : int = prim::GetAttr[name="stride"](%928)
  %1198 : bool = aten::eq(%1197, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:11
  %out.39 : Tensor = prim::If(%1198) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:8
    block0():
      %3531 : Tensor, %3532 : Tensor = prim::ConstantChunk[chunks=2, dim=1](%input.238)
      %1203 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="branch2"](%928)
      %1204 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="0"](%1203)
      %1205 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%1203)
      %1206 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="3"](%1203)
      %1207 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%1203)
      %1208 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="5"](%1203)
      %1209 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="6"](%1203)
      %1210 : Tensor = prim::GetAttr[name="weight"](%1204)
      %1211 : Tensor? = prim::GetAttr[name="bias"](%1204)
      %input.243 : Tensor = aten::conv2d(%3532, %1210, %1211, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1216 : bool = prim::GetAttr[name="training"](%1205)
       = prim::If(%1216) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1217 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1205)
          %1218 : Tensor = aten::add(%1217, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1205, %1218)
          -> ()
        block1():
          -> ()
      %1219 : bool = prim::GetAttr[name="training"](%1205)
      %1220 : Tensor = prim::GetAttr[name="running_mean"](%1205)
      %1221 : Tensor = prim::GetAttr[name="running_var"](%1205)
      %1222 : Tensor = prim::GetAttr[name="weight"](%1205)
      %1223 : Tensor = prim::GetAttr[name="bias"](%1205)
       = prim::If(%1219) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1224 : int[] = aten::size(%input.243) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.340 : int = aten::__getitem__(%1224, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1226 : int = aten::len(%1224) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1227 : int = aten::sub(%1226, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.341 : int = prim::Loop(%1227, %10, %size_prods.340) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.86 : int, %size_prods.342 : int):
              %1231 : int = aten::add(%i.86, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1232 : int = aten::__getitem__(%1224, %1231) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.343 : int = aten::mul(%size_prods.342, %1232) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.343)
          %1234 : bool = aten::eq(%size_prods.341, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1234) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1235 : str = aten::format(%8, %1224) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1235) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.244 : Tensor = aten::batch_norm(%input.243, %1222, %1223, %1220, %1221, %1219, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.245 : Tensor = aten::relu_(%input.244) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1238 : Tensor = prim::GetAttr[name="weight"](%1206)
      %1239 : Tensor? = prim::GetAttr[name="bias"](%1206)
      %input.246 : Tensor = aten::conv2d(%input.245, %1238, %1239, %3554, %3554, %3554, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1244 : bool = prim::GetAttr[name="training"](%1207)
       = prim::If(%1244) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1245 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1207)
          %1246 : Tensor = aten::add(%1245, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1207, %1246)
          -> ()
        block1():
          -> ()
      %1247 : bool = prim::GetAttr[name="training"](%1207)
      %1248 : Tensor = prim::GetAttr[name="running_mean"](%1207)
      %1249 : Tensor = prim::GetAttr[name="running_var"](%1207)
      %1250 : Tensor = prim::GetAttr[name="weight"](%1207)
      %1251 : Tensor = prim::GetAttr[name="bias"](%1207)
       = prim::If(%1247) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1252 : int[] = aten::size(%input.246) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.344 : int = aten::__getitem__(%1252, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1254 : int = aten::len(%1252) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1255 : int = aten::sub(%1254, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.345 : int = prim::Loop(%1255, %10, %size_prods.344) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.87 : int, %size_prods.346 : int):
              %1259 : int = aten::add(%i.87, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1260 : int = aten::__getitem__(%1252, %1259) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.347 : int = aten::mul(%size_prods.346, %1260) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.347)
          %1262 : bool = aten::eq(%size_prods.345, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1262) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1263 : str = aten::format(%8, %1252) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1263) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.247 : Tensor = aten::batch_norm(%input.246, %1250, %1251, %1248, %1249, %1247, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1265 : Tensor = prim::GetAttr[name="weight"](%1208)
      %1266 : Tensor? = prim::GetAttr[name="bias"](%1208)
      %input.248 : Tensor = aten::conv2d(%input.247, %1265, %1266, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1271 : bool = prim::GetAttr[name="training"](%1209)
       = prim::If(%1271) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1272 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1209)
          %1273 : Tensor = aten::add(%1272, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1209, %1273)
          -> ()
        block1():
          -> ()
      %1274 : bool = prim::GetAttr[name="training"](%1209)
      %1275 : Tensor = prim::GetAttr[name="running_mean"](%1209)
      %1276 : Tensor = prim::GetAttr[name="running_var"](%1209)
      %1277 : Tensor = prim::GetAttr[name="weight"](%1209)
      %1278 : Tensor = prim::GetAttr[name="bias"](%1209)
       = prim::If(%1274) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1279 : int[] = aten::size(%input.248) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.348 : int = aten::__getitem__(%1279, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1281 : int = aten::len(%1279) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1282 : int = aten::sub(%1281, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.349 : int = prim::Loop(%1282, %10, %size_prods.348) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.88 : int, %size_prods.350 : int):
              %1286 : int = aten::add(%i.88, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1287 : int = aten::__getitem__(%1279, %1286) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.351 : int = aten::mul(%size_prods.350, %1287) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.351)
          %1289 : bool = aten::eq(%size_prods.349, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1289) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1290 : str = aten::format(%8, %1279) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1290) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.249 : Tensor = aten::batch_norm(%input.248, %1277, %1278, %1275, %1276, %1274, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.250 : Tensor = aten::relu_(%input.249) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1293 : Tensor[] = prim::ListConstruct(%3531, %input.250)
      %out.40 : Tensor = aten::cat(%1293, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:90:18
      -> (%out.40)
    block1():
      %1295 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="branch2"](%928)
      %1296 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="0"](%1295)
      %1297 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%1295)
      %1298 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="3"](%1295)
      %1299 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%1295)
      %1300 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="5"](%1295)
      %1301 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="6"](%1295)
      %1302 : Tensor = prim::GetAttr[name="weight"](%1296)
      %1303 : Tensor? = prim::GetAttr[name="bias"](%1296)
      %input.251 : Tensor = aten::conv2d(%input.238, %1302, %1303, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1308 : bool = prim::GetAttr[name="training"](%1297)
       = prim::If(%1308) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1309 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1297)
          %1310 : Tensor = aten::add(%1309, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1297, %1310)
          -> ()
        block1():
          -> ()
      %1311 : bool = prim::GetAttr[name="training"](%1297)
      %1312 : Tensor = prim::GetAttr[name="running_mean"](%1297)
      %1313 : Tensor = prim::GetAttr[name="running_var"](%1297)
      %1314 : Tensor = prim::GetAttr[name="weight"](%1297)
      %1315 : Tensor = prim::GetAttr[name="bias"](%1297)
       = prim::If(%1311) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1316 : int[] = aten::size(%input.251) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.352 : int = aten::__getitem__(%1316, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1318 : int = aten::len(%1316) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1319 : int = aten::sub(%1318, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.353 : int = prim::Loop(%1319, %10, %size_prods.352) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.89 : int, %size_prods.354 : int):
              %1323 : int = aten::add(%i.89, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1324 : int = aten::__getitem__(%1316, %1323) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.355 : int = aten::mul(%size_prods.354, %1324) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.355)
          %1326 : bool = aten::eq(%size_prods.353, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1326) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1327 : str = aten::format(%8, %1316) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1327) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.252 : Tensor = aten::batch_norm(%input.251, %1314, %1315, %1312, %1313, %1311, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.253 : Tensor = aten::relu_(%input.252) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1330 : Tensor = prim::GetAttr[name="weight"](%1298)
      %1331 : Tensor? = prim::GetAttr[name="bias"](%1298)
      %input.254 : Tensor = aten::conv2d(%input.253, %1330, %1331, %3554, %3554, %3554, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1336 : bool = prim::GetAttr[name="training"](%1299)
       = prim::If(%1336) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1337 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1299)
          %1338 : Tensor = aten::add(%1337, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1299, %1338)
          -> ()
        block1():
          -> ()
      %1339 : bool = prim::GetAttr[name="training"](%1299)
      %1340 : Tensor = prim::GetAttr[name="running_mean"](%1299)
      %1341 : Tensor = prim::GetAttr[name="running_var"](%1299)
      %1342 : Tensor = prim::GetAttr[name="weight"](%1299)
      %1343 : Tensor = prim::GetAttr[name="bias"](%1299)
       = prim::If(%1339) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1344 : int[] = aten::size(%input.254) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.356 : int = aten::__getitem__(%1344, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1346 : int = aten::len(%1344) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1347 : int = aten::sub(%1346, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.357 : int = prim::Loop(%1347, %10, %size_prods.356) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.90 : int, %size_prods.358 : int):
              %1351 : int = aten::add(%i.90, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1352 : int = aten::__getitem__(%1344, %1351) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.359 : int = aten::mul(%size_prods.358, %1352) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.359)
          %1354 : bool = aten::eq(%size_prods.357, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1354) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1355 : str = aten::format(%8, %1344) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1355) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.256 : Tensor = aten::batch_norm(%input.254, %1342, %1343, %1340, %1341, %1339, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1357 : Tensor = prim::GetAttr[name="weight"](%1300)
      %1358 : Tensor? = prim::GetAttr[name="bias"](%1300)
      %input.257 : Tensor = aten::conv2d(%input.256, %1357, %1358, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1363 : bool = prim::GetAttr[name="training"](%1301)
       = prim::If(%1363) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1364 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1301)
          %1365 : Tensor = aten::add(%1364, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1301, %1365)
          -> ()
        block1():
          -> ()
      %1366 : bool = prim::GetAttr[name="training"](%1301)
      %1367 : Tensor = prim::GetAttr[name="running_mean"](%1301)
      %1368 : Tensor = prim::GetAttr[name="running_var"](%1301)
      %1369 : Tensor = prim::GetAttr[name="weight"](%1301)
      %1370 : Tensor = prim::GetAttr[name="bias"](%1301)
       = prim::If(%1366) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1371 : int[] = aten::size(%input.257) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.360 : int = aten::__getitem__(%1371, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1373 : int = aten::len(%1371) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1374 : int = aten::sub(%1373, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.361 : int = prim::Loop(%1374, %10, %size_prods.360) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.91 : int, %size_prods.362 : int):
              %1378 : int = aten::add(%i.91, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1379 : int = aten::__getitem__(%1371, %1378) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.363 : int = aten::mul(%size_prods.362, %1379) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.363)
          %1381 : bool = aten::eq(%size_prods.361, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1381) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1382 : str = aten::format(%8, %1371) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1382) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.258 : Tensor = aten::batch_norm(%input.257, %1369, %1370, %1367, %1368, %1366, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.259 : Tensor = aten::relu_(%input.258) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1385 : Tensor[] = prim::ListConstruct(%input.238, %input.259)
      %out.41 : Tensor = aten::cat(%1385, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:92:18
      -> (%out.41)
  %1387 : int[] = aten::size(%out.39) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:22:45
  %batchsize.14 : int, %num_channels.14 : int, %height.14 : int, %width.14 : int = prim::ListUnpack(%1387)
  %channels_per_group.14 : int = aten::floordiv(%num_channels.14, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:23:25
  %1393 : int[] = prim::ListConstruct(%batchsize.14, %4, %channels_per_group.14, %height.14, %width.14)
  %x.37 : Tensor = aten::view(%out.39, %1393) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:26:8
  %1395 : Tensor = aten::transpose(%x.37, %11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %x.38 : Tensor = aten::contiguous(%1395, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %1397 : int[] = prim::ListConstruct(%batchsize.14, %14, %height.14, %width.14)
  %input.255 : Tensor = aten::view(%x.38, %1397) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:32:8
  %1399 : int = prim::GetAttr[name="stride"](%929)
  %1400 : bool = aten::eq(%1399, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:11
  %out.42 : Tensor = prim::If(%1400) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:8
    block0():
      %3533 : Tensor, %3534 : Tensor = prim::ConstantChunk[chunks=2, dim=1](%input.255)
      %1405 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="branch2"](%929)
      %1406 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="0"](%1405)
      %1407 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%1405)
      %1408 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="3"](%1405)
      %1409 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%1405)
      %1410 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="5"](%1405)
      %1411 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="6"](%1405)
      %1412 : Tensor = prim::GetAttr[name="weight"](%1406)
      %1413 : Tensor? = prim::GetAttr[name="bias"](%1406)
      %input.260 : Tensor = aten::conv2d(%3534, %1412, %1413, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1418 : bool = prim::GetAttr[name="training"](%1407)
       = prim::If(%1418) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1419 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1407)
          %1420 : Tensor = aten::add(%1419, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1407, %1420)
          -> ()
        block1():
          -> ()
      %1421 : bool = prim::GetAttr[name="training"](%1407)
      %1422 : Tensor = prim::GetAttr[name="running_mean"](%1407)
      %1423 : Tensor = prim::GetAttr[name="running_var"](%1407)
      %1424 : Tensor = prim::GetAttr[name="weight"](%1407)
      %1425 : Tensor = prim::GetAttr[name="bias"](%1407)
       = prim::If(%1421) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1426 : int[] = aten::size(%input.260) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.364 : int = aten::__getitem__(%1426, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1428 : int = aten::len(%1426) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1429 : int = aten::sub(%1428, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.365 : int = prim::Loop(%1429, %10, %size_prods.364) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.92 : int, %size_prods.366 : int):
              %1433 : int = aten::add(%i.92, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1434 : int = aten::__getitem__(%1426, %1433) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.367 : int = aten::mul(%size_prods.366, %1434) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.367)
          %1436 : bool = aten::eq(%size_prods.365, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1436) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1437 : str = aten::format(%8, %1426) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1437) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.261 : Tensor = aten::batch_norm(%input.260, %1424, %1425, %1422, %1423, %1421, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.262 : Tensor = aten::relu_(%input.261) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1440 : Tensor = prim::GetAttr[name="weight"](%1408)
      %1441 : Tensor? = prim::GetAttr[name="bias"](%1408)
      %input.263 : Tensor = aten::conv2d(%input.262, %1440, %1441, %3554, %3554, %3554, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1446 : bool = prim::GetAttr[name="training"](%1409)
       = prim::If(%1446) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1447 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1409)
          %1448 : Tensor = aten::add(%1447, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1409, %1448)
          -> ()
        block1():
          -> ()
      %1449 : bool = prim::GetAttr[name="training"](%1409)
      %1450 : Tensor = prim::GetAttr[name="running_mean"](%1409)
      %1451 : Tensor = prim::GetAttr[name="running_var"](%1409)
      %1452 : Tensor = prim::GetAttr[name="weight"](%1409)
      %1453 : Tensor = prim::GetAttr[name="bias"](%1409)
       = prim::If(%1449) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1454 : int[] = aten::size(%input.263) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.368 : int = aten::__getitem__(%1454, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1456 : int = aten::len(%1454) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1457 : int = aten::sub(%1456, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.369 : int = prim::Loop(%1457, %10, %size_prods.368) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.93 : int, %size_prods.370 : int):
              %1461 : int = aten::add(%i.93, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1462 : int = aten::__getitem__(%1454, %1461) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.371 : int = aten::mul(%size_prods.370, %1462) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.371)
          %1464 : bool = aten::eq(%size_prods.369, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1464) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1465 : str = aten::format(%8, %1454) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1465) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.264 : Tensor = aten::batch_norm(%input.263, %1452, %1453, %1450, %1451, %1449, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1467 : Tensor = prim::GetAttr[name="weight"](%1410)
      %1468 : Tensor? = prim::GetAttr[name="bias"](%1410)
      %input.265 : Tensor = aten::conv2d(%input.264, %1467, %1468, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1473 : bool = prim::GetAttr[name="training"](%1411)
       = prim::If(%1473) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1474 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1411)
          %1475 : Tensor = aten::add(%1474, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1411, %1475)
          -> ()
        block1():
          -> ()
      %1476 : bool = prim::GetAttr[name="training"](%1411)
      %1477 : Tensor = prim::GetAttr[name="running_mean"](%1411)
      %1478 : Tensor = prim::GetAttr[name="running_var"](%1411)
      %1479 : Tensor = prim::GetAttr[name="weight"](%1411)
      %1480 : Tensor = prim::GetAttr[name="bias"](%1411)
       = prim::If(%1476) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1481 : int[] = aten::size(%input.265) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.372 : int = aten::__getitem__(%1481, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1483 : int = aten::len(%1481) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1484 : int = aten::sub(%1483, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.373 : int = prim::Loop(%1484, %10, %size_prods.372) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.94 : int, %size_prods.374 : int):
              %1488 : int = aten::add(%i.94, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1489 : int = aten::__getitem__(%1481, %1488) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.375 : int = aten::mul(%size_prods.374, %1489) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.375)
          %1491 : bool = aten::eq(%size_prods.373, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1491) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1492 : str = aten::format(%8, %1481) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1492) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.266 : Tensor = aten::batch_norm(%input.265, %1479, %1480, %1477, %1478, %1476, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.267 : Tensor = aten::relu_(%input.266) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1495 : Tensor[] = prim::ListConstruct(%3533, %input.267)
      %out.43 : Tensor = aten::cat(%1495, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:90:18
      -> (%out.43)
    block1():
      %1497 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="branch2"](%929)
      %1498 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="0"](%1497)
      %1499 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%1497)
      %1500 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="3"](%1497)
      %1501 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%1497)
      %1502 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="5"](%1497)
      %1503 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="6"](%1497)
      %1504 : Tensor = prim::GetAttr[name="weight"](%1498)
      %1505 : Tensor? = prim::GetAttr[name="bias"](%1498)
      %input.268 : Tensor = aten::conv2d(%input.255, %1504, %1505, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1510 : bool = prim::GetAttr[name="training"](%1499)
       = prim::If(%1510) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1511 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1499)
          %1512 : Tensor = aten::add(%1511, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1499, %1512)
          -> ()
        block1():
          -> ()
      %1513 : bool = prim::GetAttr[name="training"](%1499)
      %1514 : Tensor = prim::GetAttr[name="running_mean"](%1499)
      %1515 : Tensor = prim::GetAttr[name="running_var"](%1499)
      %1516 : Tensor = prim::GetAttr[name="weight"](%1499)
      %1517 : Tensor = prim::GetAttr[name="bias"](%1499)
       = prim::If(%1513) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1518 : int[] = aten::size(%input.268) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.376 : int = aten::__getitem__(%1518, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1520 : int = aten::len(%1518) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1521 : int = aten::sub(%1520, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.377 : int = prim::Loop(%1521, %10, %size_prods.376) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.95 : int, %size_prods.378 : int):
              %1525 : int = aten::add(%i.95, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1526 : int = aten::__getitem__(%1518, %1525) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.379 : int = aten::mul(%size_prods.378, %1526) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.379)
          %1528 : bool = aten::eq(%size_prods.377, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1528) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1529 : str = aten::format(%8, %1518) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1529) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.269 : Tensor = aten::batch_norm(%input.268, %1516, %1517, %1514, %1515, %1513, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.270 : Tensor = aten::relu_(%input.269) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1532 : Tensor = prim::GetAttr[name="weight"](%1500)
      %1533 : Tensor? = prim::GetAttr[name="bias"](%1500)
      %input.271 : Tensor = aten::conv2d(%input.270, %1532, %1533, %3554, %3554, %3554, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1538 : bool = prim::GetAttr[name="training"](%1501)
       = prim::If(%1538) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1539 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1501)
          %1540 : Tensor = aten::add(%1539, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1501, %1540)
          -> ()
        block1():
          -> ()
      %1541 : bool = prim::GetAttr[name="training"](%1501)
      %1542 : Tensor = prim::GetAttr[name="running_mean"](%1501)
      %1543 : Tensor = prim::GetAttr[name="running_var"](%1501)
      %1544 : Tensor = prim::GetAttr[name="weight"](%1501)
      %1545 : Tensor = prim::GetAttr[name="bias"](%1501)
       = prim::If(%1541) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1546 : int[] = aten::size(%input.271) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.380 : int = aten::__getitem__(%1546, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1548 : int = aten::len(%1546) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1549 : int = aten::sub(%1548, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.381 : int = prim::Loop(%1549, %10, %size_prods.380) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.96 : int, %size_prods.382 : int):
              %1553 : int = aten::add(%i.96, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1554 : int = aten::__getitem__(%1546, %1553) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.383 : int = aten::mul(%size_prods.382, %1554) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.383)
          %1556 : bool = aten::eq(%size_prods.381, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1556) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1557 : str = aten::format(%8, %1546) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1557) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.76 : Tensor = aten::batch_norm(%input.271, %1544, %1545, %1542, %1543, %1541, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1559 : Tensor = prim::GetAttr[name="weight"](%1502)
      %1560 : Tensor? = prim::GetAttr[name="bias"](%1502)
      %input.77 : Tensor = aten::conv2d(%input.76, %1559, %1560, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1565 : bool = prim::GetAttr[name="training"](%1503)
       = prim::If(%1565) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1566 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1503)
          %1567 : Tensor = aten::add(%1566, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1503, %1567)
          -> ()
        block1():
          -> ()
      %1568 : bool = prim::GetAttr[name="training"](%1503)
      %1569 : Tensor = prim::GetAttr[name="running_mean"](%1503)
      %1570 : Tensor = prim::GetAttr[name="running_var"](%1503)
      %1571 : Tensor = prim::GetAttr[name="weight"](%1503)
      %1572 : Tensor = prim::GetAttr[name="bias"](%1503)
       = prim::If(%1568) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1573 : int[] = aten::size(%input.77) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.384 : int = aten::__getitem__(%1573, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1575 : int = aten::len(%1573) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1576 : int = aten::sub(%1575, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.385 : int = prim::Loop(%1576, %10, %size_prods.384) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.97 : int, %size_prods.386 : int):
              %1580 : int = aten::add(%i.97, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1581 : int = aten::__getitem__(%1573, %1580) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.387 : int = aten::mul(%size_prods.386, %1581) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.387)
          %1583 : bool = aten::eq(%size_prods.385, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1583) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1584 : str = aten::format(%8, %1573) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1584) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.78 : Tensor = aten::batch_norm(%input.77, %1571, %1572, %1569, %1570, %1568, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.79 : Tensor = aten::relu_(%input.78) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1587 : Tensor[] = prim::ListConstruct(%input.255, %input.79)
      %out.44 : Tensor = aten::cat(%1587, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:92:18
      -> (%out.44)
  %1589 : int[] = aten::size(%out.42) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:22:45
  %batchsize.15 : int, %num_channels.15 : int, %height.15 : int, %width.15 : int = prim::ListUnpack(%1589)
  %channels_per_group.15 : int = aten::floordiv(%num_channels.15, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:23:25
  %1595 : int[] = prim::ListConstruct(%batchsize.15, %4, %channels_per_group.15, %height.15, %width.15)
  %x.39 : Tensor = aten::view(%out.42, %1595) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:26:8
  %1597 : Tensor = aten::transpose(%x.39, %11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %x.40 : Tensor = aten::contiguous(%1597, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %1599 : int[] = prim::ListConstruct(%batchsize.15, %14, %height.15, %width.15)
  %input.272 : Tensor = aten::view(%x.40, %1599) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:32:8
  %1601 : int = prim::GetAttr[name="stride"](%930)
  %1602 : bool = aten::eq(%1601, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:11
  %out.15 : Tensor = prim::If(%1602) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:8
    block0():
      %3535 : Tensor, %3536 : Tensor = prim::ConstantChunk[chunks=2, dim=1](%input.272)
      %1607 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="branch2"](%930)
      %1608 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="0"](%1607)
      %1609 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%1607)
      %1610 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="3"](%1607)
      %1611 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%1607)
      %1612 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="5"](%1607)
      %1613 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="6"](%1607)
      %1614 : Tensor = prim::GetAttr[name="weight"](%1608)
      %1615 : Tensor? = prim::GetAttr[name="bias"](%1608)
      %input.80 : Tensor = aten::conv2d(%3536, %1614, %1615, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1620 : bool = prim::GetAttr[name="training"](%1609)
       = prim::If(%1620) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1621 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1609)
          %1622 : Tensor = aten::add(%1621, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1609, %1622)
          -> ()
        block1():
          -> ()
      %1623 : bool = prim::GetAttr[name="training"](%1609)
      %1624 : Tensor = prim::GetAttr[name="running_mean"](%1609)
      %1625 : Tensor = prim::GetAttr[name="running_var"](%1609)
      %1626 : Tensor = prim::GetAttr[name="weight"](%1609)
      %1627 : Tensor = prim::GetAttr[name="bias"](%1609)
       = prim::If(%1623) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1628 : int[] = aten::size(%input.80) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.104 : int = aten::__getitem__(%1628, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1630 : int = aten::len(%1628) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1631 : int = aten::sub(%1630, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.105 : int = prim::Loop(%1631, %10, %size_prods.104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.27 : int, %size_prods.106 : int):
              %1635 : int = aten::add(%i.27, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1636 : int = aten::__getitem__(%1628, %1635) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.107 : int = aten::mul(%size_prods.106, %1636) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.107)
          %1638 : bool = aten::eq(%size_prods.105, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1638) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1639 : str = aten::format(%8, %1628) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1639) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.81 : Tensor = aten::batch_norm(%input.80, %1626, %1627, %1624, %1625, %1623, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.82 : Tensor = aten::relu_(%input.81) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1642 : Tensor = prim::GetAttr[name="weight"](%1610)
      %1643 : Tensor? = prim::GetAttr[name="bias"](%1610)
      %input.83 : Tensor = aten::conv2d(%input.82, %1642, %1643, %3554, %3554, %3554, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1648 : bool = prim::GetAttr[name="training"](%1611)
       = prim::If(%1648) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1649 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1611)
          %1650 : Tensor = aten::add(%1649, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1611, %1650)
          -> ()
        block1():
          -> ()
      %1651 : bool = prim::GetAttr[name="training"](%1611)
      %1652 : Tensor = prim::GetAttr[name="running_mean"](%1611)
      %1653 : Tensor = prim::GetAttr[name="running_var"](%1611)
      %1654 : Tensor = prim::GetAttr[name="weight"](%1611)
      %1655 : Tensor = prim::GetAttr[name="bias"](%1611)
       = prim::If(%1651) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1656 : int[] = aten::size(%input.83) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.108 : int = aten::__getitem__(%1656, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1658 : int = aten::len(%1656) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1659 : int = aten::sub(%1658, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.109 : int = prim::Loop(%1659, %10, %size_prods.108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.28 : int, %size_prods.110 : int):
              %1663 : int = aten::add(%i.28, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1664 : int = aten::__getitem__(%1656, %1663) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.111 : int = aten::mul(%size_prods.110, %1664) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.111)
          %1666 : bool = aten::eq(%size_prods.109, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1666) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1667 : str = aten::format(%8, %1656) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1667) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.84 : Tensor = aten::batch_norm(%input.83, %1654, %1655, %1652, %1653, %1651, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1669 : Tensor = prim::GetAttr[name="weight"](%1612)
      %1670 : Tensor? = prim::GetAttr[name="bias"](%1612)
      %input.85 : Tensor = aten::conv2d(%input.84, %1669, %1670, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1675 : bool = prim::GetAttr[name="training"](%1613)
       = prim::If(%1675) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1676 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1613)
          %1677 : Tensor = aten::add(%1676, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1613, %1677)
          -> ()
        block1():
          -> ()
      %1678 : bool = prim::GetAttr[name="training"](%1613)
      %1679 : Tensor = prim::GetAttr[name="running_mean"](%1613)
      %1680 : Tensor = prim::GetAttr[name="running_var"](%1613)
      %1681 : Tensor = prim::GetAttr[name="weight"](%1613)
      %1682 : Tensor = prim::GetAttr[name="bias"](%1613)
       = prim::If(%1678) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1683 : int[] = aten::size(%input.85) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.112 : int = aten::__getitem__(%1683, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1685 : int = aten::len(%1683) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1686 : int = aten::sub(%1685, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.113 : int = prim::Loop(%1686, %10, %size_prods.112) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.29 : int, %size_prods.114 : int):
              %1690 : int = aten::add(%i.29, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1691 : int = aten::__getitem__(%1683, %1690) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.115 : int = aten::mul(%size_prods.114, %1691) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.115)
          %1693 : bool = aten::eq(%size_prods.113, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1693) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1694 : str = aten::format(%8, %1683) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1694) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.86 : Tensor = aten::batch_norm(%input.85, %1681, %1682, %1679, %1680, %1678, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.87 : Tensor = aten::relu_(%input.86) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1697 : Tensor[] = prim::ListConstruct(%3535, %input.87)
      %out.13 : Tensor = aten::cat(%1697, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:90:18
      -> (%out.13)
    block1():
      %1699 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="branch2"](%930)
      %1700 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="0"](%1699)
      %1701 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%1699)
      %1702 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="3"](%1699)
      %1703 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%1699)
      %1704 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="5"](%1699)
      %1705 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="6"](%1699)
      %1706 : Tensor = prim::GetAttr[name="weight"](%1700)
      %1707 : Tensor? = prim::GetAttr[name="bias"](%1700)
      %input.88 : Tensor = aten::conv2d(%input.272, %1706, %1707, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1712 : bool = prim::GetAttr[name="training"](%1701)
       = prim::If(%1712) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1713 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1701)
          %1714 : Tensor = aten::add(%1713, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1701, %1714)
          -> ()
        block1():
          -> ()
      %1715 : bool = prim::GetAttr[name="training"](%1701)
      %1716 : Tensor = prim::GetAttr[name="running_mean"](%1701)
      %1717 : Tensor = prim::GetAttr[name="running_var"](%1701)
      %1718 : Tensor = prim::GetAttr[name="weight"](%1701)
      %1719 : Tensor = prim::GetAttr[name="bias"](%1701)
       = prim::If(%1715) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1720 : int[] = aten::size(%input.88) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.116 : int = aten::__getitem__(%1720, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1722 : int = aten::len(%1720) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1723 : int = aten::sub(%1722, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.117 : int = prim::Loop(%1723, %10, %size_prods.116) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.30 : int, %size_prods.118 : int):
              %1727 : int = aten::add(%i.30, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1728 : int = aten::__getitem__(%1720, %1727) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.119 : int = aten::mul(%size_prods.118, %1728) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.119)
          %1730 : bool = aten::eq(%size_prods.117, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1730) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1731 : str = aten::format(%8, %1720) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1731) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.89 : Tensor = aten::batch_norm(%input.88, %1718, %1719, %1716, %1717, %1715, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.90 : Tensor = aten::relu_(%input.89) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1734 : Tensor = prim::GetAttr[name="weight"](%1702)
      %1735 : Tensor? = prim::GetAttr[name="bias"](%1702)
      %input.91 : Tensor = aten::conv2d(%input.90, %1734, %1735, %3554, %3554, %3554, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1740 : bool = prim::GetAttr[name="training"](%1703)
       = prim::If(%1740) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1741 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1703)
          %1742 : Tensor = aten::add(%1741, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1703, %1742)
          -> ()
        block1():
          -> ()
      %1743 : bool = prim::GetAttr[name="training"](%1703)
      %1744 : Tensor = prim::GetAttr[name="running_mean"](%1703)
      %1745 : Tensor = prim::GetAttr[name="running_var"](%1703)
      %1746 : Tensor = prim::GetAttr[name="weight"](%1703)
      %1747 : Tensor = prim::GetAttr[name="bias"](%1703)
       = prim::If(%1743) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1748 : int[] = aten::size(%input.91) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.120 : int = aten::__getitem__(%1748, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1750 : int = aten::len(%1748) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1751 : int = aten::sub(%1750, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.121 : int = prim::Loop(%1751, %10, %size_prods.120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.31 : int, %size_prods.122 : int):
              %1755 : int = aten::add(%i.31, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1756 : int = aten::__getitem__(%1748, %1755) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.123 : int = aten::mul(%size_prods.122, %1756) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.123)
          %1758 : bool = aten::eq(%size_prods.121, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1758) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1759 : str = aten::format(%8, %1748) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1759) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.92 : Tensor = aten::batch_norm(%input.91, %1746, %1747, %1744, %1745, %1743, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1761 : Tensor = prim::GetAttr[name="weight"](%1704)
      %1762 : Tensor? = prim::GetAttr[name="bias"](%1704)
      %input.93 : Tensor = aten::conv2d(%input.92, %1761, %1762, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1767 : bool = prim::GetAttr[name="training"](%1705)
       = prim::If(%1767) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1768 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1705)
          %1769 : Tensor = aten::add(%1768, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1705, %1769)
          -> ()
        block1():
          -> ()
      %1770 : bool = prim::GetAttr[name="training"](%1705)
      %1771 : Tensor = prim::GetAttr[name="running_mean"](%1705)
      %1772 : Tensor = prim::GetAttr[name="running_var"](%1705)
      %1773 : Tensor = prim::GetAttr[name="weight"](%1705)
      %1774 : Tensor = prim::GetAttr[name="bias"](%1705)
       = prim::If(%1770) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1775 : int[] = aten::size(%input.93) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.124 : int = aten::__getitem__(%1775, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1777 : int = aten::len(%1775) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1778 : int = aten::sub(%1777, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.125 : int = prim::Loop(%1778, %10, %size_prods.124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.32 : int, %size_prods.126 : int):
              %1782 : int = aten::add(%i.32, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1783 : int = aten::__getitem__(%1775, %1782) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.127 : int = aten::mul(%size_prods.126, %1783) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.127)
          %1785 : bool = aten::eq(%size_prods.125, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1785) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1786 : str = aten::format(%8, %1775) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1786) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.94 : Tensor = aten::batch_norm(%input.93, %1773, %1774, %1771, %1772, %1770, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.95 : Tensor = aten::relu_(%input.94) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1789 : Tensor[] = prim::ListConstruct(%input.272, %input.95)
      %out.14 : Tensor = aten::cat(%1789, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:92:18
      -> (%out.14)
  %1791 : int[] = aten::size(%out.15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:22:45
  %batchsize.5 : int, %num_channels.5 : int, %height.5 : int, %width.5 : int = prim::ListUnpack(%1791)
  %channels_per_group.5 : int = aten::floordiv(%num_channels.5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:23:25
  %1797 : int[] = prim::ListConstruct(%batchsize.5, %4, %channels_per_group.5, %height.5, %width.5)
  %x.12 : Tensor = aten::view(%out.15, %1797) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:26:8
  %1799 : Tensor = aten::transpose(%x.12, %11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %x.13 : Tensor = aten::contiguous(%1799, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %1801 : int[] = prim::ListConstruct(%batchsize.5, %14, %height.5, %width.5)
  %input.289 : Tensor = aten::view(%x.13, %1801) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:32:8
  %1803 : int = prim::GetAttr[name="stride"](%931)
  %1804 : bool = aten::eq(%1803, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:11
  %out.18 : Tensor = prim::If(%1804) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:8
    block0():
      %3537 : Tensor, %3538 : Tensor = prim::ConstantChunk[chunks=2, dim=1](%input.289)
      %1809 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="branch2"](%931)
      %1810 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="0"](%1809)
      %1811 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%1809)
      %1812 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="3"](%1809)
      %1813 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%1809)
      %1814 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="5"](%1809)
      %1815 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="6"](%1809)
      %1816 : Tensor = prim::GetAttr[name="weight"](%1810)
      %1817 : Tensor? = prim::GetAttr[name="bias"](%1810)
      %input.96 : Tensor = aten::conv2d(%3538, %1816, %1817, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1822 : bool = prim::GetAttr[name="training"](%1811)
       = prim::If(%1822) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1823 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1811)
          %1824 : Tensor = aten::add(%1823, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1811, %1824)
          -> ()
        block1():
          -> ()
      %1825 : bool = prim::GetAttr[name="training"](%1811)
      %1826 : Tensor = prim::GetAttr[name="running_mean"](%1811)
      %1827 : Tensor = prim::GetAttr[name="running_var"](%1811)
      %1828 : Tensor = prim::GetAttr[name="weight"](%1811)
      %1829 : Tensor = prim::GetAttr[name="bias"](%1811)
       = prim::If(%1825) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1830 : int[] = aten::size(%input.96) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.128 : int = aten::__getitem__(%1830, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1832 : int = aten::len(%1830) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1833 : int = aten::sub(%1832, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.129 : int = prim::Loop(%1833, %10, %size_prods.128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.33 : int, %size_prods.130 : int):
              %1837 : int = aten::add(%i.33, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1838 : int = aten::__getitem__(%1830, %1837) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.131 : int = aten::mul(%size_prods.130, %1838) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.131)
          %1840 : bool = aten::eq(%size_prods.129, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1840) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1841 : str = aten::format(%8, %1830) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1841) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.97 : Tensor = aten::batch_norm(%input.96, %1828, %1829, %1826, %1827, %1825, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.98 : Tensor = aten::relu_(%input.97) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1844 : Tensor = prim::GetAttr[name="weight"](%1812)
      %1845 : Tensor? = prim::GetAttr[name="bias"](%1812)
      %input.99 : Tensor = aten::conv2d(%input.98, %1844, %1845, %3554, %3554, %3554, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1850 : bool = prim::GetAttr[name="training"](%1813)
       = prim::If(%1850) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1851 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1813)
          %1852 : Tensor = aten::add(%1851, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1813, %1852)
          -> ()
        block1():
          -> ()
      %1853 : bool = prim::GetAttr[name="training"](%1813)
      %1854 : Tensor = prim::GetAttr[name="running_mean"](%1813)
      %1855 : Tensor = prim::GetAttr[name="running_var"](%1813)
      %1856 : Tensor = prim::GetAttr[name="weight"](%1813)
      %1857 : Tensor = prim::GetAttr[name="bias"](%1813)
       = prim::If(%1853) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1858 : int[] = aten::size(%input.99) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.132 : int = aten::__getitem__(%1858, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1860 : int = aten::len(%1858) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1861 : int = aten::sub(%1860, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.133 : int = prim::Loop(%1861, %10, %size_prods.132) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.34 : int, %size_prods.134 : int):
              %1865 : int = aten::add(%i.34, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1866 : int = aten::__getitem__(%1858, %1865) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.135 : int = aten::mul(%size_prods.134, %1866) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.135)
          %1868 : bool = aten::eq(%size_prods.133, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1868) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1869 : str = aten::format(%8, %1858) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1869) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.100 : Tensor = aten::batch_norm(%input.99, %1856, %1857, %1854, %1855, %1853, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1871 : Tensor = prim::GetAttr[name="weight"](%1814)
      %1872 : Tensor? = prim::GetAttr[name="bias"](%1814)
      %input.101 : Tensor = aten::conv2d(%input.100, %1871, %1872, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1877 : bool = prim::GetAttr[name="training"](%1815)
       = prim::If(%1877) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1878 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1815)
          %1879 : Tensor = aten::add(%1878, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1815, %1879)
          -> ()
        block1():
          -> ()
      %1880 : bool = prim::GetAttr[name="training"](%1815)
      %1881 : Tensor = prim::GetAttr[name="running_mean"](%1815)
      %1882 : Tensor = prim::GetAttr[name="running_var"](%1815)
      %1883 : Tensor = prim::GetAttr[name="weight"](%1815)
      %1884 : Tensor = prim::GetAttr[name="bias"](%1815)
       = prim::If(%1880) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1885 : int[] = aten::size(%input.101) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.136 : int = aten::__getitem__(%1885, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1887 : int = aten::len(%1885) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1888 : int = aten::sub(%1887, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.137 : int = prim::Loop(%1888, %10, %size_prods.136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.35 : int, %size_prods.138 : int):
              %1892 : int = aten::add(%i.35, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1893 : int = aten::__getitem__(%1885, %1892) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.139 : int = aten::mul(%size_prods.138, %1893) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.139)
          %1895 : bool = aten::eq(%size_prods.137, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1895) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1896 : str = aten::format(%8, %1885) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1896) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.102 : Tensor = aten::batch_norm(%input.101, %1883, %1884, %1881, %1882, %1880, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.103 : Tensor = aten::relu_(%input.102) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1899 : Tensor[] = prim::ListConstruct(%3537, %input.103)
      %out.16 : Tensor = aten::cat(%1899, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:90:18
      -> (%out.16)
    block1():
      %1901 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="branch2"](%931)
      %1902 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="0"](%1901)
      %1903 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%1901)
      %1904 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="3"](%1901)
      %1905 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%1901)
      %1906 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="5"](%1901)
      %1907 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="6"](%1901)
      %1908 : Tensor = prim::GetAttr[name="weight"](%1902)
      %1909 : Tensor? = prim::GetAttr[name="bias"](%1902)
      %input.104 : Tensor = aten::conv2d(%input.289, %1908, %1909, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1914 : bool = prim::GetAttr[name="training"](%1903)
       = prim::If(%1914) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1915 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1903)
          %1916 : Tensor = aten::add(%1915, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1903, %1916)
          -> ()
        block1():
          -> ()
      %1917 : bool = prim::GetAttr[name="training"](%1903)
      %1918 : Tensor = prim::GetAttr[name="running_mean"](%1903)
      %1919 : Tensor = prim::GetAttr[name="running_var"](%1903)
      %1920 : Tensor = prim::GetAttr[name="weight"](%1903)
      %1921 : Tensor = prim::GetAttr[name="bias"](%1903)
       = prim::If(%1917) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1922 : int[] = aten::size(%input.104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.140 : int = aten::__getitem__(%1922, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1924 : int = aten::len(%1922) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1925 : int = aten::sub(%1924, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.141 : int = prim::Loop(%1925, %10, %size_prods.140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.36 : int, %size_prods.142 : int):
              %1929 : int = aten::add(%i.36, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1930 : int = aten::__getitem__(%1922, %1929) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.143 : int = aten::mul(%size_prods.142, %1930) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.143)
          %1932 : bool = aten::eq(%size_prods.141, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1932) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1933 : str = aten::format(%8, %1922) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1933) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.105 : Tensor = aten::batch_norm(%input.104, %1920, %1921, %1918, %1919, %1917, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.106 : Tensor = aten::relu_(%input.105) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1936 : Tensor = prim::GetAttr[name="weight"](%1904)
      %1937 : Tensor? = prim::GetAttr[name="bias"](%1904)
      %input.107 : Tensor = aten::conv2d(%input.106, %1936, %1937, %3554, %3554, %3554, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1942 : bool = prim::GetAttr[name="training"](%1905)
       = prim::If(%1942) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1943 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1905)
          %1944 : Tensor = aten::add(%1943, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1905, %1944)
          -> ()
        block1():
          -> ()
      %1945 : bool = prim::GetAttr[name="training"](%1905)
      %1946 : Tensor = prim::GetAttr[name="running_mean"](%1905)
      %1947 : Tensor = prim::GetAttr[name="running_var"](%1905)
      %1948 : Tensor = prim::GetAttr[name="weight"](%1905)
      %1949 : Tensor = prim::GetAttr[name="bias"](%1905)
       = prim::If(%1945) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1950 : int[] = aten::size(%input.107) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.144 : int = aten::__getitem__(%1950, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1952 : int = aten::len(%1950) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1953 : int = aten::sub(%1952, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.145 : int = prim::Loop(%1953, %10, %size_prods.144) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.37 : int, %size_prods.146 : int):
              %1957 : int = aten::add(%i.37, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1958 : int = aten::__getitem__(%1950, %1957) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.147 : int = aten::mul(%size_prods.146, %1958) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.147)
          %1960 : bool = aten::eq(%size_prods.145, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1961 : str = aten::format(%8, %1950) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1961) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.108 : Tensor = aten::batch_norm(%input.107, %1948, %1949, %1946, %1947, %1945, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %1963 : Tensor = prim::GetAttr[name="weight"](%1906)
      %1964 : Tensor? = prim::GetAttr[name="bias"](%1906)
      %input.109 : Tensor = aten::conv2d(%input.108, %1963, %1964, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %1969 : bool = prim::GetAttr[name="training"](%1907)
       = prim::If(%1969) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1970 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1907)
          %1971 : Tensor = aten::add(%1970, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1907, %1971)
          -> ()
        block1():
          -> ()
      %1972 : bool = prim::GetAttr[name="training"](%1907)
      %1973 : Tensor = prim::GetAttr[name="running_mean"](%1907)
      %1974 : Tensor = prim::GetAttr[name="running_var"](%1907)
      %1975 : Tensor = prim::GetAttr[name="weight"](%1907)
      %1976 : Tensor = prim::GetAttr[name="bias"](%1907)
       = prim::If(%1972) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1977 : int[] = aten::size(%input.109) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.148 : int = aten::__getitem__(%1977, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1979 : int = aten::len(%1977) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1980 : int = aten::sub(%1979, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.149 : int = prim::Loop(%1980, %10, %size_prods.148) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.38 : int, %size_prods.150 : int):
              %1984 : int = aten::add(%i.38, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1985 : int = aten::__getitem__(%1977, %1984) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.151 : int = aten::mul(%size_prods.150, %1985) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.151)
          %1987 : bool = aten::eq(%size_prods.149, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1987) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1988 : str = aten::format(%8, %1977) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1988) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.110 : Tensor = aten::batch_norm(%input.109, %1975, %1976, %1973, %1974, %1972, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.111 : Tensor = aten::relu_(%input.110) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1991 : Tensor[] = prim::ListConstruct(%input.289, %input.111)
      %out.17 : Tensor = aten::cat(%1991, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:92:18
      -> (%out.17)
  %1993 : int[] = aten::size(%out.18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:22:45
  %batchsize.6 : int, %num_channels.6 : int, %height.6 : int, %width.6 : int = prim::ListUnpack(%1993)
  %channels_per_group.6 : int = aten::floordiv(%num_channels.6, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:23:25
  %1999 : int[] = prim::ListConstruct(%batchsize.6, %4, %channels_per_group.6, %height.6, %width.6)
  %x.14 : Tensor = aten::view(%out.18, %1999) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:26:8
  %2001 : Tensor = aten::transpose(%x.14, %11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %x.15 : Tensor = aten::contiguous(%2001, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %2003 : int[] = prim::ListConstruct(%batchsize.6, %14, %height.6, %width.6)
  %input.220 : Tensor = aten::view(%x.15, %2003) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:32:8
  %2005 : int = prim::GetAttr[name="stride"](%932)
  %2006 : bool = aten::eq(%2005, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:11
  %out.21 : Tensor = prim::If(%2006) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:8
    block0():
      %3539 : Tensor, %3540 : Tensor = prim::ConstantChunk[chunks=2, dim=1](%input.220)
      %2011 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="branch2"](%932)
      %2012 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="0"](%2011)
      %2013 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%2011)
      %2014 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="3"](%2011)
      %2015 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%2011)
      %2016 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="5"](%2011)
      %2017 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="6"](%2011)
      %2018 : Tensor = prim::GetAttr[name="weight"](%2012)
      %2019 : Tensor? = prim::GetAttr[name="bias"](%2012)
      %input.112 : Tensor = aten::conv2d(%3540, %2018, %2019, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2024 : bool = prim::GetAttr[name="training"](%2013)
       = prim::If(%2024) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2025 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2013)
          %2026 : Tensor = aten::add(%2025, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2013, %2026)
          -> ()
        block1():
          -> ()
      %2027 : bool = prim::GetAttr[name="training"](%2013)
      %2028 : Tensor = prim::GetAttr[name="running_mean"](%2013)
      %2029 : Tensor = prim::GetAttr[name="running_var"](%2013)
      %2030 : Tensor = prim::GetAttr[name="weight"](%2013)
      %2031 : Tensor = prim::GetAttr[name="bias"](%2013)
       = prim::If(%2027) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2032 : int[] = aten::size(%input.112) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.152 : int = aten::__getitem__(%2032, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2034 : int = aten::len(%2032) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2035 : int = aten::sub(%2034, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.153 : int = prim::Loop(%2035, %10, %size_prods.152) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.39 : int, %size_prods.154 : int):
              %2039 : int = aten::add(%i.39, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2040 : int = aten::__getitem__(%2032, %2039) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.155 : int = aten::mul(%size_prods.154, %2040) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.155)
          %2042 : bool = aten::eq(%size_prods.153, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2042) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2043 : str = aten::format(%8, %2032) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2043) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.113 : Tensor = aten::batch_norm(%input.112, %2030, %2031, %2028, %2029, %2027, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.114 : Tensor = aten::relu_(%input.113) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2046 : Tensor = prim::GetAttr[name="weight"](%2014)
      %2047 : Tensor? = prim::GetAttr[name="bias"](%2014)
      %input.115 : Tensor = aten::conv2d(%input.114, %2046, %2047, %3554, %3554, %3554, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2052 : bool = prim::GetAttr[name="training"](%2015)
       = prim::If(%2052) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2053 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2015)
          %2054 : Tensor = aten::add(%2053, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2015, %2054)
          -> ()
        block1():
          -> ()
      %2055 : bool = prim::GetAttr[name="training"](%2015)
      %2056 : Tensor = prim::GetAttr[name="running_mean"](%2015)
      %2057 : Tensor = prim::GetAttr[name="running_var"](%2015)
      %2058 : Tensor = prim::GetAttr[name="weight"](%2015)
      %2059 : Tensor = prim::GetAttr[name="bias"](%2015)
       = prim::If(%2055) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2060 : int[] = aten::size(%input.115) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.156 : int = aten::__getitem__(%2060, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2062 : int = aten::len(%2060) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2063 : int = aten::sub(%2062, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.157 : int = prim::Loop(%2063, %10, %size_prods.156) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.40 : int, %size_prods.158 : int):
              %2067 : int = aten::add(%i.40, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2068 : int = aten::__getitem__(%2060, %2067) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.159 : int = aten::mul(%size_prods.158, %2068) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.159)
          %2070 : bool = aten::eq(%size_prods.157, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2070) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2071 : str = aten::format(%8, %2060) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2071) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.116 : Tensor = aten::batch_norm(%input.115, %2058, %2059, %2056, %2057, %2055, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2073 : Tensor = prim::GetAttr[name="weight"](%2016)
      %2074 : Tensor? = prim::GetAttr[name="bias"](%2016)
      %input.117 : Tensor = aten::conv2d(%input.116, %2073, %2074, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2079 : bool = prim::GetAttr[name="training"](%2017)
       = prim::If(%2079) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2080 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2017)
          %2081 : Tensor = aten::add(%2080, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2017, %2081)
          -> ()
        block1():
          -> ()
      %2082 : bool = prim::GetAttr[name="training"](%2017)
      %2083 : Tensor = prim::GetAttr[name="running_mean"](%2017)
      %2084 : Tensor = prim::GetAttr[name="running_var"](%2017)
      %2085 : Tensor = prim::GetAttr[name="weight"](%2017)
      %2086 : Tensor = prim::GetAttr[name="bias"](%2017)
       = prim::If(%2082) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2087 : int[] = aten::size(%input.117) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.160 : int = aten::__getitem__(%2087, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2089 : int = aten::len(%2087) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2090 : int = aten::sub(%2089, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.161 : int = prim::Loop(%2090, %10, %size_prods.160) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.41 : int, %size_prods.162 : int):
              %2094 : int = aten::add(%i.41, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2095 : int = aten::__getitem__(%2087, %2094) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.163 : int = aten::mul(%size_prods.162, %2095) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.163)
          %2097 : bool = aten::eq(%size_prods.161, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2097) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2098 : str = aten::format(%8, %2087) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2098) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.118 : Tensor = aten::batch_norm(%input.117, %2085, %2086, %2083, %2084, %2082, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.119 : Tensor = aten::relu_(%input.118) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2101 : Tensor[] = prim::ListConstruct(%3539, %input.119)
      %out.19 : Tensor = aten::cat(%2101, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:90:18
      -> (%out.19)
    block1():
      %2103 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="branch2"](%932)
      %2104 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="0"](%2103)
      %2105 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%2103)
      %2106 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="3"](%2103)
      %2107 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%2103)
      %2108 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="5"](%2103)
      %2109 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="6"](%2103)
      %2110 : Tensor = prim::GetAttr[name="weight"](%2104)
      %2111 : Tensor? = prim::GetAttr[name="bias"](%2104)
      %input.120 : Tensor = aten::conv2d(%input.220, %2110, %2111, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2116 : bool = prim::GetAttr[name="training"](%2105)
       = prim::If(%2116) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2117 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2105)
          %2118 : Tensor = aten::add(%2117, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2105, %2118)
          -> ()
        block1():
          -> ()
      %2119 : bool = prim::GetAttr[name="training"](%2105)
      %2120 : Tensor = prim::GetAttr[name="running_mean"](%2105)
      %2121 : Tensor = prim::GetAttr[name="running_var"](%2105)
      %2122 : Tensor = prim::GetAttr[name="weight"](%2105)
      %2123 : Tensor = prim::GetAttr[name="bias"](%2105)
       = prim::If(%2119) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2124 : int[] = aten::size(%input.120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.164 : int = aten::__getitem__(%2124, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2126 : int = aten::len(%2124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2127 : int = aten::sub(%2126, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.165 : int = prim::Loop(%2127, %10, %size_prods.164) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.42 : int, %size_prods.166 : int):
              %2131 : int = aten::add(%i.42, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2132 : int = aten::__getitem__(%2124, %2131) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.167 : int = aten::mul(%size_prods.166, %2132) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.167)
          %2134 : bool = aten::eq(%size_prods.165, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2134) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2135 : str = aten::format(%8, %2124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2135) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.121 : Tensor = aten::batch_norm(%input.120, %2122, %2123, %2120, %2121, %2119, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.122 : Tensor = aten::relu_(%input.121) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2138 : Tensor = prim::GetAttr[name="weight"](%2106)
      %2139 : Tensor? = prim::GetAttr[name="bias"](%2106)
      %input.123 : Tensor = aten::conv2d(%input.122, %2138, %2139, %3554, %3554, %3554, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2144 : bool = prim::GetAttr[name="training"](%2107)
       = prim::If(%2144) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2145 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2107)
          %2146 : Tensor = aten::add(%2145, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2107, %2146)
          -> ()
        block1():
          -> ()
      %2147 : bool = prim::GetAttr[name="training"](%2107)
      %2148 : Tensor = prim::GetAttr[name="running_mean"](%2107)
      %2149 : Tensor = prim::GetAttr[name="running_var"](%2107)
      %2150 : Tensor = prim::GetAttr[name="weight"](%2107)
      %2151 : Tensor = prim::GetAttr[name="bias"](%2107)
       = prim::If(%2147) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2152 : int[] = aten::size(%input.123) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.168 : int = aten::__getitem__(%2152, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2154 : int = aten::len(%2152) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2155 : int = aten::sub(%2154, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.169 : int = prim::Loop(%2155, %10, %size_prods.168) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.43 : int, %size_prods.170 : int):
              %2159 : int = aten::add(%i.43, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2160 : int = aten::__getitem__(%2152, %2159) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.171 : int = aten::mul(%size_prods.170, %2160) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.171)
          %2162 : bool = aten::eq(%size_prods.169, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2162) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2163 : str = aten::format(%8, %2152) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2163) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.124 : Tensor = aten::batch_norm(%input.123, %2150, %2151, %2148, %2149, %2147, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2165 : Tensor = prim::GetAttr[name="weight"](%2108)
      %2166 : Tensor? = prim::GetAttr[name="bias"](%2108)
      %input.125 : Tensor = aten::conv2d(%input.124, %2165, %2166, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2171 : bool = prim::GetAttr[name="training"](%2109)
       = prim::If(%2171) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2172 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2109)
          %2173 : Tensor = aten::add(%2172, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2109, %2173)
          -> ()
        block1():
          -> ()
      %2174 : bool = prim::GetAttr[name="training"](%2109)
      %2175 : Tensor = prim::GetAttr[name="running_mean"](%2109)
      %2176 : Tensor = prim::GetAttr[name="running_var"](%2109)
      %2177 : Tensor = prim::GetAttr[name="weight"](%2109)
      %2178 : Tensor = prim::GetAttr[name="bias"](%2109)
       = prim::If(%2174) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2179 : int[] = aten::size(%input.125) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.172 : int = aten::__getitem__(%2179, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2181 : int = aten::len(%2179) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2182 : int = aten::sub(%2181, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.173 : int = prim::Loop(%2182, %10, %size_prods.172) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.44 : int, %size_prods.174 : int):
              %2186 : int = aten::add(%i.44, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2187 : int = aten::__getitem__(%2179, %2186) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.175 : int = aten::mul(%size_prods.174, %2187) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.175)
          %2189 : bool = aten::eq(%size_prods.173, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2189) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2190 : str = aten::format(%8, %2179) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2190) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.126 : Tensor = aten::batch_norm(%input.125, %2177, %2178, %2175, %2176, %2174, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.127 : Tensor = aten::relu_(%input.126) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2193 : Tensor[] = prim::ListConstruct(%input.220, %input.127)
      %out.20 : Tensor = aten::cat(%2193, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:92:18
      -> (%out.20)
  %2195 : int[] = aten::size(%out.21) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:22:45
  %batchsize.7 : int, %num_channels.7 : int, %height.7 : int, %width.7 : int = prim::ListUnpack(%2195)
  %channels_per_group.7 : int = aten::floordiv(%num_channels.7, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:23:25
  %2201 : int[] = prim::ListConstruct(%batchsize.7, %4, %channels_per_group.7, %height.7, %width.7)
  %x.16 : Tensor = aten::view(%out.21, %2201) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:26:8
  %2203 : Tensor = aten::transpose(%x.16, %11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %x.17 : Tensor = aten::contiguous(%2203, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %2205 : int[] = prim::ListConstruct(%batchsize.7, %14, %height.7, %width.7)
  %input.218 : Tensor = aten::view(%x.17, %2205) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:32:8
  %2207 : int = prim::GetAttr[name="stride"](%933)
  %2208 : bool = aten::eq(%2207, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:11
  %out.24 : Tensor = prim::If(%2208) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:8
    block0():
      %3541 : Tensor, %3542 : Tensor = prim::ConstantChunk[chunks=2, dim=1](%input.218)
      %2213 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="branch2"](%933)
      %2214 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="0"](%2213)
      %2215 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%2213)
      %2216 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="3"](%2213)
      %2217 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%2213)
      %2218 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="5"](%2213)
      %2219 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="6"](%2213)
      %2220 : Tensor = prim::GetAttr[name="weight"](%2214)
      %2221 : Tensor? = prim::GetAttr[name="bias"](%2214)
      %input.128 : Tensor = aten::conv2d(%3542, %2220, %2221, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2226 : bool = prim::GetAttr[name="training"](%2215)
       = prim::If(%2226) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2227 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2215)
          %2228 : Tensor = aten::add(%2227, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2215, %2228)
          -> ()
        block1():
          -> ()
      %2229 : bool = prim::GetAttr[name="training"](%2215)
      %2230 : Tensor = prim::GetAttr[name="running_mean"](%2215)
      %2231 : Tensor = prim::GetAttr[name="running_var"](%2215)
      %2232 : Tensor = prim::GetAttr[name="weight"](%2215)
      %2233 : Tensor = prim::GetAttr[name="bias"](%2215)
       = prim::If(%2229) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2234 : int[] = aten::size(%input.128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.176 : int = aten::__getitem__(%2234, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2236 : int = aten::len(%2234) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2237 : int = aten::sub(%2236, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.177 : int = prim::Loop(%2237, %10, %size_prods.176) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.45 : int, %size_prods.178 : int):
              %2241 : int = aten::add(%i.45, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2242 : int = aten::__getitem__(%2234, %2241) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.179 : int = aten::mul(%size_prods.178, %2242) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.179)
          %2244 : bool = aten::eq(%size_prods.177, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2244) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2245 : str = aten::format(%8, %2234) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2245) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.129 : Tensor = aten::batch_norm(%input.128, %2232, %2233, %2230, %2231, %2229, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.130 : Tensor = aten::relu_(%input.129) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2248 : Tensor = prim::GetAttr[name="weight"](%2216)
      %2249 : Tensor? = prim::GetAttr[name="bias"](%2216)
      %input.131 : Tensor = aten::conv2d(%input.130, %2248, %2249, %3554, %3554, %3554, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2254 : bool = prim::GetAttr[name="training"](%2217)
       = prim::If(%2254) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2255 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2217)
          %2256 : Tensor = aten::add(%2255, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2217, %2256)
          -> ()
        block1():
          -> ()
      %2257 : bool = prim::GetAttr[name="training"](%2217)
      %2258 : Tensor = prim::GetAttr[name="running_mean"](%2217)
      %2259 : Tensor = prim::GetAttr[name="running_var"](%2217)
      %2260 : Tensor = prim::GetAttr[name="weight"](%2217)
      %2261 : Tensor = prim::GetAttr[name="bias"](%2217)
       = prim::If(%2257) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2262 : int[] = aten::size(%input.131) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.180 : int = aten::__getitem__(%2262, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2264 : int = aten::len(%2262) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2265 : int = aten::sub(%2264, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.181 : int = prim::Loop(%2265, %10, %size_prods.180) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.46 : int, %size_prods.182 : int):
              %2269 : int = aten::add(%i.46, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2270 : int = aten::__getitem__(%2262, %2269) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.183 : int = aten::mul(%size_prods.182, %2270) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.183)
          %2272 : bool = aten::eq(%size_prods.181, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2273 : str = aten::format(%8, %2262) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2273) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.132 : Tensor = aten::batch_norm(%input.131, %2260, %2261, %2258, %2259, %2257, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2275 : Tensor = prim::GetAttr[name="weight"](%2218)
      %2276 : Tensor? = prim::GetAttr[name="bias"](%2218)
      %input.133 : Tensor = aten::conv2d(%input.132, %2275, %2276, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2281 : bool = prim::GetAttr[name="training"](%2219)
       = prim::If(%2281) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2282 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2219)
          %2283 : Tensor = aten::add(%2282, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2219, %2283)
          -> ()
        block1():
          -> ()
      %2284 : bool = prim::GetAttr[name="training"](%2219)
      %2285 : Tensor = prim::GetAttr[name="running_mean"](%2219)
      %2286 : Tensor = prim::GetAttr[name="running_var"](%2219)
      %2287 : Tensor = prim::GetAttr[name="weight"](%2219)
      %2288 : Tensor = prim::GetAttr[name="bias"](%2219)
       = prim::If(%2284) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2289 : int[] = aten::size(%input.133) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.184 : int = aten::__getitem__(%2289, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2291 : int = aten::len(%2289) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2292 : int = aten::sub(%2291, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.185 : int = prim::Loop(%2292, %10, %size_prods.184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.47 : int, %size_prods.186 : int):
              %2296 : int = aten::add(%i.47, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2297 : int = aten::__getitem__(%2289, %2296) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.187 : int = aten::mul(%size_prods.186, %2297) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.187)
          %2299 : bool = aten::eq(%size_prods.185, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2299) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2300 : str = aten::format(%8, %2289) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2300) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.134 : Tensor = aten::batch_norm(%input.133, %2287, %2288, %2285, %2286, %2284, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.135 : Tensor = aten::relu_(%input.134) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2303 : Tensor[] = prim::ListConstruct(%3541, %input.135)
      %out.22 : Tensor = aten::cat(%2303, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:90:18
      -> (%out.22)
    block1():
      %2305 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="branch2"](%933)
      %2306 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="0"](%2305)
      %2307 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%2305)
      %2308 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="3"](%2305)
      %2309 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%2305)
      %2310 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="5"](%2305)
      %2311 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="6"](%2305)
      %2312 : Tensor = prim::GetAttr[name="weight"](%2306)
      %2313 : Tensor? = prim::GetAttr[name="bias"](%2306)
      %input.136 : Tensor = aten::conv2d(%input.218, %2312, %2313, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2318 : bool = prim::GetAttr[name="training"](%2307)
       = prim::If(%2318) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2319 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2307)
          %2320 : Tensor = aten::add(%2319, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2307, %2320)
          -> ()
        block1():
          -> ()
      %2321 : bool = prim::GetAttr[name="training"](%2307)
      %2322 : Tensor = prim::GetAttr[name="running_mean"](%2307)
      %2323 : Tensor = prim::GetAttr[name="running_var"](%2307)
      %2324 : Tensor = prim::GetAttr[name="weight"](%2307)
      %2325 : Tensor = prim::GetAttr[name="bias"](%2307)
       = prim::If(%2321) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2326 : int[] = aten::size(%input.136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.188 : int = aten::__getitem__(%2326, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2328 : int = aten::len(%2326) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2329 : int = aten::sub(%2328, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.189 : int = prim::Loop(%2329, %10, %size_prods.188) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.48 : int, %size_prods.190 : int):
              %2333 : int = aten::add(%i.48, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2334 : int = aten::__getitem__(%2326, %2333) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.191 : int = aten::mul(%size_prods.190, %2334) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.191)
          %2336 : bool = aten::eq(%size_prods.189, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2336) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2337 : str = aten::format(%8, %2326) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2337) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.137 : Tensor = aten::batch_norm(%input.136, %2324, %2325, %2322, %2323, %2321, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.138 : Tensor = aten::relu_(%input.137) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2340 : Tensor = prim::GetAttr[name="weight"](%2308)
      %2341 : Tensor? = prim::GetAttr[name="bias"](%2308)
      %input.139 : Tensor = aten::conv2d(%input.138, %2340, %2341, %3554, %3554, %3554, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2346 : bool = prim::GetAttr[name="training"](%2309)
       = prim::If(%2346) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2347 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2309)
          %2348 : Tensor = aten::add(%2347, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2309, %2348)
          -> ()
        block1():
          -> ()
      %2349 : bool = prim::GetAttr[name="training"](%2309)
      %2350 : Tensor = prim::GetAttr[name="running_mean"](%2309)
      %2351 : Tensor = prim::GetAttr[name="running_var"](%2309)
      %2352 : Tensor = prim::GetAttr[name="weight"](%2309)
      %2353 : Tensor = prim::GetAttr[name="bias"](%2309)
       = prim::If(%2349) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2354 : int[] = aten::size(%input.139) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.192 : int = aten::__getitem__(%2354, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2356 : int = aten::len(%2354) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2357 : int = aten::sub(%2356, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.193 : int = prim::Loop(%2357, %10, %size_prods.192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.49 : int, %size_prods.194 : int):
              %2361 : int = aten::add(%i.49, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2362 : int = aten::__getitem__(%2354, %2361) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.195 : int = aten::mul(%size_prods.194, %2362) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.195)
          %2364 : bool = aten::eq(%size_prods.193, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2364) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2365 : str = aten::format(%8, %2354) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2365) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.140 : Tensor = aten::batch_norm(%input.139, %2352, %2353, %2350, %2351, %2349, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2367 : Tensor = prim::GetAttr[name="weight"](%2310)
      %2368 : Tensor? = prim::GetAttr[name="bias"](%2310)
      %input.141 : Tensor = aten::conv2d(%input.140, %2367, %2368, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2373 : bool = prim::GetAttr[name="training"](%2311)
       = prim::If(%2373) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2374 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2311)
          %2375 : Tensor = aten::add(%2374, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2311, %2375)
          -> ()
        block1():
          -> ()
      %2376 : bool = prim::GetAttr[name="training"](%2311)
      %2377 : Tensor = prim::GetAttr[name="running_mean"](%2311)
      %2378 : Tensor = prim::GetAttr[name="running_var"](%2311)
      %2379 : Tensor = prim::GetAttr[name="weight"](%2311)
      %2380 : Tensor = prim::GetAttr[name="bias"](%2311)
       = prim::If(%2376) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2381 : int[] = aten::size(%input.141) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.196 : int = aten::__getitem__(%2381, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2383 : int = aten::len(%2381) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2384 : int = aten::sub(%2383, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.197 : int = prim::Loop(%2384, %10, %size_prods.196) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.50 : int, %size_prods.198 : int):
              %2388 : int = aten::add(%i.50, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2389 : int = aten::__getitem__(%2381, %2388) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.199 : int = aten::mul(%size_prods.198, %2389) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.199)
          %2391 : bool = aten::eq(%size_prods.197, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2391) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2392 : str = aten::format(%8, %2381) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2392) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.142 : Tensor = aten::batch_norm(%input.141, %2379, %2380, %2377, %2378, %2376, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.143 : Tensor = aten::relu_(%input.142) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2395 : Tensor[] = prim::ListConstruct(%input.218, %input.143)
      %out.23 : Tensor = aten::cat(%2395, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:92:18
      -> (%out.23)
  %2397 : int[] = aten::size(%out.24) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:22:45
  %batchsize.8 : int, %num_channels.8 : int, %height.8 : int, %width.8 : int = prim::ListUnpack(%2397)
  %channels_per_group.8 : int = aten::floordiv(%num_channels.8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:23:25
  %2403 : int[] = prim::ListConstruct(%batchsize.8, %4, %channels_per_group.8, %height.8, %width.8)
  %x.18 : Tensor = aten::view(%out.24, %2403) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:26:8
  %2405 : Tensor = aten::transpose(%x.18, %11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %x.19 : Tensor = aten::contiguous(%2405, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %2407 : int[] = prim::ListConstruct(%batchsize.8, %14, %height.8, %width.8)
  %input.219 : Tensor = aten::view(%x.19, %2407) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:32:8
  %2409 : int = prim::GetAttr[name="stride"](%934)
  %2410 : bool = aten::eq(%2409, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:11
  %out.45 : Tensor = prim::If(%2410) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:8
    block0():
      %3543 : Tensor, %3544 : Tensor = prim::ConstantChunk[chunks=2, dim=1](%input.219)
      %2415 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="branch2"](%934)
      %2416 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="0"](%2415)
      %2417 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%2415)
      %2418 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="3"](%2415)
      %2419 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%2415)
      %2420 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="5"](%2415)
      %2421 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="6"](%2415)
      %2422 : Tensor = prim::GetAttr[name="weight"](%2416)
      %2423 : Tensor? = prim::GetAttr[name="bias"](%2416)
      %input.273 : Tensor = aten::conv2d(%3544, %2422, %2423, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2428 : bool = prim::GetAttr[name="training"](%2417)
       = prim::If(%2428) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2429 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2417)
          %2430 : Tensor = aten::add(%2429, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2417, %2430)
          -> ()
        block1():
          -> ()
      %2431 : bool = prim::GetAttr[name="training"](%2417)
      %2432 : Tensor = prim::GetAttr[name="running_mean"](%2417)
      %2433 : Tensor = prim::GetAttr[name="running_var"](%2417)
      %2434 : Tensor = prim::GetAttr[name="weight"](%2417)
      %2435 : Tensor = prim::GetAttr[name="bias"](%2417)
       = prim::If(%2431) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2436 : int[] = aten::size(%input.273) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.388 : int = aten::__getitem__(%2436, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2438 : int = aten::len(%2436) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2439 : int = aten::sub(%2438, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.389 : int = prim::Loop(%2439, %10, %size_prods.388) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.98 : int, %size_prods.390 : int):
              %2443 : int = aten::add(%i.98, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2444 : int = aten::__getitem__(%2436, %2443) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.391 : int = aten::mul(%size_prods.390, %2444) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.391)
          %2446 : bool = aten::eq(%size_prods.389, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2446) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2447 : str = aten::format(%8, %2436) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2447) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.274 : Tensor = aten::batch_norm(%input.273, %2434, %2435, %2432, %2433, %2431, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.275 : Tensor = aten::relu_(%input.274) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2450 : Tensor = prim::GetAttr[name="weight"](%2418)
      %2451 : Tensor? = prim::GetAttr[name="bias"](%2418)
      %input.276 : Tensor = aten::conv2d(%input.275, %2450, %2451, %3554, %3554, %3554, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2456 : bool = prim::GetAttr[name="training"](%2419)
       = prim::If(%2456) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2457 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2419)
          %2458 : Tensor = aten::add(%2457, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2419, %2458)
          -> ()
        block1():
          -> ()
      %2459 : bool = prim::GetAttr[name="training"](%2419)
      %2460 : Tensor = prim::GetAttr[name="running_mean"](%2419)
      %2461 : Tensor = prim::GetAttr[name="running_var"](%2419)
      %2462 : Tensor = prim::GetAttr[name="weight"](%2419)
      %2463 : Tensor = prim::GetAttr[name="bias"](%2419)
       = prim::If(%2459) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2464 : int[] = aten::size(%input.276) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.392 : int = aten::__getitem__(%2464, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2466 : int = aten::len(%2464) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2467 : int = aten::sub(%2466, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.393 : int = prim::Loop(%2467, %10, %size_prods.392) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.99 : int, %size_prods.394 : int):
              %2471 : int = aten::add(%i.99, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2472 : int = aten::__getitem__(%2464, %2471) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.395 : int = aten::mul(%size_prods.394, %2472) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.395)
          %2474 : bool = aten::eq(%size_prods.393, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2474) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2475 : str = aten::format(%8, %2464) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2475) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.277 : Tensor = aten::batch_norm(%input.276, %2462, %2463, %2460, %2461, %2459, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2477 : Tensor = prim::GetAttr[name="weight"](%2420)
      %2478 : Tensor? = prim::GetAttr[name="bias"](%2420)
      %input.278 : Tensor = aten::conv2d(%input.277, %2477, %2478, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2483 : bool = prim::GetAttr[name="training"](%2421)
       = prim::If(%2483) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2484 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2421)
          %2485 : Tensor = aten::add(%2484, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2421, %2485)
          -> ()
        block1():
          -> ()
      %2486 : bool = prim::GetAttr[name="training"](%2421)
      %2487 : Tensor = prim::GetAttr[name="running_mean"](%2421)
      %2488 : Tensor = prim::GetAttr[name="running_var"](%2421)
      %2489 : Tensor = prim::GetAttr[name="weight"](%2421)
      %2490 : Tensor = prim::GetAttr[name="bias"](%2421)
       = prim::If(%2486) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2491 : int[] = aten::size(%input.278) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.396 : int = aten::__getitem__(%2491, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2493 : int = aten::len(%2491) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2494 : int = aten::sub(%2493, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.397 : int = prim::Loop(%2494, %10, %size_prods.396) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.100 : int, %size_prods.398 : int):
              %2498 : int = aten::add(%i.100, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2499 : int = aten::__getitem__(%2491, %2498) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.399 : int = aten::mul(%size_prods.398, %2499) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.399)
          %2501 : bool = aten::eq(%size_prods.397, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2501) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2502 : str = aten::format(%8, %2491) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2502) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.279 : Tensor = aten::batch_norm(%input.278, %2489, %2490, %2487, %2488, %2486, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.280 : Tensor = aten::relu_(%input.279) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2505 : Tensor[] = prim::ListConstruct(%3543, %input.280)
      %out.46 : Tensor = aten::cat(%2505, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:90:18
      -> (%out.46)
    block1():
      %2507 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="branch2"](%934)
      %2508 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="0"](%2507)
      %2509 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="1"](%2507)
      %2510 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="3"](%2507)
      %2511 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="4"](%2507)
      %2512 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv2d = prim::GetAttr[name="5"](%2507)
      %2513 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_13.BatchNorm2d = prim::GetAttr[name="6"](%2507)
      %2514 : Tensor = prim::GetAttr[name="weight"](%2508)
      %2515 : Tensor? = prim::GetAttr[name="bias"](%2508)
      %input.281 : Tensor = aten::conv2d(%input.219, %2514, %2515, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2520 : bool = prim::GetAttr[name="training"](%2509)
       = prim::If(%2520) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2521 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2509)
          %2522 : Tensor = aten::add(%2521, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2509, %2522)
          -> ()
        block1():
          -> ()
      %2523 : bool = prim::GetAttr[name="training"](%2509)
      %2524 : Tensor = prim::GetAttr[name="running_mean"](%2509)
      %2525 : Tensor = prim::GetAttr[name="running_var"](%2509)
      %2526 : Tensor = prim::GetAttr[name="weight"](%2509)
      %2527 : Tensor = prim::GetAttr[name="bias"](%2509)
       = prim::If(%2523) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2528 : int[] = aten::size(%input.281) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.400 : int = aten::__getitem__(%2528, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2530 : int = aten::len(%2528) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2531 : int = aten::sub(%2530, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.401 : int = prim::Loop(%2531, %10, %size_prods.400) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.101 : int, %size_prods.402 : int):
              %2535 : int = aten::add(%i.101, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2536 : int = aten::__getitem__(%2528, %2535) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.403 : int = aten::mul(%size_prods.402, %2536) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.403)
          %2538 : bool = aten::eq(%size_prods.401, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2538) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2539 : str = aten::format(%8, %2528) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2539) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.282 : Tensor = aten::batch_norm(%input.281, %2526, %2527, %2524, %2525, %2523, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.283 : Tensor = aten::relu_(%input.282) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2542 : Tensor = prim::GetAttr[name="weight"](%2510)
      %2543 : Tensor? = prim::GetAttr[name="bias"](%2510)
      %input.284 : Tensor = aten::conv2d(%input.283, %2542, %2543, %3554, %3554, %3554, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2548 : bool = prim::GetAttr[name="training"](%2511)
       = prim::If(%2548) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2549 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2511)
          %2550 : Tensor = aten::add(%2549, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2511, %2550)
          -> ()
        block1():
          -> ()
      %2551 : bool = prim::GetAttr[name="training"](%2511)
      %2552 : Tensor = prim::GetAttr[name="running_mean"](%2511)
      %2553 : Tensor = prim::GetAttr[name="running_var"](%2511)
      %2554 : Tensor = prim::GetAttr[name="weight"](%2511)
      %2555 : Tensor = prim::GetAttr[name="bias"](%2511)
       = prim::If(%2551) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2556 : int[] = aten::size(%input.284) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.404 : int = aten::__getitem__(%2556, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2558 : int = aten::len(%2556) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2559 : int = aten::sub(%2558, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.405 : int = prim::Loop(%2559, %10, %size_prods.404) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.102 : int, %size_prods.406 : int):
              %2563 : int = aten::add(%i.102, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2564 : int = aten::__getitem__(%2556, %2563) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.407 : int = aten::mul(%size_prods.406, %2564) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.407)
          %2566 : bool = aten::eq(%size_prods.405, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2566) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2567 : str = aten::format(%8, %2556) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2567) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.285 : Tensor = aten::batch_norm(%input.284, %2554, %2555, %2552, %2553, %2551, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2569 : Tensor = prim::GetAttr[name="weight"](%2512)
      %2570 : Tensor? = prim::GetAttr[name="bias"](%2512)
      %input.286 : Tensor = aten::conv2d(%input.285, %2569, %2570, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2575 : bool = prim::GetAttr[name="training"](%2513)
       = prim::If(%2575) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2576 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2513)
          %2577 : Tensor = aten::add(%2576, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2513, %2577)
          -> ()
        block1():
          -> ()
      %2578 : bool = prim::GetAttr[name="training"](%2513)
      %2579 : Tensor = prim::GetAttr[name="running_mean"](%2513)
      %2580 : Tensor = prim::GetAttr[name="running_var"](%2513)
      %2581 : Tensor = prim::GetAttr[name="weight"](%2513)
      %2582 : Tensor = prim::GetAttr[name="bias"](%2513)
       = prim::If(%2578) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2583 : int[] = aten::size(%input.286) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.408 : int = aten::__getitem__(%2583, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2585 : int = aten::len(%2583) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2586 : int = aten::sub(%2585, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.409 : int = prim::Loop(%2586, %10, %size_prods.408) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.103 : int, %size_prods.410 : int):
              %2590 : int = aten::add(%i.103, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2591 : int = aten::__getitem__(%2583, %2590) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.411 : int = aten::mul(%size_prods.410, %2591) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.411)
          %2593 : bool = aten::eq(%size_prods.409, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2593) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2594 : str = aten::format(%8, %2583) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2594) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.287 : Tensor = aten::batch_norm(%input.286, %2581, %2582, %2579, %2580, %2578, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.288 : Tensor = aten::relu_(%input.287) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2597 : Tensor[] = prim::ListConstruct(%input.219, %input.288)
      %out.47 : Tensor = aten::cat(%2597, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:92:18
      -> (%out.47)
  %2599 : int[] = aten::size(%out.45) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:22:45
  %batchsize.16 : int, %num_channels.16 : int, %height.16 : int, %width.16 : int = prim::ListUnpack(%2599)
  %channels_per_group.16 : int = aten::floordiv(%num_channels.16, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:23:25
  %2605 : int[] = prim::ListConstruct(%batchsize.16, %4, %channels_per_group.16, %height.16, %width.16)
  %x.41 : Tensor = aten::view(%out.45, %2605) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:26:8
  %2607 : Tensor = aten::transpose(%x.41, %11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %x.42 : Tensor = aten::contiguous(%2607, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %2609 : int[] = prim::ListConstruct(%batchsize.16, %14, %height.16, %width.16)
  %x.25 : Tensor = aten::view(%x.42, %2609) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:32:8
  %2611 : __torch__.torch.nn.modules.container.___torch_mangle_31.Sequential = prim::GetAttr[name="stage4"](%self)
  %2612 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_27.InvertedResidual = prim::GetAttr[name="0"](%2611)
  %2613 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_30.InvertedResidual = prim::GetAttr[name="1"](%2611)
  %2614 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_30.InvertedResidual = prim::GetAttr[name="2"](%2611)
  %2615 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_30.InvertedResidual = prim::GetAttr[name="3"](%2611)
  %2616 : int = prim::GetAttr[name="stride"](%2612)
  %2617 : bool = aten::eq(%2616, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:11
  %out.3 : Tensor = prim::If(%2617) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:8
    block0():
      %3545 : Tensor, %3546 : Tensor = prim::ConstantChunk[chunks=2, dim=1](%x.25)
      %2622 : __torch__.torch.nn.modules.container.___torch_mangle_26.Sequential = prim::GetAttr[name="branch2"](%2612)
      %2623 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="0"](%2622)
      %2624 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="1"](%2622)
      %2625 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="3"](%2622)
      %2626 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="4"](%2622)
      %2627 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="5"](%2622)
      %2628 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="6"](%2622)
      %2629 : Tensor = prim::GetAttr[name="weight"](%2623)
      %2630 : Tensor? = prim::GetAttr[name="bias"](%2623)
      %input.28 : Tensor = aten::conv2d(%3546, %2629, %2630, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2635 : bool = prim::GetAttr[name="training"](%2624)
       = prim::If(%2635) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2636 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2624)
          %2637 : Tensor = aten::add(%2636, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2624, %2637)
          -> ()
        block1():
          -> ()
      %2638 : bool = prim::GetAttr[name="training"](%2624)
      %2639 : Tensor = prim::GetAttr[name="running_mean"](%2624)
      %2640 : Tensor = prim::GetAttr[name="running_var"](%2624)
      %2641 : Tensor = prim::GetAttr[name="weight"](%2624)
      %2642 : Tensor = prim::GetAttr[name="bias"](%2624)
       = prim::If(%2638) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2643 : int[] = aten::size(%input.28) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.32 : int = aten::__getitem__(%2643, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2645 : int = aten::len(%2643) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2646 : int = aten::sub(%2645, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.33 : int = prim::Loop(%2646, %10, %size_prods.32) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.9 : int, %size_prods.34 : int):
              %2650 : int = aten::add(%i.9, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2651 : int = aten::__getitem__(%2643, %2650) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.35 : int = aten::mul(%size_prods.34, %2651) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.35)
          %2653 : bool = aten::eq(%size_prods.33, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2653) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2654 : str = aten::format(%8, %2643) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2654) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.29 : Tensor = aten::batch_norm(%input.28, %2641, %2642, %2639, %2640, %2638, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.30 : Tensor = aten::relu_(%input.29) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2657 : Tensor = prim::GetAttr[name="weight"](%2625)
      %2658 : Tensor? = prim::GetAttr[name="bias"](%2625)
      %input.31 : Tensor = aten::conv2d(%input.30, %2657, %2658, %3553, %3554, %3554, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2663 : bool = prim::GetAttr[name="training"](%2626)
       = prim::If(%2663) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2664 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2626)
          %2665 : Tensor = aten::add(%2664, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2626, %2665)
          -> ()
        block1():
          -> ()
      %2666 : bool = prim::GetAttr[name="training"](%2626)
      %2667 : Tensor = prim::GetAttr[name="running_mean"](%2626)
      %2668 : Tensor = prim::GetAttr[name="running_var"](%2626)
      %2669 : Tensor = prim::GetAttr[name="weight"](%2626)
      %2670 : Tensor = prim::GetAttr[name="bias"](%2626)
       = prim::If(%2666) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2671 : int[] = aten::size(%input.31) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.24 : int = aten::__getitem__(%2671, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2673 : int = aten::len(%2671) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2674 : int = aten::sub(%2673, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.25 : int = prim::Loop(%2674, %10, %size_prods.24) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.7 : int, %size_prods.26 : int):
              %2678 : int = aten::add(%i.7, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2679 : int = aten::__getitem__(%2671, %2678) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.27 : int = aten::mul(%size_prods.26, %2679) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.27)
          %2681 : bool = aten::eq(%size_prods.25, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2681) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2682 : str = aten::format(%8, %2671) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2682) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.32 : Tensor = aten::batch_norm(%input.31, %2669, %2670, %2667, %2668, %2666, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2684 : Tensor = prim::GetAttr[name="weight"](%2627)
      %2685 : Tensor? = prim::GetAttr[name="bias"](%2627)
      %input.21 : Tensor = aten::conv2d(%input.32, %2684, %2685, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2690 : bool = prim::GetAttr[name="training"](%2628)
       = prim::If(%2690) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2691 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2628)
          %2692 : Tensor = aten::add(%2691, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2628, %2692)
          -> ()
        block1():
          -> ()
      %2693 : bool = prim::GetAttr[name="training"](%2628)
      %2694 : Tensor = prim::GetAttr[name="running_mean"](%2628)
      %2695 : Tensor = prim::GetAttr[name="running_var"](%2628)
      %2696 : Tensor = prim::GetAttr[name="weight"](%2628)
      %2697 : Tensor = prim::GetAttr[name="bias"](%2628)
       = prim::If(%2693) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2698 : int[] = aten::size(%input.21) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.36 : int = aten::__getitem__(%2698, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2700 : int = aten::len(%2698) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2701 : int = aten::sub(%2700, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.37 : int = prim::Loop(%2701, %10, %size_prods.36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.10 : int, %size_prods.38 : int):
              %2705 : int = aten::add(%i.10, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2706 : int = aten::__getitem__(%2698, %2705) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.39 : int = aten::mul(%size_prods.38, %2706) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.39)
          %2708 : bool = aten::eq(%size_prods.37, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2708) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2709 : str = aten::format(%8, %2698) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2709) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.22 : Tensor = aten::batch_norm(%input.21, %2696, %2697, %2694, %2695, %2693, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.23 : Tensor = aten::relu_(%input.22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2712 : Tensor[] = prim::ListConstruct(%3545, %input.23)
      %out.4 : Tensor = aten::cat(%2712, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:90:18
      -> (%out.4)
    block1():
      %2714 : __torch__.torch.nn.modules.container.___torch_mangle_25.Sequential = prim::GetAttr[name="branch1"](%2612)
      %2715 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="0"](%2714)
      %2716 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="1"](%2714)
      %2717 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="2"](%2714)
      %2718 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="3"](%2714)
      %2719 : Tensor = prim::GetAttr[name="weight"](%2715)
      %2720 : Tensor? = prim::GetAttr[name="bias"](%2715)
      %input.33 : Tensor = aten::conv2d(%x.25, %2719, %2720, %3553, %3554, %3554, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2725 : bool = prim::GetAttr[name="training"](%2716)
       = prim::If(%2725) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2726 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2716)
          %2727 : Tensor = aten::add(%2726, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2716, %2727)
          -> ()
        block1():
          -> ()
      %2728 : bool = prim::GetAttr[name="training"](%2716)
      %2729 : Tensor = prim::GetAttr[name="running_mean"](%2716)
      %2730 : Tensor = prim::GetAttr[name="running_var"](%2716)
      %2731 : Tensor = prim::GetAttr[name="weight"](%2716)
      %2732 : Tensor = prim::GetAttr[name="bias"](%2716)
       = prim::If(%2728) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2733 : int[] = aten::size(%input.33) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.40 : int = aten::__getitem__(%2733, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2735 : int = aten::len(%2733) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2736 : int = aten::sub(%2735, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.41 : int = prim::Loop(%2736, %10, %size_prods.40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.11 : int, %size_prods.42 : int):
              %2740 : int = aten::add(%i.11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2741 : int = aten::__getitem__(%2733, %2740) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.43 : int = aten::mul(%size_prods.42, %2741) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.43)
          %2743 : bool = aten::eq(%size_prods.41, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2743) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2744 : str = aten::format(%8, %2733) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2744) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.34 : Tensor = aten::batch_norm(%input.33, %2731, %2732, %2729, %2730, %2728, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2746 : Tensor = prim::GetAttr[name="weight"](%2717)
      %2747 : Tensor? = prim::GetAttr[name="bias"](%2717)
      %input.35 : Tensor = aten::conv2d(%input.34, %2746, %2747, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2752 : bool = prim::GetAttr[name="training"](%2718)
       = prim::If(%2752) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2753 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2718)
          %2754 : Tensor = aten::add(%2753, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2718, %2754)
          -> ()
        block1():
          -> ()
      %2755 : bool = prim::GetAttr[name="training"](%2718)
      %2756 : Tensor = prim::GetAttr[name="running_mean"](%2718)
      %2757 : Tensor = prim::GetAttr[name="running_var"](%2718)
      %2758 : Tensor = prim::GetAttr[name="weight"](%2718)
      %2759 : Tensor = prim::GetAttr[name="bias"](%2718)
       = prim::If(%2755) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2760 : int[] = aten::size(%input.35) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.28 : int = aten::__getitem__(%2760, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2762 : int = aten::len(%2760) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2763 : int = aten::sub(%2762, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.29 : int = prim::Loop(%2763, %10, %size_prods.28) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.8 : int, %size_prods.30 : int):
              %2767 : int = aten::add(%i.8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2768 : int = aten::__getitem__(%2760, %2767) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.31 : int = aten::mul(%size_prods.30, %2768) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.31)
          %2770 : bool = aten::eq(%size_prods.29, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2770) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2771 : str = aten::format(%8, %2760) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2771) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.19 : Tensor = aten::batch_norm(%input.35, %2758, %2759, %2756, %2757, %2755, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.20 : Tensor = aten::relu_(%input.19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2774 : __torch__.torch.nn.modules.container.___torch_mangle_26.Sequential = prim::GetAttr[name="branch2"](%2612)
      %2775 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="0"](%2774)
      %2776 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="1"](%2774)
      %2777 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="3"](%2774)
      %2778 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="4"](%2774)
      %2779 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="5"](%2774)
      %2780 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="6"](%2774)
      %2781 : Tensor = prim::GetAttr[name="weight"](%2775)
      %2782 : Tensor? = prim::GetAttr[name="bias"](%2775)
      %input.36 : Tensor = aten::conv2d(%x.25, %2781, %2782, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2787 : bool = prim::GetAttr[name="training"](%2776)
       = prim::If(%2787) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2788 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2776)
          %2789 : Tensor = aten::add(%2788, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2776, %2789)
          -> ()
        block1():
          -> ()
      %2790 : bool = prim::GetAttr[name="training"](%2776)
      %2791 : Tensor = prim::GetAttr[name="running_mean"](%2776)
      %2792 : Tensor = prim::GetAttr[name="running_var"](%2776)
      %2793 : Tensor = prim::GetAttr[name="weight"](%2776)
      %2794 : Tensor = prim::GetAttr[name="bias"](%2776)
       = prim::If(%2790) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2795 : int[] = aten::size(%input.36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.44 : int = aten::__getitem__(%2795, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2797 : int = aten::len(%2795) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2798 : int = aten::sub(%2797, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.45 : int = prim::Loop(%2798, %10, %size_prods.44) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.12 : int, %size_prods.46 : int):
              %2802 : int = aten::add(%i.12, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2803 : int = aten::__getitem__(%2795, %2802) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.47 : int = aten::mul(%size_prods.46, %2803) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.47)
          %2805 : bool = aten::eq(%size_prods.45, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2805) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2806 : str = aten::format(%8, %2795) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2806) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.37 : Tensor = aten::batch_norm(%input.36, %2793, %2794, %2791, %2792, %2790, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.38 : Tensor = aten::relu_(%input.37) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2809 : Tensor = prim::GetAttr[name="weight"](%2777)
      %2810 : Tensor? = prim::GetAttr[name="bias"](%2777)
      %input.39 : Tensor = aten::conv2d(%input.38, %2809, %2810, %3553, %3554, %3554, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2815 : bool = prim::GetAttr[name="training"](%2778)
       = prim::If(%2815) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2816 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2778)
          %2817 : Tensor = aten::add(%2816, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2778, %2817)
          -> ()
        block1():
          -> ()
      %2818 : bool = prim::GetAttr[name="training"](%2778)
      %2819 : Tensor = prim::GetAttr[name="running_mean"](%2778)
      %2820 : Tensor = prim::GetAttr[name="running_var"](%2778)
      %2821 : Tensor = prim::GetAttr[name="weight"](%2778)
      %2822 : Tensor = prim::GetAttr[name="bias"](%2778)
       = prim::If(%2818) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2823 : int[] = aten::size(%input.39) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.48 : int = aten::__getitem__(%2823, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2825 : int = aten::len(%2823) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2826 : int = aten::sub(%2825, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.49 : int = prim::Loop(%2826, %10, %size_prods.48) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.13 : int, %size_prods.50 : int):
              %2830 : int = aten::add(%i.13, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2831 : int = aten::__getitem__(%2823, %2830) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.51 : int = aten::mul(%size_prods.50, %2831) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.51)
          %2833 : bool = aten::eq(%size_prods.49, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2833) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2834 : str = aten::format(%8, %2823) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2834) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.40 : Tensor = aten::batch_norm(%input.39, %2821, %2822, %2819, %2820, %2818, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2836 : Tensor = prim::GetAttr[name="weight"](%2779)
      %2837 : Tensor? = prim::GetAttr[name="bias"](%2779)
      %input.41 : Tensor = aten::conv2d(%input.40, %2836, %2837, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2842 : bool = prim::GetAttr[name="training"](%2780)
       = prim::If(%2842) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2843 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2780)
          %2844 : Tensor = aten::add(%2843, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2780, %2844)
          -> ()
        block1():
          -> ()
      %2845 : bool = prim::GetAttr[name="training"](%2780)
      %2846 : Tensor = prim::GetAttr[name="running_mean"](%2780)
      %2847 : Tensor = prim::GetAttr[name="running_var"](%2780)
      %2848 : Tensor = prim::GetAttr[name="weight"](%2780)
      %2849 : Tensor = prim::GetAttr[name="bias"](%2780)
       = prim::If(%2845) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2850 : int[] = aten::size(%input.41) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.52 : int = aten::__getitem__(%2850, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2852 : int = aten::len(%2850) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2853 : int = aten::sub(%2852, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.53 : int = prim::Loop(%2853, %10, %size_prods.52) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.14 : int, %size_prods.54 : int):
              %2857 : int = aten::add(%i.14, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2858 : int = aten::__getitem__(%2850, %2857) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.55 : int = aten::mul(%size_prods.54, %2858) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.55)
          %2860 : bool = aten::eq(%size_prods.53, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2860) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2861 : str = aten::format(%8, %2850) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2861) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.42 : Tensor = aten::batch_norm(%input.41, %2848, %2849, %2846, %2847, %2845, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.43 : Tensor = aten::relu_(%input.42) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2864 : Tensor[] = prim::ListConstruct(%input.20, %input.43)
      %out.5 : Tensor = aten::cat(%2864, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:92:18
      -> (%out.5)
  %2866 : int[] = aten::size(%out.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:22:45
  %batchsize.2 : int, %num_channels.2 : int, %height.2 : int, %width.2 : int = prim::ListUnpack(%2866)
  %channels_per_group.2 : int = aten::floordiv(%num_channels.2, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:23:25
  %2872 : int[] = prim::ListConstruct(%batchsize.2, %4, %channels_per_group.2, %height.2, %width.2)
  %x.5 : Tensor = aten::view(%out.3, %2872) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:26:8
  %2874 : Tensor = aten::transpose(%x.5, %11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %x.7 : Tensor = aten::contiguous(%2874, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %2876 : int[] = prim::ListConstruct(%batchsize.2, %14, %height.2, %width.2)
  %input.24 : Tensor = aten::view(%x.7, %2876) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:32:8
  %2878 : int = prim::GetAttr[name="stride"](%2613)
  %2879 : bool = aten::eq(%2878, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:11
  %out.6 : Tensor = prim::If(%2879) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:8
    block0():
      %3547 : Tensor, %3548 : Tensor = prim::ConstantChunk[chunks=2, dim=1](%input.24)
      %2884 : __torch__.torch.nn.modules.container.___torch_mangle_29.Sequential = prim::GetAttr[name="branch2"](%2613)
      %2885 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="0"](%2884)
      %2886 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="1"](%2884)
      %2887 : __torch__.torch.nn.modules.conv.___torch_mangle_28.Conv2d = prim::GetAttr[name="3"](%2884)
      %2888 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="4"](%2884)
      %2889 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="5"](%2884)
      %2890 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="6"](%2884)
      %2891 : Tensor = prim::GetAttr[name="weight"](%2885)
      %2892 : Tensor? = prim::GetAttr[name="bias"](%2885)
      %input.44 : Tensor = aten::conv2d(%3548, %2891, %2892, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2897 : bool = prim::GetAttr[name="training"](%2886)
       = prim::If(%2897) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2898 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2886)
          %2899 : Tensor = aten::add(%2898, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2886, %2899)
          -> ()
        block1():
          -> ()
      %2900 : bool = prim::GetAttr[name="training"](%2886)
      %2901 : Tensor = prim::GetAttr[name="running_mean"](%2886)
      %2902 : Tensor = prim::GetAttr[name="running_var"](%2886)
      %2903 : Tensor = prim::GetAttr[name="weight"](%2886)
      %2904 : Tensor = prim::GetAttr[name="bias"](%2886)
       = prim::If(%2900) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2905 : int[] = aten::size(%input.44) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.56 : int = aten::__getitem__(%2905, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2907 : int = aten::len(%2905) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2908 : int = aten::sub(%2907, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.57 : int = prim::Loop(%2908, %10, %size_prods.56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.15 : int, %size_prods.58 : int):
              %2912 : int = aten::add(%i.15, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2913 : int = aten::__getitem__(%2905, %2912) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.59 : int = aten::mul(%size_prods.58, %2913) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.59)
          %2915 : bool = aten::eq(%size_prods.57, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2915) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2916 : str = aten::format(%8, %2905) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2916) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.45 : Tensor = aten::batch_norm(%input.44, %2903, %2904, %2901, %2902, %2900, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.46 : Tensor = aten::relu_(%input.45) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2919 : Tensor = prim::GetAttr[name="weight"](%2887)
      %2920 : Tensor? = prim::GetAttr[name="bias"](%2887)
      %input.47 : Tensor = aten::conv2d(%input.46, %2919, %2920, %3554, %3554, %3554, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2925 : bool = prim::GetAttr[name="training"](%2888)
       = prim::If(%2925) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2926 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2888)
          %2927 : Tensor = aten::add(%2926, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2888, %2927)
          -> ()
        block1():
          -> ()
      %2928 : bool = prim::GetAttr[name="training"](%2888)
      %2929 : Tensor = prim::GetAttr[name="running_mean"](%2888)
      %2930 : Tensor = prim::GetAttr[name="running_var"](%2888)
      %2931 : Tensor = prim::GetAttr[name="weight"](%2888)
      %2932 : Tensor = prim::GetAttr[name="bias"](%2888)
       = prim::If(%2928) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2933 : int[] = aten::size(%input.47) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.60 : int = aten::__getitem__(%2933, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2935 : int = aten::len(%2933) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2936 : int = aten::sub(%2935, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.61 : int = prim::Loop(%2936, %10, %size_prods.60) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.16 : int, %size_prods.62 : int):
              %2940 : int = aten::add(%i.16, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2941 : int = aten::__getitem__(%2933, %2940) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.63 : int = aten::mul(%size_prods.62, %2941) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.63)
          %2943 : bool = aten::eq(%size_prods.61, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2943) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2944 : str = aten::format(%8, %2933) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2944) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.48 : Tensor = aten::batch_norm(%input.47, %2931, %2932, %2929, %2930, %2928, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %2946 : Tensor = prim::GetAttr[name="weight"](%2889)
      %2947 : Tensor? = prim::GetAttr[name="bias"](%2889)
      %input.49 : Tensor = aten::conv2d(%input.48, %2946, %2947, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2952 : bool = prim::GetAttr[name="training"](%2890)
       = prim::If(%2952) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2953 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2890)
          %2954 : Tensor = aten::add(%2953, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2890, %2954)
          -> ()
        block1():
          -> ()
      %2955 : bool = prim::GetAttr[name="training"](%2890)
      %2956 : Tensor = prim::GetAttr[name="running_mean"](%2890)
      %2957 : Tensor = prim::GetAttr[name="running_var"](%2890)
      %2958 : Tensor = prim::GetAttr[name="weight"](%2890)
      %2959 : Tensor = prim::GetAttr[name="bias"](%2890)
       = prim::If(%2955) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2960 : int[] = aten::size(%input.49) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.64 : int = aten::__getitem__(%2960, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2962 : int = aten::len(%2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2963 : int = aten::sub(%2962, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.65 : int = prim::Loop(%2963, %10, %size_prods.64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.17 : int, %size_prods.66 : int):
              %2967 : int = aten::add(%i.17, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2968 : int = aten::__getitem__(%2960, %2967) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.67 : int = aten::mul(%size_prods.66, %2968) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.67)
          %2970 : bool = aten::eq(%size_prods.65, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2970) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2971 : str = aten::format(%8, %2960) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2971) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.50 : Tensor = aten::batch_norm(%input.49, %2958, %2959, %2956, %2957, %2955, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.51 : Tensor = aten::relu_(%input.50) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2974 : Tensor[] = prim::ListConstruct(%3547, %input.51)
      %out.7 : Tensor = aten::cat(%2974, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:90:18
      -> (%out.7)
    block1():
      %2976 : __torch__.torch.nn.modules.container.___torch_mangle_29.Sequential = prim::GetAttr[name="branch2"](%2613)
      %2977 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="0"](%2976)
      %2978 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="1"](%2976)
      %2979 : __torch__.torch.nn.modules.conv.___torch_mangle_28.Conv2d = prim::GetAttr[name="3"](%2976)
      %2980 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="4"](%2976)
      %2981 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="5"](%2976)
      %2982 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="6"](%2976)
      %2983 : Tensor = prim::GetAttr[name="weight"](%2977)
      %2984 : Tensor? = prim::GetAttr[name="bias"](%2977)
      %input.52 : Tensor = aten::conv2d(%input.24, %2983, %2984, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %2989 : bool = prim::GetAttr[name="training"](%2978)
       = prim::If(%2989) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2990 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2978)
          %2991 : Tensor = aten::add(%2990, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2978, %2991)
          -> ()
        block1():
          -> ()
      %2992 : bool = prim::GetAttr[name="training"](%2978)
      %2993 : Tensor = prim::GetAttr[name="running_mean"](%2978)
      %2994 : Tensor = prim::GetAttr[name="running_var"](%2978)
      %2995 : Tensor = prim::GetAttr[name="weight"](%2978)
      %2996 : Tensor = prim::GetAttr[name="bias"](%2978)
       = prim::If(%2992) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2997 : int[] = aten::size(%input.52) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.68 : int = aten::__getitem__(%2997, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2999 : int = aten::len(%2997) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3000 : int = aten::sub(%2999, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.69 : int = prim::Loop(%3000, %10, %size_prods.68) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.18 : int, %size_prods.70 : int):
              %3004 : int = aten::add(%i.18, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3005 : int = aten::__getitem__(%2997, %3004) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.71 : int = aten::mul(%size_prods.70, %3005) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.71)
          %3007 : bool = aten::eq(%size_prods.69, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3007) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3008 : str = aten::format(%8, %2997) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3008) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.53 : Tensor = aten::batch_norm(%input.52, %2995, %2996, %2993, %2994, %2992, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.54 : Tensor = aten::relu_(%input.53) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3011 : Tensor = prim::GetAttr[name="weight"](%2979)
      %3012 : Tensor? = prim::GetAttr[name="bias"](%2979)
      %input.55 : Tensor = aten::conv2d(%input.54, %3011, %3012, %3554, %3554, %3554, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3017 : bool = prim::GetAttr[name="training"](%2980)
       = prim::If(%3017) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3018 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2980)
          %3019 : Tensor = aten::add(%3018, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2980, %3019)
          -> ()
        block1():
          -> ()
      %3020 : bool = prim::GetAttr[name="training"](%2980)
      %3021 : Tensor = prim::GetAttr[name="running_mean"](%2980)
      %3022 : Tensor = prim::GetAttr[name="running_var"](%2980)
      %3023 : Tensor = prim::GetAttr[name="weight"](%2980)
      %3024 : Tensor = prim::GetAttr[name="bias"](%2980)
       = prim::If(%3020) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3025 : int[] = aten::size(%input.55) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.72 : int = aten::__getitem__(%3025, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3027 : int = aten::len(%3025) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3028 : int = aten::sub(%3027, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.73 : int = prim::Loop(%3028, %10, %size_prods.72) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.19 : int, %size_prods.74 : int):
              %3032 : int = aten::add(%i.19, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3033 : int = aten::__getitem__(%3025, %3032) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.75 : int = aten::mul(%size_prods.74, %3033) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.75)
          %3035 : bool = aten::eq(%size_prods.73, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3035) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3036 : str = aten::format(%8, %3025) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3036) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.56 : Tensor = aten::batch_norm(%input.55, %3023, %3024, %3021, %3022, %3020, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %3038 : Tensor = prim::GetAttr[name="weight"](%2981)
      %3039 : Tensor? = prim::GetAttr[name="bias"](%2981)
      %input.57 : Tensor = aten::conv2d(%input.56, %3038, %3039, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3044 : bool = prim::GetAttr[name="training"](%2982)
       = prim::If(%3044) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3045 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2982)
          %3046 : Tensor = aten::add(%3045, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2982, %3046)
          -> ()
        block1():
          -> ()
      %3047 : bool = prim::GetAttr[name="training"](%2982)
      %3048 : Tensor = prim::GetAttr[name="running_mean"](%2982)
      %3049 : Tensor = prim::GetAttr[name="running_var"](%2982)
      %3050 : Tensor = prim::GetAttr[name="weight"](%2982)
      %3051 : Tensor = prim::GetAttr[name="bias"](%2982)
       = prim::If(%3047) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3052 : int[] = aten::size(%input.57) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.76 : int = aten::__getitem__(%3052, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3054 : int = aten::len(%3052) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3055 : int = aten::sub(%3054, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.77 : int = prim::Loop(%3055, %10, %size_prods.76) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.20 : int, %size_prods.78 : int):
              %3059 : int = aten::add(%i.20, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3060 : int = aten::__getitem__(%3052, %3059) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.79 : int = aten::mul(%size_prods.78, %3060) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.79)
          %3062 : bool = aten::eq(%size_prods.77, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3062) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3063 : str = aten::format(%8, %3052) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3063) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.58 : Tensor = aten::batch_norm(%input.57, %3050, %3051, %3048, %3049, %3047, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.59 : Tensor = aten::relu_(%input.58) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3066 : Tensor[] = prim::ListConstruct(%input.24, %input.59)
      %out.9 : Tensor = aten::cat(%3066, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:92:18
      -> (%out.9)
  %3068 : int[] = aten::size(%out.6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:22:45
  %batchsize.3 : int, %num_channels.3 : int, %height.3 : int, %width.3 : int = prim::ListUnpack(%3068)
  %channels_per_group.3 : int = aten::floordiv(%num_channels.3, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:23:25
  %3074 : int[] = prim::ListConstruct(%batchsize.3, %4, %channels_per_group.3, %height.3, %width.3)
  %x.8 : Tensor = aten::view(%out.6, %3074) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:26:8
  %3076 : Tensor = aten::transpose(%x.8, %11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %x.9 : Tensor = aten::contiguous(%3076, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %3078 : int[] = prim::ListConstruct(%batchsize.3, %14, %height.3, %width.3)
  %input.25 : Tensor = aten::view(%x.9, %3078) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:32:8
  %3080 : int = prim::GetAttr[name="stride"](%2614)
  %3081 : bool = aten::eq(%3080, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:11
  %out.12 : Tensor = prim::If(%3081) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:8
    block0():
      %3549 : Tensor, %3550 : Tensor = prim::ConstantChunk[chunks=2, dim=1](%input.25)
      %3086 : __torch__.torch.nn.modules.container.___torch_mangle_29.Sequential = prim::GetAttr[name="branch2"](%2614)
      %3087 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="0"](%3086)
      %3088 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="1"](%3086)
      %3089 : __torch__.torch.nn.modules.conv.___torch_mangle_28.Conv2d = prim::GetAttr[name="3"](%3086)
      %3090 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="4"](%3086)
      %3091 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="5"](%3086)
      %3092 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="6"](%3086)
      %3093 : Tensor = prim::GetAttr[name="weight"](%3087)
      %3094 : Tensor? = prim::GetAttr[name="bias"](%3087)
      %input.60 : Tensor = aten::conv2d(%3550, %3093, %3094, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3099 : bool = prim::GetAttr[name="training"](%3088)
       = prim::If(%3099) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3100 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3088)
          %3101 : Tensor = aten::add(%3100, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3088, %3101)
          -> ()
        block1():
          -> ()
      %3102 : bool = prim::GetAttr[name="training"](%3088)
      %3103 : Tensor = prim::GetAttr[name="running_mean"](%3088)
      %3104 : Tensor = prim::GetAttr[name="running_var"](%3088)
      %3105 : Tensor = prim::GetAttr[name="weight"](%3088)
      %3106 : Tensor = prim::GetAttr[name="bias"](%3088)
       = prim::If(%3102) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3107 : int[] = aten::size(%input.60) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.80 : int = aten::__getitem__(%3107, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3109 : int = aten::len(%3107) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3110 : int = aten::sub(%3109, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.81 : int = prim::Loop(%3110, %10, %size_prods.80) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.21 : int, %size_prods.82 : int):
              %3114 : int = aten::add(%i.21, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3115 : int = aten::__getitem__(%3107, %3114) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.83 : int = aten::mul(%size_prods.82, %3115) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.83)
          %3117 : bool = aten::eq(%size_prods.81, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3117) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3118 : str = aten::format(%8, %3107) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3118) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.61 : Tensor = aten::batch_norm(%input.60, %3105, %3106, %3103, %3104, %3102, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.62 : Tensor = aten::relu_(%input.61) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3121 : Tensor = prim::GetAttr[name="weight"](%3089)
      %3122 : Tensor? = prim::GetAttr[name="bias"](%3089)
      %input.63 : Tensor = aten::conv2d(%input.62, %3121, %3122, %3554, %3554, %3554, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3127 : bool = prim::GetAttr[name="training"](%3090)
       = prim::If(%3127) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3128 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3090)
          %3129 : Tensor = aten::add(%3128, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3090, %3129)
          -> ()
        block1():
          -> ()
      %3130 : bool = prim::GetAttr[name="training"](%3090)
      %3131 : Tensor = prim::GetAttr[name="running_mean"](%3090)
      %3132 : Tensor = prim::GetAttr[name="running_var"](%3090)
      %3133 : Tensor = prim::GetAttr[name="weight"](%3090)
      %3134 : Tensor = prim::GetAttr[name="bias"](%3090)
       = prim::If(%3130) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3135 : int[] = aten::size(%input.63) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.84 : int = aten::__getitem__(%3135, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3137 : int = aten::len(%3135) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3138 : int = aten::sub(%3137, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.85 : int = prim::Loop(%3138, %10, %size_prods.84) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.22 : int, %size_prods.86 : int):
              %3142 : int = aten::add(%i.22, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3143 : int = aten::__getitem__(%3135, %3142) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.87 : int = aten::mul(%size_prods.86, %3143) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.87)
          %3145 : bool = aten::eq(%size_prods.85, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3145) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3146 : str = aten::format(%8, %3135) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3146) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.64 : Tensor = aten::batch_norm(%input.63, %3133, %3134, %3131, %3132, %3130, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %3148 : Tensor = prim::GetAttr[name="weight"](%3091)
      %3149 : Tensor? = prim::GetAttr[name="bias"](%3091)
      %input.65 : Tensor = aten::conv2d(%input.64, %3148, %3149, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3154 : bool = prim::GetAttr[name="training"](%3092)
       = prim::If(%3154) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3155 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3092)
          %3156 : Tensor = aten::add(%3155, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3092, %3156)
          -> ()
        block1():
          -> ()
      %3157 : bool = prim::GetAttr[name="training"](%3092)
      %3158 : Tensor = prim::GetAttr[name="running_mean"](%3092)
      %3159 : Tensor = prim::GetAttr[name="running_var"](%3092)
      %3160 : Tensor = prim::GetAttr[name="weight"](%3092)
      %3161 : Tensor = prim::GetAttr[name="bias"](%3092)
       = prim::If(%3157) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3162 : int[] = aten::size(%input.65) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.88 : int = aten::__getitem__(%3162, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3164 : int = aten::len(%3162) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3165 : int = aten::sub(%3164, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.89 : int = prim::Loop(%3165, %10, %size_prods.88) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.23 : int, %size_prods.90 : int):
              %3169 : int = aten::add(%i.23, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3170 : int = aten::__getitem__(%3162, %3169) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.91 : int = aten::mul(%size_prods.90, %3170) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.91)
          %3172 : bool = aten::eq(%size_prods.89, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3172) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3173 : str = aten::format(%8, %3162) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3173) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.66 : Tensor = aten::batch_norm(%input.65, %3160, %3161, %3158, %3159, %3157, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.67 : Tensor = aten::relu_(%input.66) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3176 : Tensor[] = prim::ListConstruct(%3549, %input.67)
      %out.10 : Tensor = aten::cat(%3176, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:90:18
      -> (%out.10)
    block1():
      %3178 : __torch__.torch.nn.modules.container.___torch_mangle_29.Sequential = prim::GetAttr[name="branch2"](%2614)
      %3179 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="0"](%3178)
      %3180 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="1"](%3178)
      %3181 : __torch__.torch.nn.modules.conv.___torch_mangle_28.Conv2d = prim::GetAttr[name="3"](%3178)
      %3182 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="4"](%3178)
      %3183 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="5"](%3178)
      %3184 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="6"](%3178)
      %3185 : Tensor = prim::GetAttr[name="weight"](%3179)
      %3186 : Tensor? = prim::GetAttr[name="bias"](%3179)
      %input.68 : Tensor = aten::conv2d(%input.25, %3185, %3186, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3191 : bool = prim::GetAttr[name="training"](%3180)
       = prim::If(%3191) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3192 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3180)
          %3193 : Tensor = aten::add(%3192, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3180, %3193)
          -> ()
        block1():
          -> ()
      %3194 : bool = prim::GetAttr[name="training"](%3180)
      %3195 : Tensor = prim::GetAttr[name="running_mean"](%3180)
      %3196 : Tensor = prim::GetAttr[name="running_var"](%3180)
      %3197 : Tensor = prim::GetAttr[name="weight"](%3180)
      %3198 : Tensor = prim::GetAttr[name="bias"](%3180)
       = prim::If(%3194) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3199 : int[] = aten::size(%input.68) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.92 : int = aten::__getitem__(%3199, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3201 : int = aten::len(%3199) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3202 : int = aten::sub(%3201, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.93 : int = prim::Loop(%3202, %10, %size_prods.92) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.24 : int, %size_prods.94 : int):
              %3206 : int = aten::add(%i.24, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3207 : int = aten::__getitem__(%3199, %3206) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.95 : int = aten::mul(%size_prods.94, %3207) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.95)
          %3209 : bool = aten::eq(%size_prods.93, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3209) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3210 : str = aten::format(%8, %3199) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3210) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.69 : Tensor = aten::batch_norm(%input.68, %3197, %3198, %3195, %3196, %3194, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.70 : Tensor = aten::relu_(%input.69) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3213 : Tensor = prim::GetAttr[name="weight"](%3181)
      %3214 : Tensor? = prim::GetAttr[name="bias"](%3181)
      %input.71 : Tensor = aten::conv2d(%input.70, %3213, %3214, %3554, %3554, %3554, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3219 : bool = prim::GetAttr[name="training"](%3182)
       = prim::If(%3219) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3220 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3182)
          %3221 : Tensor = aten::add(%3220, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3182, %3221)
          -> ()
        block1():
          -> ()
      %3222 : bool = prim::GetAttr[name="training"](%3182)
      %3223 : Tensor = prim::GetAttr[name="running_mean"](%3182)
      %3224 : Tensor = prim::GetAttr[name="running_var"](%3182)
      %3225 : Tensor = prim::GetAttr[name="weight"](%3182)
      %3226 : Tensor = prim::GetAttr[name="bias"](%3182)
       = prim::If(%3222) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3227 : int[] = aten::size(%input.71) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.96 : int = aten::__getitem__(%3227, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3229 : int = aten::len(%3227) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3230 : int = aten::sub(%3229, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.97 : int = prim::Loop(%3230, %10, %size_prods.96) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.25 : int, %size_prods.98 : int):
              %3234 : int = aten::add(%i.25, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3235 : int = aten::__getitem__(%3227, %3234) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.99 : int = aten::mul(%size_prods.98, %3235) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.99)
          %3237 : bool = aten::eq(%size_prods.97, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3237) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3238 : str = aten::format(%8, %3227) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3238) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.72 : Tensor = aten::batch_norm(%input.71, %3225, %3226, %3223, %3224, %3222, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %3240 : Tensor = prim::GetAttr[name="weight"](%3183)
      %3241 : Tensor? = prim::GetAttr[name="bias"](%3183)
      %input.73 : Tensor = aten::conv2d(%input.72, %3240, %3241, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3246 : bool = prim::GetAttr[name="training"](%3184)
       = prim::If(%3246) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3247 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3184)
          %3248 : Tensor = aten::add(%3247, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3184, %3248)
          -> ()
        block1():
          -> ()
      %3249 : bool = prim::GetAttr[name="training"](%3184)
      %3250 : Tensor = prim::GetAttr[name="running_mean"](%3184)
      %3251 : Tensor = prim::GetAttr[name="running_var"](%3184)
      %3252 : Tensor = prim::GetAttr[name="weight"](%3184)
      %3253 : Tensor = prim::GetAttr[name="bias"](%3184)
       = prim::If(%3249) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3254 : int[] = aten::size(%input.73) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.100 : int = aten::__getitem__(%3254, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3256 : int = aten::len(%3254) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3257 : int = aten::sub(%3256, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.101 : int = prim::Loop(%3257, %10, %size_prods.100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.26 : int, %size_prods.102 : int):
              %3261 : int = aten::add(%i.26, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3262 : int = aten::__getitem__(%3254, %3261) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.103 : int = aten::mul(%size_prods.102, %3262) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.103)
          %3264 : bool = aten::eq(%size_prods.101, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3264) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3265 : str = aten::format(%8, %3254) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3265) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.74 : Tensor = aten::batch_norm(%input.73, %3252, %3253, %3250, %3251, %3249, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.75 : Tensor = aten::relu_(%input.74) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3268 : Tensor[] = prim::ListConstruct(%input.25, %input.75)
      %out.11 : Tensor = aten::cat(%3268, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:92:18
      -> (%out.11)
  %3270 : int[] = aten::size(%out.12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:22:45
  %batchsize.4 : int, %num_channels.4 : int, %height.4 : int, %width.4 : int = prim::ListUnpack(%3270)
  %channels_per_group.4 : int = aten::floordiv(%num_channels.4, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:23:25
  %3276 : int[] = prim::ListConstruct(%batchsize.4, %4, %channels_per_group.4, %height.4, %width.4)
  %x.10 : Tensor = aten::view(%out.12, %3276) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:26:8
  %3278 : Tensor = aten::transpose(%x.10, %11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %x.11 : Tensor = aten::contiguous(%3278, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %3280 : int[] = prim::ListConstruct(%batchsize.4, %14, %height.4, %width.4)
  %input.26 : Tensor = aten::view(%x.11, %3280) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:32:8
  %3282 : int = prim::GetAttr[name="stride"](%2615)
  %3283 : bool = aten::eq(%3282, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:11
  %out : Tensor = prim::If(%3283) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:88:8
    block0():
      %3551 : Tensor, %3552 : Tensor = prim::ConstantChunk[chunks=2, dim=1](%input.26)
      %3288 : __torch__.torch.nn.modules.container.___torch_mangle_29.Sequential = prim::GetAttr[name="branch2"](%2615)
      %3289 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="0"](%3288)
      %3290 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="1"](%3288)
      %3291 : __torch__.torch.nn.modules.conv.___torch_mangle_28.Conv2d = prim::GetAttr[name="3"](%3288)
      %3292 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="4"](%3288)
      %3293 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="5"](%3288)
      %3294 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="6"](%3288)
      %3295 : Tensor = prim::GetAttr[name="weight"](%3289)
      %3296 : Tensor? = prim::GetAttr[name="bias"](%3289)
      %input.4 : Tensor = aten::conv2d(%3552, %3295, %3296, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3301 : bool = prim::GetAttr[name="training"](%3290)
       = prim::If(%3301) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3302 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3290)
          %3303 : Tensor = aten::add(%3302, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3290, %3303)
          -> ()
        block1():
          -> ()
      %3304 : bool = prim::GetAttr[name="training"](%3290)
      %3305 : Tensor = prim::GetAttr[name="running_mean"](%3290)
      %3306 : Tensor = prim::GetAttr[name="running_var"](%3290)
      %3307 : Tensor = prim::GetAttr[name="weight"](%3290)
      %3308 : Tensor = prim::GetAttr[name="bias"](%3290)
       = prim::If(%3304) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3309 : int[] = aten::size(%input.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.12 : int = aten::__getitem__(%3309, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3311 : int = aten::len(%3309) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3312 : int = aten::sub(%3311, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.13 : int = prim::Loop(%3312, %10, %size_prods.12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.4 : int, %size_prods.14 : int):
              %3316 : int = aten::add(%i.4, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3317 : int = aten::__getitem__(%3309, %3316) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.15 : int = aten::mul(%size_prods.14, %3317) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.15)
          %3319 : bool = aten::eq(%size_prods.13, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3319) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3320 : str = aten::format(%8, %3309) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3320) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.6 : Tensor = aten::batch_norm(%input.4, %3307, %3308, %3305, %3306, %3304, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.8 : Tensor = aten::relu_(%input.6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3323 : Tensor = prim::GetAttr[name="weight"](%3291)
      %3324 : Tensor? = prim::GetAttr[name="bias"](%3291)
      %input.10 : Tensor = aten::conv2d(%input.8, %3323, %3324, %3554, %3554, %3554, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3329 : bool = prim::GetAttr[name="training"](%3292)
       = prim::If(%3329) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3330 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3292)
          %3331 : Tensor = aten::add(%3330, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3292, %3331)
          -> ()
        block1():
          -> ()
      %3332 : bool = prim::GetAttr[name="training"](%3292)
      %3333 : Tensor = prim::GetAttr[name="running_mean"](%3292)
      %3334 : Tensor = prim::GetAttr[name="running_var"](%3292)
      %3335 : Tensor = prim::GetAttr[name="weight"](%3292)
      %3336 : Tensor = prim::GetAttr[name="bias"](%3292)
       = prim::If(%3332) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3337 : int[] = aten::size(%input.10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.16 : int = aten::__getitem__(%3337, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3339 : int = aten::len(%3337) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3340 : int = aten::sub(%3339, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.17 : int = prim::Loop(%3340, %10, %size_prods.16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.5 : int, %size_prods.18 : int):
              %3344 : int = aten::add(%i.5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3345 : int = aten::__getitem__(%3337, %3344) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.19 : int = aten::mul(%size_prods.18, %3345) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.19)
          %3347 : bool = aten::eq(%size_prods.17, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3347) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3348 : str = aten::format(%8, %3337) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3348) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.12 : Tensor = aten::batch_norm(%input.10, %3335, %3336, %3333, %3334, %3332, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %3350 : Tensor = prim::GetAttr[name="weight"](%3293)
      %3351 : Tensor? = prim::GetAttr[name="bias"](%3293)
      %input.14 : Tensor = aten::conv2d(%input.12, %3350, %3351, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3356 : bool = prim::GetAttr[name="training"](%3294)
       = prim::If(%3356) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3357 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3294)
          %3358 : Tensor = aten::add(%3357, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3294, %3358)
          -> ()
        block1():
          -> ()
      %3359 : bool = prim::GetAttr[name="training"](%3294)
      %3360 : Tensor = prim::GetAttr[name="running_mean"](%3294)
      %3361 : Tensor = prim::GetAttr[name="running_var"](%3294)
      %3362 : Tensor = prim::GetAttr[name="weight"](%3294)
      %3363 : Tensor = prim::GetAttr[name="bias"](%3294)
       = prim::If(%3359) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3364 : int[] = aten::size(%input.14) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.20 : int = aten::__getitem__(%3364, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3366 : int = aten::len(%3364) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3367 : int = aten::sub(%3366, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.21 : int = prim::Loop(%3367, %10, %size_prods.20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.6 : int, %size_prods.22 : int):
              %3371 : int = aten::add(%i.6, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3372 : int = aten::__getitem__(%3364, %3371) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.23 : int = aten::mul(%size_prods.22, %3372) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.23)
          %3374 : bool = aten::eq(%size_prods.21, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3374) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3375 : str = aten::format(%8, %3364) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3375) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.16 : Tensor = aten::batch_norm(%input.14, %3362, %3363, %3360, %3361, %3359, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.18 : Tensor = aten::relu_(%input.16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3378 : Tensor[] = prim::ListConstruct(%3551, %input.18)
      %out.1 : Tensor = aten::cat(%3378, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:90:18
      -> (%out.1)
    block1():
      %3380 : __torch__.torch.nn.modules.container.___torch_mangle_29.Sequential = prim::GetAttr[name="branch2"](%2615)
      %3381 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="0"](%3380)
      %3382 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="1"](%3380)
      %3383 : __torch__.torch.nn.modules.conv.___torch_mangle_28.Conv2d = prim::GetAttr[name="3"](%3380)
      %3384 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="4"](%3380)
      %3385 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="5"](%3380)
      %3386 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="6"](%3380)
      %3387 : Tensor = prim::GetAttr[name="weight"](%3381)
      %3388 : Tensor? = prim::GetAttr[name="bias"](%3381)
      %input.27 : Tensor = aten::conv2d(%input.26, %3387, %3388, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3393 : bool = prim::GetAttr[name="training"](%3382)
       = prim::If(%3393) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3394 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3382)
          %3395 : Tensor = aten::add(%3394, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3382, %3395)
          -> ()
        block1():
          -> ()
      %3396 : bool = prim::GetAttr[name="training"](%3382)
      %3397 : Tensor = prim::GetAttr[name="running_mean"](%3382)
      %3398 : Tensor = prim::GetAttr[name="running_var"](%3382)
      %3399 : Tensor = prim::GetAttr[name="weight"](%3382)
      %3400 : Tensor = prim::GetAttr[name="bias"](%3382)
       = prim::If(%3396) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3401 : int[] = aten::size(%input.27) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.2 : int = aten::__getitem__(%3401, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3403 : int = aten::len(%3401) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3404 : int = aten::sub(%3403, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.4 : int = prim::Loop(%3404, %10, %size_prods.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.2 : int, %size_prods.7 : int):
              %3408 : int = aten::add(%i.2, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3409 : int = aten::__getitem__(%3401, %3408) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.5 : int = aten::mul(%size_prods.7, %3409) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.5)
          %3411 : bool = aten::eq(%size_prods.4, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3411) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3412 : str = aten::format(%8, %3401) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3412) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.290 : Tensor = aten::batch_norm(%input.27, %3399, %3400, %3397, %3398, %3396, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.291 : Tensor = aten::relu_(%input.290) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3415 : Tensor = prim::GetAttr[name="weight"](%3383)
      %3416 : Tensor? = prim::GetAttr[name="bias"](%3383)
      %input.9 : Tensor = aten::conv2d(%input.291, %3415, %3416, %3554, %3554, %3554, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3421 : bool = prim::GetAttr[name="training"](%3384)
       = prim::If(%3421) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3422 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3384)
          %3423 : Tensor = aten::add(%3422, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3384, %3423)
          -> ()
        block1():
          -> ()
      %3424 : bool = prim::GetAttr[name="training"](%3384)
      %3425 : Tensor = prim::GetAttr[name="running_mean"](%3384)
      %3426 : Tensor = prim::GetAttr[name="running_var"](%3384)
      %3427 : Tensor = prim::GetAttr[name="weight"](%3384)
      %3428 : Tensor = prim::GetAttr[name="bias"](%3384)
       = prim::If(%3424) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3429 : int[] = aten::size(%input.9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.8 : int = aten::__getitem__(%3429, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3431 : int = aten::len(%3429) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3432 : int = aten::sub(%3431, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.9 : int = prim::Loop(%3432, %10, %size_prods.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.3 : int, %size_prods.10 : int):
              %3436 : int = aten::add(%i.3, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3437 : int = aten::__getitem__(%3429, %3436) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.11 : int = aten::mul(%size_prods.10, %3437) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.11)
          %3439 : bool = aten::eq(%size_prods.9, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3439) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3440 : str = aten::format(%8, %3429) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3440) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.11 : Tensor = aten::batch_norm(%input.9, %3427, %3428, %3425, %3426, %3424, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %3442 : Tensor = prim::GetAttr[name="weight"](%3385)
      %3443 : Tensor? = prim::GetAttr[name="bias"](%3385)
      %input.13 : Tensor = aten::conv2d(%input.11, %3442, %3443, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      %3448 : bool = prim::GetAttr[name="training"](%3386)
       = prim::If(%3448) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3449 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3386)
          %3450 : Tensor = aten::add(%3449, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3386, %3450)
          -> ()
        block1():
          -> ()
      %3451 : bool = prim::GetAttr[name="training"](%3386)
      %3452 : Tensor = prim::GetAttr[name="running_mean"](%3386)
      %3453 : Tensor = prim::GetAttr[name="running_var"](%3386)
      %3454 : Tensor = prim::GetAttr[name="weight"](%3386)
      %3455 : Tensor = prim::GetAttr[name="bias"](%3386)
       = prim::If(%3451) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3456 : int[] = aten::size(%input.13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.412 : int = aten::__getitem__(%3456, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3458 : int = aten::len(%3456) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3459 : int = aten::sub(%3458, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.413 : int = prim::Loop(%3459, %10, %size_prods.412) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.104 : int, %size_prods.414 : int):
              %3463 : int = aten::add(%i.104, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3464 : int = aten::__getitem__(%3456, %3463) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.415 : int = aten::mul(%size_prods.414, %3464) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%10, %size_prods.415)
          %3466 : bool = aten::eq(%size_prods.413, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3466) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3467 : str = aten::format(%8, %3456) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3467) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.15 : Tensor = aten::batch_norm(%input.13, %3454, %3455, %3452, %3453, %3451, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %input.17 : Tensor = aten::relu_(%input.15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3470 : Tensor[] = prim::ListConstruct(%input.26, %input.17)
      %out.2 : Tensor = aten::cat(%3470, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:92:18
      -> (%out.2)
  %3472 : int[] = aten::size(%out) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:22:45
  %batchsize.1 : int, %num_channels.1 : int, %height.1 : int, %width.1 : int = prim::ListUnpack(%3472)
  %channels_per_group.1 : int = aten::floordiv(%num_channels.1, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:23:25
  %3478 : int[] = prim::ListConstruct(%batchsize.1, %4, %channels_per_group.1, %height.1, %width.1)
  %x.4 : Tensor = aten::view(%out, %3478) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:26:8
  %3480 : Tensor = aten::transpose(%x.4, %11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %x.6 : Tensor = aten::contiguous(%3480, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:29:8
  %3482 : int[] = prim::ListConstruct(%batchsize.1, %14, %height.1, %width.1)
  %x.29 : Tensor = aten::view(%x.6, %3482) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:32:8
  %3484 : __torch__.torch.nn.modules.container.___torch_mangle_34.Sequential = prim::GetAttr[name="conv5"](%self)
  %3485 : __torch__.torch.nn.modules.conv.___torch_mangle_32.Conv2d = prim::GetAttr[name="0"](%3484)
  %3486 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_33.BatchNorm2d = prim::GetAttr[name="1"](%3484)
  %3487 : Tensor = prim::GetAttr[name="weight"](%3485)
  %3488 : Tensor? = prim::GetAttr[name="bias"](%3485)
  %input.3 : Tensor = aten::conv2d(%x.29, %3487, %3488, %3554, %3561, %3554, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %3493 : bool = prim::GetAttr[name="training"](%3486)
   = prim::If(%3493) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %3494 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3486)
      %3495 : Tensor = aten::add(%3494, %11, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%3486, %3495)
      -> ()
    block1():
      -> ()
  %3496 : bool = prim::GetAttr[name="training"](%3486)
  %3497 : Tensor = prim::GetAttr[name="running_mean"](%3486)
  %3498 : Tensor = prim::GetAttr[name="running_var"](%3486)
  %3499 : Tensor = prim::GetAttr[name="weight"](%3486)
  %3500 : Tensor = prim::GetAttr[name="bias"](%3486)
   = prim::If(%3496) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %3501 : int[] = aten::size(%input.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.1 : int = aten::__getitem__(%3501, %9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %3503 : int = aten::len(%3501) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %3504 : int = aten::sub(%3503, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods : int = prim::Loop(%3504, %10, %size_prods.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.1 : int, %size_prods.6 : int):
          %3508 : int = aten::add(%i.1, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %3509 : int = aten::__getitem__(%3501, %3508) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.3 : int = aten::mul(%size_prods.6, %3509) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%10, %size_prods.3)
      %3511 : bool = aten::eq(%size_prods, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%3511) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %3512 : str = aten::format(%8, %3501) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%3512) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.5 : Tensor = aten::batch_norm(%input.3, %3499, %3500, %3497, %3498, %3496, %7, %6, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %x.26 : Tensor = aten::relu_(%input.5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %x.28 : Tensor = aten::mean(%x.26, %3869, %3, %2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/shufflenetv2.py:156:12
  %3517 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="fc"](%self)
  %3518 : Tensor = prim::GetAttr[name="weight"](%3517)
  %3519 : Tensor = prim::GetAttr[name="bias"](%3517)
  %x.30 : Tensor = aten::linear(%x.28, %3518, %3519) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
  return (%x.30)

