Dump Graph IR for resnet50 using example inputs:
graph(%self : __torch__.torchvision.models.resnet.ResNet,
      %x.1 : Tensor):
  %1662 : int[] = prim::Constant[value=[0, 0]]()
  %1656 : int[] = prim::Constant[value=[1, 1]]()
  %1655 : int[] = prim::Constant[value=[3, 3]]()
  %1654 : int[] = prim::Constant[value=[2, 2]]()
  %12 : str = prim::Constant[value="AssertionError: "]()
  %11 : bool = prim::Constant[value=0]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/pooling.py:163:57
  %10 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:140:77
  %9 : float = prim::Constant[value=0.10000000000000001]()
  %8 : str = prim::Constant[value="Expected more than 1 value per channel when training, got input size {}"]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
  %7 : int = prim::Constant[value=0]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:22
  %6 : bool = prim::Constant[value=1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2147:81
  %5 : int = prim::Constant[value=2]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:45
  %3 : int = prim::Constant[value=1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:243:29
  %2 : int = prim::Constant[value=-1]()
  %13 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name="conv1"](%self)
  %14 : Tensor = prim::GetAttr[name="weight"](%13)
  %15 : Tensor? = prim::GetAttr[name="bias"](%13)
  %x.3 : Tensor = aten::conv2d(%x.1, %14, %15, %1654, %1655, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %20 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="bn1"](%self)
  %21 : bool = prim::GetAttr[name="training"](%20)
   = prim::If(%21) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %22 : Tensor = prim::GetAttr[name="num_batches_tracked"](%20)
      %23 : Tensor = aten::add(%22, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%20, %23)
      -> ()
    block1():
      -> ()
  %24 : bool = prim::GetAttr[name="training"](%20)
  %25 : Tensor = prim::GetAttr[name="running_mean"](%20)
  %26 : Tensor = prim::GetAttr[name="running_var"](%20)
  %27 : Tensor = prim::GetAttr[name="weight"](%20)
  %28 : Tensor = prim::GetAttr[name="bias"](%20)
   = prim::If(%24) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %29 : int[] = aten::size(%x.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.156 : int = aten::__getitem__(%29, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %31 : int = aten::len(%29) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %32 : int = aten::sub(%31, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.157 : int = prim::Loop(%32, %6, %size_prods.156) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.40 : int, %size_prods.158 : int):
          %36 : int = aten::add(%i.40, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %37 : int = aten::__getitem__(%29, %36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.159 : int = aten::mul(%size_prods.158, %37) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.159)
      %39 : bool = aten::eq(%size_prods.157, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%39) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %40 : str = aten::format(%8, %29) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %x.5 : Tensor = aten::batch_norm(%x.3, %27, %28, %25, %26, %24, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %x.7 : Tensor = aten::relu_(%x.5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %x.9 : Tensor = aten::max_pool2d(%x.7, %1655, %1654, %1656, %1656, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:659:11
  %48 : __torch__.torch.nn.modules.container.___torch_mangle_6.Sequential = prim::GetAttr[name="layer1"](%self)
  %49 : __torch__.torchvision.models.resnet.Bottleneck = prim::GetAttr[name="0"](%48)
  %50 : __torch__.torchvision.models.resnet.___torch_mangle_5.Bottleneck = prim::GetAttr[name="1"](%48)
  %51 : __torch__.torchvision.models.resnet.___torch_mangle_5.Bottleneck = prim::GetAttr[name="2"](%48)
  %52 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="conv1"](%49)
  %53 : Tensor = prim::GetAttr[name="weight"](%52)
  %54 : Tensor? = prim::GetAttr[name="bias"](%52)
  %out.19 : Tensor = aten::conv2d(%x.9, %53, %54, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %59 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="bn1"](%49)
  %60 : bool = prim::GetAttr[name="training"](%59)
   = prim::If(%60) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %61 : Tensor = prim::GetAttr[name="num_batches_tracked"](%59)
      %62 : Tensor = aten::add(%61, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%59, %62)
      -> ()
    block1():
      -> ()
  %63 : bool = prim::GetAttr[name="training"](%59)
  %64 : Tensor = prim::GetAttr[name="running_mean"](%59)
  %65 : Tensor = prim::GetAttr[name="running_var"](%59)
  %66 : Tensor = prim::GetAttr[name="weight"](%59)
  %67 : Tensor = prim::GetAttr[name="bias"](%59)
   = prim::If(%63) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %68 : int[] = aten::size(%out.19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.76 : int = aten::__getitem__(%68, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %70 : int = aten::len(%68) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %71 : int = aten::sub(%70, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.77 : int = prim::Loop(%71, %6, %size_prods.76) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.20 : int, %size_prods.78 : int):
          %75 : int = aten::add(%i.20, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %76 : int = aten::__getitem__(%68, %75) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.79 : int = aten::mul(%size_prods.78, %76) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.79)
      %78 : bool = aten::eq(%size_prods.77, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%78) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %79 : str = aten::format(%8, %68) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%79) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.101 : Tensor = aten::batch_norm(%out.19, %66, %67, %64, %65, %63, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.102 : Tensor = aten::relu_(%out.101) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %82 : __torch__.torch.nn.modules.conv.___torch_mangle_1.Conv2d = prim::GetAttr[name="conv2"](%49)
  %83 : Tensor = prim::GetAttr[name="weight"](%82)
  %84 : Tensor? = prim::GetAttr[name="bias"](%82)
  %out.103 : Tensor = aten::conv2d(%out.102, %83, %84, %1656, %1656, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %89 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="bn2"](%49)
  %90 : bool = prim::GetAttr[name="training"](%89)
   = prim::If(%90) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %91 : Tensor = prim::GetAttr[name="num_batches_tracked"](%89)
      %92 : Tensor = aten::add(%91, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%89, %92)
      -> ()
    block1():
      -> ()
  %93 : bool = prim::GetAttr[name="training"](%89)
  %94 : Tensor = prim::GetAttr[name="running_mean"](%89)
  %95 : Tensor = prim::GetAttr[name="running_var"](%89)
  %96 : Tensor = prim::GetAttr[name="weight"](%89)
  %97 : Tensor = prim::GetAttr[name="bias"](%89)
   = prim::If(%93) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %98 : int[] = aten::size(%out.103) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.80 : int = aten::__getitem__(%98, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %100 : int = aten::len(%98) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %101 : int = aten::sub(%100, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.81 : int = prim::Loop(%101, %6, %size_prods.80) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.21 : int, %size_prods.82 : int):
          %105 : int = aten::add(%i.21, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %106 : int = aten::__getitem__(%98, %105) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.83 : int = aten::mul(%size_prods.82, %106) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.83)
      %108 : bool = aten::eq(%size_prods.81, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %109 : str = aten::format(%8, %98) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%109) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.104 : Tensor = aten::batch_norm(%out.103, %96, %97, %94, %95, %93, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.105 : Tensor = aten::relu_(%out.104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %112 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv3"](%49)
  %113 : Tensor = prim::GetAttr[name="weight"](%112)
  %114 : Tensor? = prim::GetAttr[name="bias"](%112)
  %out.106 : Tensor = aten::conv2d(%out.105, %113, %114, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %119 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="bn3"](%49)
  %120 : bool = prim::GetAttr[name="training"](%119)
   = prim::If(%120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %121 : Tensor = prim::GetAttr[name="num_batches_tracked"](%119)
      %122 : Tensor = aten::add(%121, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%119, %122)
      -> ()
    block1():
      -> ()
  %123 : bool = prim::GetAttr[name="training"](%119)
  %124 : Tensor = prim::GetAttr[name="running_mean"](%119)
  %125 : Tensor = prim::GetAttr[name="running_var"](%119)
  %126 : Tensor = prim::GetAttr[name="weight"](%119)
  %127 : Tensor = prim::GetAttr[name="bias"](%119)
   = prim::If(%123) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %128 : int[] = aten::size(%out.106) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.136 : int = aten::__getitem__(%128, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %130 : int = aten::len(%128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %131 : int = aten::sub(%130, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.137 : int = prim::Loop(%131, %6, %size_prods.136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.35 : int, %size_prods.138 : int):
          %135 : int = aten::add(%i.35, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %136 : int = aten::__getitem__(%128, %135) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.139 : int = aten::mul(%size_prods.138, %136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.139)
      %138 : bool = aten::eq(%size_prods.137, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%138) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %139 : str = aten::format(%8, %128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%139) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.107 : Tensor = aten::batch_norm(%out.106, %126, %127, %124, %125, %123, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %141 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="downsample"](%49)
  %142 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="0"](%141)
  %143 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="1"](%141)
  %144 : Tensor = prim::GetAttr[name="weight"](%142)
  %145 : Tensor? = prim::GetAttr[name="bias"](%142)
  %input.6 : Tensor = aten::conv2d(%x.9, %144, %145, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %150 : bool = prim::GetAttr[name="training"](%143)
   = prim::If(%150) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %151 : Tensor = prim::GetAttr[name="num_batches_tracked"](%143)
      %152 : Tensor = aten::add(%151, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%143, %152)
      -> ()
    block1():
      -> ()
  %153 : bool = prim::GetAttr[name="training"](%143)
  %154 : Tensor = prim::GetAttr[name="running_mean"](%143)
  %155 : Tensor = prim::GetAttr[name="running_var"](%143)
  %156 : Tensor = prim::GetAttr[name="weight"](%143)
  %157 : Tensor = prim::GetAttr[name="bias"](%143)
   = prim::If(%153) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %158 : int[] = aten::size(%input.6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.140 : int = aten::__getitem__(%158, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %160 : int = aten::len(%158) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %161 : int = aten::sub(%160, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.141 : int = prim::Loop(%161, %6, %size_prods.140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.36 : int, %size_prods.142 : int):
          %165 : int = aten::add(%i.36, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %166 : int = aten::__getitem__(%158, %165) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.143 : int = aten::mul(%size_prods.142, %166) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.143)
      %168 : bool = aten::eq(%size_prods.141, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%168) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %169 : str = aten::format(%8, %158) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%169) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %identity.2 : Tensor = aten::batch_norm(%input.6, %156, %157, %154, %155, %153, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.108 : Tensor = aten::add_(%out.107, %identity.2, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.10 : Tensor = aten::relu_(%out.108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %173 : __torch__.torch.nn.modules.conv.___torch_mangle_4.Conv2d = prim::GetAttr[name="conv1"](%50)
  %174 : Tensor = prim::GetAttr[name="weight"](%173)
  %175 : Tensor? = prim::GetAttr[name="bias"](%173)
  %out.91 : Tensor = aten::conv2d(%input.10, %174, %175, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %180 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="bn1"](%50)
  %181 : bool = prim::GetAttr[name="training"](%180)
   = prim::If(%181) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %182 : Tensor = prim::GetAttr[name="num_batches_tracked"](%180)
      %183 : Tensor = aten::add(%182, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%180, %183)
      -> ()
    block1():
      -> ()
  %184 : bool = prim::GetAttr[name="training"](%180)
  %185 : Tensor = prim::GetAttr[name="running_mean"](%180)
  %186 : Tensor = prim::GetAttr[name="running_var"](%180)
  %187 : Tensor = prim::GetAttr[name="weight"](%180)
  %188 : Tensor = prim::GetAttr[name="bias"](%180)
   = prim::If(%184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %189 : int[] = aten::size(%out.91) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.144 : int = aten::__getitem__(%189, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %191 : int = aten::len(%189) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %192 : int = aten::sub(%191, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.145 : int = prim::Loop(%192, %6, %size_prods.144) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.37 : int, %size_prods.146 : int):
          %196 : int = aten::add(%i.37, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %197 : int = aten::__getitem__(%189, %196) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.147 : int = aten::mul(%size_prods.146, %197) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.147)
      %199 : bool = aten::eq(%size_prods.145, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%199) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %200 : str = aten::format(%8, %189) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%200) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.92 : Tensor = aten::batch_norm(%out.91, %187, %188, %185, %186, %184, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.93 : Tensor = aten::relu_(%out.92) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %203 : __torch__.torch.nn.modules.conv.___torch_mangle_1.Conv2d = prim::GetAttr[name="conv2"](%50)
  %204 : Tensor = prim::GetAttr[name="weight"](%203)
  %205 : Tensor? = prim::GetAttr[name="bias"](%203)
  %out.94 : Tensor = aten::conv2d(%out.93, %204, %205, %1656, %1656, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %210 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="bn2"](%50)
  %211 : bool = prim::GetAttr[name="training"](%210)
   = prim::If(%211) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %212 : Tensor = prim::GetAttr[name="num_batches_tracked"](%210)
      %213 : Tensor = aten::add(%212, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%210, %213)
      -> ()
    block1():
      -> ()
  %214 : bool = prim::GetAttr[name="training"](%210)
  %215 : Tensor = prim::GetAttr[name="running_mean"](%210)
  %216 : Tensor = prim::GetAttr[name="running_var"](%210)
  %217 : Tensor = prim::GetAttr[name="weight"](%210)
  %218 : Tensor = prim::GetAttr[name="bias"](%210)
   = prim::If(%214) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %219 : int[] = aten::size(%out.94) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.148 : int = aten::__getitem__(%219, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %221 : int = aten::len(%219) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %222 : int = aten::sub(%221, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.149 : int = prim::Loop(%222, %6, %size_prods.148) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.38 : int, %size_prods.150 : int):
          %226 : int = aten::add(%i.38, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %227 : int = aten::__getitem__(%219, %226) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.151 : int = aten::mul(%size_prods.150, %227) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.151)
      %229 : bool = aten::eq(%size_prods.149, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%229) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %230 : str = aten::format(%8, %219) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%230) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.95 : Tensor = aten::batch_norm(%out.94, %217, %218, %215, %216, %214, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.96 : Tensor = aten::relu_(%out.95) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %233 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv3"](%50)
  %234 : Tensor = prim::GetAttr[name="weight"](%233)
  %235 : Tensor? = prim::GetAttr[name="bias"](%233)
  %out.97 : Tensor = aten::conv2d(%out.96, %234, %235, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %240 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="bn3"](%50)
  %241 : bool = prim::GetAttr[name="training"](%240)
   = prim::If(%241) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %242 : Tensor = prim::GetAttr[name="num_batches_tracked"](%240)
      %243 : Tensor = aten::add(%242, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%240, %243)
      -> ()
    block1():
      -> ()
  %244 : bool = prim::GetAttr[name="training"](%240)
  %245 : Tensor = prim::GetAttr[name="running_mean"](%240)
  %246 : Tensor = prim::GetAttr[name="running_var"](%240)
  %247 : Tensor = prim::GetAttr[name="weight"](%240)
  %248 : Tensor = prim::GetAttr[name="bias"](%240)
   = prim::If(%244) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %249 : int[] = aten::size(%out.97) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.152 : int = aten::__getitem__(%249, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %251 : int = aten::len(%249) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %252 : int = aten::sub(%251, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.153 : int = prim::Loop(%252, %6, %size_prods.152) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.39 : int, %size_prods.154 : int):
          %256 : int = aten::add(%i.39, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %257 : int = aten::__getitem__(%249, %256) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.155 : int = aten::mul(%size_prods.154, %257) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.155)
      %259 : bool = aten::eq(%size_prods.153, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%259) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %260 : str = aten::format(%8, %249) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%260) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.98 : Tensor = aten::batch_norm(%out.97, %247, %248, %245, %246, %244, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.99 : Tensor = aten::add_(%out.98, %input.10, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.8 : Tensor = aten::relu_(%out.99) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %264 : __torch__.torch.nn.modules.conv.___torch_mangle_4.Conv2d = prim::GetAttr[name="conv1"](%51)
  %265 : Tensor = prim::GetAttr[name="weight"](%264)
  %266 : Tensor? = prim::GetAttr[name="bias"](%264)
  %out.100 : Tensor = aten::conv2d(%input.8, %265, %266, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %271 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="bn1"](%51)
  %272 : bool = prim::GetAttr[name="training"](%271)
   = prim::If(%272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %273 : Tensor = prim::GetAttr[name="num_batches_tracked"](%271)
      %274 : Tensor = aten::add(%273, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%271, %274)
      -> ()
    block1():
      -> ()
  %275 : bool = prim::GetAttr[name="training"](%271)
  %276 : Tensor = prim::GetAttr[name="running_mean"](%271)
  %277 : Tensor = prim::GetAttr[name="running_var"](%271)
  %278 : Tensor = prim::GetAttr[name="weight"](%271)
  %279 : Tensor = prim::GetAttr[name="bias"](%271)
   = prim::If(%275) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %280 : int[] = aten::size(%out.100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.84 : int = aten::__getitem__(%280, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %282 : int = aten::len(%280) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %283 : int = aten::sub(%282, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.85 : int = prim::Loop(%283, %6, %size_prods.84) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.22 : int, %size_prods.86 : int):
          %287 : int = aten::add(%i.22, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %288 : int = aten::__getitem__(%280, %287) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.87 : int = aten::mul(%size_prods.86, %288) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.87)
      %290 : bool = aten::eq(%size_prods.85, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%290) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %291 : str = aten::format(%8, %280) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%291) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.56 : Tensor = aten::batch_norm(%out.100, %278, %279, %276, %277, %275, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.57 : Tensor = aten::relu_(%out.56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %294 : __torch__.torch.nn.modules.conv.___torch_mangle_1.Conv2d = prim::GetAttr[name="conv2"](%51)
  %295 : Tensor = prim::GetAttr[name="weight"](%294)
  %296 : Tensor? = prim::GetAttr[name="bias"](%294)
  %out.58 : Tensor = aten::conv2d(%out.57, %295, %296, %1656, %1656, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %301 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="bn2"](%51)
  %302 : bool = prim::GetAttr[name="training"](%301)
   = prim::If(%302) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %303 : Tensor = prim::GetAttr[name="num_batches_tracked"](%301)
      %304 : Tensor = aten::add(%303, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%301, %304)
      -> ()
    block1():
      -> ()
  %305 : bool = prim::GetAttr[name="training"](%301)
  %306 : Tensor = prim::GetAttr[name="running_mean"](%301)
  %307 : Tensor = prim::GetAttr[name="running_var"](%301)
  %308 : Tensor = prim::GetAttr[name="weight"](%301)
  %309 : Tensor = prim::GetAttr[name="bias"](%301)
   = prim::If(%305) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %310 : int[] = aten::size(%out.58) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.88 : int = aten::__getitem__(%310, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %312 : int = aten::len(%310) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %313 : int = aten::sub(%312, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.89 : int = prim::Loop(%313, %6, %size_prods.88) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.23 : int, %size_prods.90 : int):
          %317 : int = aten::add(%i.23, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %318 : int = aten::__getitem__(%310, %317) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.91 : int = aten::mul(%size_prods.90, %318) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.91)
      %320 : bool = aten::eq(%size_prods.89, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%320) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %321 : str = aten::format(%8, %310) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%321) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.59 : Tensor = aten::batch_norm(%out.58, %308, %309, %306, %307, %305, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.60 : Tensor = aten::relu_(%out.59) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %324 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv3"](%51)
  %325 : Tensor = prim::GetAttr[name="weight"](%324)
  %326 : Tensor? = prim::GetAttr[name="bias"](%324)
  %out.61 : Tensor = aten::conv2d(%out.60, %325, %326, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %331 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="bn3"](%51)
  %332 : bool = prim::GetAttr[name="training"](%331)
   = prim::If(%332) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %333 : Tensor = prim::GetAttr[name="num_batches_tracked"](%331)
      %334 : Tensor = aten::add(%333, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%331, %334)
      -> ()
    block1():
      -> ()
  %335 : bool = prim::GetAttr[name="training"](%331)
  %336 : Tensor = prim::GetAttr[name="running_mean"](%331)
  %337 : Tensor = prim::GetAttr[name="running_var"](%331)
  %338 : Tensor = prim::GetAttr[name="weight"](%331)
  %339 : Tensor = prim::GetAttr[name="bias"](%331)
   = prim::If(%335) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %340 : int[] = aten::size(%out.61) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.92 : int = aten::__getitem__(%340, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %342 : int = aten::len(%340) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %343 : int = aten::sub(%342, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.93 : int = prim::Loop(%343, %6, %size_prods.92) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.24 : int, %size_prods.94 : int):
          %347 : int = aten::add(%i.24, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %348 : int = aten::__getitem__(%340, %347) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.95 : int = aten::mul(%size_prods.94, %348) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.95)
      %350 : bool = aten::eq(%size_prods.93, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%350) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %351 : str = aten::format(%8, %340) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%351) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.62 : Tensor = aten::batch_norm(%out.61, %338, %339, %336, %337, %335, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.63 : Tensor = aten::add_(%out.62, %input.8, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %x.11 : Tensor = aten::relu_(%out.63) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %355 : __torch__.torch.nn.modules.container.___torch_mangle_18.Sequential = prim::GetAttr[name="layer2"](%self)
  %356 : __torch__.torchvision.models.resnet.___torch_mangle_14.Bottleneck = prim::GetAttr[name="0"](%355)
  %357 : __torch__.torchvision.models.resnet.___torch_mangle_17.Bottleneck = prim::GetAttr[name="1"](%355)
  %358 : __torch__.torchvision.models.resnet.___torch_mangle_17.Bottleneck = prim::GetAttr[name="2"](%355)
  %359 : __torch__.torchvision.models.resnet.___torch_mangle_17.Bottleneck = prim::GetAttr[name="3"](%355)
  %360 : __torch__.torch.nn.modules.conv.___torch_mangle_7.Conv2d = prim::GetAttr[name="conv1"](%356)
  %361 : Tensor = prim::GetAttr[name="weight"](%360)
  %362 : Tensor? = prim::GetAttr[name="bias"](%360)
  %out.64 : Tensor = aten::conv2d(%x.11, %361, %362, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %367 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="bn1"](%356)
  %368 : bool = prim::GetAttr[name="training"](%367)
   = prim::If(%368) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %369 : Tensor = prim::GetAttr[name="num_batches_tracked"](%367)
      %370 : Tensor = aten::add(%369, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%367, %370)
      -> ()
    block1():
      -> ()
  %371 : bool = prim::GetAttr[name="training"](%367)
  %372 : Tensor = prim::GetAttr[name="running_mean"](%367)
  %373 : Tensor = prim::GetAttr[name="running_var"](%367)
  %374 : Tensor = prim::GetAttr[name="weight"](%367)
  %375 : Tensor = prim::GetAttr[name="bias"](%367)
   = prim::If(%371) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %376 : int[] = aten::size(%out.64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.96 : int = aten::__getitem__(%376, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %378 : int = aten::len(%376) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %379 : int = aten::sub(%378, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.97 : int = prim::Loop(%379, %6, %size_prods.96) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.25 : int, %size_prods.98 : int):
          %383 : int = aten::add(%i.25, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %384 : int = aten::__getitem__(%376, %383) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.99 : int = aten::mul(%size_prods.98, %384) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.99)
      %386 : bool = aten::eq(%size_prods.97, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%386) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %387 : str = aten::format(%8, %376) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%387) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.65 : Tensor = aten::batch_norm(%out.64, %374, %375, %372, %373, %371, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.66 : Tensor = aten::relu_(%out.65) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %390 : __torch__.torch.nn.modules.conv.___torch_mangle_9.Conv2d = prim::GetAttr[name="conv2"](%356)
  %391 : Tensor = prim::GetAttr[name="weight"](%390)
  %392 : Tensor? = prim::GetAttr[name="bias"](%390)
  %out.67 : Tensor = aten::conv2d(%out.66, %391, %392, %1654, %1656, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %397 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="bn2"](%356)
  %398 : bool = prim::GetAttr[name="training"](%397)
   = prim::If(%398) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %399 : Tensor = prim::GetAttr[name="num_batches_tracked"](%397)
      %400 : Tensor = aten::add(%399, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%397, %400)
      -> ()
    block1():
      -> ()
  %401 : bool = prim::GetAttr[name="training"](%397)
  %402 : Tensor = prim::GetAttr[name="running_mean"](%397)
  %403 : Tensor = prim::GetAttr[name="running_var"](%397)
  %404 : Tensor = prim::GetAttr[name="weight"](%397)
  %405 : Tensor = prim::GetAttr[name="bias"](%397)
   = prim::If(%401) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %406 : int[] = aten::size(%out.67) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.100 : int = aten::__getitem__(%406, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %408 : int = aten::len(%406) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %409 : int = aten::sub(%408, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.101 : int = prim::Loop(%409, %6, %size_prods.100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.26 : int, %size_prods.102 : int):
          %413 : int = aten::add(%i.26, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %414 : int = aten::__getitem__(%406, %413) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.103 : int = aten::mul(%size_prods.102, %414) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.103)
      %416 : bool = aten::eq(%size_prods.101, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%416) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %417 : str = aten::format(%8, %406) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%417) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.68 : Tensor = aten::batch_norm(%out.67, %404, %405, %402, %403, %401, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.69 : Tensor = aten::relu_(%out.68) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %420 : __torch__.torch.nn.modules.conv.___torch_mangle_10.Conv2d = prim::GetAttr[name="conv3"](%356)
  %421 : Tensor = prim::GetAttr[name="weight"](%420)
  %422 : Tensor? = prim::GetAttr[name="bias"](%420)
  %out.70 : Tensor = aten::conv2d(%out.69, %421, %422, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %427 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_11.BatchNorm2d = prim::GetAttr[name="bn3"](%356)
  %428 : bool = prim::GetAttr[name="training"](%427)
   = prim::If(%428) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %429 : Tensor = prim::GetAttr[name="num_batches_tracked"](%427)
      %430 : Tensor = aten::add(%429, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%427, %430)
      -> ()
    block1():
      -> ()
  %431 : bool = prim::GetAttr[name="training"](%427)
  %432 : Tensor = prim::GetAttr[name="running_mean"](%427)
  %433 : Tensor = prim::GetAttr[name="running_var"](%427)
  %434 : Tensor = prim::GetAttr[name="weight"](%427)
  %435 : Tensor = prim::GetAttr[name="bias"](%427)
   = prim::If(%431) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %436 : int[] = aten::size(%out.70) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.104 : int = aten::__getitem__(%436, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %438 : int = aten::len(%436) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %439 : int = aten::sub(%438, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.105 : int = prim::Loop(%439, %6, %size_prods.104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.27 : int, %size_prods.106 : int):
          %443 : int = aten::add(%i.27, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %444 : int = aten::__getitem__(%436, %443) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.107 : int = aten::mul(%size_prods.106, %444) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.107)
      %446 : bool = aten::eq(%size_prods.105, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%446) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %447 : str = aten::format(%8, %436) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%447) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.71 : Tensor = aten::batch_norm(%out.70, %434, %435, %432, %433, %431, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %449 : __torch__.torch.nn.modules.container.___torch_mangle_13.Sequential = prim::GetAttr[name="downsample"](%356)
  %450 : __torch__.torch.nn.modules.conv.___torch_mangle_12.Conv2d = prim::GetAttr[name="0"](%449)
  %451 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_11.BatchNorm2d = prim::GetAttr[name="1"](%449)
  %452 : Tensor = prim::GetAttr[name="weight"](%450)
  %453 : Tensor? = prim::GetAttr[name="bias"](%450)
  %input.14 : Tensor = aten::conv2d(%x.11, %452, %453, %1654, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %458 : bool = prim::GetAttr[name="training"](%451)
   = prim::If(%458) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %459 : Tensor = prim::GetAttr[name="num_batches_tracked"](%451)
      %460 : Tensor = aten::add(%459, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%451, %460)
      -> ()
    block1():
      -> ()
  %461 : bool = prim::GetAttr[name="training"](%451)
  %462 : Tensor = prim::GetAttr[name="running_mean"](%451)
  %463 : Tensor = prim::GetAttr[name="running_var"](%451)
  %464 : Tensor = prim::GetAttr[name="weight"](%451)
  %465 : Tensor = prim::GetAttr[name="bias"](%451)
   = prim::If(%461) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %466 : int[] = aten::size(%input.14) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.108 : int = aten::__getitem__(%466, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %468 : int = aten::len(%466) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %469 : int = aten::sub(%468, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.109 : int = prim::Loop(%469, %6, %size_prods.108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.28 : int, %size_prods.110 : int):
          %473 : int = aten::add(%i.28, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %474 : int = aten::__getitem__(%466, %473) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.111 : int = aten::mul(%size_prods.110, %474) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.111)
      %476 : bool = aten::eq(%size_prods.109, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%476) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %477 : str = aten::format(%8, %466) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%477) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %identity.3 : Tensor = aten::batch_norm(%input.14, %464, %465, %462, %463, %461, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.72 : Tensor = aten::add_(%out.71, %identity.3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.15 : Tensor = aten::relu_(%out.72) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %481 : __torch__.torch.nn.modules.conv.___torch_mangle_15.Conv2d = prim::GetAttr[name="conv1"](%357)
  %482 : Tensor = prim::GetAttr[name="weight"](%481)
  %483 : Tensor? = prim::GetAttr[name="bias"](%481)
  %out.73 : Tensor = aten::conv2d(%input.15, %482, %483, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %488 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="bn1"](%357)
  %489 : bool = prim::GetAttr[name="training"](%488)
   = prim::If(%489) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %490 : Tensor = prim::GetAttr[name="num_batches_tracked"](%488)
      %491 : Tensor = aten::add(%490, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%488, %491)
      -> ()
    block1():
      -> ()
  %492 : bool = prim::GetAttr[name="training"](%488)
  %493 : Tensor = prim::GetAttr[name="running_mean"](%488)
  %494 : Tensor = prim::GetAttr[name="running_var"](%488)
  %495 : Tensor = prim::GetAttr[name="weight"](%488)
  %496 : Tensor = prim::GetAttr[name="bias"](%488)
   = prim::If(%492) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %497 : int[] = aten::size(%out.73) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.112 : int = aten::__getitem__(%497, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %499 : int = aten::len(%497) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %500 : int = aten::sub(%499, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.113 : int = prim::Loop(%500, %6, %size_prods.112) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.29 : int, %size_prods.114 : int):
          %504 : int = aten::add(%i.29, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %505 : int = aten::__getitem__(%497, %504) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.115 : int = aten::mul(%size_prods.114, %505) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.115)
      %507 : bool = aten::eq(%size_prods.113, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%507) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %508 : str = aten::format(%8, %497) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%508) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.74 : Tensor = aten::batch_norm(%out.73, %495, %496, %493, %494, %492, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.75 : Tensor = aten::relu_(%out.74) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %511 : __torch__.torch.nn.modules.conv.___torch_mangle_16.Conv2d = prim::GetAttr[name="conv2"](%357)
  %512 : Tensor = prim::GetAttr[name="weight"](%511)
  %513 : Tensor? = prim::GetAttr[name="bias"](%511)
  %out.76 : Tensor = aten::conv2d(%out.75, %512, %513, %1656, %1656, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %518 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="bn2"](%357)
  %519 : bool = prim::GetAttr[name="training"](%518)
   = prim::If(%519) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %520 : Tensor = prim::GetAttr[name="num_batches_tracked"](%518)
      %521 : Tensor = aten::add(%520, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%518, %521)
      -> ()
    block1():
      -> ()
  %522 : bool = prim::GetAttr[name="training"](%518)
  %523 : Tensor = prim::GetAttr[name="running_mean"](%518)
  %524 : Tensor = prim::GetAttr[name="running_var"](%518)
  %525 : Tensor = prim::GetAttr[name="weight"](%518)
  %526 : Tensor = prim::GetAttr[name="bias"](%518)
   = prim::If(%522) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %527 : int[] = aten::size(%out.76) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.116 : int = aten::__getitem__(%527, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %529 : int = aten::len(%527) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %530 : int = aten::sub(%529, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.117 : int = prim::Loop(%530, %6, %size_prods.116) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.30 : int, %size_prods.118 : int):
          %534 : int = aten::add(%i.30, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %535 : int = aten::__getitem__(%527, %534) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.119 : int = aten::mul(%size_prods.118, %535) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.119)
      %537 : bool = aten::eq(%size_prods.117, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%537) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %538 : str = aten::format(%8, %527) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%538) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.77 : Tensor = aten::batch_norm(%out.76, %525, %526, %523, %524, %522, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.78 : Tensor = aten::relu_(%out.77) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %541 : __torch__.torch.nn.modules.conv.___torch_mangle_10.Conv2d = prim::GetAttr[name="conv3"](%357)
  %542 : Tensor = prim::GetAttr[name="weight"](%541)
  %543 : Tensor? = prim::GetAttr[name="bias"](%541)
  %out.79 : Tensor = aten::conv2d(%out.78, %542, %543, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %548 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_11.BatchNorm2d = prim::GetAttr[name="bn3"](%357)
  %549 : bool = prim::GetAttr[name="training"](%548)
   = prim::If(%549) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %550 : Tensor = prim::GetAttr[name="num_batches_tracked"](%548)
      %551 : Tensor = aten::add(%550, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%548, %551)
      -> ()
    block1():
      -> ()
  %552 : bool = prim::GetAttr[name="training"](%548)
  %553 : Tensor = prim::GetAttr[name="running_mean"](%548)
  %554 : Tensor = prim::GetAttr[name="running_var"](%548)
  %555 : Tensor = prim::GetAttr[name="weight"](%548)
  %556 : Tensor = prim::GetAttr[name="bias"](%548)
   = prim::If(%552) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %557 : int[] = aten::size(%out.79) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.120 : int = aten::__getitem__(%557, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %559 : int = aten::len(%557) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %560 : int = aten::sub(%559, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.121 : int = prim::Loop(%560, %6, %size_prods.120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.31 : int, %size_prods.122 : int):
          %564 : int = aten::add(%i.31, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %565 : int = aten::__getitem__(%557, %564) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.123 : int = aten::mul(%size_prods.122, %565) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.123)
      %567 : bool = aten::eq(%size_prods.121, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%567) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %568 : str = aten::format(%8, %557) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%568) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.80 : Tensor = aten::batch_norm(%out.79, %555, %556, %553, %554, %552, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.81 : Tensor = aten::add_(%out.80, %input.15, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.12 : Tensor = aten::relu_(%out.81) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %572 : __torch__.torch.nn.modules.conv.___torch_mangle_15.Conv2d = prim::GetAttr[name="conv1"](%358)
  %573 : Tensor = prim::GetAttr[name="weight"](%572)
  %574 : Tensor? = prim::GetAttr[name="bias"](%572)
  %out.82 : Tensor = aten::conv2d(%input.12, %573, %574, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %579 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="bn1"](%358)
  %580 : bool = prim::GetAttr[name="training"](%579)
   = prim::If(%580) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %581 : Tensor = prim::GetAttr[name="num_batches_tracked"](%579)
      %582 : Tensor = aten::add(%581, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%579, %582)
      -> ()
    block1():
      -> ()
  %583 : bool = prim::GetAttr[name="training"](%579)
  %584 : Tensor = prim::GetAttr[name="running_mean"](%579)
  %585 : Tensor = prim::GetAttr[name="running_var"](%579)
  %586 : Tensor = prim::GetAttr[name="weight"](%579)
  %587 : Tensor = prim::GetAttr[name="bias"](%579)
   = prim::If(%583) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %588 : int[] = aten::size(%out.82) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.124 : int = aten::__getitem__(%588, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %590 : int = aten::len(%588) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %591 : int = aten::sub(%590, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.125 : int = prim::Loop(%591, %6, %size_prods.124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.32 : int, %size_prods.126 : int):
          %595 : int = aten::add(%i.32, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %596 : int = aten::__getitem__(%588, %595) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.127 : int = aten::mul(%size_prods.126, %596) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.127)
      %598 : bool = aten::eq(%size_prods.125, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%598) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %599 : str = aten::format(%8, %588) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%599) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.83 : Tensor = aten::batch_norm(%out.82, %586, %587, %584, %585, %583, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.84 : Tensor = aten::relu_(%out.83) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %602 : __torch__.torch.nn.modules.conv.___torch_mangle_16.Conv2d = prim::GetAttr[name="conv2"](%358)
  %603 : Tensor = prim::GetAttr[name="weight"](%602)
  %604 : Tensor? = prim::GetAttr[name="bias"](%602)
  %out.85 : Tensor = aten::conv2d(%out.84, %603, %604, %1656, %1656, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %609 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="bn2"](%358)
  %610 : bool = prim::GetAttr[name="training"](%609)
   = prim::If(%610) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %611 : Tensor = prim::GetAttr[name="num_batches_tracked"](%609)
      %612 : Tensor = aten::add(%611, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%609, %612)
      -> ()
    block1():
      -> ()
  %613 : bool = prim::GetAttr[name="training"](%609)
  %614 : Tensor = prim::GetAttr[name="running_mean"](%609)
  %615 : Tensor = prim::GetAttr[name="running_var"](%609)
  %616 : Tensor = prim::GetAttr[name="weight"](%609)
  %617 : Tensor = prim::GetAttr[name="bias"](%609)
   = prim::If(%613) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %618 : int[] = aten::size(%out.85) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.128 : int = aten::__getitem__(%618, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %620 : int = aten::len(%618) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %621 : int = aten::sub(%620, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.129 : int = prim::Loop(%621, %6, %size_prods.128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.33 : int, %size_prods.130 : int):
          %625 : int = aten::add(%i.33, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %626 : int = aten::__getitem__(%618, %625) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.131 : int = aten::mul(%size_prods.130, %626) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.131)
      %628 : bool = aten::eq(%size_prods.129, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%628) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %629 : str = aten::format(%8, %618) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%629) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.86 : Tensor = aten::batch_norm(%out.85, %616, %617, %614, %615, %613, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.87 : Tensor = aten::relu_(%out.86) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %632 : __torch__.torch.nn.modules.conv.___torch_mangle_10.Conv2d = prim::GetAttr[name="conv3"](%358)
  %633 : Tensor = prim::GetAttr[name="weight"](%632)
  %634 : Tensor? = prim::GetAttr[name="bias"](%632)
  %out.88 : Tensor = aten::conv2d(%out.87, %633, %634, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %639 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_11.BatchNorm2d = prim::GetAttr[name="bn3"](%358)
  %640 : bool = prim::GetAttr[name="training"](%639)
   = prim::If(%640) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %641 : Tensor = prim::GetAttr[name="num_batches_tracked"](%639)
      %642 : Tensor = aten::add(%641, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%639, %642)
      -> ()
    block1():
      -> ()
  %643 : bool = prim::GetAttr[name="training"](%639)
  %644 : Tensor = prim::GetAttr[name="running_mean"](%639)
  %645 : Tensor = prim::GetAttr[name="running_var"](%639)
  %646 : Tensor = prim::GetAttr[name="weight"](%639)
  %647 : Tensor = prim::GetAttr[name="bias"](%639)
   = prim::If(%643) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %648 : int[] = aten::size(%out.88) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.132 : int = aten::__getitem__(%648, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %650 : int = aten::len(%648) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %651 : int = aten::sub(%650, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.133 : int = prim::Loop(%651, %6, %size_prods.132) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.34 : int, %size_prods.134 : int):
          %655 : int = aten::add(%i.34, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %656 : int = aten::__getitem__(%648, %655) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.135 : int = aten::mul(%size_prods.134, %656) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.135)
      %658 : bool = aten::eq(%size_prods.133, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%658) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %659 : str = aten::format(%8, %648) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%659) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.89 : Tensor = aten::batch_norm(%out.88, %646, %647, %644, %645, %643, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.90 : Tensor = aten::add_(%out.89, %input.12, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.16 : Tensor = aten::relu_(%out.90) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %663 : __torch__.torch.nn.modules.conv.___torch_mangle_15.Conv2d = prim::GetAttr[name="conv1"](%359)
  %664 : Tensor = prim::GetAttr[name="weight"](%663)
  %665 : Tensor? = prim::GetAttr[name="bias"](%663)
  %out.109 : Tensor = aten::conv2d(%input.16, %664, %665, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %670 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="bn1"](%359)
  %671 : bool = prim::GetAttr[name="training"](%670)
   = prim::If(%671) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %672 : Tensor = prim::GetAttr[name="num_batches_tracked"](%670)
      %673 : Tensor = aten::add(%672, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%670, %673)
      -> ()
    block1():
      -> ()
  %674 : bool = prim::GetAttr[name="training"](%670)
  %675 : Tensor = prim::GetAttr[name="running_mean"](%670)
  %676 : Tensor = prim::GetAttr[name="running_var"](%670)
  %677 : Tensor = prim::GetAttr[name="weight"](%670)
  %678 : Tensor = prim::GetAttr[name="bias"](%670)
   = prim::If(%674) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %679 : int[] = aten::size(%out.109) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.160 : int = aten::__getitem__(%679, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %681 : int = aten::len(%679) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %682 : int = aten::sub(%681, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.161 : int = prim::Loop(%682, %6, %size_prods.160) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.41 : int, %size_prods.162 : int):
          %686 : int = aten::add(%i.41, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %687 : int = aten::__getitem__(%679, %686) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.163 : int = aten::mul(%size_prods.162, %687) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.163)
      %689 : bool = aten::eq(%size_prods.161, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%689) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %690 : str = aten::format(%8, %679) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%690) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.110 : Tensor = aten::batch_norm(%out.109, %677, %678, %675, %676, %674, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.111 : Tensor = aten::relu_(%out.110) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %693 : __torch__.torch.nn.modules.conv.___torch_mangle_16.Conv2d = prim::GetAttr[name="conv2"](%359)
  %694 : Tensor = prim::GetAttr[name="weight"](%693)
  %695 : Tensor? = prim::GetAttr[name="bias"](%693)
  %out.112 : Tensor = aten::conv2d(%out.111, %694, %695, %1656, %1656, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %700 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="bn2"](%359)
  %701 : bool = prim::GetAttr[name="training"](%700)
   = prim::If(%701) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %702 : Tensor = prim::GetAttr[name="num_batches_tracked"](%700)
      %703 : Tensor = aten::add(%702, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%700, %703)
      -> ()
    block1():
      -> ()
  %704 : bool = prim::GetAttr[name="training"](%700)
  %705 : Tensor = prim::GetAttr[name="running_mean"](%700)
  %706 : Tensor = prim::GetAttr[name="running_var"](%700)
  %707 : Tensor = prim::GetAttr[name="weight"](%700)
  %708 : Tensor = prim::GetAttr[name="bias"](%700)
   = prim::If(%704) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %709 : int[] = aten::size(%out.112) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.164 : int = aten::__getitem__(%709, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %711 : int = aten::len(%709) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %712 : int = aten::sub(%711, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.165 : int = prim::Loop(%712, %6, %size_prods.164) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.42 : int, %size_prods.166 : int):
          %716 : int = aten::add(%i.42, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %717 : int = aten::__getitem__(%709, %716) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.167 : int = aten::mul(%size_prods.166, %717) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.167)
      %719 : bool = aten::eq(%size_prods.165, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%719) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %720 : str = aten::format(%8, %709) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%720) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.113 : Tensor = aten::batch_norm(%out.112, %707, %708, %705, %706, %704, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.114 : Tensor = aten::relu_(%out.113) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %723 : __torch__.torch.nn.modules.conv.___torch_mangle_10.Conv2d = prim::GetAttr[name="conv3"](%359)
  %724 : Tensor = prim::GetAttr[name="weight"](%723)
  %725 : Tensor? = prim::GetAttr[name="bias"](%723)
  %out.115 : Tensor = aten::conv2d(%out.114, %724, %725, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %730 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_11.BatchNorm2d = prim::GetAttr[name="bn3"](%359)
  %731 : bool = prim::GetAttr[name="training"](%730)
   = prim::If(%731) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %732 : Tensor = prim::GetAttr[name="num_batches_tracked"](%730)
      %733 : Tensor = aten::add(%732, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%730, %733)
      -> ()
    block1():
      -> ()
  %734 : bool = prim::GetAttr[name="training"](%730)
  %735 : Tensor = prim::GetAttr[name="running_mean"](%730)
  %736 : Tensor = prim::GetAttr[name="running_var"](%730)
  %737 : Tensor = prim::GetAttr[name="weight"](%730)
  %738 : Tensor = prim::GetAttr[name="bias"](%730)
   = prim::If(%734) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %739 : int[] = aten::size(%out.115) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.168 : int = aten::__getitem__(%739, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %741 : int = aten::len(%739) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %742 : int = aten::sub(%741, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.169 : int = prim::Loop(%742, %6, %size_prods.168) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.43 : int, %size_prods.170 : int):
          %746 : int = aten::add(%i.43, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %747 : int = aten::__getitem__(%739, %746) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.171 : int = aten::mul(%size_prods.170, %747) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.171)
      %749 : bool = aten::eq(%size_prods.169, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%749) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %750 : str = aten::format(%8, %739) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%750) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.116 : Tensor = aten::batch_norm(%out.115, %737, %738, %735, %736, %734, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.117 : Tensor = aten::add_(%out.116, %input.16, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %x.13 : Tensor = aten::relu_(%out.117) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %754 : __torch__.torch.nn.modules.container.___torch_mangle_29.Sequential = prim::GetAttr[name="layer3"](%self)
  %755 : __torch__.torchvision.models.resnet.___torch_mangle_25.Bottleneck = prim::GetAttr[name="0"](%754)
  %756 : __torch__.torchvision.models.resnet.___torch_mangle_28.Bottleneck = prim::GetAttr[name="1"](%754)
  %757 : __torch__.torchvision.models.resnet.___torch_mangle_28.Bottleneck = prim::GetAttr[name="2"](%754)
  %758 : __torch__.torchvision.models.resnet.___torch_mangle_28.Bottleneck = prim::GetAttr[name="3"](%754)
  %759 : __torch__.torchvision.models.resnet.___torch_mangle_28.Bottleneck = prim::GetAttr[name="4"](%754)
  %760 : __torch__.torchvision.models.resnet.___torch_mangle_28.Bottleneck = prim::GetAttr[name="5"](%754)
  %761 : __torch__.torch.nn.modules.conv.___torch_mangle_19.Conv2d = prim::GetAttr[name="conv1"](%755)
  %762 : Tensor = prim::GetAttr[name="weight"](%761)
  %763 : Tensor? = prim::GetAttr[name="bias"](%761)
  %out.118 : Tensor = aten::conv2d(%x.13, %762, %763, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %768 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="bn1"](%755)
  %769 : bool = prim::GetAttr[name="training"](%768)
   = prim::If(%769) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %770 : Tensor = prim::GetAttr[name="num_batches_tracked"](%768)
      %771 : Tensor = aten::add(%770, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%768, %771)
      -> ()
    block1():
      -> ()
  %772 : bool = prim::GetAttr[name="training"](%768)
  %773 : Tensor = prim::GetAttr[name="running_mean"](%768)
  %774 : Tensor = prim::GetAttr[name="running_var"](%768)
  %775 : Tensor = prim::GetAttr[name="weight"](%768)
  %776 : Tensor = prim::GetAttr[name="bias"](%768)
   = prim::If(%772) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %777 : int[] = aten::size(%out.118) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.172 : int = aten::__getitem__(%777, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %779 : int = aten::len(%777) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %780 : int = aten::sub(%779, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.173 : int = prim::Loop(%780, %6, %size_prods.172) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.44 : int, %size_prods.174 : int):
          %784 : int = aten::add(%i.44, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %785 : int = aten::__getitem__(%777, %784) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.175 : int = aten::mul(%size_prods.174, %785) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.175)
      %787 : bool = aten::eq(%size_prods.173, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%787) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %788 : str = aten::format(%8, %777) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%788) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.119 : Tensor = aten::batch_norm(%out.118, %775, %776, %773, %774, %772, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.120 : Tensor = aten::relu_(%out.119) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %791 : __torch__.torch.nn.modules.conv.___torch_mangle_20.Conv2d = prim::GetAttr[name="conv2"](%755)
  %792 : Tensor = prim::GetAttr[name="weight"](%791)
  %793 : Tensor? = prim::GetAttr[name="bias"](%791)
  %out.121 : Tensor = aten::conv2d(%out.120, %792, %793, %1654, %1656, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %798 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="bn2"](%755)
  %799 : bool = prim::GetAttr[name="training"](%798)
   = prim::If(%799) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %800 : Tensor = prim::GetAttr[name="num_batches_tracked"](%798)
      %801 : Tensor = aten::add(%800, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%798, %801)
      -> ()
    block1():
      -> ()
  %802 : bool = prim::GetAttr[name="training"](%798)
  %803 : Tensor = prim::GetAttr[name="running_mean"](%798)
  %804 : Tensor = prim::GetAttr[name="running_var"](%798)
  %805 : Tensor = prim::GetAttr[name="weight"](%798)
  %806 : Tensor = prim::GetAttr[name="bias"](%798)
   = prim::If(%802) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %807 : int[] = aten::size(%out.121) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.176 : int = aten::__getitem__(%807, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %809 : int = aten::len(%807) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %810 : int = aten::sub(%809, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.177 : int = prim::Loop(%810, %6, %size_prods.176) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.45 : int, %size_prods.178 : int):
          %814 : int = aten::add(%i.45, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %815 : int = aten::__getitem__(%807, %814) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.179 : int = aten::mul(%size_prods.178, %815) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.179)
      %817 : bool = aten::eq(%size_prods.177, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%817) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %818 : str = aten::format(%8, %807) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%818) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.122 : Tensor = aten::batch_norm(%out.121, %805, %806, %803, %804, %802, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.123 : Tensor = aten::relu_(%out.122) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %821 : __torch__.torch.nn.modules.conv.___torch_mangle_21.Conv2d = prim::GetAttr[name="conv3"](%755)
  %822 : Tensor = prim::GetAttr[name="weight"](%821)
  %823 : Tensor? = prim::GetAttr[name="bias"](%821)
  %out.124 : Tensor = aten::conv2d(%out.123, %822, %823, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %828 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_22.BatchNorm2d = prim::GetAttr[name="bn3"](%755)
  %829 : bool = prim::GetAttr[name="training"](%828)
   = prim::If(%829) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %830 : Tensor = prim::GetAttr[name="num_batches_tracked"](%828)
      %831 : Tensor = aten::add(%830, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%828, %831)
      -> ()
    block1():
      -> ()
  %832 : bool = prim::GetAttr[name="training"](%828)
  %833 : Tensor = prim::GetAttr[name="running_mean"](%828)
  %834 : Tensor = prim::GetAttr[name="running_var"](%828)
  %835 : Tensor = prim::GetAttr[name="weight"](%828)
  %836 : Tensor = prim::GetAttr[name="bias"](%828)
   = prim::If(%832) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %837 : int[] = aten::size(%out.124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.180 : int = aten::__getitem__(%837, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %839 : int = aten::len(%837) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %840 : int = aten::sub(%839, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.181 : int = prim::Loop(%840, %6, %size_prods.180) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.46 : int, %size_prods.182 : int):
          %844 : int = aten::add(%i.46, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %845 : int = aten::__getitem__(%837, %844) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.183 : int = aten::mul(%size_prods.182, %845) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.183)
      %847 : bool = aten::eq(%size_prods.181, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%847) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %848 : str = aten::format(%8, %837) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%848) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.125 : Tensor = aten::batch_norm(%out.124, %835, %836, %833, %834, %832, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %850 : __torch__.torch.nn.modules.container.___torch_mangle_24.Sequential = prim::GetAttr[name="downsample"](%755)
  %851 : __torch__.torch.nn.modules.conv.___torch_mangle_23.Conv2d = prim::GetAttr[name="0"](%850)
  %852 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_22.BatchNorm2d = prim::GetAttr[name="1"](%850)
  %853 : Tensor = prim::GetAttr[name="weight"](%851)
  %854 : Tensor? = prim::GetAttr[name="bias"](%851)
  %input.13 : Tensor = aten::conv2d(%x.13, %853, %854, %1654, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %859 : bool = prim::GetAttr[name="training"](%852)
   = prim::If(%859) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %860 : Tensor = prim::GetAttr[name="num_batches_tracked"](%852)
      %861 : Tensor = aten::add(%860, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%852, %861)
      -> ()
    block1():
      -> ()
  %862 : bool = prim::GetAttr[name="training"](%852)
  %863 : Tensor = prim::GetAttr[name="running_mean"](%852)
  %864 : Tensor = prim::GetAttr[name="running_var"](%852)
  %865 : Tensor = prim::GetAttr[name="weight"](%852)
  %866 : Tensor = prim::GetAttr[name="bias"](%852)
   = prim::If(%862) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %867 : int[] = aten::size(%input.13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.184 : int = aten::__getitem__(%867, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %869 : int = aten::len(%867) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %870 : int = aten::sub(%869, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.185 : int = prim::Loop(%870, %6, %size_prods.184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.47 : int, %size_prods.186 : int):
          %874 : int = aten::add(%i.47, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %875 : int = aten::__getitem__(%867, %874) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.187 : int = aten::mul(%size_prods.186, %875) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.187)
      %877 : bool = aten::eq(%size_prods.185, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%877) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %878 : str = aten::format(%8, %867) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%878) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %identity.4 : Tensor = aten::batch_norm(%input.13, %865, %866, %863, %864, %862, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.126 : Tensor = aten::add_(%out.125, %identity.4, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.17 : Tensor = aten::relu_(%out.126) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %882 : __torch__.torch.nn.modules.conv.___torch_mangle_26.Conv2d = prim::GetAttr[name="conv1"](%756)
  %883 : Tensor = prim::GetAttr[name="weight"](%882)
  %884 : Tensor? = prim::GetAttr[name="bias"](%882)
  %out.127 : Tensor = aten::conv2d(%input.17, %883, %884, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %889 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="bn1"](%756)
  %890 : bool = prim::GetAttr[name="training"](%889)
   = prim::If(%890) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %891 : Tensor = prim::GetAttr[name="num_batches_tracked"](%889)
      %892 : Tensor = aten::add(%891, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%889, %892)
      -> ()
    block1():
      -> ()
  %893 : bool = prim::GetAttr[name="training"](%889)
  %894 : Tensor = prim::GetAttr[name="running_mean"](%889)
  %895 : Tensor = prim::GetAttr[name="running_var"](%889)
  %896 : Tensor = prim::GetAttr[name="weight"](%889)
  %897 : Tensor = prim::GetAttr[name="bias"](%889)
   = prim::If(%893) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %898 : int[] = aten::size(%out.127) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.188 : int = aten::__getitem__(%898, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %900 : int = aten::len(%898) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %901 : int = aten::sub(%900, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.189 : int = prim::Loop(%901, %6, %size_prods.188) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.48 : int, %size_prods.190 : int):
          %905 : int = aten::add(%i.48, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %906 : int = aten::__getitem__(%898, %905) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.191 : int = aten::mul(%size_prods.190, %906) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.191)
      %908 : bool = aten::eq(%size_prods.189, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%908) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %909 : str = aten::format(%8, %898) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%909) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.128 : Tensor = aten::batch_norm(%out.127, %896, %897, %894, %895, %893, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.129 : Tensor = aten::relu_(%out.128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %912 : __torch__.torch.nn.modules.conv.___torch_mangle_27.Conv2d = prim::GetAttr[name="conv2"](%756)
  %913 : Tensor = prim::GetAttr[name="weight"](%912)
  %914 : Tensor? = prim::GetAttr[name="bias"](%912)
  %out.130 : Tensor = aten::conv2d(%out.129, %913, %914, %1656, %1656, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %919 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="bn2"](%756)
  %920 : bool = prim::GetAttr[name="training"](%919)
   = prim::If(%920) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %921 : Tensor = prim::GetAttr[name="num_batches_tracked"](%919)
      %922 : Tensor = aten::add(%921, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%919, %922)
      -> ()
    block1():
      -> ()
  %923 : bool = prim::GetAttr[name="training"](%919)
  %924 : Tensor = prim::GetAttr[name="running_mean"](%919)
  %925 : Tensor = prim::GetAttr[name="running_var"](%919)
  %926 : Tensor = prim::GetAttr[name="weight"](%919)
  %927 : Tensor = prim::GetAttr[name="bias"](%919)
   = prim::If(%923) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %928 : int[] = aten::size(%out.130) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.192 : int = aten::__getitem__(%928, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %930 : int = aten::len(%928) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %931 : int = aten::sub(%930, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.193 : int = prim::Loop(%931, %6, %size_prods.192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.49 : int, %size_prods.194 : int):
          %935 : int = aten::add(%i.49, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %936 : int = aten::__getitem__(%928, %935) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.195 : int = aten::mul(%size_prods.194, %936) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.195)
      %938 : bool = aten::eq(%size_prods.193, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%938) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %939 : str = aten::format(%8, %928) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%939) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.131 : Tensor = aten::batch_norm(%out.130, %926, %927, %924, %925, %923, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.132 : Tensor = aten::relu_(%out.131) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %942 : __torch__.torch.nn.modules.conv.___torch_mangle_21.Conv2d = prim::GetAttr[name="conv3"](%756)
  %943 : Tensor = prim::GetAttr[name="weight"](%942)
  %944 : Tensor? = prim::GetAttr[name="bias"](%942)
  %out.133 : Tensor = aten::conv2d(%out.132, %943, %944, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %949 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_22.BatchNorm2d = prim::GetAttr[name="bn3"](%756)
  %950 : bool = prim::GetAttr[name="training"](%949)
   = prim::If(%950) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %951 : Tensor = prim::GetAttr[name="num_batches_tracked"](%949)
      %952 : Tensor = aten::add(%951, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%949, %952)
      -> ()
    block1():
      -> ()
  %953 : bool = prim::GetAttr[name="training"](%949)
  %954 : Tensor = prim::GetAttr[name="running_mean"](%949)
  %955 : Tensor = prim::GetAttr[name="running_var"](%949)
  %956 : Tensor = prim::GetAttr[name="weight"](%949)
  %957 : Tensor = prim::GetAttr[name="bias"](%949)
   = prim::If(%953) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %958 : int[] = aten::size(%out.133) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.196 : int = aten::__getitem__(%958, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %960 : int = aten::len(%958) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %961 : int = aten::sub(%960, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.197 : int = prim::Loop(%961, %6, %size_prods.196) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.50 : int, %size_prods.198 : int):
          %965 : int = aten::add(%i.50, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %966 : int = aten::__getitem__(%958, %965) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.199 : int = aten::mul(%size_prods.198, %966) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.199)
      %968 : bool = aten::eq(%size_prods.197, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%968) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %969 : str = aten::format(%8, %958) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%969) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.134 : Tensor = aten::batch_norm(%out.133, %956, %957, %954, %955, %953, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.135 : Tensor = aten::add_(%out.134, %input.17, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.18 : Tensor = aten::relu_(%out.135) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %973 : __torch__.torch.nn.modules.conv.___torch_mangle_26.Conv2d = prim::GetAttr[name="conv1"](%757)
  %974 : Tensor = prim::GetAttr[name="weight"](%973)
  %975 : Tensor? = prim::GetAttr[name="bias"](%973)
  %out.37 : Tensor = aten::conv2d(%input.18, %974, %975, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %980 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="bn1"](%757)
  %981 : bool = prim::GetAttr[name="training"](%980)
   = prim::If(%981) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %982 : Tensor = prim::GetAttr[name="num_batches_tracked"](%980)
      %983 : Tensor = aten::add(%982, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%980, %983)
      -> ()
    block1():
      -> ()
  %984 : bool = prim::GetAttr[name="training"](%980)
  %985 : Tensor = prim::GetAttr[name="running_mean"](%980)
  %986 : Tensor = prim::GetAttr[name="running_var"](%980)
  %987 : Tensor = prim::GetAttr[name="weight"](%980)
  %988 : Tensor = prim::GetAttr[name="bias"](%980)
   = prim::If(%984) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %989 : int[] = aten::size(%out.37) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.40 : int = aten::__getitem__(%989, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %991 : int = aten::len(%989) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %992 : int = aten::sub(%991, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.41 : int = prim::Loop(%992, %6, %size_prods.40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.11 : int, %size_prods.42 : int):
          %996 : int = aten::add(%i.11, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %997 : int = aten::__getitem__(%989, %996) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.43 : int = aten::mul(%size_prods.42, %997) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.43)
      %999 : bool = aten::eq(%size_prods.41, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%999) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1000 : str = aten::format(%8, %989) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1000) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.29 : Tensor = aten::batch_norm(%out.37, %987, %988, %985, %986, %984, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.30 : Tensor = aten::relu_(%out.29) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1003 : __torch__.torch.nn.modules.conv.___torch_mangle_27.Conv2d = prim::GetAttr[name="conv2"](%757)
  %1004 : Tensor = prim::GetAttr[name="weight"](%1003)
  %1005 : Tensor? = prim::GetAttr[name="bias"](%1003)
  %out.31 : Tensor = aten::conv2d(%out.30, %1004, %1005, %1656, %1656, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1010 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="bn2"](%757)
  %1011 : bool = prim::GetAttr[name="training"](%1010)
   = prim::If(%1011) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1012 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1010)
      %1013 : Tensor = aten::add(%1012, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1010, %1013)
      -> ()
    block1():
      -> ()
  %1014 : bool = prim::GetAttr[name="training"](%1010)
  %1015 : Tensor = prim::GetAttr[name="running_mean"](%1010)
  %1016 : Tensor = prim::GetAttr[name="running_var"](%1010)
  %1017 : Tensor = prim::GetAttr[name="weight"](%1010)
  %1018 : Tensor = prim::GetAttr[name="bias"](%1010)
   = prim::If(%1014) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1019 : int[] = aten::size(%out.31) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.44 : int = aten::__getitem__(%1019, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1021 : int = aten::len(%1019) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1022 : int = aten::sub(%1021, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.45 : int = prim::Loop(%1022, %6, %size_prods.44) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.12 : int, %size_prods.46 : int):
          %1026 : int = aten::add(%i.12, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1027 : int = aten::__getitem__(%1019, %1026) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.47 : int = aten::mul(%size_prods.46, %1027) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.47)
      %1029 : bool = aten::eq(%size_prods.45, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1029) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1030 : str = aten::format(%8, %1019) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1030) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.32 : Tensor = aten::batch_norm(%out.31, %1017, %1018, %1015, %1016, %1014, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.33 : Tensor = aten::relu_(%out.32) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1033 : __torch__.torch.nn.modules.conv.___torch_mangle_21.Conv2d = prim::GetAttr[name="conv3"](%757)
  %1034 : Tensor = prim::GetAttr[name="weight"](%1033)
  %1035 : Tensor? = prim::GetAttr[name="bias"](%1033)
  %out.34 : Tensor = aten::conv2d(%out.33, %1034, %1035, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1040 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_22.BatchNorm2d = prim::GetAttr[name="bn3"](%757)
  %1041 : bool = prim::GetAttr[name="training"](%1040)
   = prim::If(%1041) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1042 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1040)
      %1043 : Tensor = aten::add(%1042, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1040, %1043)
      -> ()
    block1():
      -> ()
  %1044 : bool = prim::GetAttr[name="training"](%1040)
  %1045 : Tensor = prim::GetAttr[name="running_mean"](%1040)
  %1046 : Tensor = prim::GetAttr[name="running_var"](%1040)
  %1047 : Tensor = prim::GetAttr[name="weight"](%1040)
  %1048 : Tensor = prim::GetAttr[name="bias"](%1040)
   = prim::If(%1044) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1049 : int[] = aten::size(%out.34) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.48 : int = aten::__getitem__(%1049, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1051 : int = aten::len(%1049) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1052 : int = aten::sub(%1051, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.49 : int = prim::Loop(%1052, %6, %size_prods.48) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.13 : int, %size_prods.50 : int):
          %1056 : int = aten::add(%i.13, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1057 : int = aten::__getitem__(%1049, %1056) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.51 : int = aten::mul(%size_prods.50, %1057) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.51)
      %1059 : bool = aten::eq(%size_prods.49, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1059) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1060 : str = aten::format(%8, %1049) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1060) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.35 : Tensor = aten::batch_norm(%out.34, %1047, %1048, %1045, %1046, %1044, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.36 : Tensor = aten::add_(%out.35, %input.18, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.19 : Tensor = aten::relu_(%out.36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1064 : __torch__.torch.nn.modules.conv.___torch_mangle_26.Conv2d = prim::GetAttr[name="conv1"](%758)
  %1065 : Tensor = prim::GetAttr[name="weight"](%1064)
  %1066 : Tensor? = prim::GetAttr[name="bias"](%1064)
  %out.46 : Tensor = aten::conv2d(%input.19, %1065, %1066, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1071 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="bn1"](%758)
  %1072 : bool = prim::GetAttr[name="training"](%1071)
   = prim::If(%1072) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1073 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1071)
      %1074 : Tensor = aten::add(%1073, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1071, %1074)
      -> ()
    block1():
      -> ()
  %1075 : bool = prim::GetAttr[name="training"](%1071)
  %1076 : Tensor = prim::GetAttr[name="running_mean"](%1071)
  %1077 : Tensor = prim::GetAttr[name="running_var"](%1071)
  %1078 : Tensor = prim::GetAttr[name="weight"](%1071)
  %1079 : Tensor = prim::GetAttr[name="bias"](%1071)
   = prim::If(%1075) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1080 : int[] = aten::size(%out.46) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.52 : int = aten::__getitem__(%1080, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1082 : int = aten::len(%1080) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1083 : int = aten::sub(%1082, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.53 : int = prim::Loop(%1083, %6, %size_prods.52) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.14 : int, %size_prods.54 : int):
          %1087 : int = aten::add(%i.14, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1088 : int = aten::__getitem__(%1080, %1087) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.55 : int = aten::mul(%size_prods.54, %1088) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.55)
      %1090 : bool = aten::eq(%size_prods.53, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1090) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1091 : str = aten::format(%8, %1080) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1091) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.38 : Tensor = aten::batch_norm(%out.46, %1078, %1079, %1076, %1077, %1075, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.39 : Tensor = aten::relu_(%out.38) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1094 : __torch__.torch.nn.modules.conv.___torch_mangle_27.Conv2d = prim::GetAttr[name="conv2"](%758)
  %1095 : Tensor = prim::GetAttr[name="weight"](%1094)
  %1096 : Tensor? = prim::GetAttr[name="bias"](%1094)
  %out.40 : Tensor = aten::conv2d(%out.39, %1095, %1096, %1656, %1656, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1101 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="bn2"](%758)
  %1102 : bool = prim::GetAttr[name="training"](%1101)
   = prim::If(%1102) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1103 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1101)
      %1104 : Tensor = aten::add(%1103, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1101, %1104)
      -> ()
    block1():
      -> ()
  %1105 : bool = prim::GetAttr[name="training"](%1101)
  %1106 : Tensor = prim::GetAttr[name="running_mean"](%1101)
  %1107 : Tensor = prim::GetAttr[name="running_var"](%1101)
  %1108 : Tensor = prim::GetAttr[name="weight"](%1101)
  %1109 : Tensor = prim::GetAttr[name="bias"](%1101)
   = prim::If(%1105) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1110 : int[] = aten::size(%out.40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.56 : int = aten::__getitem__(%1110, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1112 : int = aten::len(%1110) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1113 : int = aten::sub(%1112, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.57 : int = prim::Loop(%1113, %6, %size_prods.56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.15 : int, %size_prods.58 : int):
          %1117 : int = aten::add(%i.15, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1118 : int = aten::__getitem__(%1110, %1117) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.59 : int = aten::mul(%size_prods.58, %1118) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.59)
      %1120 : bool = aten::eq(%size_prods.57, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1121 : str = aten::format(%8, %1110) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1121) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.41 : Tensor = aten::batch_norm(%out.40, %1108, %1109, %1106, %1107, %1105, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.42 : Tensor = aten::relu_(%out.41) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1124 : __torch__.torch.nn.modules.conv.___torch_mangle_21.Conv2d = prim::GetAttr[name="conv3"](%758)
  %1125 : Tensor = prim::GetAttr[name="weight"](%1124)
  %1126 : Tensor? = prim::GetAttr[name="bias"](%1124)
  %out.43 : Tensor = aten::conv2d(%out.42, %1125, %1126, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1131 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_22.BatchNorm2d = prim::GetAttr[name="bn3"](%758)
  %1132 : bool = prim::GetAttr[name="training"](%1131)
   = prim::If(%1132) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1133 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1131)
      %1134 : Tensor = aten::add(%1133, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1131, %1134)
      -> ()
    block1():
      -> ()
  %1135 : bool = prim::GetAttr[name="training"](%1131)
  %1136 : Tensor = prim::GetAttr[name="running_mean"](%1131)
  %1137 : Tensor = prim::GetAttr[name="running_var"](%1131)
  %1138 : Tensor = prim::GetAttr[name="weight"](%1131)
  %1139 : Tensor = prim::GetAttr[name="bias"](%1131)
   = prim::If(%1135) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1140 : int[] = aten::size(%out.43) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.60 : int = aten::__getitem__(%1140, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1142 : int = aten::len(%1140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1143 : int = aten::sub(%1142, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.61 : int = prim::Loop(%1143, %6, %size_prods.60) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.16 : int, %size_prods.62 : int):
          %1147 : int = aten::add(%i.16, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1148 : int = aten::__getitem__(%1140, %1147) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.63 : int = aten::mul(%size_prods.62, %1148) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.63)
      %1150 : bool = aten::eq(%size_prods.61, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1150) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1151 : str = aten::format(%8, %1140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1151) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.44 : Tensor = aten::batch_norm(%out.43, %1138, %1139, %1136, %1137, %1135, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.45 : Tensor = aten::add_(%out.44, %input.19, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.9 : Tensor = aten::relu_(%out.45) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1155 : __torch__.torch.nn.modules.conv.___torch_mangle_26.Conv2d = prim::GetAttr[name="conv1"](%759)
  %1156 : Tensor = prim::GetAttr[name="weight"](%1155)
  %1157 : Tensor? = prim::GetAttr[name="bias"](%1155)
  %out.55 : Tensor = aten::conv2d(%input.9, %1156, %1157, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1162 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="bn1"](%759)
  %1163 : bool = prim::GetAttr[name="training"](%1162)
   = prim::If(%1163) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1164 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1162)
      %1165 : Tensor = aten::add(%1164, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1162, %1165)
      -> ()
    block1():
      -> ()
  %1166 : bool = prim::GetAttr[name="training"](%1162)
  %1167 : Tensor = prim::GetAttr[name="running_mean"](%1162)
  %1168 : Tensor = prim::GetAttr[name="running_var"](%1162)
  %1169 : Tensor = prim::GetAttr[name="weight"](%1162)
  %1170 : Tensor = prim::GetAttr[name="bias"](%1162)
   = prim::If(%1166) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1171 : int[] = aten::size(%out.55) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.64 : int = aten::__getitem__(%1171, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1173 : int = aten::len(%1171) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1174 : int = aten::sub(%1173, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.65 : int = prim::Loop(%1174, %6, %size_prods.64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.17 : int, %size_prods.66 : int):
          %1178 : int = aten::add(%i.17, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1179 : int = aten::__getitem__(%1171, %1178) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.67 : int = aten::mul(%size_prods.66, %1179) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.67)
      %1181 : bool = aten::eq(%size_prods.65, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1181) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1182 : str = aten::format(%8, %1171) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1182) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.47 : Tensor = aten::batch_norm(%out.55, %1169, %1170, %1167, %1168, %1166, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.48 : Tensor = aten::relu_(%out.47) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1185 : __torch__.torch.nn.modules.conv.___torch_mangle_27.Conv2d = prim::GetAttr[name="conv2"](%759)
  %1186 : Tensor = prim::GetAttr[name="weight"](%1185)
  %1187 : Tensor? = prim::GetAttr[name="bias"](%1185)
  %out.49 : Tensor = aten::conv2d(%out.48, %1186, %1187, %1656, %1656, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1192 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="bn2"](%759)
  %1193 : bool = prim::GetAttr[name="training"](%1192)
   = prim::If(%1193) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1194 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1192)
      %1195 : Tensor = aten::add(%1194, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1192, %1195)
      -> ()
    block1():
      -> ()
  %1196 : bool = prim::GetAttr[name="training"](%1192)
  %1197 : Tensor = prim::GetAttr[name="running_mean"](%1192)
  %1198 : Tensor = prim::GetAttr[name="running_var"](%1192)
  %1199 : Tensor = prim::GetAttr[name="weight"](%1192)
  %1200 : Tensor = prim::GetAttr[name="bias"](%1192)
   = prim::If(%1196) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1201 : int[] = aten::size(%out.49) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.68 : int = aten::__getitem__(%1201, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1203 : int = aten::len(%1201) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1204 : int = aten::sub(%1203, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.69 : int = prim::Loop(%1204, %6, %size_prods.68) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.18 : int, %size_prods.70 : int):
          %1208 : int = aten::add(%i.18, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1209 : int = aten::__getitem__(%1201, %1208) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.71 : int = aten::mul(%size_prods.70, %1209) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.71)
      %1211 : bool = aten::eq(%size_prods.69, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1211) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1212 : str = aten::format(%8, %1201) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.50 : Tensor = aten::batch_norm(%out.49, %1199, %1200, %1197, %1198, %1196, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.51 : Tensor = aten::relu_(%out.50) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1215 : __torch__.torch.nn.modules.conv.___torch_mangle_21.Conv2d = prim::GetAttr[name="conv3"](%759)
  %1216 : Tensor = prim::GetAttr[name="weight"](%1215)
  %1217 : Tensor? = prim::GetAttr[name="bias"](%1215)
  %out.52 : Tensor = aten::conv2d(%out.51, %1216, %1217, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1222 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_22.BatchNorm2d = prim::GetAttr[name="bn3"](%759)
  %1223 : bool = prim::GetAttr[name="training"](%1222)
   = prim::If(%1223) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1224 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1222)
      %1225 : Tensor = aten::add(%1224, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1222, %1225)
      -> ()
    block1():
      -> ()
  %1226 : bool = prim::GetAttr[name="training"](%1222)
  %1227 : Tensor = prim::GetAttr[name="running_mean"](%1222)
  %1228 : Tensor = prim::GetAttr[name="running_var"](%1222)
  %1229 : Tensor = prim::GetAttr[name="weight"](%1222)
  %1230 : Tensor = prim::GetAttr[name="bias"](%1222)
   = prim::If(%1226) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1231 : int[] = aten::size(%out.52) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.72 : int = aten::__getitem__(%1231, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1233 : int = aten::len(%1231) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1234 : int = aten::sub(%1233, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.73 : int = prim::Loop(%1234, %6, %size_prods.72) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.19 : int, %size_prods.74 : int):
          %1238 : int = aten::add(%i.19, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1239 : int = aten::__getitem__(%1231, %1238) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.75 : int = aten::mul(%size_prods.74, %1239) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.75)
      %1241 : bool = aten::eq(%size_prods.73, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1241) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1242 : str = aten::format(%8, %1231) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1242) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.53 : Tensor = aten::batch_norm(%out.52, %1229, %1230, %1227, %1228, %1226, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.54 : Tensor = aten::add_(%out.53, %input.9, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.11 : Tensor = aten::relu_(%out.54) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1246 : __torch__.torch.nn.modules.conv.___torch_mangle_26.Conv2d = prim::GetAttr[name="conv1"](%760)
  %1247 : Tensor = prim::GetAttr[name="weight"](%1246)
  %1248 : Tensor? = prim::GetAttr[name="bias"](%1246)
  %out.136 : Tensor = aten::conv2d(%input.11, %1247, %1248, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1253 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="bn1"](%760)
  %1254 : bool = prim::GetAttr[name="training"](%1253)
   = prim::If(%1254) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1255 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1253)
      %1256 : Tensor = aten::add(%1255, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1253, %1256)
      -> ()
    block1():
      -> ()
  %1257 : bool = prim::GetAttr[name="training"](%1253)
  %1258 : Tensor = prim::GetAttr[name="running_mean"](%1253)
  %1259 : Tensor = prim::GetAttr[name="running_var"](%1253)
  %1260 : Tensor = prim::GetAttr[name="weight"](%1253)
  %1261 : Tensor = prim::GetAttr[name="bias"](%1253)
   = prim::If(%1257) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1262 : int[] = aten::size(%out.136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.200 : int = aten::__getitem__(%1262, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1264 : int = aten::len(%1262) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1265 : int = aten::sub(%1264, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.201 : int = prim::Loop(%1265, %6, %size_prods.200) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.51 : int, %size_prods.202 : int):
          %1269 : int = aten::add(%i.51, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1270 : int = aten::__getitem__(%1262, %1269) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.203 : int = aten::mul(%size_prods.202, %1270) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.203)
      %1272 : bool = aten::eq(%size_prods.201, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1273 : str = aten::format(%8, %1262) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1273) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.137 : Tensor = aten::batch_norm(%out.136, %1260, %1261, %1258, %1259, %1257, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.138 : Tensor = aten::relu_(%out.137) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1276 : __torch__.torch.nn.modules.conv.___torch_mangle_27.Conv2d = prim::GetAttr[name="conv2"](%760)
  %1277 : Tensor = prim::GetAttr[name="weight"](%1276)
  %1278 : Tensor? = prim::GetAttr[name="bias"](%1276)
  %out.139 : Tensor = aten::conv2d(%out.138, %1277, %1278, %1656, %1656, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1283 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="bn2"](%760)
  %1284 : bool = prim::GetAttr[name="training"](%1283)
   = prim::If(%1284) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1285 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1283)
      %1286 : Tensor = aten::add(%1285, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1283, %1286)
      -> ()
    block1():
      -> ()
  %1287 : bool = prim::GetAttr[name="training"](%1283)
  %1288 : Tensor = prim::GetAttr[name="running_mean"](%1283)
  %1289 : Tensor = prim::GetAttr[name="running_var"](%1283)
  %1290 : Tensor = prim::GetAttr[name="weight"](%1283)
  %1291 : Tensor = prim::GetAttr[name="bias"](%1283)
   = prim::If(%1287) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1292 : int[] = aten::size(%out.139) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.204 : int = aten::__getitem__(%1292, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1294 : int = aten::len(%1292) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1295 : int = aten::sub(%1294, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.205 : int = prim::Loop(%1295, %6, %size_prods.204) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.52 : int, %size_prods.206 : int):
          %1299 : int = aten::add(%i.52, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1300 : int = aten::__getitem__(%1292, %1299) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.207 : int = aten::mul(%size_prods.206, %1300) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.207)
      %1302 : bool = aten::eq(%size_prods.205, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1302) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1303 : str = aten::format(%8, %1292) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1303) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.140 : Tensor = aten::batch_norm(%out.139, %1290, %1291, %1288, %1289, %1287, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.141 : Tensor = aten::relu_(%out.140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1306 : __torch__.torch.nn.modules.conv.___torch_mangle_21.Conv2d = prim::GetAttr[name="conv3"](%760)
  %1307 : Tensor = prim::GetAttr[name="weight"](%1306)
  %1308 : Tensor? = prim::GetAttr[name="bias"](%1306)
  %out.142 : Tensor = aten::conv2d(%out.141, %1307, %1308, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1313 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_22.BatchNorm2d = prim::GetAttr[name="bn3"](%760)
  %1314 : bool = prim::GetAttr[name="training"](%1313)
   = prim::If(%1314) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1315 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1313)
      %1316 : Tensor = aten::add(%1315, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1313, %1316)
      -> ()
    block1():
      -> ()
  %1317 : bool = prim::GetAttr[name="training"](%1313)
  %1318 : Tensor = prim::GetAttr[name="running_mean"](%1313)
  %1319 : Tensor = prim::GetAttr[name="running_var"](%1313)
  %1320 : Tensor = prim::GetAttr[name="weight"](%1313)
  %1321 : Tensor = prim::GetAttr[name="bias"](%1313)
   = prim::If(%1317) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1322 : int[] = aten::size(%out.142) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.208 : int = aten::__getitem__(%1322, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1324 : int = aten::len(%1322) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1325 : int = aten::sub(%1324, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.209 : int = prim::Loop(%1325, %6, %size_prods.208) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.53 : int, %size_prods.210 : int):
          %1329 : int = aten::add(%i.53, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1330 : int = aten::__getitem__(%1322, %1329) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.211 : int = aten::mul(%size_prods.210, %1330) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.211)
      %1332 : bool = aten::eq(%size_prods.209, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1332) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1333 : str = aten::format(%8, %1322) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1333) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.143 : Tensor = aten::batch_norm(%out.142, %1320, %1321, %1318, %1319, %1317, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.144 : Tensor = aten::add_(%out.143, %input.11, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %x.15 : Tensor = aten::relu_(%out.144) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1337 : __torch__.torch.nn.modules.container.___torch_mangle_40.Sequential = prim::GetAttr[name="layer4"](%self)
  %1338 : __torch__.torchvision.models.resnet.___torch_mangle_36.Bottleneck = prim::GetAttr[name="0"](%1337)
  %1339 : __torch__.torchvision.models.resnet.___torch_mangle_39.Bottleneck = prim::GetAttr[name="1"](%1337)
  %1340 : __torch__.torchvision.models.resnet.___torch_mangle_39.Bottleneck = prim::GetAttr[name="2"](%1337)
  %1341 : __torch__.torch.nn.modules.conv.___torch_mangle_30.Conv2d = prim::GetAttr[name="conv1"](%1338)
  %1342 : Tensor = prim::GetAttr[name="weight"](%1341)
  %1343 : Tensor? = prim::GetAttr[name="bias"](%1341)
  %out.2 : Tensor = aten::conv2d(%x.15, %1342, %1343, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1348 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_11.BatchNorm2d = prim::GetAttr[name="bn1"](%1338)
  %1349 : bool = prim::GetAttr[name="training"](%1348)
   = prim::If(%1349) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1350 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1348)
      %1351 : Tensor = aten::add(%1350, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1348, %1351)
      -> ()
    block1():
      -> ()
  %1352 : bool = prim::GetAttr[name="training"](%1348)
  %1353 : Tensor = prim::GetAttr[name="running_mean"](%1348)
  %1354 : Tensor = prim::GetAttr[name="running_var"](%1348)
  %1355 : Tensor = prim::GetAttr[name="weight"](%1348)
  %1356 : Tensor = prim::GetAttr[name="bias"](%1348)
   = prim::If(%1352) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1357 : int[] = aten::size(%out.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.16 : int = aten::__getitem__(%1357, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1359 : int = aten::len(%1357) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1360 : int = aten::sub(%1359, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.17 : int = prim::Loop(%1360, %6, %size_prods.16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.5 : int, %size_prods.18 : int):
          %1364 : int = aten::add(%i.5, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1365 : int = aten::__getitem__(%1357, %1364) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.19 : int = aten::mul(%size_prods.18, %1365) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.19)
      %1367 : bool = aten::eq(%size_prods.17, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1367) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1368 : str = aten::format(%8, %1357) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1368) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.4 : Tensor = aten::batch_norm(%out.2, %1355, %1356, %1353, %1354, %1352, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.6 : Tensor = aten::relu_(%out.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1371 : __torch__.torch.nn.modules.conv.___torch_mangle_31.Conv2d = prim::GetAttr[name="conv2"](%1338)
  %1372 : Tensor = prim::GetAttr[name="weight"](%1371)
  %1373 : Tensor? = prim::GetAttr[name="bias"](%1371)
  %out.8 : Tensor = aten::conv2d(%out.6, %1372, %1373, %1654, %1656, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1378 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_11.BatchNorm2d = prim::GetAttr[name="bn2"](%1338)
  %1379 : bool = prim::GetAttr[name="training"](%1378)
   = prim::If(%1379) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1380 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1378)
      %1381 : Tensor = aten::add(%1380, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1378, %1381)
      -> ()
    block1():
      -> ()
  %1382 : bool = prim::GetAttr[name="training"](%1378)
  %1383 : Tensor = prim::GetAttr[name="running_mean"](%1378)
  %1384 : Tensor = prim::GetAttr[name="running_var"](%1378)
  %1385 : Tensor = prim::GetAttr[name="weight"](%1378)
  %1386 : Tensor = prim::GetAttr[name="bias"](%1378)
   = prim::If(%1382) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1387 : int[] = aten::size(%out.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.20 : int = aten::__getitem__(%1387, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1389 : int = aten::len(%1387) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1390 : int = aten::sub(%1389, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.21 : int = prim::Loop(%1390, %6, %size_prods.20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.6 : int, %size_prods.22 : int):
          %1394 : int = aten::add(%i.6, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1395 : int = aten::__getitem__(%1387, %1394) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.23 : int = aten::mul(%size_prods.22, %1395) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.23)
      %1397 : bool = aten::eq(%size_prods.21, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1397) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1398 : str = aten::format(%8, %1387) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1398) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.10 : Tensor = aten::batch_norm(%out.8, %1385, %1386, %1383, %1384, %1382, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.12 : Tensor = aten::relu_(%out.10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1401 : __torch__.torch.nn.modules.conv.___torch_mangle_32.Conv2d = prim::GetAttr[name="conv3"](%1338)
  %1402 : Tensor = prim::GetAttr[name="weight"](%1401)
  %1403 : Tensor? = prim::GetAttr[name="bias"](%1401)
  %out.14 : Tensor = aten::conv2d(%out.12, %1402, %1403, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1408 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_33.BatchNorm2d = prim::GetAttr[name="bn3"](%1338)
  %1409 : bool = prim::GetAttr[name="training"](%1408)
   = prim::If(%1409) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1410 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1408)
      %1411 : Tensor = aten::add(%1410, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1408, %1411)
      -> ()
    block1():
      -> ()
  %1412 : bool = prim::GetAttr[name="training"](%1408)
  %1413 : Tensor = prim::GetAttr[name="running_mean"](%1408)
  %1414 : Tensor = prim::GetAttr[name="running_var"](%1408)
  %1415 : Tensor = prim::GetAttr[name="weight"](%1408)
  %1416 : Tensor = prim::GetAttr[name="bias"](%1408)
   = prim::If(%1412) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1417 : int[] = aten::size(%out.14) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.12 : int = aten::__getitem__(%1417, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1419 : int = aten::len(%1417) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1420 : int = aten::sub(%1419, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.13 : int = prim::Loop(%1420, %6, %size_prods.12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.4 : int, %size_prods.14 : int):
          %1424 : int = aten::add(%i.4, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1425 : int = aten::__getitem__(%1417, %1424) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.15 : int = aten::mul(%size_prods.14, %1425) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.15)
      %1427 : bool = aten::eq(%size_prods.13, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1427) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1428 : str = aten::format(%8, %1417) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1428) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.16 : Tensor = aten::batch_norm(%out.14, %1415, %1416, %1413, %1414, %1412, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %1430 : __torch__.torch.nn.modules.container.___torch_mangle_35.Sequential = prim::GetAttr[name="downsample"](%1338)
  %1431 : __torch__.torch.nn.modules.conv.___torch_mangle_34.Conv2d = prim::GetAttr[name="0"](%1430)
  %1432 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_33.BatchNorm2d = prim::GetAttr[name="1"](%1430)
  %1433 : Tensor = prim::GetAttr[name="weight"](%1431)
  %1434 : Tensor? = prim::GetAttr[name="bias"](%1431)
  %input.3 : Tensor = aten::conv2d(%x.15, %1433, %1434, %1654, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1439 : bool = prim::GetAttr[name="training"](%1432)
   = prim::If(%1439) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1440 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1432)
      %1441 : Tensor = aten::add(%1440, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1432, %1441)
      -> ()
    block1():
      -> ()
  %1442 : bool = prim::GetAttr[name="training"](%1432)
  %1443 : Tensor = prim::GetAttr[name="running_mean"](%1432)
  %1444 : Tensor = prim::GetAttr[name="running_var"](%1432)
  %1445 : Tensor = prim::GetAttr[name="weight"](%1432)
  %1446 : Tensor = prim::GetAttr[name="bias"](%1432)
   = prim::If(%1442) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1447 : int[] = aten::size(%input.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.24 : int = aten::__getitem__(%1447, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1449 : int = aten::len(%1447) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1450 : int = aten::sub(%1449, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.25 : int = prim::Loop(%1450, %6, %size_prods.24) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.7 : int, %size_prods.26 : int):
          %1454 : int = aten::add(%i.7, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1455 : int = aten::__getitem__(%1447, %1454) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.27 : int = aten::mul(%size_prods.26, %1455) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.27)
      %1457 : bool = aten::eq(%size_prods.25, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1457) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1458 : str = aten::format(%8, %1447) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1458) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %identity.1 : Tensor = aten::batch_norm(%input.3, %1445, %1446, %1443, %1444, %1442, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.18 : Tensor = aten::add_(%out.16, %identity.1, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.4 : Tensor = aten::relu_(%out.18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1462 : __torch__.torch.nn.modules.conv.___torch_mangle_37.Conv2d = prim::GetAttr[name="conv1"](%1339)
  %1463 : Tensor = prim::GetAttr[name="weight"](%1462)
  %1464 : Tensor? = prim::GetAttr[name="bias"](%1462)
  %out.28 : Tensor = aten::conv2d(%input.4, %1463, %1464, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1469 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_11.BatchNorm2d = prim::GetAttr[name="bn1"](%1339)
  %1470 : bool = prim::GetAttr[name="training"](%1469)
   = prim::If(%1470) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1471 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1469)
      %1472 : Tensor = aten::add(%1471, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1469, %1472)
      -> ()
    block1():
      -> ()
  %1473 : bool = prim::GetAttr[name="training"](%1469)
  %1474 : Tensor = prim::GetAttr[name="running_mean"](%1469)
  %1475 : Tensor = prim::GetAttr[name="running_var"](%1469)
  %1476 : Tensor = prim::GetAttr[name="weight"](%1469)
  %1477 : Tensor = prim::GetAttr[name="bias"](%1469)
   = prim::If(%1473) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1478 : int[] = aten::size(%out.28) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.28 : int = aten::__getitem__(%1478, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1480 : int = aten::len(%1478) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1481 : int = aten::sub(%1480, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.29 : int = prim::Loop(%1481, %6, %size_prods.28) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.8 : int, %size_prods.30 : int):
          %1485 : int = aten::add(%i.8, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1486 : int = aten::__getitem__(%1478, %1485) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.31 : int = aten::mul(%size_prods.30, %1486) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.31)
      %1488 : bool = aten::eq(%size_prods.29, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1488) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1489 : str = aten::format(%8, %1478) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1489) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.20 : Tensor = aten::batch_norm(%out.28, %1476, %1477, %1474, %1475, %1473, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.21 : Tensor = aten::relu_(%out.20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1492 : __torch__.torch.nn.modules.conv.___torch_mangle_38.Conv2d = prim::GetAttr[name="conv2"](%1339)
  %1493 : Tensor = prim::GetAttr[name="weight"](%1492)
  %1494 : Tensor? = prim::GetAttr[name="bias"](%1492)
  %out.22 : Tensor = aten::conv2d(%out.21, %1493, %1494, %1656, %1656, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1499 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_11.BatchNorm2d = prim::GetAttr[name="bn2"](%1339)
  %1500 : bool = prim::GetAttr[name="training"](%1499)
   = prim::If(%1500) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1501 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1499)
      %1502 : Tensor = aten::add(%1501, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1499, %1502)
      -> ()
    block1():
      -> ()
  %1503 : bool = prim::GetAttr[name="training"](%1499)
  %1504 : Tensor = prim::GetAttr[name="running_mean"](%1499)
  %1505 : Tensor = prim::GetAttr[name="running_var"](%1499)
  %1506 : Tensor = prim::GetAttr[name="weight"](%1499)
  %1507 : Tensor = prim::GetAttr[name="bias"](%1499)
   = prim::If(%1503) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1508 : int[] = aten::size(%out.22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.32 : int = aten::__getitem__(%1508, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1510 : int = aten::len(%1508) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1511 : int = aten::sub(%1510, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.33 : int = prim::Loop(%1511, %6, %size_prods.32) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.9 : int, %size_prods.34 : int):
          %1515 : int = aten::add(%i.9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1516 : int = aten::__getitem__(%1508, %1515) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.35 : int = aten::mul(%size_prods.34, %1516) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.35)
      %1518 : bool = aten::eq(%size_prods.33, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1518) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1519 : str = aten::format(%8, %1508) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1519) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.23 : Tensor = aten::batch_norm(%out.22, %1506, %1507, %1504, %1505, %1503, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.24 : Tensor = aten::relu_(%out.23) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1522 : __torch__.torch.nn.modules.conv.___torch_mangle_32.Conv2d = prim::GetAttr[name="conv3"](%1339)
  %1523 : Tensor = prim::GetAttr[name="weight"](%1522)
  %1524 : Tensor? = prim::GetAttr[name="bias"](%1522)
  %out.25 : Tensor = aten::conv2d(%out.24, %1523, %1524, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1529 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_33.BatchNorm2d = prim::GetAttr[name="bn3"](%1339)
  %1530 : bool = prim::GetAttr[name="training"](%1529)
   = prim::If(%1530) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1531 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1529)
      %1532 : Tensor = aten::add(%1531, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1529, %1532)
      -> ()
    block1():
      -> ()
  %1533 : bool = prim::GetAttr[name="training"](%1529)
  %1534 : Tensor = prim::GetAttr[name="running_mean"](%1529)
  %1535 : Tensor = prim::GetAttr[name="running_var"](%1529)
  %1536 : Tensor = prim::GetAttr[name="weight"](%1529)
  %1537 : Tensor = prim::GetAttr[name="bias"](%1529)
   = prim::If(%1533) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1538 : int[] = aten::size(%out.25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.36 : int = aten::__getitem__(%1538, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1540 : int = aten::len(%1538) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1541 : int = aten::sub(%1540, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.37 : int = prim::Loop(%1541, %6, %size_prods.36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.10 : int, %size_prods.38 : int):
          %1545 : int = aten::add(%i.10, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1546 : int = aten::__getitem__(%1538, %1545) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.39 : int = aten::mul(%size_prods.38, %1546) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.39)
      %1548 : bool = aten::eq(%size_prods.37, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1548) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1549 : str = aten::format(%8, %1538) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1549) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.26 : Tensor = aten::batch_norm(%out.25, %1536, %1537, %1534, %1535, %1533, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.27 : Tensor = aten::add_(%out.26, %input.4, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.5 : Tensor = aten::relu_(%out.27) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1553 : __torch__.torch.nn.modules.conv.___torch_mangle_37.Conv2d = prim::GetAttr[name="conv1"](%1340)
  %1554 : Tensor = prim::GetAttr[name="weight"](%1553)
  %1555 : Tensor? = prim::GetAttr[name="bias"](%1553)
  %out.1 : Tensor = aten::conv2d(%input.5, %1554, %1555, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1560 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_11.BatchNorm2d = prim::GetAttr[name="bn1"](%1340)
  %1561 : bool = prim::GetAttr[name="training"](%1560)
   = prim::If(%1561) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1562 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1560)
      %1563 : Tensor = aten::add(%1562, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1560, %1563)
      -> ()
    block1():
      -> ()
  %1564 : bool = prim::GetAttr[name="training"](%1560)
  %1565 : Tensor = prim::GetAttr[name="running_mean"](%1560)
  %1566 : Tensor = prim::GetAttr[name="running_var"](%1560)
  %1567 : Tensor = prim::GetAttr[name="weight"](%1560)
  %1568 : Tensor = prim::GetAttr[name="bias"](%1560)
   = prim::If(%1564) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1569 : int[] = aten::size(%out.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.2 : int = aten::__getitem__(%1569, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1571 : int = aten::len(%1569) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1572 : int = aten::sub(%1571, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.4 : int = prim::Loop(%1572, %6, %size_prods.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.2 : int, %size_prods.7 : int):
          %1576 : int = aten::add(%i.2, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1577 : int = aten::__getitem__(%1569, %1576) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.5 : int = aten::mul(%size_prods.7, %1577) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.5)
      %1579 : bool = aten::eq(%size_prods.4, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1579) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1580 : str = aten::format(%8, %1569) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1580) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.3 : Tensor = aten::batch_norm(%out.1, %1567, %1568, %1565, %1566, %1564, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.5 : Tensor = aten::relu_(%out.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1583 : __torch__.torch.nn.modules.conv.___torch_mangle_38.Conv2d = prim::GetAttr[name="conv2"](%1340)
  %1584 : Tensor = prim::GetAttr[name="weight"](%1583)
  %1585 : Tensor? = prim::GetAttr[name="bias"](%1583)
  %out.7 : Tensor = aten::conv2d(%out.5, %1584, %1585, %1656, %1656, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1590 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_11.BatchNorm2d = prim::GetAttr[name="bn2"](%1340)
  %1591 : bool = prim::GetAttr[name="training"](%1590)
   = prim::If(%1591) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1592 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1590)
      %1593 : Tensor = aten::add(%1592, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1590, %1593)
      -> ()
    block1():
      -> ()
  %1594 : bool = prim::GetAttr[name="training"](%1590)
  %1595 : Tensor = prim::GetAttr[name="running_mean"](%1590)
  %1596 : Tensor = prim::GetAttr[name="running_var"](%1590)
  %1597 : Tensor = prim::GetAttr[name="weight"](%1590)
  %1598 : Tensor = prim::GetAttr[name="bias"](%1590)
   = prim::If(%1594) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1599 : int[] = aten::size(%out.7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.8 : int = aten::__getitem__(%1599, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1601 : int = aten::len(%1599) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1602 : int = aten::sub(%1601, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.9 : int = prim::Loop(%1602, %6, %size_prods.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.3 : int, %size_prods.10 : int):
          %1606 : int = aten::add(%i.3, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1607 : int = aten::__getitem__(%1599, %1606) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.11 : int = aten::mul(%size_prods.10, %1607) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.11)
      %1609 : bool = aten::eq(%size_prods.9, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1609) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1610 : str = aten::format(%8, %1599) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1610) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.9 : Tensor = aten::batch_norm(%out.7, %1597, %1598, %1595, %1596, %1594, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.11 : Tensor = aten::relu_(%out.9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1613 : __torch__.torch.nn.modules.conv.___torch_mangle_32.Conv2d = prim::GetAttr[name="conv3"](%1340)
  %1614 : Tensor = prim::GetAttr[name="weight"](%1613)
  %1615 : Tensor? = prim::GetAttr[name="bias"](%1613)
  %out.13 : Tensor = aten::conv2d(%out.11, %1614, %1615, %1656, %1662, %1656, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1620 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_33.BatchNorm2d = prim::GetAttr[name="bn3"](%1340)
  %1621 : bool = prim::GetAttr[name="training"](%1620)
   = prim::If(%1621) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1622 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1620)
      %1623 : Tensor = aten::add(%1622, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1620, %1623)
      -> ()
    block1():
      -> ()
  %1624 : bool = prim::GetAttr[name="training"](%1620)
  %1625 : Tensor = prim::GetAttr[name="running_mean"](%1620)
  %1626 : Tensor = prim::GetAttr[name="running_var"](%1620)
  %1627 : Tensor = prim::GetAttr[name="weight"](%1620)
  %1628 : Tensor = prim::GetAttr[name="bias"](%1620)
   = prim::If(%1624) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1629 : int[] = aten::size(%out.13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.1 : int = aten::__getitem__(%1629, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1631 : int = aten::len(%1629) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1632 : int = aten::sub(%1631, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods : int = prim::Loop(%1632, %6, %size_prods.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.1 : int, %size_prods.6 : int):
          %1636 : int = aten::add(%i.1, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1637 : int = aten::__getitem__(%1629, %1636) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.3 : int = aten::mul(%size_prods.6, %1637) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.3)
      %1639 : bool = aten::eq(%size_prods, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1639) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1640 : str = aten::format(%8, %1629) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1640) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.15 : Tensor = aten::batch_norm(%out.13, %1627, %1628, %1625, %1626, %1624, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.17 : Tensor = aten::add_(%out.15, %input.5, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %x.17 : Tensor = aten::relu_(%out.17) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1645 : int[] = aten::size(%x.17) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1036:51
  %1646 : int = aten::len(%1645) # <string>:5:9
  %1647 : bool = aten::gt(%1646, %5) # <string>:5:9
   = prim::If(%1647) # <string>:5:2
    block0():
      -> ()
    block1():
       = prim::RaiseException(%12) # <string>:5:2
      -> ()
  %x.19 : Tensor = aten::adaptive_avg_pool2d(%x.17, %1656) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
  %x.21 : Tensor = aten::flatten(%x.19, %3, %2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:243:12
  %1650 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="fc"](%self)
  %1651 : Tensor = prim::GetAttr[name="weight"](%1650)
  %1652 : Tensor = prim::GetAttr[name="bias"](%1650)
  %x.23 : Tensor = aten::linear(%x.21, %1651, %1652) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
  return (%x.23)

