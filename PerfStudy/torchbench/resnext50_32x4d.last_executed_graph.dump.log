Dump Graph IR for resnext50_32x4d using example inputs:
graph(%self : __torch__.torchvision.models.resnet.ResNet,
      %x.1 : Tensor):
  %1663 : int[] = prim::Constant[value=[0, 0]]()
  %1657 : int[] = prim::Constant[value=[1, 1]]()
  %1656 : int[] = prim::Constant[value=[3, 3]]()
  %1655 : int[] = prim::Constant[value=[2, 2]]()
  %13 : str = prim::Constant[value="AssertionError: "]()
  %12 : int = prim::Constant[value=32]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:396:53
  %11 : bool = prim::Constant[value=0]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/pooling.py:163:57
  %10 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:140:77
  %9 : float = prim::Constant[value=0.10000000000000001]()
  %8 : str = prim::Constant[value="Expected more than 1 value per channel when training, got input size {}"]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
  %7 : int = prim::Constant[value=0]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:22
  %6 : bool = prim::Constant[value=1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2147:81
  %5 : int = prim::Constant[value=2]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:45
  %3 : int = prim::Constant[value=1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:243:29
  %2 : int = prim::Constant[value=-1]()
  %14 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name="conv1"](%self)
  %15 : Tensor = prim::GetAttr[name="weight"](%14)
  %16 : Tensor? = prim::GetAttr[name="bias"](%14)
  %x.3 : Tensor = aten::conv2d(%x.1, %15, %16, %1655, %1656, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %21 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="bn1"](%self)
  %22 : bool = prim::GetAttr[name="training"](%21)
   = prim::If(%22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %23 : Tensor = prim::GetAttr[name="num_batches_tracked"](%21)
      %24 : Tensor = aten::add(%23, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%21, %24)
      -> ()
    block1():
      -> ()
  %25 : bool = prim::GetAttr[name="training"](%21)
  %26 : Tensor = prim::GetAttr[name="running_mean"](%21)
  %27 : Tensor = prim::GetAttr[name="running_var"](%21)
  %28 : Tensor = prim::GetAttr[name="weight"](%21)
  %29 : Tensor = prim::GetAttr[name="bias"](%21)
   = prim::If(%25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %30 : int[] = aten::size(%x.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.156 : int = aten::__getitem__(%30, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %32 : int = aten::len(%30) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %33 : int = aten::sub(%32, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.157 : int = prim::Loop(%33, %6, %size_prods.156) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.40 : int, %size_prods.158 : int):
          %37 : int = aten::add(%i.40, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %38 : int = aten::__getitem__(%30, %37) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.159 : int = aten::mul(%size_prods.158, %38) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.159)
      %40 : bool = aten::eq(%size_prods.157, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %41 : str = aten::format(%8, %30) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%41) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %x.5 : Tensor = aten::batch_norm(%x.3, %28, %29, %26, %27, %25, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %x.7 : Tensor = aten::relu_(%x.5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %x.9 : Tensor = aten::max_pool2d(%x.7, %1656, %1655, %1657, %1657, %11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:659:11
  %49 : __torch__.torch.nn.modules.container.___torch_mangle_8.Sequential = prim::GetAttr[name="layer1"](%self)
  %50 : __torch__.torchvision.models.resnet.Bottleneck = prim::GetAttr[name="0"](%49)
  %51 : __torch__.torchvision.models.resnet.___torch_mangle_7.Bottleneck = prim::GetAttr[name="1"](%49)
  %52 : __torch__.torchvision.models.resnet.___torch_mangle_7.Bottleneck = prim::GetAttr[name="2"](%49)
  %53 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="conv1"](%50)
  %54 : Tensor = prim::GetAttr[name="weight"](%53)
  %55 : Tensor? = prim::GetAttr[name="bias"](%53)
  %out.19 : Tensor = aten::conv2d(%x.9, %54, %55, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %60 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="bn1"](%50)
  %61 : bool = prim::GetAttr[name="training"](%60)
   = prim::If(%61) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %62 : Tensor = prim::GetAttr[name="num_batches_tracked"](%60)
      %63 : Tensor = aten::add(%62, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%60, %63)
      -> ()
    block1():
      -> ()
  %64 : bool = prim::GetAttr[name="training"](%60)
  %65 : Tensor = prim::GetAttr[name="running_mean"](%60)
  %66 : Tensor = prim::GetAttr[name="running_var"](%60)
  %67 : Tensor = prim::GetAttr[name="weight"](%60)
  %68 : Tensor = prim::GetAttr[name="bias"](%60)
   = prim::If(%64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %69 : int[] = aten::size(%out.19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.76 : int = aten::__getitem__(%69, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %71 : int = aten::len(%69) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %72 : int = aten::sub(%71, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.77 : int = prim::Loop(%72, %6, %size_prods.76) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.20 : int, %size_prods.78 : int):
          %76 : int = aten::add(%i.20, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %77 : int = aten::__getitem__(%69, %76) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.79 : int = aten::mul(%size_prods.78, %77) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.79)
      %79 : bool = aten::eq(%size_prods.77, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%79) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %80 : str = aten::format(%8, %69) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%80) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.101 : Tensor = aten::batch_norm(%out.19, %67, %68, %65, %66, %64, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.102 : Tensor = aten::relu_(%out.101) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %83 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%50)
  %84 : Tensor = prim::GetAttr[name="weight"](%83)
  %85 : Tensor? = prim::GetAttr[name="bias"](%83)
  %out.103 : Tensor = aten::conv2d(%out.102, %84, %85, %1657, %1657, %1657, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %90 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="bn2"](%50)
  %91 : bool = prim::GetAttr[name="training"](%90)
   = prim::If(%91) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %92 : Tensor = prim::GetAttr[name="num_batches_tracked"](%90)
      %93 : Tensor = aten::add(%92, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%90, %93)
      -> ()
    block1():
      -> ()
  %94 : bool = prim::GetAttr[name="training"](%90)
  %95 : Tensor = prim::GetAttr[name="running_mean"](%90)
  %96 : Tensor = prim::GetAttr[name="running_var"](%90)
  %97 : Tensor = prim::GetAttr[name="weight"](%90)
  %98 : Tensor = prim::GetAttr[name="bias"](%90)
   = prim::If(%94) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %99 : int[] = aten::size(%out.103) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.80 : int = aten::__getitem__(%99, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %101 : int = aten::len(%99) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %102 : int = aten::sub(%101, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.81 : int = prim::Loop(%102, %6, %size_prods.80) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.21 : int, %size_prods.82 : int):
          %106 : int = aten::add(%i.21, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %107 : int = aten::__getitem__(%99, %106) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.83 : int = aten::mul(%size_prods.82, %107) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.83)
      %109 : bool = aten::eq(%size_prods.81, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%109) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %110 : str = aten::format(%8, %99) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%110) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.104 : Tensor = aten::batch_norm(%out.103, %97, %98, %95, %96, %94, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.105 : Tensor = aten::relu_(%out.104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %113 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv2d = prim::GetAttr[name="conv3"](%50)
  %114 : Tensor = prim::GetAttr[name="weight"](%113)
  %115 : Tensor? = prim::GetAttr[name="bias"](%113)
  %out.106 : Tensor = aten::conv2d(%out.105, %114, %115, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %120 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_4.BatchNorm2d = prim::GetAttr[name="bn3"](%50)
  %121 : bool = prim::GetAttr[name="training"](%120)
   = prim::If(%121) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %122 : Tensor = prim::GetAttr[name="num_batches_tracked"](%120)
      %123 : Tensor = aten::add(%122, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%120, %123)
      -> ()
    block1():
      -> ()
  %124 : bool = prim::GetAttr[name="training"](%120)
  %125 : Tensor = prim::GetAttr[name="running_mean"](%120)
  %126 : Tensor = prim::GetAttr[name="running_var"](%120)
  %127 : Tensor = prim::GetAttr[name="weight"](%120)
  %128 : Tensor = prim::GetAttr[name="bias"](%120)
   = prim::If(%124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %129 : int[] = aten::size(%out.106) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.136 : int = aten::__getitem__(%129, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %131 : int = aten::len(%129) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %132 : int = aten::sub(%131, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.137 : int = prim::Loop(%132, %6, %size_prods.136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.35 : int, %size_prods.138 : int):
          %136 : int = aten::add(%i.35, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %137 : int = aten::__getitem__(%129, %136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.139 : int = aten::mul(%size_prods.138, %137) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.139)
      %139 : bool = aten::eq(%size_prods.137, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%139) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %140 : str = aten::format(%8, %129) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.107 : Tensor = aten::batch_norm(%out.106, %127, %128, %125, %126, %124, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %142 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="downsample"](%50)
  %143 : __torch__.torch.nn.modules.conv.___torch_mangle_5.Conv2d = prim::GetAttr[name="0"](%142)
  %144 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_4.BatchNorm2d = prim::GetAttr[name="1"](%142)
  %145 : Tensor = prim::GetAttr[name="weight"](%143)
  %146 : Tensor? = prim::GetAttr[name="bias"](%143)
  %input.6 : Tensor = aten::conv2d(%x.9, %145, %146, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %151 : bool = prim::GetAttr[name="training"](%144)
   = prim::If(%151) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %152 : Tensor = prim::GetAttr[name="num_batches_tracked"](%144)
      %153 : Tensor = aten::add(%152, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%144, %153)
      -> ()
    block1():
      -> ()
  %154 : bool = prim::GetAttr[name="training"](%144)
  %155 : Tensor = prim::GetAttr[name="running_mean"](%144)
  %156 : Tensor = prim::GetAttr[name="running_var"](%144)
  %157 : Tensor = prim::GetAttr[name="weight"](%144)
  %158 : Tensor = prim::GetAttr[name="bias"](%144)
   = prim::If(%154) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %159 : int[] = aten::size(%input.6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.140 : int = aten::__getitem__(%159, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %161 : int = aten::len(%159) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %162 : int = aten::sub(%161, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.141 : int = prim::Loop(%162, %6, %size_prods.140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.36 : int, %size_prods.142 : int):
          %166 : int = aten::add(%i.36, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %167 : int = aten::__getitem__(%159, %166) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.143 : int = aten::mul(%size_prods.142, %167) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.143)
      %169 : bool = aten::eq(%size_prods.141, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%169) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %170 : str = aten::format(%8, %159) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%170) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %identity.2 : Tensor = aten::batch_norm(%input.6, %157, %158, %155, %156, %154, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.108 : Tensor = aten::add_(%out.107, %identity.2, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.10 : Tensor = aten::relu_(%out.108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %174 : __torch__.torch.nn.modules.conv.___torch_mangle_6.Conv2d = prim::GetAttr[name="conv1"](%51)
  %175 : Tensor = prim::GetAttr[name="weight"](%174)
  %176 : Tensor? = prim::GetAttr[name="bias"](%174)
  %out.91 : Tensor = aten::conv2d(%input.10, %175, %176, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %181 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="bn1"](%51)
  %182 : bool = prim::GetAttr[name="training"](%181)
   = prim::If(%182) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %183 : Tensor = prim::GetAttr[name="num_batches_tracked"](%181)
      %184 : Tensor = aten::add(%183, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%181, %184)
      -> ()
    block1():
      -> ()
  %185 : bool = prim::GetAttr[name="training"](%181)
  %186 : Tensor = prim::GetAttr[name="running_mean"](%181)
  %187 : Tensor = prim::GetAttr[name="running_var"](%181)
  %188 : Tensor = prim::GetAttr[name="weight"](%181)
  %189 : Tensor = prim::GetAttr[name="bias"](%181)
   = prim::If(%185) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %190 : int[] = aten::size(%out.91) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.144 : int = aten::__getitem__(%190, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %192 : int = aten::len(%190) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %193 : int = aten::sub(%192, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.145 : int = prim::Loop(%193, %6, %size_prods.144) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.37 : int, %size_prods.146 : int):
          %197 : int = aten::add(%i.37, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %198 : int = aten::__getitem__(%190, %197) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.147 : int = aten::mul(%size_prods.146, %198) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.147)
      %200 : bool = aten::eq(%size_prods.145, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%200) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %201 : str = aten::format(%8, %190) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%201) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.92 : Tensor = aten::batch_norm(%out.91, %188, %189, %186, %187, %185, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.93 : Tensor = aten::relu_(%out.92) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %204 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%51)
  %205 : Tensor = prim::GetAttr[name="weight"](%204)
  %206 : Tensor? = prim::GetAttr[name="bias"](%204)
  %out.94 : Tensor = aten::conv2d(%out.93, %205, %206, %1657, %1657, %1657, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %211 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="bn2"](%51)
  %212 : bool = prim::GetAttr[name="training"](%211)
   = prim::If(%212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %213 : Tensor = prim::GetAttr[name="num_batches_tracked"](%211)
      %214 : Tensor = aten::add(%213, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%211, %214)
      -> ()
    block1():
      -> ()
  %215 : bool = prim::GetAttr[name="training"](%211)
  %216 : Tensor = prim::GetAttr[name="running_mean"](%211)
  %217 : Tensor = prim::GetAttr[name="running_var"](%211)
  %218 : Tensor = prim::GetAttr[name="weight"](%211)
  %219 : Tensor = prim::GetAttr[name="bias"](%211)
   = prim::If(%215) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %220 : int[] = aten::size(%out.94) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.148 : int = aten::__getitem__(%220, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %222 : int = aten::len(%220) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %223 : int = aten::sub(%222, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.149 : int = prim::Loop(%223, %6, %size_prods.148) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.38 : int, %size_prods.150 : int):
          %227 : int = aten::add(%i.38, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %228 : int = aten::__getitem__(%220, %227) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.151 : int = aten::mul(%size_prods.150, %228) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.151)
      %230 : bool = aten::eq(%size_prods.149, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%230) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %231 : str = aten::format(%8, %220) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%231) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.95 : Tensor = aten::batch_norm(%out.94, %218, %219, %216, %217, %215, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.96 : Tensor = aten::relu_(%out.95) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %234 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv2d = prim::GetAttr[name="conv3"](%51)
  %235 : Tensor = prim::GetAttr[name="weight"](%234)
  %236 : Tensor? = prim::GetAttr[name="bias"](%234)
  %out.97 : Tensor = aten::conv2d(%out.96, %235, %236, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %241 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_4.BatchNorm2d = prim::GetAttr[name="bn3"](%51)
  %242 : bool = prim::GetAttr[name="training"](%241)
   = prim::If(%242) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %243 : Tensor = prim::GetAttr[name="num_batches_tracked"](%241)
      %244 : Tensor = aten::add(%243, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%241, %244)
      -> ()
    block1():
      -> ()
  %245 : bool = prim::GetAttr[name="training"](%241)
  %246 : Tensor = prim::GetAttr[name="running_mean"](%241)
  %247 : Tensor = prim::GetAttr[name="running_var"](%241)
  %248 : Tensor = prim::GetAttr[name="weight"](%241)
  %249 : Tensor = prim::GetAttr[name="bias"](%241)
   = prim::If(%245) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %250 : int[] = aten::size(%out.97) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.152 : int = aten::__getitem__(%250, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %252 : int = aten::len(%250) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %253 : int = aten::sub(%252, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.153 : int = prim::Loop(%253, %6, %size_prods.152) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.39 : int, %size_prods.154 : int):
          %257 : int = aten::add(%i.39, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %258 : int = aten::__getitem__(%250, %257) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.155 : int = aten::mul(%size_prods.154, %258) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.155)
      %260 : bool = aten::eq(%size_prods.153, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%260) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %261 : str = aten::format(%8, %250) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%261) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.98 : Tensor = aten::batch_norm(%out.97, %248, %249, %246, %247, %245, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.99 : Tensor = aten::add_(%out.98, %input.10, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.8 : Tensor = aten::relu_(%out.99) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %265 : __torch__.torch.nn.modules.conv.___torch_mangle_6.Conv2d = prim::GetAttr[name="conv1"](%52)
  %266 : Tensor = prim::GetAttr[name="weight"](%265)
  %267 : Tensor? = prim::GetAttr[name="bias"](%265)
  %out.100 : Tensor = aten::conv2d(%input.8, %266, %267, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %272 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="bn1"](%52)
  %273 : bool = prim::GetAttr[name="training"](%272)
   = prim::If(%273) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %274 : Tensor = prim::GetAttr[name="num_batches_tracked"](%272)
      %275 : Tensor = aten::add(%274, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%272, %275)
      -> ()
    block1():
      -> ()
  %276 : bool = prim::GetAttr[name="training"](%272)
  %277 : Tensor = prim::GetAttr[name="running_mean"](%272)
  %278 : Tensor = prim::GetAttr[name="running_var"](%272)
  %279 : Tensor = prim::GetAttr[name="weight"](%272)
  %280 : Tensor = prim::GetAttr[name="bias"](%272)
   = prim::If(%276) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %281 : int[] = aten::size(%out.100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.84 : int = aten::__getitem__(%281, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %283 : int = aten::len(%281) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %284 : int = aten::sub(%283, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.85 : int = prim::Loop(%284, %6, %size_prods.84) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.22 : int, %size_prods.86 : int):
          %288 : int = aten::add(%i.22, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %289 : int = aten::__getitem__(%281, %288) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.87 : int = aten::mul(%size_prods.86, %289) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.87)
      %291 : bool = aten::eq(%size_prods.85, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%291) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %292 : str = aten::format(%8, %281) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%292) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.56 : Tensor = aten::batch_norm(%out.100, %279, %280, %277, %278, %276, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.57 : Tensor = aten::relu_(%out.56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %295 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%52)
  %296 : Tensor = prim::GetAttr[name="weight"](%295)
  %297 : Tensor? = prim::GetAttr[name="bias"](%295)
  %out.58 : Tensor = aten::conv2d(%out.57, %296, %297, %1657, %1657, %1657, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %302 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="bn2"](%52)
  %303 : bool = prim::GetAttr[name="training"](%302)
   = prim::If(%303) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %304 : Tensor = prim::GetAttr[name="num_batches_tracked"](%302)
      %305 : Tensor = aten::add(%304, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%302, %305)
      -> ()
    block1():
      -> ()
  %306 : bool = prim::GetAttr[name="training"](%302)
  %307 : Tensor = prim::GetAttr[name="running_mean"](%302)
  %308 : Tensor = prim::GetAttr[name="running_var"](%302)
  %309 : Tensor = prim::GetAttr[name="weight"](%302)
  %310 : Tensor = prim::GetAttr[name="bias"](%302)
   = prim::If(%306) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %311 : int[] = aten::size(%out.58) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.88 : int = aten::__getitem__(%311, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %313 : int = aten::len(%311) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %314 : int = aten::sub(%313, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.89 : int = prim::Loop(%314, %6, %size_prods.88) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.23 : int, %size_prods.90 : int):
          %318 : int = aten::add(%i.23, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %319 : int = aten::__getitem__(%311, %318) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.91 : int = aten::mul(%size_prods.90, %319) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.91)
      %321 : bool = aten::eq(%size_prods.89, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%321) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %322 : str = aten::format(%8, %311) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%322) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.59 : Tensor = aten::batch_norm(%out.58, %309, %310, %307, %308, %306, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.60 : Tensor = aten::relu_(%out.59) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %325 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv2d = prim::GetAttr[name="conv3"](%52)
  %326 : Tensor = prim::GetAttr[name="weight"](%325)
  %327 : Tensor? = prim::GetAttr[name="bias"](%325)
  %out.61 : Tensor = aten::conv2d(%out.60, %326, %327, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %332 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_4.BatchNorm2d = prim::GetAttr[name="bn3"](%52)
  %333 : bool = prim::GetAttr[name="training"](%332)
   = prim::If(%333) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %334 : Tensor = prim::GetAttr[name="num_batches_tracked"](%332)
      %335 : Tensor = aten::add(%334, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%332, %335)
      -> ()
    block1():
      -> ()
  %336 : bool = prim::GetAttr[name="training"](%332)
  %337 : Tensor = prim::GetAttr[name="running_mean"](%332)
  %338 : Tensor = prim::GetAttr[name="running_var"](%332)
  %339 : Tensor = prim::GetAttr[name="weight"](%332)
  %340 : Tensor = prim::GetAttr[name="bias"](%332)
   = prim::If(%336) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %341 : int[] = aten::size(%out.61) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.92 : int = aten::__getitem__(%341, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %343 : int = aten::len(%341) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %344 : int = aten::sub(%343, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.93 : int = prim::Loop(%344, %6, %size_prods.92) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.24 : int, %size_prods.94 : int):
          %348 : int = aten::add(%i.24, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %349 : int = aten::__getitem__(%341, %348) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.95 : int = aten::mul(%size_prods.94, %349) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.95)
      %351 : bool = aten::eq(%size_prods.93, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%351) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %352 : str = aten::format(%8, %341) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%352) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.62 : Tensor = aten::batch_norm(%out.61, %339, %340, %337, %338, %336, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.63 : Tensor = aten::add_(%out.62, %input.8, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %x.11 : Tensor = aten::relu_(%out.63) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %356 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="layer2"](%self)
  %357 : __torch__.torchvision.models.resnet.___torch_mangle_15.Bottleneck = prim::GetAttr[name="0"](%356)
  %358 : __torch__.torchvision.models.resnet.___torch_mangle_18.Bottleneck = prim::GetAttr[name="1"](%356)
  %359 : __torch__.torchvision.models.resnet.___torch_mangle_18.Bottleneck = prim::GetAttr[name="2"](%356)
  %360 : __torch__.torchvision.models.resnet.___torch_mangle_18.Bottleneck = prim::GetAttr[name="3"](%356)
  %361 : __torch__.torch.nn.modules.conv.___torch_mangle_9.Conv2d = prim::GetAttr[name="conv1"](%357)
  %362 : Tensor = prim::GetAttr[name="weight"](%361)
  %363 : Tensor? = prim::GetAttr[name="bias"](%361)
  %out.64 : Tensor = aten::conv2d(%x.11, %362, %363, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %368 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_4.BatchNorm2d = prim::GetAttr[name="bn1"](%357)
  %369 : bool = prim::GetAttr[name="training"](%368)
   = prim::If(%369) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %370 : Tensor = prim::GetAttr[name="num_batches_tracked"](%368)
      %371 : Tensor = aten::add(%370, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%368, %371)
      -> ()
    block1():
      -> ()
  %372 : bool = prim::GetAttr[name="training"](%368)
  %373 : Tensor = prim::GetAttr[name="running_mean"](%368)
  %374 : Tensor = prim::GetAttr[name="running_var"](%368)
  %375 : Tensor = prim::GetAttr[name="weight"](%368)
  %376 : Tensor = prim::GetAttr[name="bias"](%368)
   = prim::If(%372) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %377 : int[] = aten::size(%out.64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.96 : int = aten::__getitem__(%377, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %379 : int = aten::len(%377) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %380 : int = aten::sub(%379, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.97 : int = prim::Loop(%380, %6, %size_prods.96) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.25 : int, %size_prods.98 : int):
          %384 : int = aten::add(%i.25, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %385 : int = aten::__getitem__(%377, %384) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.99 : int = aten::mul(%size_prods.98, %385) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.99)
      %387 : bool = aten::eq(%size_prods.97, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%387) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %388 : str = aten::format(%8, %377) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%388) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.65 : Tensor = aten::batch_norm(%out.64, %375, %376, %373, %374, %372, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.66 : Tensor = aten::relu_(%out.65) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %391 : __torch__.torch.nn.modules.conv.___torch_mangle_10.Conv2d = prim::GetAttr[name="conv2"](%357)
  %392 : Tensor = prim::GetAttr[name="weight"](%391)
  %393 : Tensor? = prim::GetAttr[name="bias"](%391)
  %out.67 : Tensor = aten::conv2d(%out.66, %392, %393, %1655, %1657, %1657, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %398 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_4.BatchNorm2d = prim::GetAttr[name="bn2"](%357)
  %399 : bool = prim::GetAttr[name="training"](%398)
   = prim::If(%399) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %400 : Tensor = prim::GetAttr[name="num_batches_tracked"](%398)
      %401 : Tensor = aten::add(%400, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%398, %401)
      -> ()
    block1():
      -> ()
  %402 : bool = prim::GetAttr[name="training"](%398)
  %403 : Tensor = prim::GetAttr[name="running_mean"](%398)
  %404 : Tensor = prim::GetAttr[name="running_var"](%398)
  %405 : Tensor = prim::GetAttr[name="weight"](%398)
  %406 : Tensor = prim::GetAttr[name="bias"](%398)
   = prim::If(%402) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %407 : int[] = aten::size(%out.67) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.100 : int = aten::__getitem__(%407, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %409 : int = aten::len(%407) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %410 : int = aten::sub(%409, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.101 : int = prim::Loop(%410, %6, %size_prods.100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.26 : int, %size_prods.102 : int):
          %414 : int = aten::add(%i.26, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %415 : int = aten::__getitem__(%407, %414) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.103 : int = aten::mul(%size_prods.102, %415) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.103)
      %417 : bool = aten::eq(%size_prods.101, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%417) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %418 : str = aten::format(%8, %407) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%418) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.68 : Tensor = aten::batch_norm(%out.67, %405, %406, %403, %404, %402, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.69 : Tensor = aten::relu_(%out.68) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %421 : __torch__.torch.nn.modules.conv.___torch_mangle_11.Conv2d = prim::GetAttr[name="conv3"](%357)
  %422 : Tensor = prim::GetAttr[name="weight"](%421)
  %423 : Tensor? = prim::GetAttr[name="bias"](%421)
  %out.70 : Tensor = aten::conv2d(%out.69, %422, %423, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %428 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_12.BatchNorm2d = prim::GetAttr[name="bn3"](%357)
  %429 : bool = prim::GetAttr[name="training"](%428)
   = prim::If(%429) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %430 : Tensor = prim::GetAttr[name="num_batches_tracked"](%428)
      %431 : Tensor = aten::add(%430, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%428, %431)
      -> ()
    block1():
      -> ()
  %432 : bool = prim::GetAttr[name="training"](%428)
  %433 : Tensor = prim::GetAttr[name="running_mean"](%428)
  %434 : Tensor = prim::GetAttr[name="running_var"](%428)
  %435 : Tensor = prim::GetAttr[name="weight"](%428)
  %436 : Tensor = prim::GetAttr[name="bias"](%428)
   = prim::If(%432) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %437 : int[] = aten::size(%out.70) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.104 : int = aten::__getitem__(%437, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %439 : int = aten::len(%437) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %440 : int = aten::sub(%439, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.105 : int = prim::Loop(%440, %6, %size_prods.104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.27 : int, %size_prods.106 : int):
          %444 : int = aten::add(%i.27, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %445 : int = aten::__getitem__(%437, %444) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.107 : int = aten::mul(%size_prods.106, %445) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.107)
      %447 : bool = aten::eq(%size_prods.105, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%447) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %448 : str = aten::format(%8, %437) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%448) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.71 : Tensor = aten::batch_norm(%out.70, %435, %436, %433, %434, %432, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %450 : __torch__.torch.nn.modules.container.___torch_mangle_14.Sequential = prim::GetAttr[name="downsample"](%357)
  %451 : __torch__.torch.nn.modules.conv.___torch_mangle_13.Conv2d = prim::GetAttr[name="0"](%450)
  %452 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_12.BatchNorm2d = prim::GetAttr[name="1"](%450)
  %453 : Tensor = prim::GetAttr[name="weight"](%451)
  %454 : Tensor? = prim::GetAttr[name="bias"](%451)
  %input.14 : Tensor = aten::conv2d(%x.11, %453, %454, %1655, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %459 : bool = prim::GetAttr[name="training"](%452)
   = prim::If(%459) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %460 : Tensor = prim::GetAttr[name="num_batches_tracked"](%452)
      %461 : Tensor = aten::add(%460, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%452, %461)
      -> ()
    block1():
      -> ()
  %462 : bool = prim::GetAttr[name="training"](%452)
  %463 : Tensor = prim::GetAttr[name="running_mean"](%452)
  %464 : Tensor = prim::GetAttr[name="running_var"](%452)
  %465 : Tensor = prim::GetAttr[name="weight"](%452)
  %466 : Tensor = prim::GetAttr[name="bias"](%452)
   = prim::If(%462) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %467 : int[] = aten::size(%input.14) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.108 : int = aten::__getitem__(%467, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %469 : int = aten::len(%467) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %470 : int = aten::sub(%469, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.109 : int = prim::Loop(%470, %6, %size_prods.108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.28 : int, %size_prods.110 : int):
          %474 : int = aten::add(%i.28, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %475 : int = aten::__getitem__(%467, %474) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.111 : int = aten::mul(%size_prods.110, %475) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.111)
      %477 : bool = aten::eq(%size_prods.109, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%477) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %478 : str = aten::format(%8, %467) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%478) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %identity.3 : Tensor = aten::batch_norm(%input.14, %465, %466, %463, %464, %462, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.72 : Tensor = aten::add_(%out.71, %identity.3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.15 : Tensor = aten::relu_(%out.72) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %482 : __torch__.torch.nn.modules.conv.___torch_mangle_16.Conv2d = prim::GetAttr[name="conv1"](%358)
  %483 : Tensor = prim::GetAttr[name="weight"](%482)
  %484 : Tensor? = prim::GetAttr[name="bias"](%482)
  %out.73 : Tensor = aten::conv2d(%input.15, %483, %484, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %489 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_4.BatchNorm2d = prim::GetAttr[name="bn1"](%358)
  %490 : bool = prim::GetAttr[name="training"](%489)
   = prim::If(%490) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %491 : Tensor = prim::GetAttr[name="num_batches_tracked"](%489)
      %492 : Tensor = aten::add(%491, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%489, %492)
      -> ()
    block1():
      -> ()
  %493 : bool = prim::GetAttr[name="training"](%489)
  %494 : Tensor = prim::GetAttr[name="running_mean"](%489)
  %495 : Tensor = prim::GetAttr[name="running_var"](%489)
  %496 : Tensor = prim::GetAttr[name="weight"](%489)
  %497 : Tensor = prim::GetAttr[name="bias"](%489)
   = prim::If(%493) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %498 : int[] = aten::size(%out.73) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.112 : int = aten::__getitem__(%498, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %500 : int = aten::len(%498) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %501 : int = aten::sub(%500, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.113 : int = prim::Loop(%501, %6, %size_prods.112) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.29 : int, %size_prods.114 : int):
          %505 : int = aten::add(%i.29, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %506 : int = aten::__getitem__(%498, %505) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.115 : int = aten::mul(%size_prods.114, %506) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.115)
      %508 : bool = aten::eq(%size_prods.113, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%508) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %509 : str = aten::format(%8, %498) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%509) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.74 : Tensor = aten::batch_norm(%out.73, %496, %497, %494, %495, %493, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.75 : Tensor = aten::relu_(%out.74) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %512 : __torch__.torch.nn.modules.conv.___torch_mangle_17.Conv2d = prim::GetAttr[name="conv2"](%358)
  %513 : Tensor = prim::GetAttr[name="weight"](%512)
  %514 : Tensor? = prim::GetAttr[name="bias"](%512)
  %out.76 : Tensor = aten::conv2d(%out.75, %513, %514, %1657, %1657, %1657, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %519 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_4.BatchNorm2d = prim::GetAttr[name="bn2"](%358)
  %520 : bool = prim::GetAttr[name="training"](%519)
   = prim::If(%520) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %521 : Tensor = prim::GetAttr[name="num_batches_tracked"](%519)
      %522 : Tensor = aten::add(%521, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%519, %522)
      -> ()
    block1():
      -> ()
  %523 : bool = prim::GetAttr[name="training"](%519)
  %524 : Tensor = prim::GetAttr[name="running_mean"](%519)
  %525 : Tensor = prim::GetAttr[name="running_var"](%519)
  %526 : Tensor = prim::GetAttr[name="weight"](%519)
  %527 : Tensor = prim::GetAttr[name="bias"](%519)
   = prim::If(%523) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %528 : int[] = aten::size(%out.76) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.116 : int = aten::__getitem__(%528, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %530 : int = aten::len(%528) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %531 : int = aten::sub(%530, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.117 : int = prim::Loop(%531, %6, %size_prods.116) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.30 : int, %size_prods.118 : int):
          %535 : int = aten::add(%i.30, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %536 : int = aten::__getitem__(%528, %535) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.119 : int = aten::mul(%size_prods.118, %536) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.119)
      %538 : bool = aten::eq(%size_prods.117, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%538) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %539 : str = aten::format(%8, %528) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%539) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.77 : Tensor = aten::batch_norm(%out.76, %526, %527, %524, %525, %523, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.78 : Tensor = aten::relu_(%out.77) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %542 : __torch__.torch.nn.modules.conv.___torch_mangle_11.Conv2d = prim::GetAttr[name="conv3"](%358)
  %543 : Tensor = prim::GetAttr[name="weight"](%542)
  %544 : Tensor? = prim::GetAttr[name="bias"](%542)
  %out.79 : Tensor = aten::conv2d(%out.78, %543, %544, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %549 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_12.BatchNorm2d = prim::GetAttr[name="bn3"](%358)
  %550 : bool = prim::GetAttr[name="training"](%549)
   = prim::If(%550) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %551 : Tensor = prim::GetAttr[name="num_batches_tracked"](%549)
      %552 : Tensor = aten::add(%551, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%549, %552)
      -> ()
    block1():
      -> ()
  %553 : bool = prim::GetAttr[name="training"](%549)
  %554 : Tensor = prim::GetAttr[name="running_mean"](%549)
  %555 : Tensor = prim::GetAttr[name="running_var"](%549)
  %556 : Tensor = prim::GetAttr[name="weight"](%549)
  %557 : Tensor = prim::GetAttr[name="bias"](%549)
   = prim::If(%553) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %558 : int[] = aten::size(%out.79) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.120 : int = aten::__getitem__(%558, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %560 : int = aten::len(%558) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %561 : int = aten::sub(%560, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.121 : int = prim::Loop(%561, %6, %size_prods.120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.31 : int, %size_prods.122 : int):
          %565 : int = aten::add(%i.31, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %566 : int = aten::__getitem__(%558, %565) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.123 : int = aten::mul(%size_prods.122, %566) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.123)
      %568 : bool = aten::eq(%size_prods.121, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%568) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %569 : str = aten::format(%8, %558) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%569) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.80 : Tensor = aten::batch_norm(%out.79, %556, %557, %554, %555, %553, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.81 : Tensor = aten::add_(%out.80, %input.15, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.12 : Tensor = aten::relu_(%out.81) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %573 : __torch__.torch.nn.modules.conv.___torch_mangle_16.Conv2d = prim::GetAttr[name="conv1"](%359)
  %574 : Tensor = prim::GetAttr[name="weight"](%573)
  %575 : Tensor? = prim::GetAttr[name="bias"](%573)
  %out.82 : Tensor = aten::conv2d(%input.12, %574, %575, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %580 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_4.BatchNorm2d = prim::GetAttr[name="bn1"](%359)
  %581 : bool = prim::GetAttr[name="training"](%580)
   = prim::If(%581) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %582 : Tensor = prim::GetAttr[name="num_batches_tracked"](%580)
      %583 : Tensor = aten::add(%582, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%580, %583)
      -> ()
    block1():
      -> ()
  %584 : bool = prim::GetAttr[name="training"](%580)
  %585 : Tensor = prim::GetAttr[name="running_mean"](%580)
  %586 : Tensor = prim::GetAttr[name="running_var"](%580)
  %587 : Tensor = prim::GetAttr[name="weight"](%580)
  %588 : Tensor = prim::GetAttr[name="bias"](%580)
   = prim::If(%584) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %589 : int[] = aten::size(%out.82) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.124 : int = aten::__getitem__(%589, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %591 : int = aten::len(%589) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %592 : int = aten::sub(%591, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.125 : int = prim::Loop(%592, %6, %size_prods.124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.32 : int, %size_prods.126 : int):
          %596 : int = aten::add(%i.32, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %597 : int = aten::__getitem__(%589, %596) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.127 : int = aten::mul(%size_prods.126, %597) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.127)
      %599 : bool = aten::eq(%size_prods.125, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%599) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %600 : str = aten::format(%8, %589) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%600) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.83 : Tensor = aten::batch_norm(%out.82, %587, %588, %585, %586, %584, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.84 : Tensor = aten::relu_(%out.83) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %603 : __torch__.torch.nn.modules.conv.___torch_mangle_17.Conv2d = prim::GetAttr[name="conv2"](%359)
  %604 : Tensor = prim::GetAttr[name="weight"](%603)
  %605 : Tensor? = prim::GetAttr[name="bias"](%603)
  %out.85 : Tensor = aten::conv2d(%out.84, %604, %605, %1657, %1657, %1657, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %610 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_4.BatchNorm2d = prim::GetAttr[name="bn2"](%359)
  %611 : bool = prim::GetAttr[name="training"](%610)
   = prim::If(%611) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %612 : Tensor = prim::GetAttr[name="num_batches_tracked"](%610)
      %613 : Tensor = aten::add(%612, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%610, %613)
      -> ()
    block1():
      -> ()
  %614 : bool = prim::GetAttr[name="training"](%610)
  %615 : Tensor = prim::GetAttr[name="running_mean"](%610)
  %616 : Tensor = prim::GetAttr[name="running_var"](%610)
  %617 : Tensor = prim::GetAttr[name="weight"](%610)
  %618 : Tensor = prim::GetAttr[name="bias"](%610)
   = prim::If(%614) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %619 : int[] = aten::size(%out.85) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.128 : int = aten::__getitem__(%619, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %621 : int = aten::len(%619) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %622 : int = aten::sub(%621, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.129 : int = prim::Loop(%622, %6, %size_prods.128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.33 : int, %size_prods.130 : int):
          %626 : int = aten::add(%i.33, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %627 : int = aten::__getitem__(%619, %626) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.131 : int = aten::mul(%size_prods.130, %627) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.131)
      %629 : bool = aten::eq(%size_prods.129, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%629) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %630 : str = aten::format(%8, %619) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%630) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.86 : Tensor = aten::batch_norm(%out.85, %617, %618, %615, %616, %614, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.87 : Tensor = aten::relu_(%out.86) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %633 : __torch__.torch.nn.modules.conv.___torch_mangle_11.Conv2d = prim::GetAttr[name="conv3"](%359)
  %634 : Tensor = prim::GetAttr[name="weight"](%633)
  %635 : Tensor? = prim::GetAttr[name="bias"](%633)
  %out.88 : Tensor = aten::conv2d(%out.87, %634, %635, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %640 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_12.BatchNorm2d = prim::GetAttr[name="bn3"](%359)
  %641 : bool = prim::GetAttr[name="training"](%640)
   = prim::If(%641) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %642 : Tensor = prim::GetAttr[name="num_batches_tracked"](%640)
      %643 : Tensor = aten::add(%642, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%640, %643)
      -> ()
    block1():
      -> ()
  %644 : bool = prim::GetAttr[name="training"](%640)
  %645 : Tensor = prim::GetAttr[name="running_mean"](%640)
  %646 : Tensor = prim::GetAttr[name="running_var"](%640)
  %647 : Tensor = prim::GetAttr[name="weight"](%640)
  %648 : Tensor = prim::GetAttr[name="bias"](%640)
   = prim::If(%644) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %649 : int[] = aten::size(%out.88) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.132 : int = aten::__getitem__(%649, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %651 : int = aten::len(%649) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %652 : int = aten::sub(%651, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.133 : int = prim::Loop(%652, %6, %size_prods.132) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.34 : int, %size_prods.134 : int):
          %656 : int = aten::add(%i.34, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %657 : int = aten::__getitem__(%649, %656) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.135 : int = aten::mul(%size_prods.134, %657) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.135)
      %659 : bool = aten::eq(%size_prods.133, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%659) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %660 : str = aten::format(%8, %649) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%660) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.89 : Tensor = aten::batch_norm(%out.88, %647, %648, %645, %646, %644, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.90 : Tensor = aten::add_(%out.89, %input.12, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.16 : Tensor = aten::relu_(%out.90) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %664 : __torch__.torch.nn.modules.conv.___torch_mangle_16.Conv2d = prim::GetAttr[name="conv1"](%360)
  %665 : Tensor = prim::GetAttr[name="weight"](%664)
  %666 : Tensor? = prim::GetAttr[name="bias"](%664)
  %out.109 : Tensor = aten::conv2d(%input.16, %665, %666, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %671 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_4.BatchNorm2d = prim::GetAttr[name="bn1"](%360)
  %672 : bool = prim::GetAttr[name="training"](%671)
   = prim::If(%672) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %673 : Tensor = prim::GetAttr[name="num_batches_tracked"](%671)
      %674 : Tensor = aten::add(%673, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%671, %674)
      -> ()
    block1():
      -> ()
  %675 : bool = prim::GetAttr[name="training"](%671)
  %676 : Tensor = prim::GetAttr[name="running_mean"](%671)
  %677 : Tensor = prim::GetAttr[name="running_var"](%671)
  %678 : Tensor = prim::GetAttr[name="weight"](%671)
  %679 : Tensor = prim::GetAttr[name="bias"](%671)
   = prim::If(%675) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %680 : int[] = aten::size(%out.109) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.160 : int = aten::__getitem__(%680, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %682 : int = aten::len(%680) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %683 : int = aten::sub(%682, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.161 : int = prim::Loop(%683, %6, %size_prods.160) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.41 : int, %size_prods.162 : int):
          %687 : int = aten::add(%i.41, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %688 : int = aten::__getitem__(%680, %687) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.163 : int = aten::mul(%size_prods.162, %688) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.163)
      %690 : bool = aten::eq(%size_prods.161, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%690) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %691 : str = aten::format(%8, %680) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%691) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.110 : Tensor = aten::batch_norm(%out.109, %678, %679, %676, %677, %675, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.111 : Tensor = aten::relu_(%out.110) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %694 : __torch__.torch.nn.modules.conv.___torch_mangle_17.Conv2d = prim::GetAttr[name="conv2"](%360)
  %695 : Tensor = prim::GetAttr[name="weight"](%694)
  %696 : Tensor? = prim::GetAttr[name="bias"](%694)
  %out.112 : Tensor = aten::conv2d(%out.111, %695, %696, %1657, %1657, %1657, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %701 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_4.BatchNorm2d = prim::GetAttr[name="bn2"](%360)
  %702 : bool = prim::GetAttr[name="training"](%701)
   = prim::If(%702) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %703 : Tensor = prim::GetAttr[name="num_batches_tracked"](%701)
      %704 : Tensor = aten::add(%703, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%701, %704)
      -> ()
    block1():
      -> ()
  %705 : bool = prim::GetAttr[name="training"](%701)
  %706 : Tensor = prim::GetAttr[name="running_mean"](%701)
  %707 : Tensor = prim::GetAttr[name="running_var"](%701)
  %708 : Tensor = prim::GetAttr[name="weight"](%701)
  %709 : Tensor = prim::GetAttr[name="bias"](%701)
   = prim::If(%705) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %710 : int[] = aten::size(%out.112) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.164 : int = aten::__getitem__(%710, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %712 : int = aten::len(%710) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %713 : int = aten::sub(%712, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.165 : int = prim::Loop(%713, %6, %size_prods.164) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.42 : int, %size_prods.166 : int):
          %717 : int = aten::add(%i.42, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %718 : int = aten::__getitem__(%710, %717) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.167 : int = aten::mul(%size_prods.166, %718) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.167)
      %720 : bool = aten::eq(%size_prods.165, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%720) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %721 : str = aten::format(%8, %710) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%721) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.113 : Tensor = aten::batch_norm(%out.112, %708, %709, %706, %707, %705, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.114 : Tensor = aten::relu_(%out.113) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %724 : __torch__.torch.nn.modules.conv.___torch_mangle_11.Conv2d = prim::GetAttr[name="conv3"](%360)
  %725 : Tensor = prim::GetAttr[name="weight"](%724)
  %726 : Tensor? = prim::GetAttr[name="bias"](%724)
  %out.115 : Tensor = aten::conv2d(%out.114, %725, %726, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %731 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_12.BatchNorm2d = prim::GetAttr[name="bn3"](%360)
  %732 : bool = prim::GetAttr[name="training"](%731)
   = prim::If(%732) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %733 : Tensor = prim::GetAttr[name="num_batches_tracked"](%731)
      %734 : Tensor = aten::add(%733, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%731, %734)
      -> ()
    block1():
      -> ()
  %735 : bool = prim::GetAttr[name="training"](%731)
  %736 : Tensor = prim::GetAttr[name="running_mean"](%731)
  %737 : Tensor = prim::GetAttr[name="running_var"](%731)
  %738 : Tensor = prim::GetAttr[name="weight"](%731)
  %739 : Tensor = prim::GetAttr[name="bias"](%731)
   = prim::If(%735) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %740 : int[] = aten::size(%out.115) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.168 : int = aten::__getitem__(%740, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %742 : int = aten::len(%740) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %743 : int = aten::sub(%742, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.169 : int = prim::Loop(%743, %6, %size_prods.168) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.43 : int, %size_prods.170 : int):
          %747 : int = aten::add(%i.43, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %748 : int = aten::__getitem__(%740, %747) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.171 : int = aten::mul(%size_prods.170, %748) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.171)
      %750 : bool = aten::eq(%size_prods.169, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%750) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %751 : str = aten::format(%8, %740) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%751) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.116 : Tensor = aten::batch_norm(%out.115, %738, %739, %736, %737, %735, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.117 : Tensor = aten::add_(%out.116, %input.16, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %x.13 : Tensor = aten::relu_(%out.117) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %755 : __torch__.torch.nn.modules.container.___torch_mangle_30.Sequential = prim::GetAttr[name="layer3"](%self)
  %756 : __torch__.torchvision.models.resnet.___torch_mangle_26.Bottleneck = prim::GetAttr[name="0"](%755)
  %757 : __torch__.torchvision.models.resnet.___torch_mangle_29.Bottleneck = prim::GetAttr[name="1"](%755)
  %758 : __torch__.torchvision.models.resnet.___torch_mangle_29.Bottleneck = prim::GetAttr[name="2"](%755)
  %759 : __torch__.torchvision.models.resnet.___torch_mangle_29.Bottleneck = prim::GetAttr[name="3"](%755)
  %760 : __torch__.torchvision.models.resnet.___torch_mangle_29.Bottleneck = prim::GetAttr[name="4"](%755)
  %761 : __torch__.torchvision.models.resnet.___torch_mangle_29.Bottleneck = prim::GetAttr[name="5"](%755)
  %762 : __torch__.torch.nn.modules.conv.___torch_mangle_20.Conv2d = prim::GetAttr[name="conv1"](%756)
  %763 : Tensor = prim::GetAttr[name="weight"](%762)
  %764 : Tensor? = prim::GetAttr[name="bias"](%762)
  %out.118 : Tensor = aten::conv2d(%x.13, %763, %764, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %769 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_12.BatchNorm2d = prim::GetAttr[name="bn1"](%756)
  %770 : bool = prim::GetAttr[name="training"](%769)
   = prim::If(%770) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %771 : Tensor = prim::GetAttr[name="num_batches_tracked"](%769)
      %772 : Tensor = aten::add(%771, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%769, %772)
      -> ()
    block1():
      -> ()
  %773 : bool = prim::GetAttr[name="training"](%769)
  %774 : Tensor = prim::GetAttr[name="running_mean"](%769)
  %775 : Tensor = prim::GetAttr[name="running_var"](%769)
  %776 : Tensor = prim::GetAttr[name="weight"](%769)
  %777 : Tensor = prim::GetAttr[name="bias"](%769)
   = prim::If(%773) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %778 : int[] = aten::size(%out.118) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.172 : int = aten::__getitem__(%778, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %780 : int = aten::len(%778) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %781 : int = aten::sub(%780, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.173 : int = prim::Loop(%781, %6, %size_prods.172) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.44 : int, %size_prods.174 : int):
          %785 : int = aten::add(%i.44, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %786 : int = aten::__getitem__(%778, %785) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.175 : int = aten::mul(%size_prods.174, %786) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.175)
      %788 : bool = aten::eq(%size_prods.173, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%788) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %789 : str = aten::format(%8, %778) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%789) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.119 : Tensor = aten::batch_norm(%out.118, %776, %777, %774, %775, %773, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.120 : Tensor = aten::relu_(%out.119) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %792 : __torch__.torch.nn.modules.conv.___torch_mangle_21.Conv2d = prim::GetAttr[name="conv2"](%756)
  %793 : Tensor = prim::GetAttr[name="weight"](%792)
  %794 : Tensor? = prim::GetAttr[name="bias"](%792)
  %out.121 : Tensor = aten::conv2d(%out.120, %793, %794, %1655, %1657, %1657, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %799 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_12.BatchNorm2d = prim::GetAttr[name="bn2"](%756)
  %800 : bool = prim::GetAttr[name="training"](%799)
   = prim::If(%800) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %801 : Tensor = prim::GetAttr[name="num_batches_tracked"](%799)
      %802 : Tensor = aten::add(%801, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%799, %802)
      -> ()
    block1():
      -> ()
  %803 : bool = prim::GetAttr[name="training"](%799)
  %804 : Tensor = prim::GetAttr[name="running_mean"](%799)
  %805 : Tensor = prim::GetAttr[name="running_var"](%799)
  %806 : Tensor = prim::GetAttr[name="weight"](%799)
  %807 : Tensor = prim::GetAttr[name="bias"](%799)
   = prim::If(%803) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %808 : int[] = aten::size(%out.121) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.176 : int = aten::__getitem__(%808, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %810 : int = aten::len(%808) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %811 : int = aten::sub(%810, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.177 : int = prim::Loop(%811, %6, %size_prods.176) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.45 : int, %size_prods.178 : int):
          %815 : int = aten::add(%i.45, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %816 : int = aten::__getitem__(%808, %815) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.179 : int = aten::mul(%size_prods.178, %816) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.179)
      %818 : bool = aten::eq(%size_prods.177, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%818) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %819 : str = aten::format(%8, %808) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%819) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.122 : Tensor = aten::batch_norm(%out.121, %806, %807, %804, %805, %803, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.123 : Tensor = aten::relu_(%out.122) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %822 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="conv3"](%756)
  %823 : Tensor = prim::GetAttr[name="weight"](%822)
  %824 : Tensor? = prim::GetAttr[name="bias"](%822)
  %out.124 : Tensor = aten::conv2d(%out.123, %823, %824, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %829 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="bn3"](%756)
  %830 : bool = prim::GetAttr[name="training"](%829)
   = prim::If(%830) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %831 : Tensor = prim::GetAttr[name="num_batches_tracked"](%829)
      %832 : Tensor = aten::add(%831, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%829, %832)
      -> ()
    block1():
      -> ()
  %833 : bool = prim::GetAttr[name="training"](%829)
  %834 : Tensor = prim::GetAttr[name="running_mean"](%829)
  %835 : Tensor = prim::GetAttr[name="running_var"](%829)
  %836 : Tensor = prim::GetAttr[name="weight"](%829)
  %837 : Tensor = prim::GetAttr[name="bias"](%829)
   = prim::If(%833) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %838 : int[] = aten::size(%out.124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.180 : int = aten::__getitem__(%838, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %840 : int = aten::len(%838) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %841 : int = aten::sub(%840, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.181 : int = prim::Loop(%841, %6, %size_prods.180) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.46 : int, %size_prods.182 : int):
          %845 : int = aten::add(%i.46, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %846 : int = aten::__getitem__(%838, %845) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.183 : int = aten::mul(%size_prods.182, %846) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.183)
      %848 : bool = aten::eq(%size_prods.181, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%848) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %849 : str = aten::format(%8, %838) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%849) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.125 : Tensor = aten::batch_norm(%out.124, %836, %837, %834, %835, %833, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %851 : __torch__.torch.nn.modules.container.___torch_mangle_25.Sequential = prim::GetAttr[name="downsample"](%756)
  %852 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="0"](%851)
  %853 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="1"](%851)
  %854 : Tensor = prim::GetAttr[name="weight"](%852)
  %855 : Tensor? = prim::GetAttr[name="bias"](%852)
  %input.13 : Tensor = aten::conv2d(%x.13, %854, %855, %1655, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %860 : bool = prim::GetAttr[name="training"](%853)
   = prim::If(%860) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %861 : Tensor = prim::GetAttr[name="num_batches_tracked"](%853)
      %862 : Tensor = aten::add(%861, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%853, %862)
      -> ()
    block1():
      -> ()
  %863 : bool = prim::GetAttr[name="training"](%853)
  %864 : Tensor = prim::GetAttr[name="running_mean"](%853)
  %865 : Tensor = prim::GetAttr[name="running_var"](%853)
  %866 : Tensor = prim::GetAttr[name="weight"](%853)
  %867 : Tensor = prim::GetAttr[name="bias"](%853)
   = prim::If(%863) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %868 : int[] = aten::size(%input.13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.184 : int = aten::__getitem__(%868, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %870 : int = aten::len(%868) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %871 : int = aten::sub(%870, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.185 : int = prim::Loop(%871, %6, %size_prods.184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.47 : int, %size_prods.186 : int):
          %875 : int = aten::add(%i.47, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %876 : int = aten::__getitem__(%868, %875) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.187 : int = aten::mul(%size_prods.186, %876) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.187)
      %878 : bool = aten::eq(%size_prods.185, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%878) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %879 : str = aten::format(%8, %868) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%879) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %identity.4 : Tensor = aten::batch_norm(%input.13, %866, %867, %864, %865, %863, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.126 : Tensor = aten::add_(%out.125, %identity.4, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.17 : Tensor = aten::relu_(%out.126) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %883 : __torch__.torch.nn.modules.conv.___torch_mangle_27.Conv2d = prim::GetAttr[name="conv1"](%757)
  %884 : Tensor = prim::GetAttr[name="weight"](%883)
  %885 : Tensor? = prim::GetAttr[name="bias"](%883)
  %out.127 : Tensor = aten::conv2d(%input.17, %884, %885, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %890 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_12.BatchNorm2d = prim::GetAttr[name="bn1"](%757)
  %891 : bool = prim::GetAttr[name="training"](%890)
   = prim::If(%891) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %892 : Tensor = prim::GetAttr[name="num_batches_tracked"](%890)
      %893 : Tensor = aten::add(%892, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%890, %893)
      -> ()
    block1():
      -> ()
  %894 : bool = prim::GetAttr[name="training"](%890)
  %895 : Tensor = prim::GetAttr[name="running_mean"](%890)
  %896 : Tensor = prim::GetAttr[name="running_var"](%890)
  %897 : Tensor = prim::GetAttr[name="weight"](%890)
  %898 : Tensor = prim::GetAttr[name="bias"](%890)
   = prim::If(%894) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %899 : int[] = aten::size(%out.127) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.188 : int = aten::__getitem__(%899, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %901 : int = aten::len(%899) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %902 : int = aten::sub(%901, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.189 : int = prim::Loop(%902, %6, %size_prods.188) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.48 : int, %size_prods.190 : int):
          %906 : int = aten::add(%i.48, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %907 : int = aten::__getitem__(%899, %906) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.191 : int = aten::mul(%size_prods.190, %907) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.191)
      %909 : bool = aten::eq(%size_prods.189, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%909) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %910 : str = aten::format(%8, %899) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%910) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.128 : Tensor = aten::batch_norm(%out.127, %897, %898, %895, %896, %894, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.129 : Tensor = aten::relu_(%out.128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %913 : __torch__.torch.nn.modules.conv.___torch_mangle_28.Conv2d = prim::GetAttr[name="conv2"](%757)
  %914 : Tensor = prim::GetAttr[name="weight"](%913)
  %915 : Tensor? = prim::GetAttr[name="bias"](%913)
  %out.130 : Tensor = aten::conv2d(%out.129, %914, %915, %1657, %1657, %1657, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %920 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_12.BatchNorm2d = prim::GetAttr[name="bn2"](%757)
  %921 : bool = prim::GetAttr[name="training"](%920)
   = prim::If(%921) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %922 : Tensor = prim::GetAttr[name="num_batches_tracked"](%920)
      %923 : Tensor = aten::add(%922, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%920, %923)
      -> ()
    block1():
      -> ()
  %924 : bool = prim::GetAttr[name="training"](%920)
  %925 : Tensor = prim::GetAttr[name="running_mean"](%920)
  %926 : Tensor = prim::GetAttr[name="running_var"](%920)
  %927 : Tensor = prim::GetAttr[name="weight"](%920)
  %928 : Tensor = prim::GetAttr[name="bias"](%920)
   = prim::If(%924) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %929 : int[] = aten::size(%out.130) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.192 : int = aten::__getitem__(%929, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %931 : int = aten::len(%929) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %932 : int = aten::sub(%931, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.193 : int = prim::Loop(%932, %6, %size_prods.192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.49 : int, %size_prods.194 : int):
          %936 : int = aten::add(%i.49, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %937 : int = aten::__getitem__(%929, %936) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.195 : int = aten::mul(%size_prods.194, %937) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.195)
      %939 : bool = aten::eq(%size_prods.193, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%939) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %940 : str = aten::format(%8, %929) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%940) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.131 : Tensor = aten::batch_norm(%out.130, %927, %928, %925, %926, %924, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.132 : Tensor = aten::relu_(%out.131) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %943 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="conv3"](%757)
  %944 : Tensor = prim::GetAttr[name="weight"](%943)
  %945 : Tensor? = prim::GetAttr[name="bias"](%943)
  %out.133 : Tensor = aten::conv2d(%out.132, %944, %945, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %950 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="bn3"](%757)
  %951 : bool = prim::GetAttr[name="training"](%950)
   = prim::If(%951) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %952 : Tensor = prim::GetAttr[name="num_batches_tracked"](%950)
      %953 : Tensor = aten::add(%952, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%950, %953)
      -> ()
    block1():
      -> ()
  %954 : bool = prim::GetAttr[name="training"](%950)
  %955 : Tensor = prim::GetAttr[name="running_mean"](%950)
  %956 : Tensor = prim::GetAttr[name="running_var"](%950)
  %957 : Tensor = prim::GetAttr[name="weight"](%950)
  %958 : Tensor = prim::GetAttr[name="bias"](%950)
   = prim::If(%954) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %959 : int[] = aten::size(%out.133) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.196 : int = aten::__getitem__(%959, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %961 : int = aten::len(%959) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %962 : int = aten::sub(%961, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.197 : int = prim::Loop(%962, %6, %size_prods.196) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.50 : int, %size_prods.198 : int):
          %966 : int = aten::add(%i.50, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %967 : int = aten::__getitem__(%959, %966) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.199 : int = aten::mul(%size_prods.198, %967) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.199)
      %969 : bool = aten::eq(%size_prods.197, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%969) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %970 : str = aten::format(%8, %959) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%970) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.134 : Tensor = aten::batch_norm(%out.133, %957, %958, %955, %956, %954, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.135 : Tensor = aten::add_(%out.134, %input.17, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.18 : Tensor = aten::relu_(%out.135) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %974 : __torch__.torch.nn.modules.conv.___torch_mangle_27.Conv2d = prim::GetAttr[name="conv1"](%758)
  %975 : Tensor = prim::GetAttr[name="weight"](%974)
  %976 : Tensor? = prim::GetAttr[name="bias"](%974)
  %out.37 : Tensor = aten::conv2d(%input.18, %975, %976, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %981 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_12.BatchNorm2d = prim::GetAttr[name="bn1"](%758)
  %982 : bool = prim::GetAttr[name="training"](%981)
   = prim::If(%982) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %983 : Tensor = prim::GetAttr[name="num_batches_tracked"](%981)
      %984 : Tensor = aten::add(%983, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%981, %984)
      -> ()
    block1():
      -> ()
  %985 : bool = prim::GetAttr[name="training"](%981)
  %986 : Tensor = prim::GetAttr[name="running_mean"](%981)
  %987 : Tensor = prim::GetAttr[name="running_var"](%981)
  %988 : Tensor = prim::GetAttr[name="weight"](%981)
  %989 : Tensor = prim::GetAttr[name="bias"](%981)
   = prim::If(%985) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %990 : int[] = aten::size(%out.37) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.40 : int = aten::__getitem__(%990, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %992 : int = aten::len(%990) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %993 : int = aten::sub(%992, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.41 : int = prim::Loop(%993, %6, %size_prods.40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.11 : int, %size_prods.42 : int):
          %997 : int = aten::add(%i.11, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %998 : int = aten::__getitem__(%990, %997) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.43 : int = aten::mul(%size_prods.42, %998) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.43)
      %1000 : bool = aten::eq(%size_prods.41, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1000) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1001 : str = aten::format(%8, %990) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1001) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.29 : Tensor = aten::batch_norm(%out.37, %988, %989, %986, %987, %985, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.30 : Tensor = aten::relu_(%out.29) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1004 : __torch__.torch.nn.modules.conv.___torch_mangle_28.Conv2d = prim::GetAttr[name="conv2"](%758)
  %1005 : Tensor = prim::GetAttr[name="weight"](%1004)
  %1006 : Tensor? = prim::GetAttr[name="bias"](%1004)
  %out.31 : Tensor = aten::conv2d(%out.30, %1005, %1006, %1657, %1657, %1657, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1011 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_12.BatchNorm2d = prim::GetAttr[name="bn2"](%758)
  %1012 : bool = prim::GetAttr[name="training"](%1011)
   = prim::If(%1012) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1013 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1011)
      %1014 : Tensor = aten::add(%1013, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1011, %1014)
      -> ()
    block1():
      -> ()
  %1015 : bool = prim::GetAttr[name="training"](%1011)
  %1016 : Tensor = prim::GetAttr[name="running_mean"](%1011)
  %1017 : Tensor = prim::GetAttr[name="running_var"](%1011)
  %1018 : Tensor = prim::GetAttr[name="weight"](%1011)
  %1019 : Tensor = prim::GetAttr[name="bias"](%1011)
   = prim::If(%1015) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1020 : int[] = aten::size(%out.31) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.44 : int = aten::__getitem__(%1020, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1022 : int = aten::len(%1020) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1023 : int = aten::sub(%1022, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.45 : int = prim::Loop(%1023, %6, %size_prods.44) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.12 : int, %size_prods.46 : int):
          %1027 : int = aten::add(%i.12, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1028 : int = aten::__getitem__(%1020, %1027) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.47 : int = aten::mul(%size_prods.46, %1028) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.47)
      %1030 : bool = aten::eq(%size_prods.45, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1030) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1031 : str = aten::format(%8, %1020) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1031) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.32 : Tensor = aten::batch_norm(%out.31, %1018, %1019, %1016, %1017, %1015, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.33 : Tensor = aten::relu_(%out.32) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1034 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="conv3"](%758)
  %1035 : Tensor = prim::GetAttr[name="weight"](%1034)
  %1036 : Tensor? = prim::GetAttr[name="bias"](%1034)
  %out.34 : Tensor = aten::conv2d(%out.33, %1035, %1036, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1041 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="bn3"](%758)
  %1042 : bool = prim::GetAttr[name="training"](%1041)
   = prim::If(%1042) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1043 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1041)
      %1044 : Tensor = aten::add(%1043, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1041, %1044)
      -> ()
    block1():
      -> ()
  %1045 : bool = prim::GetAttr[name="training"](%1041)
  %1046 : Tensor = prim::GetAttr[name="running_mean"](%1041)
  %1047 : Tensor = prim::GetAttr[name="running_var"](%1041)
  %1048 : Tensor = prim::GetAttr[name="weight"](%1041)
  %1049 : Tensor = prim::GetAttr[name="bias"](%1041)
   = prim::If(%1045) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1050 : int[] = aten::size(%out.34) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.48 : int = aten::__getitem__(%1050, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1052 : int = aten::len(%1050) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1053 : int = aten::sub(%1052, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.49 : int = prim::Loop(%1053, %6, %size_prods.48) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.13 : int, %size_prods.50 : int):
          %1057 : int = aten::add(%i.13, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1058 : int = aten::__getitem__(%1050, %1057) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.51 : int = aten::mul(%size_prods.50, %1058) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.51)
      %1060 : bool = aten::eq(%size_prods.49, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1060) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1061 : str = aten::format(%8, %1050) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1061) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.35 : Tensor = aten::batch_norm(%out.34, %1048, %1049, %1046, %1047, %1045, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.36 : Tensor = aten::add_(%out.35, %input.18, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.19 : Tensor = aten::relu_(%out.36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1065 : __torch__.torch.nn.modules.conv.___torch_mangle_27.Conv2d = prim::GetAttr[name="conv1"](%759)
  %1066 : Tensor = prim::GetAttr[name="weight"](%1065)
  %1067 : Tensor? = prim::GetAttr[name="bias"](%1065)
  %out.46 : Tensor = aten::conv2d(%input.19, %1066, %1067, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1072 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_12.BatchNorm2d = prim::GetAttr[name="bn1"](%759)
  %1073 : bool = prim::GetAttr[name="training"](%1072)
   = prim::If(%1073) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1074 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1072)
      %1075 : Tensor = aten::add(%1074, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1072, %1075)
      -> ()
    block1():
      -> ()
  %1076 : bool = prim::GetAttr[name="training"](%1072)
  %1077 : Tensor = prim::GetAttr[name="running_mean"](%1072)
  %1078 : Tensor = prim::GetAttr[name="running_var"](%1072)
  %1079 : Tensor = prim::GetAttr[name="weight"](%1072)
  %1080 : Tensor = prim::GetAttr[name="bias"](%1072)
   = prim::If(%1076) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1081 : int[] = aten::size(%out.46) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.52 : int = aten::__getitem__(%1081, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1083 : int = aten::len(%1081) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1084 : int = aten::sub(%1083, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.53 : int = prim::Loop(%1084, %6, %size_prods.52) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.14 : int, %size_prods.54 : int):
          %1088 : int = aten::add(%i.14, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1089 : int = aten::__getitem__(%1081, %1088) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.55 : int = aten::mul(%size_prods.54, %1089) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.55)
      %1091 : bool = aten::eq(%size_prods.53, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1091) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1092 : str = aten::format(%8, %1081) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1092) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.38 : Tensor = aten::batch_norm(%out.46, %1079, %1080, %1077, %1078, %1076, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.39 : Tensor = aten::relu_(%out.38) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1095 : __torch__.torch.nn.modules.conv.___torch_mangle_28.Conv2d = prim::GetAttr[name="conv2"](%759)
  %1096 : Tensor = prim::GetAttr[name="weight"](%1095)
  %1097 : Tensor? = prim::GetAttr[name="bias"](%1095)
  %out.40 : Tensor = aten::conv2d(%out.39, %1096, %1097, %1657, %1657, %1657, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1102 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_12.BatchNorm2d = prim::GetAttr[name="bn2"](%759)
  %1103 : bool = prim::GetAttr[name="training"](%1102)
   = prim::If(%1103) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1104 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1102)
      %1105 : Tensor = aten::add(%1104, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1102, %1105)
      -> ()
    block1():
      -> ()
  %1106 : bool = prim::GetAttr[name="training"](%1102)
  %1107 : Tensor = prim::GetAttr[name="running_mean"](%1102)
  %1108 : Tensor = prim::GetAttr[name="running_var"](%1102)
  %1109 : Tensor = prim::GetAttr[name="weight"](%1102)
  %1110 : Tensor = prim::GetAttr[name="bias"](%1102)
   = prim::If(%1106) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1111 : int[] = aten::size(%out.40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.56 : int = aten::__getitem__(%1111, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1113 : int = aten::len(%1111) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1114 : int = aten::sub(%1113, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.57 : int = prim::Loop(%1114, %6, %size_prods.56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.15 : int, %size_prods.58 : int):
          %1118 : int = aten::add(%i.15, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1119 : int = aten::__getitem__(%1111, %1118) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.59 : int = aten::mul(%size_prods.58, %1119) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.59)
      %1121 : bool = aten::eq(%size_prods.57, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1121) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1122 : str = aten::format(%8, %1111) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1122) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.41 : Tensor = aten::batch_norm(%out.40, %1109, %1110, %1107, %1108, %1106, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.42 : Tensor = aten::relu_(%out.41) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1125 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="conv3"](%759)
  %1126 : Tensor = prim::GetAttr[name="weight"](%1125)
  %1127 : Tensor? = prim::GetAttr[name="bias"](%1125)
  %out.43 : Tensor = aten::conv2d(%out.42, %1126, %1127, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1132 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="bn3"](%759)
  %1133 : bool = prim::GetAttr[name="training"](%1132)
   = prim::If(%1133) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1134 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1132)
      %1135 : Tensor = aten::add(%1134, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1132, %1135)
      -> ()
    block1():
      -> ()
  %1136 : bool = prim::GetAttr[name="training"](%1132)
  %1137 : Tensor = prim::GetAttr[name="running_mean"](%1132)
  %1138 : Tensor = prim::GetAttr[name="running_var"](%1132)
  %1139 : Tensor = prim::GetAttr[name="weight"](%1132)
  %1140 : Tensor = prim::GetAttr[name="bias"](%1132)
   = prim::If(%1136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1141 : int[] = aten::size(%out.43) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.60 : int = aten::__getitem__(%1141, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1143 : int = aten::len(%1141) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1144 : int = aten::sub(%1143, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.61 : int = prim::Loop(%1144, %6, %size_prods.60) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.16 : int, %size_prods.62 : int):
          %1148 : int = aten::add(%i.16, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1149 : int = aten::__getitem__(%1141, %1148) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.63 : int = aten::mul(%size_prods.62, %1149) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.63)
      %1151 : bool = aten::eq(%size_prods.61, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1151) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1152 : str = aten::format(%8, %1141) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1152) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.44 : Tensor = aten::batch_norm(%out.43, %1139, %1140, %1137, %1138, %1136, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.45 : Tensor = aten::add_(%out.44, %input.19, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.9 : Tensor = aten::relu_(%out.45) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1156 : __torch__.torch.nn.modules.conv.___torch_mangle_27.Conv2d = prim::GetAttr[name="conv1"](%760)
  %1157 : Tensor = prim::GetAttr[name="weight"](%1156)
  %1158 : Tensor? = prim::GetAttr[name="bias"](%1156)
  %out.55 : Tensor = aten::conv2d(%input.9, %1157, %1158, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1163 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_12.BatchNorm2d = prim::GetAttr[name="bn1"](%760)
  %1164 : bool = prim::GetAttr[name="training"](%1163)
   = prim::If(%1164) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1165 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1163)
      %1166 : Tensor = aten::add(%1165, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1163, %1166)
      -> ()
    block1():
      -> ()
  %1167 : bool = prim::GetAttr[name="training"](%1163)
  %1168 : Tensor = prim::GetAttr[name="running_mean"](%1163)
  %1169 : Tensor = prim::GetAttr[name="running_var"](%1163)
  %1170 : Tensor = prim::GetAttr[name="weight"](%1163)
  %1171 : Tensor = prim::GetAttr[name="bias"](%1163)
   = prim::If(%1167) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1172 : int[] = aten::size(%out.55) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.64 : int = aten::__getitem__(%1172, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1174 : int = aten::len(%1172) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1175 : int = aten::sub(%1174, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.65 : int = prim::Loop(%1175, %6, %size_prods.64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.17 : int, %size_prods.66 : int):
          %1179 : int = aten::add(%i.17, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1180 : int = aten::__getitem__(%1172, %1179) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.67 : int = aten::mul(%size_prods.66, %1180) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.67)
      %1182 : bool = aten::eq(%size_prods.65, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1182) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1183 : str = aten::format(%8, %1172) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1183) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.47 : Tensor = aten::batch_norm(%out.55, %1170, %1171, %1168, %1169, %1167, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.48 : Tensor = aten::relu_(%out.47) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1186 : __torch__.torch.nn.modules.conv.___torch_mangle_28.Conv2d = prim::GetAttr[name="conv2"](%760)
  %1187 : Tensor = prim::GetAttr[name="weight"](%1186)
  %1188 : Tensor? = prim::GetAttr[name="bias"](%1186)
  %out.49 : Tensor = aten::conv2d(%out.48, %1187, %1188, %1657, %1657, %1657, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1193 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_12.BatchNorm2d = prim::GetAttr[name="bn2"](%760)
  %1194 : bool = prim::GetAttr[name="training"](%1193)
   = prim::If(%1194) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1195 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1193)
      %1196 : Tensor = aten::add(%1195, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1193, %1196)
      -> ()
    block1():
      -> ()
  %1197 : bool = prim::GetAttr[name="training"](%1193)
  %1198 : Tensor = prim::GetAttr[name="running_mean"](%1193)
  %1199 : Tensor = prim::GetAttr[name="running_var"](%1193)
  %1200 : Tensor = prim::GetAttr[name="weight"](%1193)
  %1201 : Tensor = prim::GetAttr[name="bias"](%1193)
   = prim::If(%1197) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1202 : int[] = aten::size(%out.49) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.68 : int = aten::__getitem__(%1202, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1204 : int = aten::len(%1202) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1205 : int = aten::sub(%1204, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.69 : int = prim::Loop(%1205, %6, %size_prods.68) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.18 : int, %size_prods.70 : int):
          %1209 : int = aten::add(%i.18, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1210 : int = aten::__getitem__(%1202, %1209) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.71 : int = aten::mul(%size_prods.70, %1210) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.71)
      %1212 : bool = aten::eq(%size_prods.69, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1213 : str = aten::format(%8, %1202) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1213) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.50 : Tensor = aten::batch_norm(%out.49, %1200, %1201, %1198, %1199, %1197, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.51 : Tensor = aten::relu_(%out.50) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1216 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="conv3"](%760)
  %1217 : Tensor = prim::GetAttr[name="weight"](%1216)
  %1218 : Tensor? = prim::GetAttr[name="bias"](%1216)
  %out.52 : Tensor = aten::conv2d(%out.51, %1217, %1218, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1223 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="bn3"](%760)
  %1224 : bool = prim::GetAttr[name="training"](%1223)
   = prim::If(%1224) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1225 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1223)
      %1226 : Tensor = aten::add(%1225, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1223, %1226)
      -> ()
    block1():
      -> ()
  %1227 : bool = prim::GetAttr[name="training"](%1223)
  %1228 : Tensor = prim::GetAttr[name="running_mean"](%1223)
  %1229 : Tensor = prim::GetAttr[name="running_var"](%1223)
  %1230 : Tensor = prim::GetAttr[name="weight"](%1223)
  %1231 : Tensor = prim::GetAttr[name="bias"](%1223)
   = prim::If(%1227) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1232 : int[] = aten::size(%out.52) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.72 : int = aten::__getitem__(%1232, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1234 : int = aten::len(%1232) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1235 : int = aten::sub(%1234, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.73 : int = prim::Loop(%1235, %6, %size_prods.72) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.19 : int, %size_prods.74 : int):
          %1239 : int = aten::add(%i.19, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1240 : int = aten::__getitem__(%1232, %1239) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.75 : int = aten::mul(%size_prods.74, %1240) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.75)
      %1242 : bool = aten::eq(%size_prods.73, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1242) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1243 : str = aten::format(%8, %1232) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1243) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.53 : Tensor = aten::batch_norm(%out.52, %1230, %1231, %1228, %1229, %1227, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.54 : Tensor = aten::add_(%out.53, %input.9, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.11 : Tensor = aten::relu_(%out.54) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1247 : __torch__.torch.nn.modules.conv.___torch_mangle_27.Conv2d = prim::GetAttr[name="conv1"](%761)
  %1248 : Tensor = prim::GetAttr[name="weight"](%1247)
  %1249 : Tensor? = prim::GetAttr[name="bias"](%1247)
  %out.136 : Tensor = aten::conv2d(%input.11, %1248, %1249, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1254 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_12.BatchNorm2d = prim::GetAttr[name="bn1"](%761)
  %1255 : bool = prim::GetAttr[name="training"](%1254)
   = prim::If(%1255) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1256 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1254)
      %1257 : Tensor = aten::add(%1256, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1254, %1257)
      -> ()
    block1():
      -> ()
  %1258 : bool = prim::GetAttr[name="training"](%1254)
  %1259 : Tensor = prim::GetAttr[name="running_mean"](%1254)
  %1260 : Tensor = prim::GetAttr[name="running_var"](%1254)
  %1261 : Tensor = prim::GetAttr[name="weight"](%1254)
  %1262 : Tensor = prim::GetAttr[name="bias"](%1254)
   = prim::If(%1258) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1263 : int[] = aten::size(%out.136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.200 : int = aten::__getitem__(%1263, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1265 : int = aten::len(%1263) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1266 : int = aten::sub(%1265, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.201 : int = prim::Loop(%1266, %6, %size_prods.200) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.51 : int, %size_prods.202 : int):
          %1270 : int = aten::add(%i.51, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1271 : int = aten::__getitem__(%1263, %1270) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.203 : int = aten::mul(%size_prods.202, %1271) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.203)
      %1273 : bool = aten::eq(%size_prods.201, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1273) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1274 : str = aten::format(%8, %1263) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1274) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.137 : Tensor = aten::batch_norm(%out.136, %1261, %1262, %1259, %1260, %1258, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.138 : Tensor = aten::relu_(%out.137) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1277 : __torch__.torch.nn.modules.conv.___torch_mangle_28.Conv2d = prim::GetAttr[name="conv2"](%761)
  %1278 : Tensor = prim::GetAttr[name="weight"](%1277)
  %1279 : Tensor? = prim::GetAttr[name="bias"](%1277)
  %out.139 : Tensor = aten::conv2d(%out.138, %1278, %1279, %1657, %1657, %1657, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1284 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_12.BatchNorm2d = prim::GetAttr[name="bn2"](%761)
  %1285 : bool = prim::GetAttr[name="training"](%1284)
   = prim::If(%1285) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1286 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1284)
      %1287 : Tensor = aten::add(%1286, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1284, %1287)
      -> ()
    block1():
      -> ()
  %1288 : bool = prim::GetAttr[name="training"](%1284)
  %1289 : Tensor = prim::GetAttr[name="running_mean"](%1284)
  %1290 : Tensor = prim::GetAttr[name="running_var"](%1284)
  %1291 : Tensor = prim::GetAttr[name="weight"](%1284)
  %1292 : Tensor = prim::GetAttr[name="bias"](%1284)
   = prim::If(%1288) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1293 : int[] = aten::size(%out.139) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.204 : int = aten::__getitem__(%1293, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1295 : int = aten::len(%1293) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1296 : int = aten::sub(%1295, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.205 : int = prim::Loop(%1296, %6, %size_prods.204) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.52 : int, %size_prods.206 : int):
          %1300 : int = aten::add(%i.52, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1301 : int = aten::__getitem__(%1293, %1300) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.207 : int = aten::mul(%size_prods.206, %1301) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.207)
      %1303 : bool = aten::eq(%size_prods.205, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1303) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1304 : str = aten::format(%8, %1293) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1304) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.140 : Tensor = aten::batch_norm(%out.139, %1291, %1292, %1289, %1290, %1288, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.141 : Tensor = aten::relu_(%out.140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1307 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv2d = prim::GetAttr[name="conv3"](%761)
  %1308 : Tensor = prim::GetAttr[name="weight"](%1307)
  %1309 : Tensor? = prim::GetAttr[name="bias"](%1307)
  %out.142 : Tensor = aten::conv2d(%out.141, %1308, %1309, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1314 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="bn3"](%761)
  %1315 : bool = prim::GetAttr[name="training"](%1314)
   = prim::If(%1315) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1316 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1314)
      %1317 : Tensor = aten::add(%1316, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1314, %1317)
      -> ()
    block1():
      -> ()
  %1318 : bool = prim::GetAttr[name="training"](%1314)
  %1319 : Tensor = prim::GetAttr[name="running_mean"](%1314)
  %1320 : Tensor = prim::GetAttr[name="running_var"](%1314)
  %1321 : Tensor = prim::GetAttr[name="weight"](%1314)
  %1322 : Tensor = prim::GetAttr[name="bias"](%1314)
   = prim::If(%1318) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1323 : int[] = aten::size(%out.142) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.208 : int = aten::__getitem__(%1323, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1325 : int = aten::len(%1323) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1326 : int = aten::sub(%1325, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.209 : int = prim::Loop(%1326, %6, %size_prods.208) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.53 : int, %size_prods.210 : int):
          %1330 : int = aten::add(%i.53, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1331 : int = aten::__getitem__(%1323, %1330) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.211 : int = aten::mul(%size_prods.210, %1331) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.211)
      %1333 : bool = aten::eq(%size_prods.209, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1333) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1334 : str = aten::format(%8, %1323) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1334) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.143 : Tensor = aten::batch_norm(%out.142, %1321, %1322, %1319, %1320, %1318, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.144 : Tensor = aten::add_(%out.143, %input.11, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %x.15 : Tensor = aten::relu_(%out.144) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1338 : __torch__.torch.nn.modules.container.___torch_mangle_41.Sequential = prim::GetAttr[name="layer4"](%self)
  %1339 : __torch__.torchvision.models.resnet.___torch_mangle_37.Bottleneck = prim::GetAttr[name="0"](%1338)
  %1340 : __torch__.torchvision.models.resnet.___torch_mangle_40.Bottleneck = prim::GetAttr[name="1"](%1338)
  %1341 : __torch__.torchvision.models.resnet.___torch_mangle_40.Bottleneck = prim::GetAttr[name="2"](%1338)
  %1342 : __torch__.torch.nn.modules.conv.___torch_mangle_31.Conv2d = prim::GetAttr[name="conv1"](%1339)
  %1343 : Tensor = prim::GetAttr[name="weight"](%1342)
  %1344 : Tensor? = prim::GetAttr[name="bias"](%1342)
  %out.2 : Tensor = aten::conv2d(%x.15, %1343, %1344, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1349 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="bn1"](%1339)
  %1350 : bool = prim::GetAttr[name="training"](%1349)
   = prim::If(%1350) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1351 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1349)
      %1352 : Tensor = aten::add(%1351, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1349, %1352)
      -> ()
    block1():
      -> ()
  %1353 : bool = prim::GetAttr[name="training"](%1349)
  %1354 : Tensor = prim::GetAttr[name="running_mean"](%1349)
  %1355 : Tensor = prim::GetAttr[name="running_var"](%1349)
  %1356 : Tensor = prim::GetAttr[name="weight"](%1349)
  %1357 : Tensor = prim::GetAttr[name="bias"](%1349)
   = prim::If(%1353) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1358 : int[] = aten::size(%out.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.16 : int = aten::__getitem__(%1358, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1360 : int = aten::len(%1358) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1361 : int = aten::sub(%1360, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.17 : int = prim::Loop(%1361, %6, %size_prods.16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.5 : int, %size_prods.18 : int):
          %1365 : int = aten::add(%i.5, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1366 : int = aten::__getitem__(%1358, %1365) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.19 : int = aten::mul(%size_prods.18, %1366) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.19)
      %1368 : bool = aten::eq(%size_prods.17, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1368) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1369 : str = aten::format(%8, %1358) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1369) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.4 : Tensor = aten::batch_norm(%out.2, %1356, %1357, %1354, %1355, %1353, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.6 : Tensor = aten::relu_(%out.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1372 : __torch__.torch.nn.modules.conv.___torch_mangle_32.Conv2d = prim::GetAttr[name="conv2"](%1339)
  %1373 : Tensor = prim::GetAttr[name="weight"](%1372)
  %1374 : Tensor? = prim::GetAttr[name="bias"](%1372)
  %out.8 : Tensor = aten::conv2d(%out.6, %1373, %1374, %1655, %1657, %1657, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1379 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="bn2"](%1339)
  %1380 : bool = prim::GetAttr[name="training"](%1379)
   = prim::If(%1380) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1381 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1379)
      %1382 : Tensor = aten::add(%1381, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1379, %1382)
      -> ()
    block1():
      -> ()
  %1383 : bool = prim::GetAttr[name="training"](%1379)
  %1384 : Tensor = prim::GetAttr[name="running_mean"](%1379)
  %1385 : Tensor = prim::GetAttr[name="running_var"](%1379)
  %1386 : Tensor = prim::GetAttr[name="weight"](%1379)
  %1387 : Tensor = prim::GetAttr[name="bias"](%1379)
   = prim::If(%1383) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1388 : int[] = aten::size(%out.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.20 : int = aten::__getitem__(%1388, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1390 : int = aten::len(%1388) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1391 : int = aten::sub(%1390, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.21 : int = prim::Loop(%1391, %6, %size_prods.20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.6 : int, %size_prods.22 : int):
          %1395 : int = aten::add(%i.6, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1396 : int = aten::__getitem__(%1388, %1395) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.23 : int = aten::mul(%size_prods.22, %1396) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.23)
      %1398 : bool = aten::eq(%size_prods.21, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1398) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1399 : str = aten::format(%8, %1388) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1399) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.10 : Tensor = aten::batch_norm(%out.8, %1386, %1387, %1384, %1385, %1383, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.12 : Tensor = aten::relu_(%out.10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1402 : __torch__.torch.nn.modules.conv.___torch_mangle_33.Conv2d = prim::GetAttr[name="conv3"](%1339)
  %1403 : Tensor = prim::GetAttr[name="weight"](%1402)
  %1404 : Tensor? = prim::GetAttr[name="bias"](%1402)
  %out.14 : Tensor = aten::conv2d(%out.12, %1403, %1404, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1409 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_34.BatchNorm2d = prim::GetAttr[name="bn3"](%1339)
  %1410 : bool = prim::GetAttr[name="training"](%1409)
   = prim::If(%1410) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1411 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1409)
      %1412 : Tensor = aten::add(%1411, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1409, %1412)
      -> ()
    block1():
      -> ()
  %1413 : bool = prim::GetAttr[name="training"](%1409)
  %1414 : Tensor = prim::GetAttr[name="running_mean"](%1409)
  %1415 : Tensor = prim::GetAttr[name="running_var"](%1409)
  %1416 : Tensor = prim::GetAttr[name="weight"](%1409)
  %1417 : Tensor = prim::GetAttr[name="bias"](%1409)
   = prim::If(%1413) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1418 : int[] = aten::size(%out.14) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.12 : int = aten::__getitem__(%1418, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1420 : int = aten::len(%1418) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1421 : int = aten::sub(%1420, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.13 : int = prim::Loop(%1421, %6, %size_prods.12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.4 : int, %size_prods.14 : int):
          %1425 : int = aten::add(%i.4, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1426 : int = aten::__getitem__(%1418, %1425) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.15 : int = aten::mul(%size_prods.14, %1426) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.15)
      %1428 : bool = aten::eq(%size_prods.13, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1428) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1429 : str = aten::format(%8, %1418) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1429) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.16 : Tensor = aten::batch_norm(%out.14, %1416, %1417, %1414, %1415, %1413, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %1431 : __torch__.torch.nn.modules.container.___torch_mangle_36.Sequential = prim::GetAttr[name="downsample"](%1339)
  %1432 : __torch__.torch.nn.modules.conv.___torch_mangle_35.Conv2d = prim::GetAttr[name="0"](%1431)
  %1433 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_34.BatchNorm2d = prim::GetAttr[name="1"](%1431)
  %1434 : Tensor = prim::GetAttr[name="weight"](%1432)
  %1435 : Tensor? = prim::GetAttr[name="bias"](%1432)
  %input.3 : Tensor = aten::conv2d(%x.15, %1434, %1435, %1655, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1440 : bool = prim::GetAttr[name="training"](%1433)
   = prim::If(%1440) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1441 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1433)
      %1442 : Tensor = aten::add(%1441, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1433, %1442)
      -> ()
    block1():
      -> ()
  %1443 : bool = prim::GetAttr[name="training"](%1433)
  %1444 : Tensor = prim::GetAttr[name="running_mean"](%1433)
  %1445 : Tensor = prim::GetAttr[name="running_var"](%1433)
  %1446 : Tensor = prim::GetAttr[name="weight"](%1433)
  %1447 : Tensor = prim::GetAttr[name="bias"](%1433)
   = prim::If(%1443) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1448 : int[] = aten::size(%input.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.24 : int = aten::__getitem__(%1448, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1450 : int = aten::len(%1448) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1451 : int = aten::sub(%1450, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.25 : int = prim::Loop(%1451, %6, %size_prods.24) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.7 : int, %size_prods.26 : int):
          %1455 : int = aten::add(%i.7, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1456 : int = aten::__getitem__(%1448, %1455) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.27 : int = aten::mul(%size_prods.26, %1456) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.27)
      %1458 : bool = aten::eq(%size_prods.25, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1458) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1459 : str = aten::format(%8, %1448) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1459) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %identity.1 : Tensor = aten::batch_norm(%input.3, %1446, %1447, %1444, %1445, %1443, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.18 : Tensor = aten::add_(%out.16, %identity.1, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.4 : Tensor = aten::relu_(%out.18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1463 : __torch__.torch.nn.modules.conv.___torch_mangle_38.Conv2d = prim::GetAttr[name="conv1"](%1340)
  %1464 : Tensor = prim::GetAttr[name="weight"](%1463)
  %1465 : Tensor? = prim::GetAttr[name="bias"](%1463)
  %out.28 : Tensor = aten::conv2d(%input.4, %1464, %1465, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1470 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="bn1"](%1340)
  %1471 : bool = prim::GetAttr[name="training"](%1470)
   = prim::If(%1471) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1472 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1470)
      %1473 : Tensor = aten::add(%1472, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1470, %1473)
      -> ()
    block1():
      -> ()
  %1474 : bool = prim::GetAttr[name="training"](%1470)
  %1475 : Tensor = prim::GetAttr[name="running_mean"](%1470)
  %1476 : Tensor = prim::GetAttr[name="running_var"](%1470)
  %1477 : Tensor = prim::GetAttr[name="weight"](%1470)
  %1478 : Tensor = prim::GetAttr[name="bias"](%1470)
   = prim::If(%1474) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1479 : int[] = aten::size(%out.28) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.28 : int = aten::__getitem__(%1479, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1481 : int = aten::len(%1479) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1482 : int = aten::sub(%1481, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.29 : int = prim::Loop(%1482, %6, %size_prods.28) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.8 : int, %size_prods.30 : int):
          %1486 : int = aten::add(%i.8, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1487 : int = aten::__getitem__(%1479, %1486) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.31 : int = aten::mul(%size_prods.30, %1487) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.31)
      %1489 : bool = aten::eq(%size_prods.29, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1489) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1490 : str = aten::format(%8, %1479) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1490) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.20 : Tensor = aten::batch_norm(%out.28, %1477, %1478, %1475, %1476, %1474, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.21 : Tensor = aten::relu_(%out.20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1493 : __torch__.torch.nn.modules.conv.___torch_mangle_39.Conv2d = prim::GetAttr[name="conv2"](%1340)
  %1494 : Tensor = prim::GetAttr[name="weight"](%1493)
  %1495 : Tensor? = prim::GetAttr[name="bias"](%1493)
  %out.22 : Tensor = aten::conv2d(%out.21, %1494, %1495, %1657, %1657, %1657, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1500 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="bn2"](%1340)
  %1501 : bool = prim::GetAttr[name="training"](%1500)
   = prim::If(%1501) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1502 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1500)
      %1503 : Tensor = aten::add(%1502, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1500, %1503)
      -> ()
    block1():
      -> ()
  %1504 : bool = prim::GetAttr[name="training"](%1500)
  %1505 : Tensor = prim::GetAttr[name="running_mean"](%1500)
  %1506 : Tensor = prim::GetAttr[name="running_var"](%1500)
  %1507 : Tensor = prim::GetAttr[name="weight"](%1500)
  %1508 : Tensor = prim::GetAttr[name="bias"](%1500)
   = prim::If(%1504) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1509 : int[] = aten::size(%out.22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.32 : int = aten::__getitem__(%1509, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1511 : int = aten::len(%1509) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1512 : int = aten::sub(%1511, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.33 : int = prim::Loop(%1512, %6, %size_prods.32) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.9 : int, %size_prods.34 : int):
          %1516 : int = aten::add(%i.9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1517 : int = aten::__getitem__(%1509, %1516) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.35 : int = aten::mul(%size_prods.34, %1517) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.35)
      %1519 : bool = aten::eq(%size_prods.33, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1519) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1520 : str = aten::format(%8, %1509) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1520) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.23 : Tensor = aten::batch_norm(%out.22, %1507, %1508, %1505, %1506, %1504, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.24 : Tensor = aten::relu_(%out.23) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1523 : __torch__.torch.nn.modules.conv.___torch_mangle_33.Conv2d = prim::GetAttr[name="conv3"](%1340)
  %1524 : Tensor = prim::GetAttr[name="weight"](%1523)
  %1525 : Tensor? = prim::GetAttr[name="bias"](%1523)
  %out.25 : Tensor = aten::conv2d(%out.24, %1524, %1525, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1530 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_34.BatchNorm2d = prim::GetAttr[name="bn3"](%1340)
  %1531 : bool = prim::GetAttr[name="training"](%1530)
   = prim::If(%1531) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1532 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1530)
      %1533 : Tensor = aten::add(%1532, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1530, %1533)
      -> ()
    block1():
      -> ()
  %1534 : bool = prim::GetAttr[name="training"](%1530)
  %1535 : Tensor = prim::GetAttr[name="running_mean"](%1530)
  %1536 : Tensor = prim::GetAttr[name="running_var"](%1530)
  %1537 : Tensor = prim::GetAttr[name="weight"](%1530)
  %1538 : Tensor = prim::GetAttr[name="bias"](%1530)
   = prim::If(%1534) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1539 : int[] = aten::size(%out.25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.36 : int = aten::__getitem__(%1539, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1541 : int = aten::len(%1539) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1542 : int = aten::sub(%1541, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.37 : int = prim::Loop(%1542, %6, %size_prods.36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.10 : int, %size_prods.38 : int):
          %1546 : int = aten::add(%i.10, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1547 : int = aten::__getitem__(%1539, %1546) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.39 : int = aten::mul(%size_prods.38, %1547) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.39)
      %1549 : bool = aten::eq(%size_prods.37, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1549) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1550 : str = aten::format(%8, %1539) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1550) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.26 : Tensor = aten::batch_norm(%out.25, %1537, %1538, %1535, %1536, %1534, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.27 : Tensor = aten::add_(%out.26, %input.4, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %input.5 : Tensor = aten::relu_(%out.27) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1554 : __torch__.torch.nn.modules.conv.___torch_mangle_38.Conv2d = prim::GetAttr[name="conv1"](%1341)
  %1555 : Tensor = prim::GetAttr[name="weight"](%1554)
  %1556 : Tensor? = prim::GetAttr[name="bias"](%1554)
  %out.1 : Tensor = aten::conv2d(%input.5, %1555, %1556, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1561 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="bn1"](%1341)
  %1562 : bool = prim::GetAttr[name="training"](%1561)
   = prim::If(%1562) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1563 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1561)
      %1564 : Tensor = aten::add(%1563, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1561, %1564)
      -> ()
    block1():
      -> ()
  %1565 : bool = prim::GetAttr[name="training"](%1561)
  %1566 : Tensor = prim::GetAttr[name="running_mean"](%1561)
  %1567 : Tensor = prim::GetAttr[name="running_var"](%1561)
  %1568 : Tensor = prim::GetAttr[name="weight"](%1561)
  %1569 : Tensor = prim::GetAttr[name="bias"](%1561)
   = prim::If(%1565) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1570 : int[] = aten::size(%out.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.2 : int = aten::__getitem__(%1570, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1572 : int = aten::len(%1570) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1573 : int = aten::sub(%1572, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.4 : int = prim::Loop(%1573, %6, %size_prods.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.2 : int, %size_prods.7 : int):
          %1577 : int = aten::add(%i.2, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1578 : int = aten::__getitem__(%1570, %1577) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.5 : int = aten::mul(%size_prods.7, %1578) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.5)
      %1580 : bool = aten::eq(%size_prods.4, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1580) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1581 : str = aten::format(%8, %1570) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1581) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.3 : Tensor = aten::batch_norm(%out.1, %1568, %1569, %1566, %1567, %1565, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.5 : Tensor = aten::relu_(%out.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1584 : __torch__.torch.nn.modules.conv.___torch_mangle_39.Conv2d = prim::GetAttr[name="conv2"](%1341)
  %1585 : Tensor = prim::GetAttr[name="weight"](%1584)
  %1586 : Tensor? = prim::GetAttr[name="bias"](%1584)
  %out.7 : Tensor = aten::conv2d(%out.5, %1585, %1586, %1657, %1657, %1657, %12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1591 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="bn2"](%1341)
  %1592 : bool = prim::GetAttr[name="training"](%1591)
   = prim::If(%1592) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1593 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1591)
      %1594 : Tensor = aten::add(%1593, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1591, %1594)
      -> ()
    block1():
      -> ()
  %1595 : bool = prim::GetAttr[name="training"](%1591)
  %1596 : Tensor = prim::GetAttr[name="running_mean"](%1591)
  %1597 : Tensor = prim::GetAttr[name="running_var"](%1591)
  %1598 : Tensor = prim::GetAttr[name="weight"](%1591)
  %1599 : Tensor = prim::GetAttr[name="bias"](%1591)
   = prim::If(%1595) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1600 : int[] = aten::size(%out.7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.8 : int = aten::__getitem__(%1600, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1602 : int = aten::len(%1600) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1603 : int = aten::sub(%1602, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.9 : int = prim::Loop(%1603, %6, %size_prods.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.3 : int, %size_prods.10 : int):
          %1607 : int = aten::add(%i.3, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1608 : int = aten::__getitem__(%1600, %1607) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.11 : int = aten::mul(%size_prods.10, %1608) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.11)
      %1610 : bool = aten::eq(%size_prods.9, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1610) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1611 : str = aten::format(%8, %1600) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1611) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.9 : Tensor = aten::batch_norm(%out.7, %1598, %1599, %1596, %1597, %1595, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.11 : Tensor = aten::relu_(%out.9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1614 : __torch__.torch.nn.modules.conv.___torch_mangle_33.Conv2d = prim::GetAttr[name="conv3"](%1341)
  %1615 : Tensor = prim::GetAttr[name="weight"](%1614)
  %1616 : Tensor? = prim::GetAttr[name="bias"](%1614)
  %out.13 : Tensor = aten::conv2d(%out.11, %1615, %1616, %1657, %1663, %1657, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1621 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_34.BatchNorm2d = prim::GetAttr[name="bn3"](%1341)
  %1622 : bool = prim::GetAttr[name="training"](%1621)
   = prim::If(%1622) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1623 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1621)
      %1624 : Tensor = aten::add(%1623, %3, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1621, %1624)
      -> ()
    block1():
      -> ()
  %1625 : bool = prim::GetAttr[name="training"](%1621)
  %1626 : Tensor = prim::GetAttr[name="running_mean"](%1621)
  %1627 : Tensor = prim::GetAttr[name="running_var"](%1621)
  %1628 : Tensor = prim::GetAttr[name="weight"](%1621)
  %1629 : Tensor = prim::GetAttr[name="bias"](%1621)
   = prim::If(%1625) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1630 : int[] = aten::size(%out.13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.1 : int = aten::__getitem__(%1630, %7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1632 : int = aten::len(%1630) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1633 : int = aten::sub(%1632, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods : int = prim::Loop(%1633, %6, %size_prods.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.1 : int, %size_prods.6 : int):
          %1637 : int = aten::add(%i.1, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1638 : int = aten::__getitem__(%1630, %1637) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.3 : int = aten::mul(%size_prods.6, %1638) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%6, %size_prods.3)
      %1640 : bool = aten::eq(%size_prods, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1640) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1641 : str = aten::format(%8, %1630) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1641) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %out.15 : Tensor = aten::batch_norm(%out.13, %1628, %1629, %1626, %1627, %1625, %9, %10, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %out.17 : Tensor = aten::add_(%out.15, %input.5, %3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:138:8
  %x.17 : Tensor = aten::relu_(%out.17) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1646 : int[] = aten::size(%x.17) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1036:51
  %1647 : int = aten::len(%1646) # <string>:5:9
  %1648 : bool = aten::gt(%1647, %5) # <string>:5:9
   = prim::If(%1648) # <string>:5:2
    block0():
      -> ()
    block1():
       = prim::RaiseException(%13) # <string>:5:2
      -> ()
  %x.19 : Tensor = aten::adaptive_avg_pool2d(%x.17, %1657) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
  %x.21 : Tensor = aten::flatten(%x.19, %3, %2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/resnet.py:243:12
  %1651 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="fc"](%self)
  %1652 : Tensor = prim::GetAttr[name="weight"](%1651)
  %1653 : Tensor = prim::GetAttr[name="bias"](%1651)
  %x.23 : Tensor = aten::linear(%x.21, %1652, %1653) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
  return (%x.23)

