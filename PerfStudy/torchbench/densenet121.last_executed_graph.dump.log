Dump Graph IR for densenet121 using example inputs:
graph(%self : __torch__.torchvision.models.densenet.DenseNet,
      %x.1 : Tensor):
  %6205 : int[] = prim::Constant[value=[0, 0]]()
  %6199 : int[] = prim::Constant[value=[1, 1]]()
  %6198 : int[] = prim::Constant[value=[3, 3]]()
  %6197 : int[] = prim::Constant[value=[2, 2]]()
  %20 : int = prim::Constant[value=-1]()
  %19 : int = prim::Constant[value=1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:218:42
  %18 : None = prim::Constant() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/pooling.py:616:82
  %17 : str = prim::Constant[value="dropout probability has to be between 0 and 1, but got {}"]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
  %16 : float = prim::Constant[value=0.]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:11
  %15 : float = prim::Constant[value=1.]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:22
  %14 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
  %13 : int = prim::Constant[value=4]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:26
  %12 : int = prim::Constant[value=9223372036854775807]()
  %11 : str = prim::Constant[value="Memory Efficient not supported in JIT"]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:32
  %10 : bool = prim::Constant[value=0]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/pooling.py:163:57
  %9 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:140:77
  %8 : float = prim::Constant[value=0.10000000000000001]()
  %7 : str = prim::Constant[value="Expected more than 1 value per channel when training, got input size {}"]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
  %6 : int = prim::Constant[value=0]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:22
  %5 : bool = prim::Constant[value=1]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2147:81
  %4 : int = prim::Constant[value=2]() # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:45
  %2 : str = prim::Constant[value="AssertionError: "]()
  %21 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="features"](%self)
  %22 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name="conv0"](%21)
  %23 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="norm0"](%21)
  %24 : __torch__.torchvision.models.densenet._DenseBlock = prim::GetAttr[name="denseblock1"](%21)
  %25 : __torch__.torchvision.models.densenet._Transition = prim::GetAttr[name="transition1"](%21)
  %26 : __torch__.torchvision.models.densenet.___torch_mangle_41._DenseBlock = prim::GetAttr[name="denseblock2"](%21)
  %27 : __torch__.torchvision.models.densenet.___torch_mangle_44._Transition = prim::GetAttr[name="transition2"](%21)
  %28 : __torch__.torchvision.models.densenet.___torch_mangle_92._DenseBlock = prim::GetAttr[name="denseblock3"](%21)
  %29 : __torch__.torchvision.models.densenet.___torch_mangle_95._Transition = prim::GetAttr[name="transition3"](%21)
  %30 : __torch__.torchvision.models.densenet.___torch_mangle_96._DenseBlock = prim::GetAttr[name="denseblock4"](%21)
  %31 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_93.BatchNorm2d = prim::GetAttr[name="norm5"](%21)
  %32 : Tensor = prim::GetAttr[name="weight"](%22)
  %33 : Tensor? = prim::GetAttr[name="bias"](%22)
  %input.4 : Tensor = aten::conv2d(%x.1, %32, %33, %6197, %6198, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %38 : bool = prim::GetAttr[name="training"](%23)
   = prim::If(%38) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %39 : Tensor = prim::GetAttr[name="num_batches_tracked"](%23)
      %40 : Tensor = aten::add(%39, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%23, %40)
      -> ()
    block1():
      -> ()
  %41 : bool = prim::GetAttr[name="training"](%23)
  %42 : Tensor = prim::GetAttr[name="running_mean"](%23)
  %43 : Tensor = prim::GetAttr[name="running_var"](%23)
  %44 : Tensor = prim::GetAttr[name="weight"](%23)
  %45 : Tensor = prim::GetAttr[name="bias"](%23)
   = prim::If(%41) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %46 : int[] = aten::size(%input.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.244 : int = aten::__getitem__(%46, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %48 : int = aten::len(%46) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %49 : int = aten::sub(%48, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.245 : int = prim::Loop(%49, %5, %size_prods.244) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.62 : int, %size_prods.246 : int):
          %53 : int = aten::add(%i.62, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %54 : int = aten::__getitem__(%46, %53) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.247 : int = aten::mul(%size_prods.246, %54) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.247)
      %56 : bool = aten::eq(%size_prods.245, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %57 : str = aten::format(%7, %46) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%57) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.6 : Tensor = aten::batch_norm(%input.4, %44, %45, %42, %43, %41, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %input.8 : Tensor = aten::relu_(%input.6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %input.10 : Tensor = aten::max_pool2d(%input.8, %6198, %6197, %6199, %6199, %10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:659:11
  %features.2 : Tensor[] = prim::ListConstruct(%input.10)
  %66 : __torch__.torchvision.models.densenet._DenseLayer = prim::GetAttr[name="denselayer1"](%24)
  %67 : __torch__.torchvision.models.densenet.___torch_mangle_5._DenseLayer = prim::GetAttr[name="denselayer2"](%24)
  %68 : __torch__.torchvision.models.densenet.___torch_mangle_7._DenseLayer = prim::GetAttr[name="denselayer3"](%24)
  %69 : __torch__.torchvision.models.densenet.___torch_mangle_10._DenseLayer = prim::GetAttr[name="denselayer4"](%24)
  %70 : __torch__.torchvision.models.densenet.___torch_mangle_13._DenseLayer = prim::GetAttr[name="denselayer5"](%24)
  %71 : __torch__.torchvision.models.densenet.___torch_mangle_16._DenseLayer = prim::GetAttr[name="denselayer6"](%24)
  %72 : Tensor = prim::Uninitialized()
  %73 : bool = prim::GetAttr[name="memory_efficient"](%66)
  %74 : bool = prim::If(%73) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %75 : bool = prim::Uninitialized()
      %76 : int = aten::len(%features.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %77 : bool = aten::gt(%76, %6)
      %78 : bool, %79 : bool, %80 : int = prim::Loop(%12, %77, %10, %75, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%81 : int, %82 : bool, %83 : bool, %84 : int):
          %tensor.34 : Tensor = aten::__getitem__(%features.2, %84) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %86 : bool = prim::requires_grad(%tensor.34)
          %87 : bool, %88 : bool = prim::If(%86) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %75)
          %89 : int = aten::add(%84, %19)
          %90 : bool = aten::lt(%89, %76)
          %91 : bool = aten::__and__(%90, %87)
          -> (%91, %86, %88, %89)
      %92 : bool = prim::If(%78)
        block0():
          -> (%79)
        block1():
          -> (%10)
      -> (%92)
    block1():
      -> (%10)
  %bottleneck_output.66 : Tensor = prim::If(%74) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.34 : Tensor = aten::cat(%features.2, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %95 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="conv1"](%66)
      %96 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="norm1"](%66)
      %97 : int = aten::dim(%concated_features.34) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %98 : bool = aten::ne(%97, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%98) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %100 : str = aten::format(%14, %97) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %101 : bool = prim::GetAttr[name="training"](%96)
       = prim::If(%101) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %102 : Tensor = prim::GetAttr[name="num_batches_tracked"](%96)
          %103 : Tensor = aten::add(%102, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%96, %103)
          -> ()
        block1():
          -> ()
      %104 : bool = prim::GetAttr[name="training"](%96)
      %105 : Tensor = prim::GetAttr[name="running_mean"](%96)
      %106 : Tensor = prim::GetAttr[name="running_var"](%96)
      %107 : Tensor = prim::GetAttr[name="weight"](%96)
      %108 : Tensor = prim::GetAttr[name="bias"](%96)
       = prim::If(%104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %109 : int[] = aten::size(%concated_features.34) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.252 : int = aten::__getitem__(%109, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %111 : int = aten::len(%109) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %112 : int = aten::sub(%111, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.253 : int = prim::Loop(%112, %5, %size_prods.252) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.64 : int, %size_prods.254 : int):
              %116 : int = aten::add(%i.64, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %117 : int = aten::__getitem__(%109, %116) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.255 : int = aten::mul(%size_prods.254, %117) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.255)
          %119 : bool = aten::eq(%size_prods.253, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%119) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %120 : str = aten::format(%7, %109) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %121 : Tensor = aten::batch_norm(%concated_features.34, %107, %108, %105, %106, %104, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.67 : Tensor = aten::relu_(%121) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %123 : Tensor = prim::GetAttr[name="weight"](%95)
      %124 : Tensor? = prim::GetAttr[name="bias"](%95)
      %bottleneck_output.67 : Tensor = aten::conv2d(%result.67, %123, %124, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.67)
  %129 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%66)
  %130 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%66)
  %131 : int = aten::dim(%bottleneck_output.66) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %132 : bool = aten::ne(%131, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%132) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %134 : str = aten::format(%14, %131) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%134) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %135 : bool = prim::GetAttr[name="training"](%130)
   = prim::If(%135) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %136 : Tensor = prim::GetAttr[name="num_batches_tracked"](%130)
      %137 : Tensor = aten::add(%136, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%130, %137)
      -> ()
    block1():
      -> ()
  %138 : bool = prim::GetAttr[name="training"](%130)
  %139 : Tensor = prim::GetAttr[name="running_mean"](%130)
  %140 : Tensor = prim::GetAttr[name="running_var"](%130)
  %141 : Tensor = prim::GetAttr[name="weight"](%130)
  %142 : Tensor = prim::GetAttr[name="bias"](%130)
   = prim::If(%138) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %143 : int[] = aten::size(%bottleneck_output.66) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.256 : int = aten::__getitem__(%143, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %145 : int = aten::len(%143) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %146 : int = aten::sub(%145, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.257 : int = prim::Loop(%146, %5, %size_prods.256) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.65 : int, %size_prods.258 : int):
          %150 : int = aten::add(%i.65, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %151 : int = aten::__getitem__(%143, %150) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.259 : int = aten::mul(%size_prods.258, %151) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.259)
      %153 : bool = aten::eq(%size_prods.257, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%153) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %154 : str = aten::format(%7, %143) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%154) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %155 : Tensor = aten::batch_norm(%bottleneck_output.66, %141, %142, %139, %140, %138, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.68 : Tensor = aten::relu_(%155) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %157 : Tensor = prim::GetAttr[name="weight"](%129)
  %158 : Tensor? = prim::GetAttr[name="bias"](%129)
  %new_features.59 : Tensor = aten::conv2d(%result.68, %157, %158, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %163 : float = prim::GetAttr[name="drop_rate"](%66)
  %164 : bool = aten::gt(%163, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.69 : Tensor = prim::If(%164) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %167 : bool = prim::GetAttr[name="training"](%66)
      %168 : bool = aten::lt(%163, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %169 : bool = prim::If(%168) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %170 : bool = aten::gt(%163, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%170)
       = prim::If(%169) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %171 : str = aten::format(%17, %163) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%171) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %172 : Tensor = aten::dropout(%new_features.59, %163, %167) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%172)
    block1():
      -> (%new_features.59)
  %173 : Tensor[] = aten::append(%features.2, %new_features.69) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %175 : bool = prim::GetAttr[name="memory_efficient"](%67)
  %176 : bool = prim::If(%175) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %177 : bool = prim::Uninitialized()
      %178 : int = aten::len(%features.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %179 : bool = aten::gt(%178, %6)
      %180 : bool, %181 : bool, %182 : int = prim::Loop(%12, %179, %10, %177, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%183 : int, %184 : bool, %185 : bool, %186 : int):
          %tensor.30 : Tensor = aten::__getitem__(%features.2, %186) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %188 : bool = prim::requires_grad(%tensor.30)
          %189 : bool, %190 : bool = prim::If(%188) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %177)
          %191 : int = aten::add(%186, %19)
          %192 : bool = aten::lt(%191, %178)
          %193 : bool = aten::__and__(%192, %189)
          -> (%193, %188, %190, %191)
      %194 : bool = prim::If(%180)
        block0():
          -> (%181)
        block1():
          -> (%10)
      -> (%194)
    block1():
      -> (%10)
  %bottleneck_output.58 : Tensor = prim::If(%176) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.30 : Tensor = aten::cat(%features.2, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %197 : __torch__.torch.nn.modules.conv.___torch_mangle_4.Conv2d = prim::GetAttr[name="conv1"](%67)
      %198 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_3.BatchNorm2d = prim::GetAttr[name="norm1"](%67)
      %199 : int = aten::dim(%concated_features.30) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %200 : bool = aten::ne(%199, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%200) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %202 : str = aten::format(%14, %199) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%202) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %203 : bool = prim::GetAttr[name="training"](%198)
       = prim::If(%203) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %204 : Tensor = prim::GetAttr[name="num_batches_tracked"](%198)
          %205 : Tensor = aten::add(%204, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%198, %205)
          -> ()
        block1():
          -> ()
      %206 : bool = prim::GetAttr[name="training"](%198)
      %207 : Tensor = prim::GetAttr[name="running_mean"](%198)
      %208 : Tensor = prim::GetAttr[name="running_var"](%198)
      %209 : Tensor = prim::GetAttr[name="weight"](%198)
      %210 : Tensor = prim::GetAttr[name="bias"](%198)
       = prim::If(%206) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %211 : int[] = aten::size(%concated_features.30) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.260 : int = aten::__getitem__(%211, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %213 : int = aten::len(%211) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %214 : int = aten::sub(%213, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.261 : int = prim::Loop(%214, %5, %size_prods.260) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.66 : int, %size_prods.262 : int):
              %218 : int = aten::add(%i.66, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %219 : int = aten::__getitem__(%211, %218) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.263 : int = aten::mul(%size_prods.262, %219) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.263)
          %221 : bool = aten::eq(%size_prods.261, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%221) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %222 : str = aten::format(%7, %211) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%222) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %223 : Tensor = aten::batch_norm(%concated_features.30, %209, %210, %207, %208, %206, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.59 : Tensor = aten::relu_(%223) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %225 : Tensor = prim::GetAttr[name="weight"](%197)
      %226 : Tensor? = prim::GetAttr[name="bias"](%197)
      %bottleneck_output.59 : Tensor = aten::conv2d(%result.59, %225, %226, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.59)
  %231 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%67)
  %232 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%67)
  %233 : int = aten::dim(%bottleneck_output.58) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %234 : bool = aten::ne(%233, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%234) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %236 : str = aten::format(%14, %233) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%236) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %237 : bool = prim::GetAttr[name="training"](%232)
   = prim::If(%237) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %238 : Tensor = prim::GetAttr[name="num_batches_tracked"](%232)
      %239 : Tensor = aten::add(%238, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%232, %239)
      -> ()
    block1():
      -> ()
  %240 : bool = prim::GetAttr[name="training"](%232)
  %241 : Tensor = prim::GetAttr[name="running_mean"](%232)
  %242 : Tensor = prim::GetAttr[name="running_var"](%232)
  %243 : Tensor = prim::GetAttr[name="weight"](%232)
  %244 : Tensor = prim::GetAttr[name="bias"](%232)
   = prim::If(%240) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %245 : int[] = aten::size(%bottleneck_output.58) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.264 : int = aten::__getitem__(%245, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %247 : int = aten::len(%245) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %248 : int = aten::sub(%247, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.265 : int = prim::Loop(%248, %5, %size_prods.264) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.67 : int, %size_prods.266 : int):
          %252 : int = aten::add(%i.67, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %253 : int = aten::__getitem__(%245, %252) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.267 : int = aten::mul(%size_prods.266, %253) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.267)
      %255 : bool = aten::eq(%size_prods.265, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%255) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %256 : str = aten::format(%7, %245) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%256) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %257 : Tensor = aten::batch_norm(%bottleneck_output.58, %243, %244, %241, %242, %240, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.60 : Tensor = aten::relu_(%257) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %259 : Tensor = prim::GetAttr[name="weight"](%231)
  %260 : Tensor? = prim::GetAttr[name="bias"](%231)
  %new_features.61 : Tensor = aten::conv2d(%result.60, %259, %260, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %265 : float = prim::GetAttr[name="drop_rate"](%67)
  %266 : bool = aten::gt(%265, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.62 : Tensor = prim::If(%266) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %269 : bool = prim::GetAttr[name="training"](%67)
      %270 : bool = aten::lt(%265, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %271 : bool = prim::If(%270) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %272 : bool = aten::gt(%265, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%272)
       = prim::If(%271) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %273 : str = aten::format(%17, %265) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%273) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %274 : Tensor = aten::dropout(%new_features.61, %265, %269) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%274)
    block1():
      -> (%new_features.61)
  %275 : Tensor[] = aten::append(%features.2, %new_features.62) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %277 : bool = prim::GetAttr[name="memory_efficient"](%68)
  %278 : bool = prim::If(%277) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %279 : bool = prim::Uninitialized()
      %280 : int = aten::len(%features.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %281 : bool = aten::gt(%280, %6)
      %282 : bool, %283 : bool, %284 : int = prim::Loop(%12, %281, %10, %279, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%285 : int, %286 : bool, %287 : bool, %288 : int):
          %tensor.31 : Tensor = aten::__getitem__(%features.2, %288) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %290 : bool = prim::requires_grad(%tensor.31)
          %291 : bool, %292 : bool = prim::If(%290) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %279)
          %293 : int = aten::add(%288, %19)
          %294 : bool = aten::lt(%293, %280)
          %295 : bool = aten::__and__(%294, %291)
          -> (%295, %290, %292, %293)
      %296 : bool = prim::If(%282)
        block0():
          -> (%283)
        block1():
          -> (%10)
      -> (%296)
    block1():
      -> (%10)
  %bottleneck_output.60 : Tensor = prim::If(%278) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.31 : Tensor = aten::cat(%features.2, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %299 : __torch__.torch.nn.modules.conv.___torch_mangle_6.Conv2d = prim::GetAttr[name="conv1"](%68)
      %300 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm1"](%68)
      %301 : int = aten::dim(%concated_features.31) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %302 : bool = aten::ne(%301, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%302) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %304 : str = aten::format(%14, %301) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%304) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %305 : bool = prim::GetAttr[name="training"](%300)
       = prim::If(%305) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %306 : Tensor = prim::GetAttr[name="num_batches_tracked"](%300)
          %307 : Tensor = aten::add(%306, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%300, %307)
          -> ()
        block1():
          -> ()
      %308 : bool = prim::GetAttr[name="training"](%300)
      %309 : Tensor = prim::GetAttr[name="running_mean"](%300)
      %310 : Tensor = prim::GetAttr[name="running_var"](%300)
      %311 : Tensor = prim::GetAttr[name="weight"](%300)
      %312 : Tensor = prim::GetAttr[name="bias"](%300)
       = prim::If(%308) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %313 : int[] = aten::size(%concated_features.31) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.268 : int = aten::__getitem__(%313, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %315 : int = aten::len(%313) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %316 : int = aten::sub(%315, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.269 : int = prim::Loop(%316, %5, %size_prods.268) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.68 : int, %size_prods.270 : int):
              %320 : int = aten::add(%i.68, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %321 : int = aten::__getitem__(%313, %320) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.271 : int = aten::mul(%size_prods.270, %321) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.271)
          %323 : bool = aten::eq(%size_prods.269, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%323) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %324 : str = aten::format(%7, %313) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%324) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %325 : Tensor = aten::batch_norm(%concated_features.31, %311, %312, %309, %310, %308, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.61 : Tensor = aten::relu_(%325) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %327 : Tensor = prim::GetAttr[name="weight"](%299)
      %328 : Tensor? = prim::GetAttr[name="bias"](%299)
      %bottleneck_output.61 : Tensor = aten::conv2d(%result.61, %327, %328, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.61)
  %333 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%68)
  %334 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%68)
  %335 : int = aten::dim(%bottleneck_output.60) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %336 : bool = aten::ne(%335, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%336) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %338 : str = aten::format(%14, %335) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%338) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %339 : bool = prim::GetAttr[name="training"](%334)
   = prim::If(%339) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %340 : Tensor = prim::GetAttr[name="num_batches_tracked"](%334)
      %341 : Tensor = aten::add(%340, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%334, %341)
      -> ()
    block1():
      -> ()
  %342 : bool = prim::GetAttr[name="training"](%334)
  %343 : Tensor = prim::GetAttr[name="running_mean"](%334)
  %344 : Tensor = prim::GetAttr[name="running_var"](%334)
  %345 : Tensor = prim::GetAttr[name="weight"](%334)
  %346 : Tensor = prim::GetAttr[name="bias"](%334)
   = prim::If(%342) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %347 : int[] = aten::size(%bottleneck_output.60) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.272 : int = aten::__getitem__(%347, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %349 : int = aten::len(%347) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %350 : int = aten::sub(%349, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.273 : int = prim::Loop(%350, %5, %size_prods.272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.69 : int, %size_prods.274 : int):
          %354 : int = aten::add(%i.69, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %355 : int = aten::__getitem__(%347, %354) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.275 : int = aten::mul(%size_prods.274, %355) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.275)
      %357 : bool = aten::eq(%size_prods.273, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%357) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %358 : str = aten::format(%7, %347) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%358) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %359 : Tensor = aten::batch_norm(%bottleneck_output.60, %345, %346, %343, %344, %342, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.62 : Tensor = aten::relu_(%359) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %361 : Tensor = prim::GetAttr[name="weight"](%333)
  %362 : Tensor? = prim::GetAttr[name="bias"](%333)
  %new_features.63 : Tensor = aten::conv2d(%result.62, %361, %362, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %367 : float = prim::GetAttr[name="drop_rate"](%68)
  %368 : bool = aten::gt(%367, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.64 : Tensor = prim::If(%368) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %371 : bool = prim::GetAttr[name="training"](%68)
      %372 : bool = aten::lt(%367, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %373 : bool = prim::If(%372) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %374 : bool = aten::gt(%367, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%374)
       = prim::If(%373) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %375 : str = aten::format(%17, %367) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%375) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %376 : Tensor = aten::dropout(%new_features.63, %367, %371) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%376)
    block1():
      -> (%new_features.63)
  %377 : Tensor[] = aten::append(%features.2, %new_features.64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %379 : bool = prim::GetAttr[name="memory_efficient"](%69)
  %380 : bool = prim::If(%379) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %381 : bool = prim::Uninitialized()
      %382 : int = aten::len(%features.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %383 : bool = aten::gt(%382, %6)
      %384 : bool, %385 : bool, %386 : int = prim::Loop(%12, %383, %10, %381, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%387 : int, %388 : bool, %389 : bool, %390 : int):
          %tensor.32 : Tensor = aten::__getitem__(%features.2, %390) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %392 : bool = prim::requires_grad(%tensor.32)
          %393 : bool, %394 : bool = prim::If(%392) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %381)
          %395 : int = aten::add(%390, %19)
          %396 : bool = aten::lt(%395, %382)
          %397 : bool = aten::__and__(%396, %393)
          -> (%397, %392, %394, %395)
      %398 : bool = prim::If(%384)
        block0():
          -> (%385)
        block1():
          -> (%10)
      -> (%398)
    block1():
      -> (%10)
  %bottleneck_output.62 : Tensor = prim::If(%380) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.32 : Tensor = aten::cat(%features.2, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %401 : __torch__.torch.nn.modules.conv.___torch_mangle_9.Conv2d = prim::GetAttr[name="conv1"](%69)
      %402 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="norm1"](%69)
      %403 : int = aten::dim(%concated_features.32) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %404 : bool = aten::ne(%403, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%404) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %406 : str = aten::format(%14, %403) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%406) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %407 : bool = prim::GetAttr[name="training"](%402)
       = prim::If(%407) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %408 : Tensor = prim::GetAttr[name="num_batches_tracked"](%402)
          %409 : Tensor = aten::add(%408, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%402, %409)
          -> ()
        block1():
          -> ()
      %410 : bool = prim::GetAttr[name="training"](%402)
      %411 : Tensor = prim::GetAttr[name="running_mean"](%402)
      %412 : Tensor = prim::GetAttr[name="running_var"](%402)
      %413 : Tensor = prim::GetAttr[name="weight"](%402)
      %414 : Tensor = prim::GetAttr[name="bias"](%402)
       = prim::If(%410) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %415 : int[] = aten::size(%concated_features.32) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.276 : int = aten::__getitem__(%415, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %417 : int = aten::len(%415) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %418 : int = aten::sub(%417, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.277 : int = prim::Loop(%418, %5, %size_prods.276) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.70 : int, %size_prods.278 : int):
              %422 : int = aten::add(%i.70, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %423 : int = aten::__getitem__(%415, %422) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.279 : int = aten::mul(%size_prods.278, %423) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.279)
          %425 : bool = aten::eq(%size_prods.277, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%425) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %426 : str = aten::format(%7, %415) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%426) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %427 : Tensor = aten::batch_norm(%concated_features.32, %413, %414, %411, %412, %410, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.63 : Tensor = aten::relu_(%427) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %429 : Tensor = prim::GetAttr[name="weight"](%401)
      %430 : Tensor? = prim::GetAttr[name="bias"](%401)
      %bottleneck_output.63 : Tensor = aten::conv2d(%result.63, %429, %430, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.63)
  %435 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%69)
  %436 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%69)
  %437 : int = aten::dim(%bottleneck_output.62) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %438 : bool = aten::ne(%437, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%438) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %440 : str = aten::format(%14, %437) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%440) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %441 : bool = prim::GetAttr[name="training"](%436)
   = prim::If(%441) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %442 : Tensor = prim::GetAttr[name="num_batches_tracked"](%436)
      %443 : Tensor = aten::add(%442, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%436, %443)
      -> ()
    block1():
      -> ()
  %444 : bool = prim::GetAttr[name="training"](%436)
  %445 : Tensor = prim::GetAttr[name="running_mean"](%436)
  %446 : Tensor = prim::GetAttr[name="running_var"](%436)
  %447 : Tensor = prim::GetAttr[name="weight"](%436)
  %448 : Tensor = prim::GetAttr[name="bias"](%436)
   = prim::If(%444) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %449 : int[] = aten::size(%bottleneck_output.62) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.280 : int = aten::__getitem__(%449, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %451 : int = aten::len(%449) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %452 : int = aten::sub(%451, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.281 : int = prim::Loop(%452, %5, %size_prods.280) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.71 : int, %size_prods.282 : int):
          %456 : int = aten::add(%i.71, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %457 : int = aten::__getitem__(%449, %456) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.283 : int = aten::mul(%size_prods.282, %457) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.283)
      %459 : bool = aten::eq(%size_prods.281, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%459) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %460 : str = aten::format(%7, %449) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%460) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %461 : Tensor = aten::batch_norm(%bottleneck_output.62, %447, %448, %445, %446, %444, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.64 : Tensor = aten::relu_(%461) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %463 : Tensor = prim::GetAttr[name="weight"](%435)
  %464 : Tensor? = prim::GetAttr[name="bias"](%435)
  %new_features.65 : Tensor = aten::conv2d(%result.64, %463, %464, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %469 : float = prim::GetAttr[name="drop_rate"](%69)
  %470 : bool = aten::gt(%469, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.66 : Tensor = prim::If(%470) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %473 : bool = prim::GetAttr[name="training"](%69)
      %474 : bool = aten::lt(%469, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %475 : bool = prim::If(%474) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %476 : bool = aten::gt(%469, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%476)
       = prim::If(%475) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %477 : str = aten::format(%17, %469) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%477) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %478 : Tensor = aten::dropout(%new_features.65, %469, %473) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%478)
    block1():
      -> (%new_features.65)
  %479 : Tensor[] = aten::append(%features.2, %new_features.66) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %481 : bool = prim::GetAttr[name="memory_efficient"](%70)
  %482 : bool = prim::If(%481) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %483 : bool = prim::Uninitialized()
      %484 : int = aten::len(%features.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %485 : bool = aten::gt(%484, %6)
      %486 : bool, %487 : bool, %488 : int = prim::Loop(%12, %485, %10, %483, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%489 : int, %490 : bool, %491 : bool, %492 : int):
          %tensor.33 : Tensor = aten::__getitem__(%features.2, %492) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %494 : bool = prim::requires_grad(%tensor.33)
          %495 : bool, %496 : bool = prim::If(%494) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %483)
          %497 : int = aten::add(%492, %19)
          %498 : bool = aten::lt(%497, %484)
          %499 : bool = aten::__and__(%498, %495)
          -> (%499, %494, %496, %497)
      %500 : bool = prim::If(%486)
        block0():
          -> (%487)
        block1():
          -> (%10)
      -> (%500)
    block1():
      -> (%10)
  %bottleneck_output.64 : Tensor = prim::If(%482) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.33 : Tensor = aten::cat(%features.2, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %503 : __torch__.torch.nn.modules.conv.___torch_mangle_12.Conv2d = prim::GetAttr[name="conv1"](%70)
      %504 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_11.BatchNorm2d = prim::GetAttr[name="norm1"](%70)
      %505 : int = aten::dim(%concated_features.33) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %506 : bool = aten::ne(%505, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%506) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %508 : str = aten::format(%14, %505) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%508) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %509 : bool = prim::GetAttr[name="training"](%504)
       = prim::If(%509) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %510 : Tensor = prim::GetAttr[name="num_batches_tracked"](%504)
          %511 : Tensor = aten::add(%510, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%504, %511)
          -> ()
        block1():
          -> ()
      %512 : bool = prim::GetAttr[name="training"](%504)
      %513 : Tensor = prim::GetAttr[name="running_mean"](%504)
      %514 : Tensor = prim::GetAttr[name="running_var"](%504)
      %515 : Tensor = prim::GetAttr[name="weight"](%504)
      %516 : Tensor = prim::GetAttr[name="bias"](%504)
       = prim::If(%512) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %517 : int[] = aten::size(%concated_features.33) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.284 : int = aten::__getitem__(%517, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %519 : int = aten::len(%517) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %520 : int = aten::sub(%519, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.285 : int = prim::Loop(%520, %5, %size_prods.284) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.72 : int, %size_prods.286 : int):
              %524 : int = aten::add(%i.72, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %525 : int = aten::__getitem__(%517, %524) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.287 : int = aten::mul(%size_prods.286, %525) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.287)
          %527 : bool = aten::eq(%size_prods.285, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%527) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %528 : str = aten::format(%7, %517) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%528) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %529 : Tensor = aten::batch_norm(%concated_features.33, %515, %516, %513, %514, %512, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.65 : Tensor = aten::relu_(%529) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %531 : Tensor = prim::GetAttr[name="weight"](%503)
      %532 : Tensor? = prim::GetAttr[name="bias"](%503)
      %bottleneck_output.65 : Tensor = aten::conv2d(%result.65, %531, %532, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.65)
  %537 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%70)
  %538 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%70)
  %539 : int = aten::dim(%bottleneck_output.64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %540 : bool = aten::ne(%539, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%540) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %542 : str = aten::format(%14, %539) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%542) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %543 : bool = prim::GetAttr[name="training"](%538)
   = prim::If(%543) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %544 : Tensor = prim::GetAttr[name="num_batches_tracked"](%538)
      %545 : Tensor = aten::add(%544, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%538, %545)
      -> ()
    block1():
      -> ()
  %546 : bool = prim::GetAttr[name="training"](%538)
  %547 : Tensor = prim::GetAttr[name="running_mean"](%538)
  %548 : Tensor = prim::GetAttr[name="running_var"](%538)
  %549 : Tensor = prim::GetAttr[name="weight"](%538)
  %550 : Tensor = prim::GetAttr[name="bias"](%538)
   = prim::If(%546) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %551 : int[] = aten::size(%bottleneck_output.64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.288 : int = aten::__getitem__(%551, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %553 : int = aten::len(%551) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %554 : int = aten::sub(%553, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.289 : int = prim::Loop(%554, %5, %size_prods.288) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.73 : int, %size_prods.290 : int):
          %558 : int = aten::add(%i.73, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %559 : int = aten::__getitem__(%551, %558) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.291 : int = aten::mul(%size_prods.290, %559) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.291)
      %561 : bool = aten::eq(%size_prods.289, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%561) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %562 : str = aten::format(%7, %551) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%562) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %563 : Tensor = aten::batch_norm(%bottleneck_output.64, %549, %550, %547, %548, %546, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.66 : Tensor = aten::relu_(%563) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %565 : Tensor = prim::GetAttr[name="weight"](%537)
  %566 : Tensor? = prim::GetAttr[name="bias"](%537)
  %new_features.67 : Tensor = aten::conv2d(%result.66, %565, %566, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %571 : float = prim::GetAttr[name="drop_rate"](%70)
  %572 : bool = aten::gt(%571, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.68 : Tensor = prim::If(%572) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %575 : bool = prim::GetAttr[name="training"](%70)
      %576 : bool = aten::lt(%571, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %577 : bool = prim::If(%576) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %578 : bool = aten::gt(%571, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%578)
       = prim::If(%577) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %579 : str = aten::format(%17, %571) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%579) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %580 : Tensor = aten::dropout(%new_features.67, %571, %575) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%580)
    block1():
      -> (%new_features.67)
  %581 : Tensor[] = aten::append(%features.2, %new_features.68) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %583 : bool = prim::GetAttr[name="memory_efficient"](%71)
  %584 : bool = prim::If(%583) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %585 : bool = prim::Uninitialized()
      %586 : int = aten::len(%features.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %587 : bool = aten::gt(%586, %6)
      %588 : bool, %589 : bool, %590 : int = prim::Loop(%12, %587, %10, %585, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%591 : int, %592 : bool, %593 : bool, %594 : int):
          %tensor.35 : Tensor = aten::__getitem__(%features.2, %594) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %596 : bool = prim::requires_grad(%tensor.35)
          %597 : bool, %598 : bool = prim::If(%596) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %585)
          %599 : int = aten::add(%594, %19)
          %600 : bool = aten::lt(%599, %586)
          %601 : bool = aten::__and__(%600, %597)
          -> (%601, %596, %598, %599)
      %602 : bool = prim::If(%588)
        block0():
          -> (%589)
        block1():
          -> (%10)
      -> (%602)
    block1():
      -> (%10)
  %bottleneck_output.68 : Tensor = prim::If(%584) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.35 : Tensor = aten::cat(%features.2, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %605 : __torch__.torch.nn.modules.conv.___torch_mangle_15.Conv2d = prim::GetAttr[name="conv1"](%71)
      %606 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_14.BatchNorm2d = prim::GetAttr[name="norm1"](%71)
      %607 : int = aten::dim(%concated_features.35) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %608 : bool = aten::ne(%607, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%608) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %610 : str = aten::format(%14, %607) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%610) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %611 : bool = prim::GetAttr[name="training"](%606)
       = prim::If(%611) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %612 : Tensor = prim::GetAttr[name="num_batches_tracked"](%606)
          %613 : Tensor = aten::add(%612, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%606, %613)
          -> ()
        block1():
          -> ()
      %614 : bool = prim::GetAttr[name="training"](%606)
      %615 : Tensor = prim::GetAttr[name="running_mean"](%606)
      %616 : Tensor = prim::GetAttr[name="running_var"](%606)
      %617 : Tensor = prim::GetAttr[name="weight"](%606)
      %618 : Tensor = prim::GetAttr[name="bias"](%606)
       = prim::If(%614) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %619 : int[] = aten::size(%concated_features.35) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.292 : int = aten::__getitem__(%619, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %621 : int = aten::len(%619) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %622 : int = aten::sub(%621, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.293 : int = prim::Loop(%622, %5, %size_prods.292) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.74 : int, %size_prods.294 : int):
              %626 : int = aten::add(%i.74, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %627 : int = aten::__getitem__(%619, %626) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.295 : int = aten::mul(%size_prods.294, %627) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.295)
          %629 : bool = aten::eq(%size_prods.293, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%629) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %630 : str = aten::format(%7, %619) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%630) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %631 : Tensor = aten::batch_norm(%concated_features.35, %617, %618, %615, %616, %614, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.69 : Tensor = aten::relu_(%631) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %633 : Tensor = prim::GetAttr[name="weight"](%605)
      %634 : Tensor? = prim::GetAttr[name="bias"](%605)
      %bottleneck_output.69 : Tensor = aten::conv2d(%result.69, %633, %634, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.69)
  %639 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%71)
  %640 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%71)
  %641 : int = aten::dim(%bottleneck_output.68) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %642 : bool = aten::ne(%641, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%642) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %644 : str = aten::format(%14, %641) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%644) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %645 : bool = prim::GetAttr[name="training"](%640)
   = prim::If(%645) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %646 : Tensor = prim::GetAttr[name="num_batches_tracked"](%640)
      %647 : Tensor = aten::add(%646, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%640, %647)
      -> ()
    block1():
      -> ()
  %648 : bool = prim::GetAttr[name="training"](%640)
  %649 : Tensor = prim::GetAttr[name="running_mean"](%640)
  %650 : Tensor = prim::GetAttr[name="running_var"](%640)
  %651 : Tensor = prim::GetAttr[name="weight"](%640)
  %652 : Tensor = prim::GetAttr[name="bias"](%640)
   = prim::If(%648) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %653 : int[] = aten::size(%bottleneck_output.68) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.248 : int = aten::__getitem__(%653, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %655 : int = aten::len(%653) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %656 : int = aten::sub(%655, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.249 : int = prim::Loop(%656, %5, %size_prods.248) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.63 : int, %size_prods.250 : int):
          %660 : int = aten::add(%i.63, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %661 : int = aten::__getitem__(%653, %660) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.251 : int = aten::mul(%size_prods.250, %661) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.251)
      %663 : bool = aten::eq(%size_prods.249, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%663) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %664 : str = aten::format(%7, %653) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%664) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %665 : Tensor = aten::batch_norm(%bottleneck_output.68, %651, %652, %649, %650, %648, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.70 : Tensor = aten::relu_(%665) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %667 : Tensor = prim::GetAttr[name="weight"](%639)
  %668 : Tensor? = prim::GetAttr[name="bias"](%639)
  %new_features.72 : Tensor = aten::conv2d(%result.70, %667, %668, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %673 : float = prim::GetAttr[name="drop_rate"](%71)
  %674 : bool = aten::gt(%673, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.70 : Tensor = prim::If(%674) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %677 : bool = prim::GetAttr[name="training"](%71)
      %678 : bool = aten::lt(%673, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %679 : bool = prim::If(%678) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %680 : bool = aten::gt(%673, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%680)
       = prim::If(%679) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %681 : str = aten::format(%17, %673) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%681) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %682 : Tensor = aten::dropout(%new_features.72, %673, %677) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%682)
    block1():
      -> (%new_features.72)
  %683 : Tensor[] = aten::append(%features.2, %new_features.70) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %input.11 : Tensor = aten::cat(%features.2, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:129:15
  %685 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_17.BatchNorm2d = prim::GetAttr[name="norm"](%25)
  %686 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="conv"](%25)
  %687 : int = aten::dim(%input.11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %688 : bool = aten::ne(%687, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%688) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %690 : str = aten::format(%14, %687) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%690) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %691 : bool = prim::GetAttr[name="training"](%685)
   = prim::If(%691) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %692 : Tensor = prim::GetAttr[name="num_batches_tracked"](%685)
      %693 : Tensor = aten::add(%692, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%685, %693)
      -> ()
    block1():
      -> ()
  %694 : bool = prim::GetAttr[name="training"](%685)
  %695 : Tensor = prim::GetAttr[name="running_mean"](%685)
  %696 : Tensor = prim::GetAttr[name="running_var"](%685)
  %697 : Tensor = prim::GetAttr[name="weight"](%685)
  %698 : Tensor = prim::GetAttr[name="bias"](%685)
   = prim::If(%694) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %699 : int[] = aten::size(%input.11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.296 : int = aten::__getitem__(%699, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %701 : int = aten::len(%699) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %702 : int = aten::sub(%701, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.297 : int = prim::Loop(%702, %5, %size_prods.296) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.75 : int, %size_prods.298 : int):
          %706 : int = aten::add(%i.75, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %707 : int = aten::__getitem__(%699, %706) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.299 : int = aten::mul(%size_prods.298, %707) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.299)
      %709 : bool = aten::eq(%size_prods.297, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%709) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %710 : str = aten::format(%7, %699) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%710) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.16 : Tensor = aten::batch_norm(%input.11, %697, %698, %695, %696, %694, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %input.12 : Tensor = aten::relu_(%input.16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %713 : Tensor = prim::GetAttr[name="weight"](%686)
  %714 : Tensor? = prim::GetAttr[name="bias"](%686)
  %input.14 : Tensor = aten::conv2d(%input.12, %713, %714, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %input.13 : Tensor = aten::avg_pool2d(%input.14, %6197, %6197, %6205, %10, %5, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/pooling.py:615:15
  %features.3 : Tensor[] = prim::ListConstruct(%input.13)
  %724 : __torch__.torchvision.models.densenet.___torch_mangle_7._DenseLayer = prim::GetAttr[name="denselayer1"](%26)
  %725 : __torch__.torchvision.models.densenet.___torch_mangle_10._DenseLayer = prim::GetAttr[name="denselayer2"](%26)
  %726 : __torch__.torchvision.models.densenet.___torch_mangle_13._DenseLayer = prim::GetAttr[name="denselayer3"](%26)
  %727 : __torch__.torchvision.models.densenet.___torch_mangle_16._DenseLayer = prim::GetAttr[name="denselayer4"](%26)
  %728 : __torch__.torchvision.models.densenet.___torch_mangle_19._DenseLayer = prim::GetAttr[name="denselayer5"](%26)
  %729 : __torch__.torchvision.models.densenet.___torch_mangle_22._DenseLayer = prim::GetAttr[name="denselayer6"](%26)
  %730 : __torch__.torchvision.models.densenet.___torch_mangle_25._DenseLayer = prim::GetAttr[name="denselayer7"](%26)
  %731 : __torch__.torchvision.models.densenet.___torch_mangle_28._DenseLayer = prim::GetAttr[name="denselayer8"](%26)
  %732 : __torch__.torchvision.models.densenet.___torch_mangle_31._DenseLayer = prim::GetAttr[name="denselayer9"](%26)
  %733 : __torch__.torchvision.models.densenet.___torch_mangle_34._DenseLayer = prim::GetAttr[name="denselayer10"](%26)
  %734 : __torch__.torchvision.models.densenet.___torch_mangle_37._DenseLayer = prim::GetAttr[name="denselayer11"](%26)
  %735 : __torch__.torchvision.models.densenet.___torch_mangle_40._DenseLayer = prim::GetAttr[name="denselayer12"](%26)
  %737 : bool = prim::GetAttr[name="memory_efficient"](%724)
  %738 : bool = prim::If(%737) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %739 : bool = prim::Uninitialized()
      %740 : int = aten::len(%features.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %741 : bool = aten::gt(%740, %6)
      %742 : bool, %743 : bool, %744 : int = prim::Loop(%12, %741, %10, %739, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%745 : int, %746 : bool, %747 : bool, %748 : int):
          %tensor.36 : Tensor = aten::__getitem__(%features.3, %748) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %750 : bool = prim::requires_grad(%tensor.36)
          %751 : bool, %752 : bool = prim::If(%750) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %739)
          %753 : int = aten::add(%748, %19)
          %754 : bool = aten::lt(%753, %740)
          %755 : bool = aten::__and__(%754, %751)
          -> (%755, %750, %752, %753)
      %756 : bool = prim::If(%742)
        block0():
          -> (%743)
        block1():
          -> (%10)
      -> (%756)
    block1():
      -> (%10)
  %bottleneck_output.70 : Tensor = prim::If(%738) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.36 : Tensor = aten::cat(%features.3, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %759 : __torch__.torch.nn.modules.conv.___torch_mangle_6.Conv2d = prim::GetAttr[name="conv1"](%724)
      %760 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm1"](%724)
      %761 : int = aten::dim(%concated_features.36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %762 : bool = aten::ne(%761, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%762) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %764 : str = aten::format(%14, %761) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%764) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %765 : bool = prim::GetAttr[name="training"](%760)
       = prim::If(%765) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %766 : Tensor = prim::GetAttr[name="num_batches_tracked"](%760)
          %767 : Tensor = aten::add(%766, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%760, %767)
          -> ()
        block1():
          -> ()
      %768 : bool = prim::GetAttr[name="training"](%760)
      %769 : Tensor = prim::GetAttr[name="running_mean"](%760)
      %770 : Tensor = prim::GetAttr[name="running_var"](%760)
      %771 : Tensor = prim::GetAttr[name="weight"](%760)
      %772 : Tensor = prim::GetAttr[name="bias"](%760)
       = prim::If(%768) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %773 : int[] = aten::size(%concated_features.36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.304 : int = aten::__getitem__(%773, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %775 : int = aten::len(%773) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %776 : int = aten::sub(%775, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.305 : int = prim::Loop(%776, %5, %size_prods.304) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.77 : int, %size_prods.306 : int):
              %780 : int = aten::add(%i.77, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %781 : int = aten::__getitem__(%773, %780) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.307 : int = aten::mul(%size_prods.306, %781) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.307)
          %783 : bool = aten::eq(%size_prods.305, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%783) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %784 : str = aten::format(%7, %773) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%784) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %785 : Tensor = aten::batch_norm(%concated_features.36, %771, %772, %769, %770, %768, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.71 : Tensor = aten::relu_(%785) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %787 : Tensor = prim::GetAttr[name="weight"](%759)
      %788 : Tensor? = prim::GetAttr[name="bias"](%759)
      %bottleneck_output.71 : Tensor = aten::conv2d(%result.71, %787, %788, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.71)
  %793 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%724)
  %794 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%724)
  %795 : int = aten::dim(%bottleneck_output.70) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %796 : bool = aten::ne(%795, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%796) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %798 : str = aten::format(%14, %795) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%798) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %799 : bool = prim::GetAttr[name="training"](%794)
   = prim::If(%799) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %800 : Tensor = prim::GetAttr[name="num_batches_tracked"](%794)
      %801 : Tensor = aten::add(%800, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%794, %801)
      -> ()
    block1():
      -> ()
  %802 : bool = prim::GetAttr[name="training"](%794)
  %803 : Tensor = prim::GetAttr[name="running_mean"](%794)
  %804 : Tensor = prim::GetAttr[name="running_var"](%794)
  %805 : Tensor = prim::GetAttr[name="weight"](%794)
  %806 : Tensor = prim::GetAttr[name="bias"](%794)
   = prim::If(%802) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %807 : int[] = aten::size(%bottleneck_output.70) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.308 : int = aten::__getitem__(%807, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %809 : int = aten::len(%807) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %810 : int = aten::sub(%809, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.309 : int = prim::Loop(%810, %5, %size_prods.308) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.78 : int, %size_prods.310 : int):
          %814 : int = aten::add(%i.78, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %815 : int = aten::__getitem__(%807, %814) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.311 : int = aten::mul(%size_prods.310, %815) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.311)
      %817 : bool = aten::eq(%size_prods.309, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%817) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %818 : str = aten::format(%7, %807) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%818) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %819 : Tensor = aten::batch_norm(%bottleneck_output.70, %805, %806, %803, %804, %802, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.72 : Tensor = aten::relu_(%819) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %821 : Tensor = prim::GetAttr[name="weight"](%793)
  %822 : Tensor? = prim::GetAttr[name="bias"](%793)
  %new_features.74 : Tensor = aten::conv2d(%result.72, %821, %822, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %827 : float = prim::GetAttr[name="drop_rate"](%724)
  %828 : bool = aten::gt(%827, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.71 : Tensor = prim::If(%828) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %831 : bool = prim::GetAttr[name="training"](%724)
      %832 : bool = aten::lt(%827, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %833 : bool = prim::If(%832) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %834 : bool = aten::gt(%827, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%834)
       = prim::If(%833) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %835 : str = aten::format(%17, %827) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%835) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %836 : Tensor = aten::dropout(%new_features.74, %827, %831) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%836)
    block1():
      -> (%new_features.74)
  %837 : Tensor[] = aten::append(%features.3, %new_features.71) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %839 : bool = prim::GetAttr[name="memory_efficient"](%725)
  %840 : bool = prim::If(%839) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %841 : bool = prim::Uninitialized()
      %842 : int = aten::len(%features.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %843 : bool = aten::gt(%842, %6)
      %844 : bool, %845 : bool, %846 : int = prim::Loop(%12, %843, %10, %841, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%847 : int, %848 : bool, %849 : bool, %850 : int):
          %tensor.37 : Tensor = aten::__getitem__(%features.3, %850) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %852 : bool = prim::requires_grad(%tensor.37)
          %853 : bool, %854 : bool = prim::If(%852) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %841)
          %855 : int = aten::add(%850, %19)
          %856 : bool = aten::lt(%855, %842)
          %857 : bool = aten::__and__(%856, %853)
          -> (%857, %852, %854, %855)
      %858 : bool = prim::If(%844)
        block0():
          -> (%845)
        block1():
          -> (%10)
      -> (%858)
    block1():
      -> (%10)
  %bottleneck_output.72 : Tensor = prim::If(%840) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.37 : Tensor = aten::cat(%features.3, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %861 : __torch__.torch.nn.modules.conv.___torch_mangle_9.Conv2d = prim::GetAttr[name="conv1"](%725)
      %862 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="norm1"](%725)
      %863 : int = aten::dim(%concated_features.37) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %864 : bool = aten::ne(%863, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%864) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %866 : str = aten::format(%14, %863) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%866) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %867 : bool = prim::GetAttr[name="training"](%862)
       = prim::If(%867) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %868 : Tensor = prim::GetAttr[name="num_batches_tracked"](%862)
          %869 : Tensor = aten::add(%868, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%862, %869)
          -> ()
        block1():
          -> ()
      %870 : bool = prim::GetAttr[name="training"](%862)
      %871 : Tensor = prim::GetAttr[name="running_mean"](%862)
      %872 : Tensor = prim::GetAttr[name="running_var"](%862)
      %873 : Tensor = prim::GetAttr[name="weight"](%862)
      %874 : Tensor = prim::GetAttr[name="bias"](%862)
       = prim::If(%870) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %875 : int[] = aten::size(%concated_features.37) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.312 : int = aten::__getitem__(%875, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %877 : int = aten::len(%875) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %878 : int = aten::sub(%877, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.313 : int = prim::Loop(%878, %5, %size_prods.312) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.79 : int, %size_prods.314 : int):
              %882 : int = aten::add(%i.79, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %883 : int = aten::__getitem__(%875, %882) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.315 : int = aten::mul(%size_prods.314, %883) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.315)
          %885 : bool = aten::eq(%size_prods.313, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%885) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %886 : str = aten::format(%7, %875) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%886) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %887 : Tensor = aten::batch_norm(%concated_features.37, %873, %874, %871, %872, %870, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.73 : Tensor = aten::relu_(%887) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %889 : Tensor = prim::GetAttr[name="weight"](%861)
      %890 : Tensor? = prim::GetAttr[name="bias"](%861)
      %bottleneck_output.73 : Tensor = aten::conv2d(%result.73, %889, %890, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.73)
  %895 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%725)
  %896 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%725)
  %897 : int = aten::dim(%bottleneck_output.72) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %898 : bool = aten::ne(%897, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%898) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %900 : str = aten::format(%14, %897) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%900) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %901 : bool = prim::GetAttr[name="training"](%896)
   = prim::If(%901) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %902 : Tensor = prim::GetAttr[name="num_batches_tracked"](%896)
      %903 : Tensor = aten::add(%902, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%896, %903)
      -> ()
    block1():
      -> ()
  %904 : bool = prim::GetAttr[name="training"](%896)
  %905 : Tensor = prim::GetAttr[name="running_mean"](%896)
  %906 : Tensor = prim::GetAttr[name="running_var"](%896)
  %907 : Tensor = prim::GetAttr[name="weight"](%896)
  %908 : Tensor = prim::GetAttr[name="bias"](%896)
   = prim::If(%904) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %909 : int[] = aten::size(%bottleneck_output.72) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.316 : int = aten::__getitem__(%909, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %911 : int = aten::len(%909) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %912 : int = aten::sub(%911, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.317 : int = prim::Loop(%912, %5, %size_prods.316) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.80 : int, %size_prods.318 : int):
          %916 : int = aten::add(%i.80, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %917 : int = aten::__getitem__(%909, %916) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.319 : int = aten::mul(%size_prods.318, %917) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.319)
      %919 : bool = aten::eq(%size_prods.317, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%919) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %920 : str = aten::format(%7, %909) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%920) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %921 : Tensor = aten::batch_norm(%bottleneck_output.72, %907, %908, %905, %906, %904, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.74 : Tensor = aten::relu_(%921) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %923 : Tensor = prim::GetAttr[name="weight"](%895)
  %924 : Tensor? = prim::GetAttr[name="bias"](%895)
  %new_features.76 : Tensor = aten::conv2d(%result.74, %923, %924, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %929 : float = prim::GetAttr[name="drop_rate"](%725)
  %930 : bool = aten::gt(%929, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.73 : Tensor = prim::If(%930) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %933 : bool = prim::GetAttr[name="training"](%725)
      %934 : bool = aten::lt(%929, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %935 : bool = prim::If(%934) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %936 : bool = aten::gt(%929, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%936)
       = prim::If(%935) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %937 : str = aten::format(%17, %929) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%937) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %938 : Tensor = aten::dropout(%new_features.76, %929, %933) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%938)
    block1():
      -> (%new_features.76)
  %939 : Tensor[] = aten::append(%features.3, %new_features.73) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %941 : bool = prim::GetAttr[name="memory_efficient"](%726)
  %942 : bool = prim::If(%941) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %943 : bool = prim::Uninitialized()
      %944 : int = aten::len(%features.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %945 : bool = aten::gt(%944, %6)
      %946 : bool, %947 : bool, %948 : int = prim::Loop(%12, %945, %10, %943, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%949 : int, %950 : bool, %951 : bool, %952 : int):
          %tensor.38 : Tensor = aten::__getitem__(%features.3, %952) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %954 : bool = prim::requires_grad(%tensor.38)
          %955 : bool, %956 : bool = prim::If(%954) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %943)
          %957 : int = aten::add(%952, %19)
          %958 : bool = aten::lt(%957, %944)
          %959 : bool = aten::__and__(%958, %955)
          -> (%959, %954, %956, %957)
      %960 : bool = prim::If(%946)
        block0():
          -> (%947)
        block1():
          -> (%10)
      -> (%960)
    block1():
      -> (%10)
  %bottleneck_output.74 : Tensor = prim::If(%942) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.38 : Tensor = aten::cat(%features.3, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %963 : __torch__.torch.nn.modules.conv.___torch_mangle_12.Conv2d = prim::GetAttr[name="conv1"](%726)
      %964 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_11.BatchNorm2d = prim::GetAttr[name="norm1"](%726)
      %965 : int = aten::dim(%concated_features.38) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %966 : bool = aten::ne(%965, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%966) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %968 : str = aten::format(%14, %965) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%968) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %969 : bool = prim::GetAttr[name="training"](%964)
       = prim::If(%969) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %970 : Tensor = prim::GetAttr[name="num_batches_tracked"](%964)
          %971 : Tensor = aten::add(%970, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%964, %971)
          -> ()
        block1():
          -> ()
      %972 : bool = prim::GetAttr[name="training"](%964)
      %973 : Tensor = prim::GetAttr[name="running_mean"](%964)
      %974 : Tensor = prim::GetAttr[name="running_var"](%964)
      %975 : Tensor = prim::GetAttr[name="weight"](%964)
      %976 : Tensor = prim::GetAttr[name="bias"](%964)
       = prim::If(%972) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %977 : int[] = aten::size(%concated_features.38) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.320 : int = aten::__getitem__(%977, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %979 : int = aten::len(%977) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %980 : int = aten::sub(%979, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.321 : int = prim::Loop(%980, %5, %size_prods.320) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.81 : int, %size_prods.322 : int):
              %984 : int = aten::add(%i.81, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %985 : int = aten::__getitem__(%977, %984) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.323 : int = aten::mul(%size_prods.322, %985) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.323)
          %987 : bool = aten::eq(%size_prods.321, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%987) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %988 : str = aten::format(%7, %977) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%988) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %989 : Tensor = aten::batch_norm(%concated_features.38, %975, %976, %973, %974, %972, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.75 : Tensor = aten::relu_(%989) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %991 : Tensor = prim::GetAttr[name="weight"](%963)
      %992 : Tensor? = prim::GetAttr[name="bias"](%963)
      %bottleneck_output.75 : Tensor = aten::conv2d(%result.75, %991, %992, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.75)
  %997 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%726)
  %998 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%726)
  %999 : int = aten::dim(%bottleneck_output.74) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %1000 : bool = aten::ne(%999, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%1000) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %1002 : str = aten::format(%14, %999) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%1002) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %1003 : bool = prim::GetAttr[name="training"](%998)
   = prim::If(%1003) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1004 : Tensor = prim::GetAttr[name="num_batches_tracked"](%998)
      %1005 : Tensor = aten::add(%1004, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%998, %1005)
      -> ()
    block1():
      -> ()
  %1006 : bool = prim::GetAttr[name="training"](%998)
  %1007 : Tensor = prim::GetAttr[name="running_mean"](%998)
  %1008 : Tensor = prim::GetAttr[name="running_var"](%998)
  %1009 : Tensor = prim::GetAttr[name="weight"](%998)
  %1010 : Tensor = prim::GetAttr[name="bias"](%998)
   = prim::If(%1006) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1011 : int[] = aten::size(%bottleneck_output.74) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.324 : int = aten::__getitem__(%1011, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1013 : int = aten::len(%1011) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1014 : int = aten::sub(%1013, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.325 : int = prim::Loop(%1014, %5, %size_prods.324) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.82 : int, %size_prods.326 : int):
          %1018 : int = aten::add(%i.82, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1019 : int = aten::__getitem__(%1011, %1018) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.327 : int = aten::mul(%size_prods.326, %1019) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.327)
      %1021 : bool = aten::eq(%size_prods.325, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1021) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1022 : str = aten::format(%7, %1011) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1022) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %1023 : Tensor = aten::batch_norm(%bottleneck_output.74, %1009, %1010, %1007, %1008, %1006, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.76 : Tensor = aten::relu_(%1023) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1025 : Tensor = prim::GetAttr[name="weight"](%997)
  %1026 : Tensor? = prim::GetAttr[name="bias"](%997)
  %new_features.78 : Tensor = aten::conv2d(%result.76, %1025, %1026, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1031 : float = prim::GetAttr[name="drop_rate"](%726)
  %1032 : bool = aten::gt(%1031, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.75 : Tensor = prim::If(%1032) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %1035 : bool = prim::GetAttr[name="training"](%726)
      %1036 : bool = aten::lt(%1031, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %1037 : bool = prim::If(%1036) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %1038 : bool = aten::gt(%1031, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%1038)
       = prim::If(%1037) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %1039 : str = aten::format(%17, %1031) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%1039) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %1040 : Tensor = aten::dropout(%new_features.78, %1031, %1035) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%1040)
    block1():
      -> (%new_features.78)
  %1041 : Tensor[] = aten::append(%features.3, %new_features.75) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %1043 : bool = prim::GetAttr[name="memory_efficient"](%727)
  %1044 : bool = prim::If(%1043) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %1045 : bool = prim::Uninitialized()
      %1046 : int = aten::len(%features.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %1047 : bool = aten::gt(%1046, %6)
      %1048 : bool, %1049 : bool, %1050 : int = prim::Loop(%12, %1047, %10, %1045, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%1051 : int, %1052 : bool, %1053 : bool, %1054 : int):
          %tensor.39 : Tensor = aten::__getitem__(%features.3, %1054) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %1056 : bool = prim::requires_grad(%tensor.39)
          %1057 : bool, %1058 : bool = prim::If(%1056) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %1045)
          %1059 : int = aten::add(%1054, %19)
          %1060 : bool = aten::lt(%1059, %1046)
          %1061 : bool = aten::__and__(%1060, %1057)
          -> (%1061, %1056, %1058, %1059)
      %1062 : bool = prim::If(%1048)
        block0():
          -> (%1049)
        block1():
          -> (%10)
      -> (%1062)
    block1():
      -> (%10)
  %bottleneck_output.76 : Tensor = prim::If(%1044) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.39 : Tensor = aten::cat(%features.3, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %1065 : __torch__.torch.nn.modules.conv.___torch_mangle_15.Conv2d = prim::GetAttr[name="conv1"](%727)
      %1066 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_14.BatchNorm2d = prim::GetAttr[name="norm1"](%727)
      %1067 : int = aten::dim(%concated_features.39) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %1068 : bool = aten::ne(%1067, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%1068) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %1070 : str = aten::format(%14, %1067) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%1070) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %1071 : bool = prim::GetAttr[name="training"](%1066)
       = prim::If(%1071) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1072 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1066)
          %1073 : Tensor = aten::add(%1072, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1066, %1073)
          -> ()
        block1():
          -> ()
      %1074 : bool = prim::GetAttr[name="training"](%1066)
      %1075 : Tensor = prim::GetAttr[name="running_mean"](%1066)
      %1076 : Tensor = prim::GetAttr[name="running_var"](%1066)
      %1077 : Tensor = prim::GetAttr[name="weight"](%1066)
      %1078 : Tensor = prim::GetAttr[name="bias"](%1066)
       = prim::If(%1074) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1079 : int[] = aten::size(%concated_features.39) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.328 : int = aten::__getitem__(%1079, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1081 : int = aten::len(%1079) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1082 : int = aten::sub(%1081, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.329 : int = prim::Loop(%1082, %5, %size_prods.328) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.83 : int, %size_prods.330 : int):
              %1086 : int = aten::add(%i.83, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1087 : int = aten::__getitem__(%1079, %1086) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.331 : int = aten::mul(%size_prods.330, %1087) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.331)
          %1089 : bool = aten::eq(%size_prods.329, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1089) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1090 : str = aten::format(%7, %1079) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1090) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %1091 : Tensor = aten::batch_norm(%concated_features.39, %1077, %1078, %1075, %1076, %1074, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.77 : Tensor = aten::relu_(%1091) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1093 : Tensor = prim::GetAttr[name="weight"](%1065)
      %1094 : Tensor? = prim::GetAttr[name="bias"](%1065)
      %bottleneck_output.77 : Tensor = aten::conv2d(%result.77, %1093, %1094, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.77)
  %1099 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%727)
  %1100 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%727)
  %1101 : int = aten::dim(%bottleneck_output.76) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %1102 : bool = aten::ne(%1101, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%1102) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %1104 : str = aten::format(%14, %1101) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%1104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %1105 : bool = prim::GetAttr[name="training"](%1100)
   = prim::If(%1105) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1106 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1100)
      %1107 : Tensor = aten::add(%1106, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1100, %1107)
      -> ()
    block1():
      -> ()
  %1108 : bool = prim::GetAttr[name="training"](%1100)
  %1109 : Tensor = prim::GetAttr[name="running_mean"](%1100)
  %1110 : Tensor = prim::GetAttr[name="running_var"](%1100)
  %1111 : Tensor = prim::GetAttr[name="weight"](%1100)
  %1112 : Tensor = prim::GetAttr[name="bias"](%1100)
   = prim::If(%1108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1113 : int[] = aten::size(%bottleneck_output.76) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.332 : int = aten::__getitem__(%1113, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1115 : int = aten::len(%1113) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1116 : int = aten::sub(%1115, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.333 : int = prim::Loop(%1116, %5, %size_prods.332) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.84 : int, %size_prods.334 : int):
          %1120 : int = aten::add(%i.84, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1121 : int = aten::__getitem__(%1113, %1120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.335 : int = aten::mul(%size_prods.334, %1121) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.335)
      %1123 : bool = aten::eq(%size_prods.333, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1123) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1124 : str = aten::format(%7, %1113) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %1125 : Tensor = aten::batch_norm(%bottleneck_output.76, %1111, %1112, %1109, %1110, %1108, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.78 : Tensor = aten::relu_(%1125) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1127 : Tensor = prim::GetAttr[name="weight"](%1099)
  %1128 : Tensor? = prim::GetAttr[name="bias"](%1099)
  %new_features.80 : Tensor = aten::conv2d(%result.78, %1127, %1128, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1133 : float = prim::GetAttr[name="drop_rate"](%727)
  %1134 : bool = aten::gt(%1133, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.77 : Tensor = prim::If(%1134) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %1137 : bool = prim::GetAttr[name="training"](%727)
      %1138 : bool = aten::lt(%1133, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %1139 : bool = prim::If(%1138) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %1140 : bool = aten::gt(%1133, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%1140)
       = prim::If(%1139) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %1141 : str = aten::format(%17, %1133) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%1141) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %1142 : Tensor = aten::dropout(%new_features.80, %1133, %1137) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%1142)
    block1():
      -> (%new_features.80)
  %1143 : Tensor[] = aten::append(%features.3, %new_features.77) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %1145 : bool = prim::GetAttr[name="memory_efficient"](%728)
  %1146 : bool = prim::If(%1145) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %1147 : bool = prim::Uninitialized()
      %1148 : int = aten::len(%features.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %1149 : bool = aten::gt(%1148, %6)
      %1150 : bool, %1151 : bool, %1152 : int = prim::Loop(%12, %1149, %10, %1147, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%1153 : int, %1154 : bool, %1155 : bool, %1156 : int):
          %tensor.40 : Tensor = aten::__getitem__(%features.3, %1156) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %1158 : bool = prim::requires_grad(%tensor.40)
          %1159 : bool, %1160 : bool = prim::If(%1158) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %1147)
          %1161 : int = aten::add(%1156, %19)
          %1162 : bool = aten::lt(%1161, %1148)
          %1163 : bool = aten::__and__(%1162, %1159)
          -> (%1163, %1158, %1160, %1161)
      %1164 : bool = prim::If(%1150)
        block0():
          -> (%1151)
        block1():
          -> (%10)
      -> (%1164)
    block1():
      -> (%10)
  %bottleneck_output.78 : Tensor = prim::If(%1146) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.40 : Tensor = aten::cat(%features.3, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %1167 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="conv1"](%728)
      %1168 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_17.BatchNorm2d = prim::GetAttr[name="norm1"](%728)
      %1169 : int = aten::dim(%concated_features.40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %1170 : bool = aten::ne(%1169, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%1170) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %1172 : str = aten::format(%14, %1169) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%1172) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %1173 : bool = prim::GetAttr[name="training"](%1168)
       = prim::If(%1173) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1174 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1168)
          %1175 : Tensor = aten::add(%1174, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1168, %1175)
          -> ()
        block1():
          -> ()
      %1176 : bool = prim::GetAttr[name="training"](%1168)
      %1177 : Tensor = prim::GetAttr[name="running_mean"](%1168)
      %1178 : Tensor = prim::GetAttr[name="running_var"](%1168)
      %1179 : Tensor = prim::GetAttr[name="weight"](%1168)
      %1180 : Tensor = prim::GetAttr[name="bias"](%1168)
       = prim::If(%1176) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1181 : int[] = aten::size(%concated_features.40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.336 : int = aten::__getitem__(%1181, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1183 : int = aten::len(%1181) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1184 : int = aten::sub(%1183, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.337 : int = prim::Loop(%1184, %5, %size_prods.336) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.85 : int, %size_prods.338 : int):
              %1188 : int = aten::add(%i.85, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1189 : int = aten::__getitem__(%1181, %1188) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.339 : int = aten::mul(%size_prods.338, %1189) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.339)
          %1191 : bool = aten::eq(%size_prods.337, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1191) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1192 : str = aten::format(%7, %1181) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %1193 : Tensor = aten::batch_norm(%concated_features.40, %1179, %1180, %1177, %1178, %1176, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.79 : Tensor = aten::relu_(%1193) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1195 : Tensor = prim::GetAttr[name="weight"](%1167)
      %1196 : Tensor? = prim::GetAttr[name="bias"](%1167)
      %bottleneck_output.79 : Tensor = aten::conv2d(%result.79, %1195, %1196, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.79)
  %1201 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%728)
  %1202 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%728)
  %1203 : int = aten::dim(%bottleneck_output.78) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %1204 : bool = aten::ne(%1203, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%1204) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %1206 : str = aten::format(%14, %1203) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%1206) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %1207 : bool = prim::GetAttr[name="training"](%1202)
   = prim::If(%1207) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1208 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1202)
      %1209 : Tensor = aten::add(%1208, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1202, %1209)
      -> ()
    block1():
      -> ()
  %1210 : bool = prim::GetAttr[name="training"](%1202)
  %1211 : Tensor = prim::GetAttr[name="running_mean"](%1202)
  %1212 : Tensor = prim::GetAttr[name="running_var"](%1202)
  %1213 : Tensor = prim::GetAttr[name="weight"](%1202)
  %1214 : Tensor = prim::GetAttr[name="bias"](%1202)
   = prim::If(%1210) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1215 : int[] = aten::size(%bottleneck_output.78) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.192 : int = aten::__getitem__(%1215, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1217 : int = aten::len(%1215) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1218 : int = aten::sub(%1217, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.193 : int = prim::Loop(%1218, %5, %size_prods.192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.49 : int, %size_prods.194 : int):
          %1222 : int = aten::add(%i.49, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1223 : int = aten::__getitem__(%1215, %1222) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.195 : int = aten::mul(%size_prods.194, %1223) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.195)
      %1225 : bool = aten::eq(%size_prods.193, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1225) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1226 : str = aten::format(%7, %1215) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1226) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %1227 : Tensor = aten::batch_norm(%bottleneck_output.78, %1213, %1214, %1211, %1212, %1210, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.80 : Tensor = aten::relu_(%1227) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1229 : Tensor = prim::GetAttr[name="weight"](%1201)
  %1230 : Tensor? = prim::GetAttr[name="bias"](%1201)
  %new_features.82 : Tensor = aten::conv2d(%result.80, %1229, %1230, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1235 : float = prim::GetAttr[name="drop_rate"](%728)
  %1236 : bool = aten::gt(%1235, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.79 : Tensor = prim::If(%1236) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %1239 : bool = prim::GetAttr[name="training"](%728)
      %1240 : bool = aten::lt(%1235, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %1241 : bool = prim::If(%1240) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %1242 : bool = aten::gt(%1235, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%1242)
       = prim::If(%1241) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %1243 : str = aten::format(%17, %1235) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%1243) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %1244 : Tensor = aten::dropout(%new_features.82, %1235, %1239) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%1244)
    block1():
      -> (%new_features.82)
  %1245 : Tensor[] = aten::append(%features.3, %new_features.79) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %1247 : bool = prim::GetAttr[name="memory_efficient"](%729)
  %1248 : bool = prim::If(%1247) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %1249 : bool = prim::Uninitialized()
      %1250 : int = aten::len(%features.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %1251 : bool = aten::gt(%1250, %6)
      %1252 : bool, %1253 : bool, %1254 : int = prim::Loop(%12, %1251, %10, %1249, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%1255 : int, %1256 : bool, %1257 : bool, %1258 : int):
          %tensor.41 : Tensor = aten::__getitem__(%features.3, %1258) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %1260 : bool = prim::requires_grad(%tensor.41)
          %1261 : bool, %1262 : bool = prim::If(%1260) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %1249)
          %1263 : int = aten::add(%1258, %19)
          %1264 : bool = aten::lt(%1263, %1250)
          %1265 : bool = aten::__and__(%1264, %1261)
          -> (%1265, %1260, %1262, %1263)
      %1266 : bool = prim::If(%1252)
        block0():
          -> (%1253)
        block1():
          -> (%10)
      -> (%1266)
    block1():
      -> (%10)
  %bottleneck_output.80 : Tensor = prim::If(%1248) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.41 : Tensor = aten::cat(%features.3, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %1269 : __torch__.torch.nn.modules.conv.___torch_mangle_21.Conv2d = prim::GetAttr[name="conv1"](%729)
      %1270 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_20.BatchNorm2d = prim::GetAttr[name="norm1"](%729)
      %1271 : int = aten::dim(%concated_features.41) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %1272 : bool = aten::ne(%1271, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%1272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %1274 : str = aten::format(%14, %1271) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%1274) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %1275 : bool = prim::GetAttr[name="training"](%1270)
       = prim::If(%1275) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1276 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1270)
          %1277 : Tensor = aten::add(%1276, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1270, %1277)
          -> ()
        block1():
          -> ()
      %1278 : bool = prim::GetAttr[name="training"](%1270)
      %1279 : Tensor = prim::GetAttr[name="running_mean"](%1270)
      %1280 : Tensor = prim::GetAttr[name="running_var"](%1270)
      %1281 : Tensor = prim::GetAttr[name="weight"](%1270)
      %1282 : Tensor = prim::GetAttr[name="bias"](%1270)
       = prim::If(%1278) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1283 : int[] = aten::size(%concated_features.41) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.196 : int = aten::__getitem__(%1283, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1285 : int = aten::len(%1283) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1286 : int = aten::sub(%1285, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.197 : int = prim::Loop(%1286, %5, %size_prods.196) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.50 : int, %size_prods.198 : int):
              %1290 : int = aten::add(%i.50, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1291 : int = aten::__getitem__(%1283, %1290) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.199 : int = aten::mul(%size_prods.198, %1291) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.199)
          %1293 : bool = aten::eq(%size_prods.197, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1293) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1294 : str = aten::format(%7, %1283) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1294) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %1295 : Tensor = aten::batch_norm(%concated_features.41, %1281, %1282, %1279, %1280, %1278, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.81 : Tensor = aten::relu_(%1295) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1297 : Tensor = prim::GetAttr[name="weight"](%1269)
      %1298 : Tensor? = prim::GetAttr[name="bias"](%1269)
      %bottleneck_output.81 : Tensor = aten::conv2d(%result.81, %1297, %1298, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.81)
  %1303 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%729)
  %1304 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%729)
  %1305 : int = aten::dim(%bottleneck_output.80) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %1306 : bool = aten::ne(%1305, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%1306) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %1308 : str = aten::format(%14, %1305) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%1308) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %1309 : bool = prim::GetAttr[name="training"](%1304)
   = prim::If(%1309) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1310 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1304)
      %1311 : Tensor = aten::add(%1310, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1304, %1311)
      -> ()
    block1():
      -> ()
  %1312 : bool = prim::GetAttr[name="training"](%1304)
  %1313 : Tensor = prim::GetAttr[name="running_mean"](%1304)
  %1314 : Tensor = prim::GetAttr[name="running_var"](%1304)
  %1315 : Tensor = prim::GetAttr[name="weight"](%1304)
  %1316 : Tensor = prim::GetAttr[name="bias"](%1304)
   = prim::If(%1312) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1317 : int[] = aten::size(%bottleneck_output.80) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.200 : int = aten::__getitem__(%1317, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1319 : int = aten::len(%1317) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1320 : int = aten::sub(%1319, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.201 : int = prim::Loop(%1320, %5, %size_prods.200) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.51 : int, %size_prods.202 : int):
          %1324 : int = aten::add(%i.51, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1325 : int = aten::__getitem__(%1317, %1324) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.203 : int = aten::mul(%size_prods.202, %1325) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.203)
      %1327 : bool = aten::eq(%size_prods.201, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1327) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1328 : str = aten::format(%7, %1317) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1328) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %1329 : Tensor = aten::batch_norm(%bottleneck_output.80, %1315, %1316, %1313, %1314, %1312, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.82 : Tensor = aten::relu_(%1329) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1331 : Tensor = prim::GetAttr[name="weight"](%1303)
  %1332 : Tensor? = prim::GetAttr[name="bias"](%1303)
  %new_features.84 : Tensor = aten::conv2d(%result.82, %1331, %1332, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1337 : float = prim::GetAttr[name="drop_rate"](%729)
  %1338 : bool = aten::gt(%1337, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.81 : Tensor = prim::If(%1338) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %1341 : bool = prim::GetAttr[name="training"](%729)
      %1342 : bool = aten::lt(%1337, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %1343 : bool = prim::If(%1342) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %1344 : bool = aten::gt(%1337, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%1344)
       = prim::If(%1343) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %1345 : str = aten::format(%17, %1337) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%1345) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %1346 : Tensor = aten::dropout(%new_features.84, %1337, %1341) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%1346)
    block1():
      -> (%new_features.84)
  %1347 : Tensor[] = aten::append(%features.3, %new_features.81) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %1349 : bool = prim::GetAttr[name="memory_efficient"](%730)
  %1350 : bool = prim::If(%1349) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %1351 : bool = prim::Uninitialized()
      %1352 : int = aten::len(%features.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %1353 : bool = aten::gt(%1352, %6)
      %1354 : bool, %1355 : bool, %1356 : int = prim::Loop(%12, %1353, %10, %1351, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%1357 : int, %1358 : bool, %1359 : bool, %1360 : int):
          %tensor.25 : Tensor = aten::__getitem__(%features.3, %1360) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %1362 : bool = prim::requires_grad(%tensor.25)
          %1363 : bool, %1364 : bool = prim::If(%1362) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %1351)
          %1365 : int = aten::add(%1360, %19)
          %1366 : bool = aten::lt(%1365, %1352)
          %1367 : bool = aten::__and__(%1366, %1363)
          -> (%1367, %1362, %1364, %1365)
      %1368 : bool = prim::If(%1354)
        block0():
          -> (%1355)
        block1():
          -> (%10)
      -> (%1368)
    block1():
      -> (%10)
  %bottleneck_output.48 : Tensor = prim::If(%1350) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.25 : Tensor = aten::cat(%features.3, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %1371 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="conv1"](%730)
      %1372 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="norm1"](%730)
      %1373 : int = aten::dim(%concated_features.25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %1374 : bool = aten::ne(%1373, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%1374) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %1376 : str = aten::format(%14, %1373) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%1376) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %1377 : bool = prim::GetAttr[name="training"](%1372)
       = prim::If(%1377) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1378 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1372)
          %1379 : Tensor = aten::add(%1378, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1372, %1379)
          -> ()
        block1():
          -> ()
      %1380 : bool = prim::GetAttr[name="training"](%1372)
      %1381 : Tensor = prim::GetAttr[name="running_mean"](%1372)
      %1382 : Tensor = prim::GetAttr[name="running_var"](%1372)
      %1383 : Tensor = prim::GetAttr[name="weight"](%1372)
      %1384 : Tensor = prim::GetAttr[name="bias"](%1372)
       = prim::If(%1380) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1385 : int[] = aten::size(%concated_features.25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.204 : int = aten::__getitem__(%1385, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1387 : int = aten::len(%1385) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1388 : int = aten::sub(%1387, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.205 : int = prim::Loop(%1388, %5, %size_prods.204) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.52 : int, %size_prods.206 : int):
              %1392 : int = aten::add(%i.52, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1393 : int = aten::__getitem__(%1385, %1392) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.207 : int = aten::mul(%size_prods.206, %1393) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.207)
          %1395 : bool = aten::eq(%size_prods.205, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1395) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1396 : str = aten::format(%7, %1385) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1396) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %1397 : Tensor = aten::batch_norm(%concated_features.25, %1383, %1384, %1381, %1382, %1380, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.49 : Tensor = aten::relu_(%1397) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1399 : Tensor = prim::GetAttr[name="weight"](%1371)
      %1400 : Tensor? = prim::GetAttr[name="bias"](%1371)
      %bottleneck_output.49 : Tensor = aten::conv2d(%result.49, %1399, %1400, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.49)
  %1405 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%730)
  %1406 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%730)
  %1407 : int = aten::dim(%bottleneck_output.48) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %1408 : bool = aten::ne(%1407, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%1408) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %1410 : str = aten::format(%14, %1407) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%1410) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %1411 : bool = prim::GetAttr[name="training"](%1406)
   = prim::If(%1411) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1412 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1406)
      %1413 : Tensor = aten::add(%1412, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1406, %1413)
      -> ()
    block1():
      -> ()
  %1414 : bool = prim::GetAttr[name="training"](%1406)
  %1415 : Tensor = prim::GetAttr[name="running_mean"](%1406)
  %1416 : Tensor = prim::GetAttr[name="running_var"](%1406)
  %1417 : Tensor = prim::GetAttr[name="weight"](%1406)
  %1418 : Tensor = prim::GetAttr[name="bias"](%1406)
   = prim::If(%1414) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1419 : int[] = aten::size(%bottleneck_output.48) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.208 : int = aten::__getitem__(%1419, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1421 : int = aten::len(%1419) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1422 : int = aten::sub(%1421, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.209 : int = prim::Loop(%1422, %5, %size_prods.208) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.53 : int, %size_prods.210 : int):
          %1426 : int = aten::add(%i.53, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1427 : int = aten::__getitem__(%1419, %1426) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.211 : int = aten::mul(%size_prods.210, %1427) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.211)
      %1429 : bool = aten::eq(%size_prods.209, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1429) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1430 : str = aten::format(%7, %1419) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1430) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %1431 : Tensor = aten::batch_norm(%bottleneck_output.48, %1417, %1418, %1415, %1416, %1414, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.50 : Tensor = aten::relu_(%1431) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1433 : Tensor = prim::GetAttr[name="weight"](%1405)
  %1434 : Tensor? = prim::GetAttr[name="bias"](%1405)
  %new_features.49 : Tensor = aten::conv2d(%result.50, %1433, %1434, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1439 : float = prim::GetAttr[name="drop_rate"](%730)
  %1440 : bool = aten::gt(%1439, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.50 : Tensor = prim::If(%1440) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %1443 : bool = prim::GetAttr[name="training"](%730)
      %1444 : bool = aten::lt(%1439, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %1445 : bool = prim::If(%1444) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %1446 : bool = aten::gt(%1439, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%1446)
       = prim::If(%1445) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %1447 : str = aten::format(%17, %1439) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%1447) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %1448 : Tensor = aten::dropout(%new_features.49, %1439, %1443) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%1448)
    block1():
      -> (%new_features.49)
  %1449 : Tensor[] = aten::append(%features.3, %new_features.50) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %1451 : bool = prim::GetAttr[name="memory_efficient"](%731)
  %1452 : bool = prim::If(%1451) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %1453 : bool = prim::Uninitialized()
      %1454 : int = aten::len(%features.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %1455 : bool = aten::gt(%1454, %6)
      %1456 : bool, %1457 : bool, %1458 : int = prim::Loop(%12, %1455, %10, %1453, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%1459 : int, %1460 : bool, %1461 : bool, %1462 : int):
          %tensor.26 : Tensor = aten::__getitem__(%features.3, %1462) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %1464 : bool = prim::requires_grad(%tensor.26)
          %1465 : bool, %1466 : bool = prim::If(%1464) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %1453)
          %1467 : int = aten::add(%1462, %19)
          %1468 : bool = aten::lt(%1467, %1454)
          %1469 : bool = aten::__and__(%1468, %1465)
          -> (%1469, %1464, %1466, %1467)
      %1470 : bool = prim::If(%1456)
        block0():
          -> (%1457)
        block1():
          -> (%10)
      -> (%1470)
    block1():
      -> (%10)
  %bottleneck_output.50 : Tensor = prim::If(%1452) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.26 : Tensor = aten::cat(%features.3, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %1473 : __torch__.torch.nn.modules.conv.___torch_mangle_27.Conv2d = prim::GetAttr[name="conv1"](%731)
      %1474 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_26.BatchNorm2d = prim::GetAttr[name="norm1"](%731)
      %1475 : int = aten::dim(%concated_features.26) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %1476 : bool = aten::ne(%1475, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%1476) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %1478 : str = aten::format(%14, %1475) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%1478) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %1479 : bool = prim::GetAttr[name="training"](%1474)
       = prim::If(%1479) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1480 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1474)
          %1481 : Tensor = aten::add(%1480, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1474, %1481)
          -> ()
        block1():
          -> ()
      %1482 : bool = prim::GetAttr[name="training"](%1474)
      %1483 : Tensor = prim::GetAttr[name="running_mean"](%1474)
      %1484 : Tensor = prim::GetAttr[name="running_var"](%1474)
      %1485 : Tensor = prim::GetAttr[name="weight"](%1474)
      %1486 : Tensor = prim::GetAttr[name="bias"](%1474)
       = prim::If(%1482) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1487 : int[] = aten::size(%concated_features.26) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.212 : int = aten::__getitem__(%1487, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1489 : int = aten::len(%1487) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1490 : int = aten::sub(%1489, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.213 : int = prim::Loop(%1490, %5, %size_prods.212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.54 : int, %size_prods.214 : int):
              %1494 : int = aten::add(%i.54, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1495 : int = aten::__getitem__(%1487, %1494) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.215 : int = aten::mul(%size_prods.214, %1495) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.215)
          %1497 : bool = aten::eq(%size_prods.213, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1497) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1498 : str = aten::format(%7, %1487) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1498) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %1499 : Tensor = aten::batch_norm(%concated_features.26, %1485, %1486, %1483, %1484, %1482, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.51 : Tensor = aten::relu_(%1499) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1501 : Tensor = prim::GetAttr[name="weight"](%1473)
      %1502 : Tensor? = prim::GetAttr[name="bias"](%1473)
      %bottleneck_output.51 : Tensor = aten::conv2d(%result.51, %1501, %1502, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.51)
  %1507 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%731)
  %1508 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%731)
  %1509 : int = aten::dim(%bottleneck_output.50) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %1510 : bool = aten::ne(%1509, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%1510) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %1512 : str = aten::format(%14, %1509) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%1512) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %1513 : bool = prim::GetAttr[name="training"](%1508)
   = prim::If(%1513) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1514 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1508)
      %1515 : Tensor = aten::add(%1514, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1508, %1515)
      -> ()
    block1():
      -> ()
  %1516 : bool = prim::GetAttr[name="training"](%1508)
  %1517 : Tensor = prim::GetAttr[name="running_mean"](%1508)
  %1518 : Tensor = prim::GetAttr[name="running_var"](%1508)
  %1519 : Tensor = prim::GetAttr[name="weight"](%1508)
  %1520 : Tensor = prim::GetAttr[name="bias"](%1508)
   = prim::If(%1516) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1521 : int[] = aten::size(%bottleneck_output.50) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.216 : int = aten::__getitem__(%1521, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1523 : int = aten::len(%1521) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1524 : int = aten::sub(%1523, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.217 : int = prim::Loop(%1524, %5, %size_prods.216) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.55 : int, %size_prods.218 : int):
          %1528 : int = aten::add(%i.55, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1529 : int = aten::__getitem__(%1521, %1528) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.219 : int = aten::mul(%size_prods.218, %1529) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.219)
      %1531 : bool = aten::eq(%size_prods.217, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1531) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1532 : str = aten::format(%7, %1521) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1532) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %1533 : Tensor = aten::batch_norm(%bottleneck_output.50, %1519, %1520, %1517, %1518, %1516, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.52 : Tensor = aten::relu_(%1533) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1535 : Tensor = prim::GetAttr[name="weight"](%1507)
  %1536 : Tensor? = prim::GetAttr[name="bias"](%1507)
  %new_features.51 : Tensor = aten::conv2d(%result.52, %1535, %1536, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1541 : float = prim::GetAttr[name="drop_rate"](%731)
  %1542 : bool = aten::gt(%1541, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.52 : Tensor = prim::If(%1542) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %1545 : bool = prim::GetAttr[name="training"](%731)
      %1546 : bool = aten::lt(%1541, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %1547 : bool = prim::If(%1546) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %1548 : bool = aten::gt(%1541, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%1548)
       = prim::If(%1547) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %1549 : str = aten::format(%17, %1541) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%1549) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %1550 : Tensor = aten::dropout(%new_features.51, %1541, %1545) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%1550)
    block1():
      -> (%new_features.51)
  %1551 : Tensor[] = aten::append(%features.3, %new_features.52) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %1553 : bool = prim::GetAttr[name="memory_efficient"](%732)
  %1554 : bool = prim::If(%1553) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %1555 : bool = prim::Uninitialized()
      %1556 : int = aten::len(%features.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %1557 : bool = aten::gt(%1556, %6)
      %1558 : bool, %1559 : bool, %1560 : int = prim::Loop(%12, %1557, %10, %1555, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%1561 : int, %1562 : bool, %1563 : bool, %1564 : int):
          %tensor.27 : Tensor = aten::__getitem__(%features.3, %1564) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %1566 : bool = prim::requires_grad(%tensor.27)
          %1567 : bool, %1568 : bool = prim::If(%1566) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %1555)
          %1569 : int = aten::add(%1564, %19)
          %1570 : bool = aten::lt(%1569, %1556)
          %1571 : bool = aten::__and__(%1570, %1567)
          -> (%1571, %1566, %1568, %1569)
      %1572 : bool = prim::If(%1558)
        block0():
          -> (%1559)
        block1():
          -> (%10)
      -> (%1572)
    block1():
      -> (%10)
  %bottleneck_output.52 : Tensor = prim::If(%1554) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.27 : Tensor = aten::cat(%features.3, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %1575 : __torch__.torch.nn.modules.conv.___torch_mangle_30.Conv2d = prim::GetAttr[name="conv1"](%732)
      %1576 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_29.BatchNorm2d = prim::GetAttr[name="norm1"](%732)
      %1577 : int = aten::dim(%concated_features.27) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %1578 : bool = aten::ne(%1577, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%1578) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %1580 : str = aten::format(%14, %1577) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%1580) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %1581 : bool = prim::GetAttr[name="training"](%1576)
       = prim::If(%1581) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1582 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1576)
          %1583 : Tensor = aten::add(%1582, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1576, %1583)
          -> ()
        block1():
          -> ()
      %1584 : bool = prim::GetAttr[name="training"](%1576)
      %1585 : Tensor = prim::GetAttr[name="running_mean"](%1576)
      %1586 : Tensor = prim::GetAttr[name="running_var"](%1576)
      %1587 : Tensor = prim::GetAttr[name="weight"](%1576)
      %1588 : Tensor = prim::GetAttr[name="bias"](%1576)
       = prim::If(%1584) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1589 : int[] = aten::size(%concated_features.27) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.220 : int = aten::__getitem__(%1589, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1591 : int = aten::len(%1589) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1592 : int = aten::sub(%1591, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.221 : int = prim::Loop(%1592, %5, %size_prods.220) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.56 : int, %size_prods.222 : int):
              %1596 : int = aten::add(%i.56, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1597 : int = aten::__getitem__(%1589, %1596) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.223 : int = aten::mul(%size_prods.222, %1597) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.223)
          %1599 : bool = aten::eq(%size_prods.221, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1599) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1600 : str = aten::format(%7, %1589) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1600) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %1601 : Tensor = aten::batch_norm(%concated_features.27, %1587, %1588, %1585, %1586, %1584, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.53 : Tensor = aten::relu_(%1601) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1603 : Tensor = prim::GetAttr[name="weight"](%1575)
      %1604 : Tensor? = prim::GetAttr[name="bias"](%1575)
      %bottleneck_output.53 : Tensor = aten::conv2d(%result.53, %1603, %1604, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.53)
  %1609 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%732)
  %1610 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%732)
  %1611 : int = aten::dim(%bottleneck_output.52) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %1612 : bool = aten::ne(%1611, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%1612) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %1614 : str = aten::format(%14, %1611) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%1614) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %1615 : bool = prim::GetAttr[name="training"](%1610)
   = prim::If(%1615) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1616 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1610)
      %1617 : Tensor = aten::add(%1616, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1610, %1617)
      -> ()
    block1():
      -> ()
  %1618 : bool = prim::GetAttr[name="training"](%1610)
  %1619 : Tensor = prim::GetAttr[name="running_mean"](%1610)
  %1620 : Tensor = prim::GetAttr[name="running_var"](%1610)
  %1621 : Tensor = prim::GetAttr[name="weight"](%1610)
  %1622 : Tensor = prim::GetAttr[name="bias"](%1610)
   = prim::If(%1618) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1623 : int[] = aten::size(%bottleneck_output.52) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.224 : int = aten::__getitem__(%1623, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1625 : int = aten::len(%1623) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1626 : int = aten::sub(%1625, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.225 : int = prim::Loop(%1626, %5, %size_prods.224) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.57 : int, %size_prods.226 : int):
          %1630 : int = aten::add(%i.57, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1631 : int = aten::__getitem__(%1623, %1630) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.227 : int = aten::mul(%size_prods.226, %1631) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.227)
      %1633 : bool = aten::eq(%size_prods.225, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1633) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1634 : str = aten::format(%7, %1623) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1634) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %1635 : Tensor = aten::batch_norm(%bottleneck_output.52, %1621, %1622, %1619, %1620, %1618, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.54 : Tensor = aten::relu_(%1635) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1637 : Tensor = prim::GetAttr[name="weight"](%1609)
  %1638 : Tensor? = prim::GetAttr[name="bias"](%1609)
  %new_features.53 : Tensor = aten::conv2d(%result.54, %1637, %1638, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1643 : float = prim::GetAttr[name="drop_rate"](%732)
  %1644 : bool = aten::gt(%1643, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.54 : Tensor = prim::If(%1644) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %1647 : bool = prim::GetAttr[name="training"](%732)
      %1648 : bool = aten::lt(%1643, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %1649 : bool = prim::If(%1648) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %1650 : bool = aten::gt(%1643, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%1650)
       = prim::If(%1649) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %1651 : str = aten::format(%17, %1643) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%1651) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %1652 : Tensor = aten::dropout(%new_features.53, %1643, %1647) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%1652)
    block1():
      -> (%new_features.53)
  %1653 : Tensor[] = aten::append(%features.3, %new_features.54) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %1655 : bool = prim::GetAttr[name="memory_efficient"](%733)
  %1656 : bool = prim::If(%1655) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %1657 : bool = prim::Uninitialized()
      %1658 : int = aten::len(%features.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %1659 : bool = aten::gt(%1658, %6)
      %1660 : bool, %1661 : bool, %1662 : int = prim::Loop(%12, %1659, %10, %1657, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%1663 : int, %1664 : bool, %1665 : bool, %1666 : int):
          %tensor.28 : Tensor = aten::__getitem__(%features.3, %1666) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %1668 : bool = prim::requires_grad(%tensor.28)
          %1669 : bool, %1670 : bool = prim::If(%1668) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %1657)
          %1671 : int = aten::add(%1666, %19)
          %1672 : bool = aten::lt(%1671, %1658)
          %1673 : bool = aten::__and__(%1672, %1669)
          -> (%1673, %1668, %1670, %1671)
      %1674 : bool = prim::If(%1660)
        block0():
          -> (%1661)
        block1():
          -> (%10)
      -> (%1674)
    block1():
      -> (%10)
  %bottleneck_output.54 : Tensor = prim::If(%1656) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.28 : Tensor = aten::cat(%features.3, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %1677 : __torch__.torch.nn.modules.conv.___torch_mangle_33.Conv2d = prim::GetAttr[name="conv1"](%733)
      %1678 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_32.BatchNorm2d = prim::GetAttr[name="norm1"](%733)
      %1679 : int = aten::dim(%concated_features.28) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %1680 : bool = aten::ne(%1679, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%1680) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %1682 : str = aten::format(%14, %1679) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%1682) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %1683 : bool = prim::GetAttr[name="training"](%1678)
       = prim::If(%1683) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1684 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1678)
          %1685 : Tensor = aten::add(%1684, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1678, %1685)
          -> ()
        block1():
          -> ()
      %1686 : bool = prim::GetAttr[name="training"](%1678)
      %1687 : Tensor = prim::GetAttr[name="running_mean"](%1678)
      %1688 : Tensor = prim::GetAttr[name="running_var"](%1678)
      %1689 : Tensor = prim::GetAttr[name="weight"](%1678)
      %1690 : Tensor = prim::GetAttr[name="bias"](%1678)
       = prim::If(%1686) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1691 : int[] = aten::size(%concated_features.28) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.228 : int = aten::__getitem__(%1691, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1693 : int = aten::len(%1691) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1694 : int = aten::sub(%1693, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.229 : int = prim::Loop(%1694, %5, %size_prods.228) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.58 : int, %size_prods.230 : int):
              %1698 : int = aten::add(%i.58, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1699 : int = aten::__getitem__(%1691, %1698) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.231 : int = aten::mul(%size_prods.230, %1699) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.231)
          %1701 : bool = aten::eq(%size_prods.229, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1701) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1702 : str = aten::format(%7, %1691) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1702) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %1703 : Tensor = aten::batch_norm(%concated_features.28, %1689, %1690, %1687, %1688, %1686, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.55 : Tensor = aten::relu_(%1703) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1705 : Tensor = prim::GetAttr[name="weight"](%1677)
      %1706 : Tensor? = prim::GetAttr[name="bias"](%1677)
      %bottleneck_output.55 : Tensor = aten::conv2d(%result.55, %1705, %1706, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.55)
  %1711 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%733)
  %1712 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%733)
  %1713 : int = aten::dim(%bottleneck_output.54) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %1714 : bool = aten::ne(%1713, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%1714) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %1716 : str = aten::format(%14, %1713) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%1716) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %1717 : bool = prim::GetAttr[name="training"](%1712)
   = prim::If(%1717) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1718 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1712)
      %1719 : Tensor = aten::add(%1718, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1712, %1719)
      -> ()
    block1():
      -> ()
  %1720 : bool = prim::GetAttr[name="training"](%1712)
  %1721 : Tensor = prim::GetAttr[name="running_mean"](%1712)
  %1722 : Tensor = prim::GetAttr[name="running_var"](%1712)
  %1723 : Tensor = prim::GetAttr[name="weight"](%1712)
  %1724 : Tensor = prim::GetAttr[name="bias"](%1712)
   = prim::If(%1720) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1725 : int[] = aten::size(%bottleneck_output.54) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.232 : int = aten::__getitem__(%1725, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1727 : int = aten::len(%1725) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1728 : int = aten::sub(%1727, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.233 : int = prim::Loop(%1728, %5, %size_prods.232) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.59 : int, %size_prods.234 : int):
          %1732 : int = aten::add(%i.59, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1733 : int = aten::__getitem__(%1725, %1732) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.235 : int = aten::mul(%size_prods.234, %1733) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.235)
      %1735 : bool = aten::eq(%size_prods.233, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1735) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1736 : str = aten::format(%7, %1725) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1736) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %1737 : Tensor = aten::batch_norm(%bottleneck_output.54, %1723, %1724, %1721, %1722, %1720, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.56 : Tensor = aten::relu_(%1737) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1739 : Tensor = prim::GetAttr[name="weight"](%1711)
  %1740 : Tensor? = prim::GetAttr[name="bias"](%1711)
  %new_features.55 : Tensor = aten::conv2d(%result.56, %1739, %1740, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1745 : float = prim::GetAttr[name="drop_rate"](%733)
  %1746 : bool = aten::gt(%1745, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.56 : Tensor = prim::If(%1746) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %1749 : bool = prim::GetAttr[name="training"](%733)
      %1750 : bool = aten::lt(%1745, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %1751 : bool = prim::If(%1750) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %1752 : bool = aten::gt(%1745, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%1752)
       = prim::If(%1751) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %1753 : str = aten::format(%17, %1745) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%1753) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %1754 : Tensor = aten::dropout(%new_features.55, %1745, %1749) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%1754)
    block1():
      -> (%new_features.55)
  %1755 : Tensor[] = aten::append(%features.3, %new_features.56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %1757 : bool = prim::GetAttr[name="memory_efficient"](%734)
  %1758 : bool = prim::If(%1757) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %1759 : bool = prim::Uninitialized()
      %1760 : int = aten::len(%features.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %1761 : bool = aten::gt(%1760, %6)
      %1762 : bool, %1763 : bool, %1764 : int = prim::Loop(%12, %1761, %10, %1759, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%1765 : int, %1766 : bool, %1767 : bool, %1768 : int):
          %tensor.29 : Tensor = aten::__getitem__(%features.3, %1768) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %1770 : bool = prim::requires_grad(%tensor.29)
          %1771 : bool, %1772 : bool = prim::If(%1770) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %1759)
          %1773 : int = aten::add(%1768, %19)
          %1774 : bool = aten::lt(%1773, %1760)
          %1775 : bool = aten::__and__(%1774, %1771)
          -> (%1775, %1770, %1772, %1773)
      %1776 : bool = prim::If(%1762)
        block0():
          -> (%1763)
        block1():
          -> (%10)
      -> (%1776)
    block1():
      -> (%10)
  %bottleneck_output.56 : Tensor = prim::If(%1758) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.29 : Tensor = aten::cat(%features.3, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %1779 : __torch__.torch.nn.modules.conv.___torch_mangle_36.Conv2d = prim::GetAttr[name="conv1"](%734)
      %1780 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_35.BatchNorm2d = prim::GetAttr[name="norm1"](%734)
      %1781 : int = aten::dim(%concated_features.29) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %1782 : bool = aten::ne(%1781, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%1782) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %1784 : str = aten::format(%14, %1781) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%1784) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %1785 : bool = prim::GetAttr[name="training"](%1780)
       = prim::If(%1785) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1786 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1780)
          %1787 : Tensor = aten::add(%1786, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1780, %1787)
          -> ()
        block1():
          -> ()
      %1788 : bool = prim::GetAttr[name="training"](%1780)
      %1789 : Tensor = prim::GetAttr[name="running_mean"](%1780)
      %1790 : Tensor = prim::GetAttr[name="running_var"](%1780)
      %1791 : Tensor = prim::GetAttr[name="weight"](%1780)
      %1792 : Tensor = prim::GetAttr[name="bias"](%1780)
       = prim::If(%1788) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1793 : int[] = aten::size(%concated_features.29) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.236 : int = aten::__getitem__(%1793, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1795 : int = aten::len(%1793) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1796 : int = aten::sub(%1795, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.237 : int = prim::Loop(%1796, %5, %size_prods.236) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.60 : int, %size_prods.238 : int):
              %1800 : int = aten::add(%i.60, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1801 : int = aten::__getitem__(%1793, %1800) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.239 : int = aten::mul(%size_prods.238, %1801) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.239)
          %1803 : bool = aten::eq(%size_prods.237, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1803) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1804 : str = aten::format(%7, %1793) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1804) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %1805 : Tensor = aten::batch_norm(%concated_features.29, %1791, %1792, %1789, %1790, %1788, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.57 : Tensor = aten::relu_(%1805) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1807 : Tensor = prim::GetAttr[name="weight"](%1779)
      %1808 : Tensor? = prim::GetAttr[name="bias"](%1779)
      %bottleneck_output.57 : Tensor = aten::conv2d(%result.57, %1807, %1808, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.57)
  %1813 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%734)
  %1814 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%734)
  %1815 : int = aten::dim(%bottleneck_output.56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %1816 : bool = aten::ne(%1815, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%1816) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %1818 : str = aten::format(%14, %1815) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%1818) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %1819 : bool = prim::GetAttr[name="training"](%1814)
   = prim::If(%1819) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1820 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1814)
      %1821 : Tensor = aten::add(%1820, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1814, %1821)
      -> ()
    block1():
      -> ()
  %1822 : bool = prim::GetAttr[name="training"](%1814)
  %1823 : Tensor = prim::GetAttr[name="running_mean"](%1814)
  %1824 : Tensor = prim::GetAttr[name="running_var"](%1814)
  %1825 : Tensor = prim::GetAttr[name="weight"](%1814)
  %1826 : Tensor = prim::GetAttr[name="bias"](%1814)
   = prim::If(%1822) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1827 : int[] = aten::size(%bottleneck_output.56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.240 : int = aten::__getitem__(%1827, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1829 : int = aten::len(%1827) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1830 : int = aten::sub(%1829, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.241 : int = prim::Loop(%1830, %5, %size_prods.240) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.61 : int, %size_prods.242 : int):
          %1834 : int = aten::add(%i.61, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1835 : int = aten::__getitem__(%1827, %1834) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.243 : int = aten::mul(%size_prods.242, %1835) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.243)
      %1837 : bool = aten::eq(%size_prods.241, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1837) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1838 : str = aten::format(%7, %1827) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1838) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %1839 : Tensor = aten::batch_norm(%bottleneck_output.56, %1825, %1826, %1823, %1824, %1822, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.58 : Tensor = aten::relu_(%1839) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1841 : Tensor = prim::GetAttr[name="weight"](%1813)
  %1842 : Tensor? = prim::GetAttr[name="bias"](%1813)
  %new_features.57 : Tensor = aten::conv2d(%result.58, %1841, %1842, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1847 : float = prim::GetAttr[name="drop_rate"](%734)
  %1848 : bool = aten::gt(%1847, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.58 : Tensor = prim::If(%1848) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %1851 : bool = prim::GetAttr[name="training"](%734)
      %1852 : bool = aten::lt(%1847, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %1853 : bool = prim::If(%1852) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %1854 : bool = aten::gt(%1847, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%1854)
       = prim::If(%1853) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %1855 : str = aten::format(%17, %1847) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%1855) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %1856 : Tensor = aten::dropout(%new_features.57, %1847, %1851) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%1856)
    block1():
      -> (%new_features.57)
  %1857 : Tensor[] = aten::append(%features.3, %new_features.58) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %1859 : bool = prim::GetAttr[name="memory_efficient"](%735)
  %1860 : bool = prim::If(%1859) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %1861 : bool = prim::Uninitialized()
      %1862 : int = aten::len(%features.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %1863 : bool = aten::gt(%1862, %6)
      %1864 : bool, %1865 : bool, %1866 : int = prim::Loop(%12, %1863, %10, %1861, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%1867 : int, %1868 : bool, %1869 : bool, %1870 : int):
          %tensor.42 : Tensor = aten::__getitem__(%features.3, %1870) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %1872 : bool = prim::requires_grad(%tensor.42)
          %1873 : bool, %1874 : bool = prim::If(%1872) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %1861)
          %1875 : int = aten::add(%1870, %19)
          %1876 : bool = aten::lt(%1875, %1862)
          %1877 : bool = aten::__and__(%1876, %1873)
          -> (%1877, %1872, %1874, %1875)
      %1878 : bool = prim::If(%1864)
        block0():
          -> (%1865)
        block1():
          -> (%10)
      -> (%1878)
    block1():
      -> (%10)
  %bottleneck_output.82 : Tensor = prim::If(%1860) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.42 : Tensor = aten::cat(%features.3, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %1881 : __torch__.torch.nn.modules.conv.___torch_mangle_39.Conv2d = prim::GetAttr[name="conv1"](%735)
      %1882 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_38.BatchNorm2d = prim::GetAttr[name="norm1"](%735)
      %1883 : int = aten::dim(%concated_features.42) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %1884 : bool = aten::ne(%1883, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%1884) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %1886 : str = aten::format(%14, %1883) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%1886) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %1887 : bool = prim::GetAttr[name="training"](%1882)
       = prim::If(%1887) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %1888 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1882)
          %1889 : Tensor = aten::add(%1888, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1882, %1889)
          -> ()
        block1():
          -> ()
      %1890 : bool = prim::GetAttr[name="training"](%1882)
      %1891 : Tensor = prim::GetAttr[name="running_mean"](%1882)
      %1892 : Tensor = prim::GetAttr[name="running_var"](%1882)
      %1893 : Tensor = prim::GetAttr[name="weight"](%1882)
      %1894 : Tensor = prim::GetAttr[name="bias"](%1882)
       = prim::If(%1890) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %1895 : int[] = aten::size(%concated_features.42) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.340 : int = aten::__getitem__(%1895, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %1897 : int = aten::len(%1895) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %1898 : int = aten::sub(%1897, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.341 : int = prim::Loop(%1898, %5, %size_prods.340) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.86 : int, %size_prods.342 : int):
              %1902 : int = aten::add(%i.86, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %1903 : int = aten::__getitem__(%1895, %1902) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.343 : int = aten::mul(%size_prods.342, %1903) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.343)
          %1905 : bool = aten::eq(%size_prods.341, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%1905) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %1906 : str = aten::format(%7, %1895) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%1906) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %1907 : Tensor = aten::batch_norm(%concated_features.42, %1893, %1894, %1891, %1892, %1890, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.83 : Tensor = aten::relu_(%1907) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %1909 : Tensor = prim::GetAttr[name="weight"](%1881)
      %1910 : Tensor? = prim::GetAttr[name="bias"](%1881)
      %bottleneck_output.83 : Tensor = aten::conv2d(%result.83, %1909, %1910, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.83)
  %1915 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%735)
  %1916 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%735)
  %1917 : int = aten::dim(%bottleneck_output.82) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %1918 : bool = aten::ne(%1917, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%1918) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %1920 : str = aten::format(%14, %1917) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%1920) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %1921 : bool = prim::GetAttr[name="training"](%1916)
   = prim::If(%1921) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1922 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1916)
      %1923 : Tensor = aten::add(%1922, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1916, %1923)
      -> ()
    block1():
      -> ()
  %1924 : bool = prim::GetAttr[name="training"](%1916)
  %1925 : Tensor = prim::GetAttr[name="running_mean"](%1916)
  %1926 : Tensor = prim::GetAttr[name="running_var"](%1916)
  %1927 : Tensor = prim::GetAttr[name="weight"](%1916)
  %1928 : Tensor = prim::GetAttr[name="bias"](%1916)
   = prim::If(%1924) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1929 : int[] = aten::size(%bottleneck_output.82) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.300 : int = aten::__getitem__(%1929, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1931 : int = aten::len(%1929) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1932 : int = aten::sub(%1931, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.301 : int = prim::Loop(%1932, %5, %size_prods.300) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.76 : int, %size_prods.302 : int):
          %1936 : int = aten::add(%i.76, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1937 : int = aten::__getitem__(%1929, %1936) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.303 : int = aten::mul(%size_prods.302, %1937) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.303)
      %1939 : bool = aten::eq(%size_prods.301, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1939) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1940 : str = aten::format(%7, %1929) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1940) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %1941 : Tensor = aten::batch_norm(%bottleneck_output.82, %1927, %1928, %1925, %1926, %1924, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.84 : Tensor = aten::relu_(%1941) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1943 : Tensor = prim::GetAttr[name="weight"](%1915)
  %1944 : Tensor? = prim::GetAttr[name="bias"](%1915)
  %new_features.83 : Tensor = aten::conv2d(%result.84, %1943, %1944, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %1949 : float = prim::GetAttr[name="drop_rate"](%735)
  %1950 : bool = aten::gt(%1949, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.60 : Tensor = prim::If(%1950) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %1953 : bool = prim::GetAttr[name="training"](%735)
      %1954 : bool = aten::lt(%1949, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %1955 : bool = prim::If(%1954) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %1956 : bool = aten::gt(%1949, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%1956)
       = prim::If(%1955) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %1957 : str = aten::format(%17, %1949) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%1957) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %1958 : Tensor = aten::dropout(%new_features.83, %1949, %1953) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%1958)
    block1():
      -> (%new_features.83)
  %1959 : Tensor[] = aten::append(%features.3, %new_features.60) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %input.15 : Tensor = aten::cat(%features.3, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:129:15
  %1961 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_42.BatchNorm2d = prim::GetAttr[name="norm"](%27)
  %1962 : __torch__.torch.nn.modules.conv.___torch_mangle_43.Conv2d = prim::GetAttr[name="conv"](%27)
  %1963 : int = aten::dim(%input.15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %1964 : bool = aten::ne(%1963, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%1964) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %1966 : str = aten::format(%14, %1963) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%1966) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %1967 : bool = prim::GetAttr[name="training"](%1961)
   = prim::If(%1967) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %1968 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1961)
      %1969 : Tensor = aten::add(%1968, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%1961, %1969)
      -> ()
    block1():
      -> ()
  %1970 : bool = prim::GetAttr[name="training"](%1961)
  %1971 : Tensor = prim::GetAttr[name="running_mean"](%1961)
  %1972 : Tensor = prim::GetAttr[name="running_var"](%1961)
  %1973 : Tensor = prim::GetAttr[name="weight"](%1961)
  %1974 : Tensor = prim::GetAttr[name="bias"](%1961)
   = prim::If(%1970) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %1975 : int[] = aten::size(%input.15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.344 : int = aten::__getitem__(%1975, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %1977 : int = aten::len(%1975) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %1978 : int = aten::sub(%1977, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.345 : int = prim::Loop(%1978, %5, %size_prods.344) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.87 : int, %size_prods.346 : int):
          %1982 : int = aten::add(%i.87, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %1983 : int = aten::__getitem__(%1975, %1982) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.347 : int = aten::mul(%size_prods.346, %1983) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.347)
      %1985 : bool = aten::eq(%size_prods.345, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%1985) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %1986 : str = aten::format(%7, %1975) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%1986) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.22 : Tensor = aten::batch_norm(%input.15, %1973, %1974, %1971, %1972, %1970, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %input.18 : Tensor = aten::relu_(%input.22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %1989 : Tensor = prim::GetAttr[name="weight"](%1962)
  %1990 : Tensor? = prim::GetAttr[name="bias"](%1962)
  %input.20 : Tensor = aten::conv2d(%input.18, %1989, %1990, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %input.17 : Tensor = aten::avg_pool2d(%input.20, %6197, %6197, %6205, %10, %5, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/pooling.py:615:15
  %features.4 : Tensor[] = prim::ListConstruct(%input.17)
  %2000 : __torch__.torchvision.models.densenet.___torch_mangle_19._DenseLayer = prim::GetAttr[name="denselayer1"](%28)
  %2001 : __torch__.torchvision.models.densenet.___torch_mangle_22._DenseLayer = prim::GetAttr[name="denselayer2"](%28)
  %2002 : __torch__.torchvision.models.densenet.___torch_mangle_25._DenseLayer = prim::GetAttr[name="denselayer3"](%28)
  %2003 : __torch__.torchvision.models.densenet.___torch_mangle_28._DenseLayer = prim::GetAttr[name="denselayer4"](%28)
  %2004 : __torch__.torchvision.models.densenet.___torch_mangle_31._DenseLayer = prim::GetAttr[name="denselayer5"](%28)
  %2005 : __torch__.torchvision.models.densenet.___torch_mangle_34._DenseLayer = prim::GetAttr[name="denselayer6"](%28)
  %2006 : __torch__.torchvision.models.densenet.___torch_mangle_37._DenseLayer = prim::GetAttr[name="denselayer7"](%28)
  %2007 : __torch__.torchvision.models.densenet.___torch_mangle_40._DenseLayer = prim::GetAttr[name="denselayer8"](%28)
  %2008 : __torch__.torchvision.models.densenet.___torch_mangle_46._DenseLayer = prim::GetAttr[name="denselayer9"](%28)
  %2009 : __torch__.torchvision.models.densenet.___torch_mangle_49._DenseLayer = prim::GetAttr[name="denselayer10"](%28)
  %2010 : __torch__.torchvision.models.densenet.___torch_mangle_52._DenseLayer = prim::GetAttr[name="denselayer11"](%28)
  %2011 : __torch__.torchvision.models.densenet.___torch_mangle_55._DenseLayer = prim::GetAttr[name="denselayer12"](%28)
  %2012 : __torch__.torchvision.models.densenet.___torch_mangle_58._DenseLayer = prim::GetAttr[name="denselayer13"](%28)
  %2013 : __torch__.torchvision.models.densenet.___torch_mangle_61._DenseLayer = prim::GetAttr[name="denselayer14"](%28)
  %2014 : __torch__.torchvision.models.densenet.___torch_mangle_64._DenseLayer = prim::GetAttr[name="denselayer15"](%28)
  %2015 : __torch__.torchvision.models.densenet.___torch_mangle_67._DenseLayer = prim::GetAttr[name="denselayer16"](%28)
  %2016 : __torch__.torchvision.models.densenet.___torch_mangle_70._DenseLayer = prim::GetAttr[name="denselayer17"](%28)
  %2017 : __torch__.torchvision.models.densenet.___torch_mangle_73._DenseLayer = prim::GetAttr[name="denselayer18"](%28)
  %2018 : __torch__.torchvision.models.densenet.___torch_mangle_76._DenseLayer = prim::GetAttr[name="denselayer19"](%28)
  %2019 : __torch__.torchvision.models.densenet.___torch_mangle_79._DenseLayer = prim::GetAttr[name="denselayer20"](%28)
  %2020 : __torch__.torchvision.models.densenet.___torch_mangle_82._DenseLayer = prim::GetAttr[name="denselayer21"](%28)
  %2021 : __torch__.torchvision.models.densenet.___torch_mangle_85._DenseLayer = prim::GetAttr[name="denselayer22"](%28)
  %2022 : __torch__.torchvision.models.densenet.___torch_mangle_88._DenseLayer = prim::GetAttr[name="denselayer23"](%28)
  %2023 : __torch__.torchvision.models.densenet.___torch_mangle_91._DenseLayer = prim::GetAttr[name="denselayer24"](%28)
  %2025 : bool = prim::GetAttr[name="memory_efficient"](%2000)
  %2026 : bool = prim::If(%2025) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %2027 : bool = prim::Uninitialized()
      %2028 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %2029 : bool = aten::gt(%2028, %6)
      %2030 : bool, %2031 : bool, %2032 : int = prim::Loop(%12, %2029, %10, %2027, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%2033 : int, %2034 : bool, %2035 : bool, %2036 : int):
          %tensor.43 : Tensor = aten::__getitem__(%features.4, %2036) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %2038 : bool = prim::requires_grad(%tensor.43)
          %2039 : bool, %2040 : bool = prim::If(%2038) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %2027)
          %2041 : int = aten::add(%2036, %19)
          %2042 : bool = aten::lt(%2041, %2028)
          %2043 : bool = aten::__and__(%2042, %2039)
          -> (%2043, %2038, %2040, %2041)
      %2044 : bool = prim::If(%2030)
        block0():
          -> (%2031)
        block1():
          -> (%10)
      -> (%2044)
    block1():
      -> (%10)
  %bottleneck_output.84 : Tensor = prim::If(%2026) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.43 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %2047 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv2d = prim::GetAttr[name="conv1"](%2000)
      %2048 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_17.BatchNorm2d = prim::GetAttr[name="norm1"](%2000)
      %2049 : int = aten::dim(%concated_features.43) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %2050 : bool = aten::ne(%2049, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%2050) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %2052 : str = aten::format(%14, %2049) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%2052) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %2053 : bool = prim::GetAttr[name="training"](%2048)
       = prim::If(%2053) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2054 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2048)
          %2055 : Tensor = aten::add(%2054, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2048, %2055)
          -> ()
        block1():
          -> ()
      %2056 : bool = prim::GetAttr[name="training"](%2048)
      %2057 : Tensor = prim::GetAttr[name="running_mean"](%2048)
      %2058 : Tensor = prim::GetAttr[name="running_var"](%2048)
      %2059 : Tensor = prim::GetAttr[name="weight"](%2048)
      %2060 : Tensor = prim::GetAttr[name="bias"](%2048)
       = prim::If(%2056) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2061 : int[] = aten::size(%concated_features.43) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.352 : int = aten::__getitem__(%2061, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2063 : int = aten::len(%2061) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2064 : int = aten::sub(%2063, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.353 : int = prim::Loop(%2064, %5, %size_prods.352) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.89 : int, %size_prods.354 : int):
              %2068 : int = aten::add(%i.89, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2069 : int = aten::__getitem__(%2061, %2068) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.355 : int = aten::mul(%size_prods.354, %2069) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.355)
          %2071 : bool = aten::eq(%size_prods.353, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2071) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2072 : str = aten::format(%7, %2061) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2072) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %2073 : Tensor = aten::batch_norm(%concated_features.43, %2059, %2060, %2057, %2058, %2056, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.85 : Tensor = aten::relu_(%2073) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2075 : Tensor = prim::GetAttr[name="weight"](%2047)
      %2076 : Tensor? = prim::GetAttr[name="bias"](%2047)
      %bottleneck_output.85 : Tensor = aten::conv2d(%result.85, %2075, %2076, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.85)
  %2081 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2000)
  %2082 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2000)
  %2083 : int = aten::dim(%bottleneck_output.84) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %2084 : bool = aten::ne(%2083, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%2084) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %2086 : str = aten::format(%14, %2083) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%2086) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %2087 : bool = prim::GetAttr[name="training"](%2082)
   = prim::If(%2087) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %2088 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2082)
      %2089 : Tensor = aten::add(%2088, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%2082, %2089)
      -> ()
    block1():
      -> ()
  %2090 : bool = prim::GetAttr[name="training"](%2082)
  %2091 : Tensor = prim::GetAttr[name="running_mean"](%2082)
  %2092 : Tensor = prim::GetAttr[name="running_var"](%2082)
  %2093 : Tensor = prim::GetAttr[name="weight"](%2082)
  %2094 : Tensor = prim::GetAttr[name="bias"](%2082)
   = prim::If(%2090) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %2095 : int[] = aten::size(%bottleneck_output.84) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.356 : int = aten::__getitem__(%2095, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %2097 : int = aten::len(%2095) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %2098 : int = aten::sub(%2097, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.357 : int = prim::Loop(%2098, %5, %size_prods.356) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.90 : int, %size_prods.358 : int):
          %2102 : int = aten::add(%i.90, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %2103 : int = aten::__getitem__(%2095, %2102) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.359 : int = aten::mul(%size_prods.358, %2103) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.359)
      %2105 : bool = aten::eq(%size_prods.357, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%2105) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %2106 : str = aten::format(%7, %2095) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%2106) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %2107 : Tensor = aten::batch_norm(%bottleneck_output.84, %2093, %2094, %2091, %2092, %2090, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.86 : Tensor = aten::relu_(%2107) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %2109 : Tensor = prim::GetAttr[name="weight"](%2081)
  %2110 : Tensor? = prim::GetAttr[name="bias"](%2081)
  %new_features.85 : Tensor = aten::conv2d(%result.86, %2109, %2110, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %2115 : float = prim::GetAttr[name="drop_rate"](%2000)
  %2116 : bool = aten::gt(%2115, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.86 : Tensor = prim::If(%2116) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %2119 : bool = prim::GetAttr[name="training"](%2000)
      %2120 : bool = aten::lt(%2115, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %2121 : bool = prim::If(%2120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %2122 : bool = aten::gt(%2115, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%2122)
       = prim::If(%2121) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %2123 : str = aten::format(%17, %2115) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%2123) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %2124 : Tensor = aten::dropout(%new_features.85, %2115, %2119) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%2124)
    block1():
      -> (%new_features.85)
  %2125 : Tensor[] = aten::append(%features.4, %new_features.86) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %2127 : bool = prim::GetAttr[name="memory_efficient"](%2001)
  %2128 : bool = prim::If(%2127) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %2129 : bool = prim::Uninitialized()
      %2130 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %2131 : bool = aten::gt(%2130, %6)
      %2132 : bool, %2133 : bool, %2134 : int = prim::Loop(%12, %2131, %10, %2129, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%2135 : int, %2136 : bool, %2137 : bool, %2138 : int):
          %tensor.44 : Tensor = aten::__getitem__(%features.4, %2138) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %2140 : bool = prim::requires_grad(%tensor.44)
          %2141 : bool, %2142 : bool = prim::If(%2140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %2129)
          %2143 : int = aten::add(%2138, %19)
          %2144 : bool = aten::lt(%2143, %2130)
          %2145 : bool = aten::__and__(%2144, %2141)
          -> (%2145, %2140, %2142, %2143)
      %2146 : bool = prim::If(%2132)
        block0():
          -> (%2133)
        block1():
          -> (%10)
      -> (%2146)
    block1():
      -> (%10)
  %bottleneck_output.86 : Tensor = prim::If(%2128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.44 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %2149 : __torch__.torch.nn.modules.conv.___torch_mangle_21.Conv2d = prim::GetAttr[name="conv1"](%2001)
      %2150 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_20.BatchNorm2d = prim::GetAttr[name="norm1"](%2001)
      %2151 : int = aten::dim(%concated_features.44) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %2152 : bool = aten::ne(%2151, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%2152) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %2154 : str = aten::format(%14, %2151) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%2154) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %2155 : bool = prim::GetAttr[name="training"](%2150)
       = prim::If(%2155) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2156 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2150)
          %2157 : Tensor = aten::add(%2156, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2150, %2157)
          -> ()
        block1():
          -> ()
      %2158 : bool = prim::GetAttr[name="training"](%2150)
      %2159 : Tensor = prim::GetAttr[name="running_mean"](%2150)
      %2160 : Tensor = prim::GetAttr[name="running_var"](%2150)
      %2161 : Tensor = prim::GetAttr[name="weight"](%2150)
      %2162 : Tensor = prim::GetAttr[name="bias"](%2150)
       = prim::If(%2158) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2163 : int[] = aten::size(%concated_features.44) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.360 : int = aten::__getitem__(%2163, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2165 : int = aten::len(%2163) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2166 : int = aten::sub(%2165, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.361 : int = prim::Loop(%2166, %5, %size_prods.360) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.91 : int, %size_prods.362 : int):
              %2170 : int = aten::add(%i.91, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2171 : int = aten::__getitem__(%2163, %2170) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.363 : int = aten::mul(%size_prods.362, %2171) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.363)
          %2173 : bool = aten::eq(%size_prods.361, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2173) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2174 : str = aten::format(%7, %2163) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2174) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %2175 : Tensor = aten::batch_norm(%concated_features.44, %2161, %2162, %2159, %2160, %2158, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.87 : Tensor = aten::relu_(%2175) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2177 : Tensor = prim::GetAttr[name="weight"](%2149)
      %2178 : Tensor? = prim::GetAttr[name="bias"](%2149)
      %bottleneck_output.87 : Tensor = aten::conv2d(%result.87, %2177, %2178, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.87)
  %2183 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2001)
  %2184 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2001)
  %2185 : int = aten::dim(%bottleneck_output.86) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %2186 : bool = aten::ne(%2185, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%2186) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %2188 : str = aten::format(%14, %2185) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%2188) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %2189 : bool = prim::GetAttr[name="training"](%2184)
   = prim::If(%2189) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %2190 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2184)
      %2191 : Tensor = aten::add(%2190, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%2184, %2191)
      -> ()
    block1():
      -> ()
  %2192 : bool = prim::GetAttr[name="training"](%2184)
  %2193 : Tensor = prim::GetAttr[name="running_mean"](%2184)
  %2194 : Tensor = prim::GetAttr[name="running_var"](%2184)
  %2195 : Tensor = prim::GetAttr[name="weight"](%2184)
  %2196 : Tensor = prim::GetAttr[name="bias"](%2184)
   = prim::If(%2192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %2197 : int[] = aten::size(%bottleneck_output.86) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.364 : int = aten::__getitem__(%2197, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %2199 : int = aten::len(%2197) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %2200 : int = aten::sub(%2199, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.365 : int = prim::Loop(%2200, %5, %size_prods.364) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.92 : int, %size_prods.366 : int):
          %2204 : int = aten::add(%i.92, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %2205 : int = aten::__getitem__(%2197, %2204) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.367 : int = aten::mul(%size_prods.366, %2205) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.367)
      %2207 : bool = aten::eq(%size_prods.365, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%2207) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %2208 : str = aten::format(%7, %2197) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%2208) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %2209 : Tensor = aten::batch_norm(%bottleneck_output.86, %2195, %2196, %2193, %2194, %2192, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.88 : Tensor = aten::relu_(%2209) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %2211 : Tensor = prim::GetAttr[name="weight"](%2183)
  %2212 : Tensor? = prim::GetAttr[name="bias"](%2183)
  %new_features.87 : Tensor = aten::conv2d(%result.88, %2211, %2212, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %2217 : float = prim::GetAttr[name="drop_rate"](%2001)
  %2218 : bool = aten::gt(%2217, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.88 : Tensor = prim::If(%2218) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %2221 : bool = prim::GetAttr[name="training"](%2001)
      %2222 : bool = aten::lt(%2217, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %2223 : bool = prim::If(%2222) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %2224 : bool = aten::gt(%2217, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%2224)
       = prim::If(%2223) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %2225 : str = aten::format(%17, %2217) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%2225) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %2226 : Tensor = aten::dropout(%new_features.87, %2217, %2221) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%2226)
    block1():
      -> (%new_features.87)
  %2227 : Tensor[] = aten::append(%features.4, %new_features.88) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %2229 : bool = prim::GetAttr[name="memory_efficient"](%2002)
  %2230 : bool = prim::If(%2229) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %2231 : bool = prim::Uninitialized()
      %2232 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %2233 : bool = aten::gt(%2232, %6)
      %2234 : bool, %2235 : bool, %2236 : int = prim::Loop(%12, %2233, %10, %2231, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%2237 : int, %2238 : bool, %2239 : bool, %2240 : int):
          %tensor.45 : Tensor = aten::__getitem__(%features.4, %2240) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %2242 : bool = prim::requires_grad(%tensor.45)
          %2243 : bool, %2244 : bool = prim::If(%2242) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %2231)
          %2245 : int = aten::add(%2240, %19)
          %2246 : bool = aten::lt(%2245, %2232)
          %2247 : bool = aten::__and__(%2246, %2243)
          -> (%2247, %2242, %2244, %2245)
      %2248 : bool = prim::If(%2234)
        block0():
          -> (%2235)
        block1():
          -> (%10)
      -> (%2248)
    block1():
      -> (%10)
  %bottleneck_output.88 : Tensor = prim::If(%2230) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.45 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %2251 : __torch__.torch.nn.modules.conv.___torch_mangle_24.Conv2d = prim::GetAttr[name="conv1"](%2002)
      %2252 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm2d = prim::GetAttr[name="norm1"](%2002)
      %2253 : int = aten::dim(%concated_features.45) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %2254 : bool = aten::ne(%2253, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%2254) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %2256 : str = aten::format(%14, %2253) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%2256) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %2257 : bool = prim::GetAttr[name="training"](%2252)
       = prim::If(%2257) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2258 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2252)
          %2259 : Tensor = aten::add(%2258, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2252, %2259)
          -> ()
        block1():
          -> ()
      %2260 : bool = prim::GetAttr[name="training"](%2252)
      %2261 : Tensor = prim::GetAttr[name="running_mean"](%2252)
      %2262 : Tensor = prim::GetAttr[name="running_var"](%2252)
      %2263 : Tensor = prim::GetAttr[name="weight"](%2252)
      %2264 : Tensor = prim::GetAttr[name="bias"](%2252)
       = prim::If(%2260) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2265 : int[] = aten::size(%concated_features.45) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.368 : int = aten::__getitem__(%2265, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2267 : int = aten::len(%2265) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2268 : int = aten::sub(%2267, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.369 : int = prim::Loop(%2268, %5, %size_prods.368) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.93 : int, %size_prods.370 : int):
              %2272 : int = aten::add(%i.93, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2273 : int = aten::__getitem__(%2265, %2272) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.371 : int = aten::mul(%size_prods.370, %2273) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.371)
          %2275 : bool = aten::eq(%size_prods.369, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2275) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2276 : str = aten::format(%7, %2265) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2276) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %2277 : Tensor = aten::batch_norm(%concated_features.45, %2263, %2264, %2261, %2262, %2260, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.89 : Tensor = aten::relu_(%2277) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2279 : Tensor = prim::GetAttr[name="weight"](%2251)
      %2280 : Tensor? = prim::GetAttr[name="bias"](%2251)
      %bottleneck_output.89 : Tensor = aten::conv2d(%result.89, %2279, %2280, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.89)
  %2285 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2002)
  %2286 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2002)
  %2287 : int = aten::dim(%bottleneck_output.88) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %2288 : bool = aten::ne(%2287, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%2288) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %2290 : str = aten::format(%14, %2287) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%2290) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %2291 : bool = prim::GetAttr[name="training"](%2286)
   = prim::If(%2291) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %2292 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2286)
      %2293 : Tensor = aten::add(%2292, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%2286, %2293)
      -> ()
    block1():
      -> ()
  %2294 : bool = prim::GetAttr[name="training"](%2286)
  %2295 : Tensor = prim::GetAttr[name="running_mean"](%2286)
  %2296 : Tensor = prim::GetAttr[name="running_var"](%2286)
  %2297 : Tensor = prim::GetAttr[name="weight"](%2286)
  %2298 : Tensor = prim::GetAttr[name="bias"](%2286)
   = prim::If(%2294) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %2299 : int[] = aten::size(%bottleneck_output.88) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.372 : int = aten::__getitem__(%2299, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %2301 : int = aten::len(%2299) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %2302 : int = aten::sub(%2301, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.373 : int = prim::Loop(%2302, %5, %size_prods.372) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.94 : int, %size_prods.374 : int):
          %2306 : int = aten::add(%i.94, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %2307 : int = aten::__getitem__(%2299, %2306) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.375 : int = aten::mul(%size_prods.374, %2307) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.375)
      %2309 : bool = aten::eq(%size_prods.373, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%2309) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %2310 : str = aten::format(%7, %2299) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%2310) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %2311 : Tensor = aten::batch_norm(%bottleneck_output.88, %2297, %2298, %2295, %2296, %2294, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.90 : Tensor = aten::relu_(%2311) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %2313 : Tensor = prim::GetAttr[name="weight"](%2285)
  %2314 : Tensor? = prim::GetAttr[name="bias"](%2285)
  %new_features.89 : Tensor = aten::conv2d(%result.90, %2313, %2314, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %2319 : float = prim::GetAttr[name="drop_rate"](%2002)
  %2320 : bool = aten::gt(%2319, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.90 : Tensor = prim::If(%2320) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %2323 : bool = prim::GetAttr[name="training"](%2002)
      %2324 : bool = aten::lt(%2319, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %2325 : bool = prim::If(%2324) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %2326 : bool = aten::gt(%2319, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%2326)
       = prim::If(%2325) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %2327 : str = aten::format(%17, %2319) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%2327) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %2328 : Tensor = aten::dropout(%new_features.89, %2319, %2323) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%2328)
    block1():
      -> (%new_features.89)
  %2329 : Tensor[] = aten::append(%features.4, %new_features.90) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %2331 : bool = prim::GetAttr[name="memory_efficient"](%2003)
  %2332 : bool = prim::If(%2331) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %2333 : bool = prim::Uninitialized()
      %2334 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %2335 : bool = aten::gt(%2334, %6)
      %2336 : bool, %2337 : bool, %2338 : int = prim::Loop(%12, %2335, %10, %2333, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%2339 : int, %2340 : bool, %2341 : bool, %2342 : int):
          %tensor.46 : Tensor = aten::__getitem__(%features.4, %2342) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %2344 : bool = prim::requires_grad(%tensor.46)
          %2345 : bool, %2346 : bool = prim::If(%2344) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %2333)
          %2347 : int = aten::add(%2342, %19)
          %2348 : bool = aten::lt(%2347, %2334)
          %2349 : bool = aten::__and__(%2348, %2345)
          -> (%2349, %2344, %2346, %2347)
      %2350 : bool = prim::If(%2336)
        block0():
          -> (%2337)
        block1():
          -> (%10)
      -> (%2350)
    block1():
      -> (%10)
  %bottleneck_output.90 : Tensor = prim::If(%2332) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.46 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %2353 : __torch__.torch.nn.modules.conv.___torch_mangle_27.Conv2d = prim::GetAttr[name="conv1"](%2003)
      %2354 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_26.BatchNorm2d = prim::GetAttr[name="norm1"](%2003)
      %2355 : int = aten::dim(%concated_features.46) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %2356 : bool = aten::ne(%2355, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%2356) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %2358 : str = aten::format(%14, %2355) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%2358) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %2359 : bool = prim::GetAttr[name="training"](%2354)
       = prim::If(%2359) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2360 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2354)
          %2361 : Tensor = aten::add(%2360, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2354, %2361)
          -> ()
        block1():
          -> ()
      %2362 : bool = prim::GetAttr[name="training"](%2354)
      %2363 : Tensor = prim::GetAttr[name="running_mean"](%2354)
      %2364 : Tensor = prim::GetAttr[name="running_var"](%2354)
      %2365 : Tensor = prim::GetAttr[name="weight"](%2354)
      %2366 : Tensor = prim::GetAttr[name="bias"](%2354)
       = prim::If(%2362) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2367 : int[] = aten::size(%concated_features.46) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.376 : int = aten::__getitem__(%2367, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2369 : int = aten::len(%2367) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2370 : int = aten::sub(%2369, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.377 : int = prim::Loop(%2370, %5, %size_prods.376) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.95 : int, %size_prods.378 : int):
              %2374 : int = aten::add(%i.95, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2375 : int = aten::__getitem__(%2367, %2374) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.379 : int = aten::mul(%size_prods.378, %2375) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.379)
          %2377 : bool = aten::eq(%size_prods.377, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2377) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2378 : str = aten::format(%7, %2367) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2378) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %2379 : Tensor = aten::batch_norm(%concated_features.46, %2365, %2366, %2363, %2364, %2362, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.91 : Tensor = aten::relu_(%2379) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2381 : Tensor = prim::GetAttr[name="weight"](%2353)
      %2382 : Tensor? = prim::GetAttr[name="bias"](%2353)
      %bottleneck_output.91 : Tensor = aten::conv2d(%result.91, %2381, %2382, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.91)
  %2387 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2003)
  %2388 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2003)
  %2389 : int = aten::dim(%bottleneck_output.90) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %2390 : bool = aten::ne(%2389, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%2390) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %2392 : str = aten::format(%14, %2389) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%2392) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %2393 : bool = prim::GetAttr[name="training"](%2388)
   = prim::If(%2393) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %2394 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2388)
      %2395 : Tensor = aten::add(%2394, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%2388, %2395)
      -> ()
    block1():
      -> ()
  %2396 : bool = prim::GetAttr[name="training"](%2388)
  %2397 : Tensor = prim::GetAttr[name="running_mean"](%2388)
  %2398 : Tensor = prim::GetAttr[name="running_var"](%2388)
  %2399 : Tensor = prim::GetAttr[name="weight"](%2388)
  %2400 : Tensor = prim::GetAttr[name="bias"](%2388)
   = prim::If(%2396) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %2401 : int[] = aten::size(%bottleneck_output.90) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.380 : int = aten::__getitem__(%2401, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %2403 : int = aten::len(%2401) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %2404 : int = aten::sub(%2403, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.381 : int = prim::Loop(%2404, %5, %size_prods.380) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.96 : int, %size_prods.382 : int):
          %2408 : int = aten::add(%i.96, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %2409 : int = aten::__getitem__(%2401, %2408) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.383 : int = aten::mul(%size_prods.382, %2409) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.383)
      %2411 : bool = aten::eq(%size_prods.381, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%2411) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %2412 : str = aten::format(%7, %2401) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%2412) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %2413 : Tensor = aten::batch_norm(%bottleneck_output.90, %2399, %2400, %2397, %2398, %2396, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.92 : Tensor = aten::relu_(%2413) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %2415 : Tensor = prim::GetAttr[name="weight"](%2387)
  %2416 : Tensor? = prim::GetAttr[name="bias"](%2387)
  %new_features.91 : Tensor = aten::conv2d(%result.92, %2415, %2416, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %2421 : float = prim::GetAttr[name="drop_rate"](%2003)
  %2422 : bool = aten::gt(%2421, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.92 : Tensor = prim::If(%2422) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %2425 : bool = prim::GetAttr[name="training"](%2003)
      %2426 : bool = aten::lt(%2421, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %2427 : bool = prim::If(%2426) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %2428 : bool = aten::gt(%2421, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%2428)
       = prim::If(%2427) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %2429 : str = aten::format(%17, %2421) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%2429) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %2430 : Tensor = aten::dropout(%new_features.91, %2421, %2425) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%2430)
    block1():
      -> (%new_features.91)
  %2431 : Tensor[] = aten::append(%features.4, %new_features.92) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %2433 : bool = prim::GetAttr[name="memory_efficient"](%2004)
  %2434 : bool = prim::If(%2433) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %2435 : bool = prim::Uninitialized()
      %2436 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %2437 : bool = aten::gt(%2436, %6)
      %2438 : bool, %2439 : bool, %2440 : int = prim::Loop(%12, %2437, %10, %2435, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%2441 : int, %2442 : bool, %2443 : bool, %2444 : int):
          %tensor.47 : Tensor = aten::__getitem__(%features.4, %2444) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %2446 : bool = prim::requires_grad(%tensor.47)
          %2447 : bool, %2448 : bool = prim::If(%2446) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %2435)
          %2449 : int = aten::add(%2444, %19)
          %2450 : bool = aten::lt(%2449, %2436)
          %2451 : bool = aten::__and__(%2450, %2447)
          -> (%2451, %2446, %2448, %2449)
      %2452 : bool = prim::If(%2438)
        block0():
          -> (%2439)
        block1():
          -> (%10)
      -> (%2452)
    block1():
      -> (%10)
  %bottleneck_output.92 : Tensor = prim::If(%2434) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.47 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %2455 : __torch__.torch.nn.modules.conv.___torch_mangle_30.Conv2d = prim::GetAttr[name="conv1"](%2004)
      %2456 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_29.BatchNorm2d = prim::GetAttr[name="norm1"](%2004)
      %2457 : int = aten::dim(%concated_features.47) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %2458 : bool = aten::ne(%2457, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%2458) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %2460 : str = aten::format(%14, %2457) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%2460) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %2461 : bool = prim::GetAttr[name="training"](%2456)
       = prim::If(%2461) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2462 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2456)
          %2463 : Tensor = aten::add(%2462, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2456, %2463)
          -> ()
        block1():
          -> ()
      %2464 : bool = prim::GetAttr[name="training"](%2456)
      %2465 : Tensor = prim::GetAttr[name="running_mean"](%2456)
      %2466 : Tensor = prim::GetAttr[name="running_var"](%2456)
      %2467 : Tensor = prim::GetAttr[name="weight"](%2456)
      %2468 : Tensor = prim::GetAttr[name="bias"](%2456)
       = prim::If(%2464) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2469 : int[] = aten::size(%concated_features.47) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.384 : int = aten::__getitem__(%2469, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2471 : int = aten::len(%2469) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2472 : int = aten::sub(%2471, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.385 : int = prim::Loop(%2472, %5, %size_prods.384) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.97 : int, %size_prods.386 : int):
              %2476 : int = aten::add(%i.97, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2477 : int = aten::__getitem__(%2469, %2476) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.387 : int = aten::mul(%size_prods.386, %2477) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.387)
          %2479 : bool = aten::eq(%size_prods.385, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2479) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2480 : str = aten::format(%7, %2469) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2480) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %2481 : Tensor = aten::batch_norm(%concated_features.47, %2467, %2468, %2465, %2466, %2464, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.93 : Tensor = aten::relu_(%2481) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2483 : Tensor = prim::GetAttr[name="weight"](%2455)
      %2484 : Tensor? = prim::GetAttr[name="bias"](%2455)
      %bottleneck_output.93 : Tensor = aten::conv2d(%result.93, %2483, %2484, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.93)
  %2489 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2004)
  %2490 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2004)
  %2491 : int = aten::dim(%bottleneck_output.92) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %2492 : bool = aten::ne(%2491, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%2492) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %2494 : str = aten::format(%14, %2491) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%2494) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %2495 : bool = prim::GetAttr[name="training"](%2490)
   = prim::If(%2495) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %2496 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2490)
      %2497 : Tensor = aten::add(%2496, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%2490, %2497)
      -> ()
    block1():
      -> ()
  %2498 : bool = prim::GetAttr[name="training"](%2490)
  %2499 : Tensor = prim::GetAttr[name="running_mean"](%2490)
  %2500 : Tensor = prim::GetAttr[name="running_var"](%2490)
  %2501 : Tensor = prim::GetAttr[name="weight"](%2490)
  %2502 : Tensor = prim::GetAttr[name="bias"](%2490)
   = prim::If(%2498) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %2503 : int[] = aten::size(%bottleneck_output.92) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.388 : int = aten::__getitem__(%2503, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %2505 : int = aten::len(%2503) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %2506 : int = aten::sub(%2505, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.389 : int = prim::Loop(%2506, %5, %size_prods.388) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.98 : int, %size_prods.390 : int):
          %2510 : int = aten::add(%i.98, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %2511 : int = aten::__getitem__(%2503, %2510) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.391 : int = aten::mul(%size_prods.390, %2511) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.391)
      %2513 : bool = aten::eq(%size_prods.389, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%2513) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %2514 : str = aten::format(%7, %2503) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%2514) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %2515 : Tensor = aten::batch_norm(%bottleneck_output.92, %2501, %2502, %2499, %2500, %2498, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.94 : Tensor = aten::relu_(%2515) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %2517 : Tensor = prim::GetAttr[name="weight"](%2489)
  %2518 : Tensor? = prim::GetAttr[name="bias"](%2489)
  %new_features.93 : Tensor = aten::conv2d(%result.94, %2517, %2518, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %2523 : float = prim::GetAttr[name="drop_rate"](%2004)
  %2524 : bool = aten::gt(%2523, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.94 : Tensor = prim::If(%2524) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %2527 : bool = prim::GetAttr[name="training"](%2004)
      %2528 : bool = aten::lt(%2523, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %2529 : bool = prim::If(%2528) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %2530 : bool = aten::gt(%2523, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%2530)
       = prim::If(%2529) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %2531 : str = aten::format(%17, %2523) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%2531) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %2532 : Tensor = aten::dropout(%new_features.93, %2523, %2527) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%2532)
    block1():
      -> (%new_features.93)
  %2533 : Tensor[] = aten::append(%features.4, %new_features.94) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %2535 : bool = prim::GetAttr[name="memory_efficient"](%2005)
  %2536 : bool = prim::If(%2535) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %2537 : bool = prim::Uninitialized()
      %2538 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %2539 : bool = aten::gt(%2538, %6)
      %2540 : bool, %2541 : bool, %2542 : int = prim::Loop(%12, %2539, %10, %2537, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%2543 : int, %2544 : bool, %2545 : bool, %2546 : int):
          %tensor.48 : Tensor = aten::__getitem__(%features.4, %2546) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %2548 : bool = prim::requires_grad(%tensor.48)
          %2549 : bool, %2550 : bool = prim::If(%2548) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %2537)
          %2551 : int = aten::add(%2546, %19)
          %2552 : bool = aten::lt(%2551, %2538)
          %2553 : bool = aten::__and__(%2552, %2549)
          -> (%2553, %2548, %2550, %2551)
      %2554 : bool = prim::If(%2540)
        block0():
          -> (%2541)
        block1():
          -> (%10)
      -> (%2554)
    block1():
      -> (%10)
  %bottleneck_output.94 : Tensor = prim::If(%2536) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.48 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %2557 : __torch__.torch.nn.modules.conv.___torch_mangle_33.Conv2d = prim::GetAttr[name="conv1"](%2005)
      %2558 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_32.BatchNorm2d = prim::GetAttr[name="norm1"](%2005)
      %2559 : int = aten::dim(%concated_features.48) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %2560 : bool = aten::ne(%2559, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%2560) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %2562 : str = aten::format(%14, %2559) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%2562) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %2563 : bool = prim::GetAttr[name="training"](%2558)
       = prim::If(%2563) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2564 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2558)
          %2565 : Tensor = aten::add(%2564, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2558, %2565)
          -> ()
        block1():
          -> ()
      %2566 : bool = prim::GetAttr[name="training"](%2558)
      %2567 : Tensor = prim::GetAttr[name="running_mean"](%2558)
      %2568 : Tensor = prim::GetAttr[name="running_var"](%2558)
      %2569 : Tensor = prim::GetAttr[name="weight"](%2558)
      %2570 : Tensor = prim::GetAttr[name="bias"](%2558)
       = prim::If(%2566) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2571 : int[] = aten::size(%concated_features.48) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.392 : int = aten::__getitem__(%2571, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2573 : int = aten::len(%2571) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2574 : int = aten::sub(%2573, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.393 : int = prim::Loop(%2574, %5, %size_prods.392) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.99 : int, %size_prods.394 : int):
              %2578 : int = aten::add(%i.99, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2579 : int = aten::__getitem__(%2571, %2578) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.395 : int = aten::mul(%size_prods.394, %2579) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.395)
          %2581 : bool = aten::eq(%size_prods.393, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2581) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2582 : str = aten::format(%7, %2571) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2582) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %2583 : Tensor = aten::batch_norm(%concated_features.48, %2569, %2570, %2567, %2568, %2566, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.95 : Tensor = aten::relu_(%2583) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2585 : Tensor = prim::GetAttr[name="weight"](%2557)
      %2586 : Tensor? = prim::GetAttr[name="bias"](%2557)
      %bottleneck_output.95 : Tensor = aten::conv2d(%result.95, %2585, %2586, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.95)
  %2591 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2005)
  %2592 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2005)
  %2593 : int = aten::dim(%bottleneck_output.94) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %2594 : bool = aten::ne(%2593, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%2594) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %2596 : str = aten::format(%14, %2593) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%2596) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %2597 : bool = prim::GetAttr[name="training"](%2592)
   = prim::If(%2597) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %2598 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2592)
      %2599 : Tensor = aten::add(%2598, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%2592, %2599)
      -> ()
    block1():
      -> ()
  %2600 : bool = prim::GetAttr[name="training"](%2592)
  %2601 : Tensor = prim::GetAttr[name="running_mean"](%2592)
  %2602 : Tensor = prim::GetAttr[name="running_var"](%2592)
  %2603 : Tensor = prim::GetAttr[name="weight"](%2592)
  %2604 : Tensor = prim::GetAttr[name="bias"](%2592)
   = prim::If(%2600) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %2605 : int[] = aten::size(%bottleneck_output.94) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.396 : int = aten::__getitem__(%2605, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %2607 : int = aten::len(%2605) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %2608 : int = aten::sub(%2607, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.397 : int = prim::Loop(%2608, %5, %size_prods.396) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.100 : int, %size_prods.398 : int):
          %2612 : int = aten::add(%i.100, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %2613 : int = aten::__getitem__(%2605, %2612) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.399 : int = aten::mul(%size_prods.398, %2613) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.399)
      %2615 : bool = aten::eq(%size_prods.397, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%2615) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %2616 : str = aten::format(%7, %2605) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%2616) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %2617 : Tensor = aten::batch_norm(%bottleneck_output.94, %2603, %2604, %2601, %2602, %2600, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.96 : Tensor = aten::relu_(%2617) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %2619 : Tensor = prim::GetAttr[name="weight"](%2591)
  %2620 : Tensor? = prim::GetAttr[name="bias"](%2591)
  %new_features.95 : Tensor = aten::conv2d(%result.96, %2619, %2620, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %2625 : float = prim::GetAttr[name="drop_rate"](%2005)
  %2626 : bool = aten::gt(%2625, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.96 : Tensor = prim::If(%2626) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %2629 : bool = prim::GetAttr[name="training"](%2005)
      %2630 : bool = aten::lt(%2625, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %2631 : bool = prim::If(%2630) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %2632 : bool = aten::gt(%2625, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%2632)
       = prim::If(%2631) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %2633 : str = aten::format(%17, %2625) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%2633) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %2634 : Tensor = aten::dropout(%new_features.95, %2625, %2629) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%2634)
    block1():
      -> (%new_features.95)
  %2635 : Tensor[] = aten::append(%features.4, %new_features.96) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %2637 : bool = prim::GetAttr[name="memory_efficient"](%2006)
  %2638 : bool = prim::If(%2637) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %2639 : bool = prim::Uninitialized()
      %2640 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %2641 : bool = aten::gt(%2640, %6)
      %2642 : bool, %2643 : bool, %2644 : int = prim::Loop(%12, %2641, %10, %2639, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%2645 : int, %2646 : bool, %2647 : bool, %2648 : int):
          %tensor.49 : Tensor = aten::__getitem__(%features.4, %2648) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %2650 : bool = prim::requires_grad(%tensor.49)
          %2651 : bool, %2652 : bool = prim::If(%2650) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %2639)
          %2653 : int = aten::add(%2648, %19)
          %2654 : bool = aten::lt(%2653, %2640)
          %2655 : bool = aten::__and__(%2654, %2651)
          -> (%2655, %2650, %2652, %2653)
      %2656 : bool = prim::If(%2642)
        block0():
          -> (%2643)
        block1():
          -> (%10)
      -> (%2656)
    block1():
      -> (%10)
  %bottleneck_output.96 : Tensor = prim::If(%2638) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.49 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %2659 : __torch__.torch.nn.modules.conv.___torch_mangle_36.Conv2d = prim::GetAttr[name="conv1"](%2006)
      %2660 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_35.BatchNorm2d = prim::GetAttr[name="norm1"](%2006)
      %2661 : int = aten::dim(%concated_features.49) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %2662 : bool = aten::ne(%2661, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%2662) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %2664 : str = aten::format(%14, %2661) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%2664) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %2665 : bool = prim::GetAttr[name="training"](%2660)
       = prim::If(%2665) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2666 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2660)
          %2667 : Tensor = aten::add(%2666, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2660, %2667)
          -> ()
        block1():
          -> ()
      %2668 : bool = prim::GetAttr[name="training"](%2660)
      %2669 : Tensor = prim::GetAttr[name="running_mean"](%2660)
      %2670 : Tensor = prim::GetAttr[name="running_var"](%2660)
      %2671 : Tensor = prim::GetAttr[name="weight"](%2660)
      %2672 : Tensor = prim::GetAttr[name="bias"](%2660)
       = prim::If(%2668) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2673 : int[] = aten::size(%concated_features.49) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.400 : int = aten::__getitem__(%2673, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2675 : int = aten::len(%2673) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2676 : int = aten::sub(%2675, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.401 : int = prim::Loop(%2676, %5, %size_prods.400) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.101 : int, %size_prods.402 : int):
              %2680 : int = aten::add(%i.101, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2681 : int = aten::__getitem__(%2673, %2680) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.403 : int = aten::mul(%size_prods.402, %2681) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.403)
          %2683 : bool = aten::eq(%size_prods.401, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2683) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2684 : str = aten::format(%7, %2673) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2684) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %2685 : Tensor = aten::batch_norm(%concated_features.49, %2671, %2672, %2669, %2670, %2668, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.97 : Tensor = aten::relu_(%2685) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2687 : Tensor = prim::GetAttr[name="weight"](%2659)
      %2688 : Tensor? = prim::GetAttr[name="bias"](%2659)
      %bottleneck_output.97 : Tensor = aten::conv2d(%result.97, %2687, %2688, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.97)
  %2693 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2006)
  %2694 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2006)
  %2695 : int = aten::dim(%bottleneck_output.96) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %2696 : bool = aten::ne(%2695, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%2696) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %2698 : str = aten::format(%14, %2695) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%2698) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %2699 : bool = prim::GetAttr[name="training"](%2694)
   = prim::If(%2699) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %2700 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2694)
      %2701 : Tensor = aten::add(%2700, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%2694, %2701)
      -> ()
    block1():
      -> ()
  %2702 : bool = prim::GetAttr[name="training"](%2694)
  %2703 : Tensor = prim::GetAttr[name="running_mean"](%2694)
  %2704 : Tensor = prim::GetAttr[name="running_var"](%2694)
  %2705 : Tensor = prim::GetAttr[name="weight"](%2694)
  %2706 : Tensor = prim::GetAttr[name="bias"](%2694)
   = prim::If(%2702) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %2707 : int[] = aten::size(%bottleneck_output.96) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.404 : int = aten::__getitem__(%2707, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %2709 : int = aten::len(%2707) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %2710 : int = aten::sub(%2709, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.405 : int = prim::Loop(%2710, %5, %size_prods.404) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.102 : int, %size_prods.406 : int):
          %2714 : int = aten::add(%i.102, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %2715 : int = aten::__getitem__(%2707, %2714) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.407 : int = aten::mul(%size_prods.406, %2715) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.407)
      %2717 : bool = aten::eq(%size_prods.405, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%2717) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %2718 : str = aten::format(%7, %2707) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%2718) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %2719 : Tensor = aten::batch_norm(%bottleneck_output.96, %2705, %2706, %2703, %2704, %2702, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.98 : Tensor = aten::relu_(%2719) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %2721 : Tensor = prim::GetAttr[name="weight"](%2693)
  %2722 : Tensor? = prim::GetAttr[name="bias"](%2693)
  %new_features.97 : Tensor = aten::conv2d(%result.98, %2721, %2722, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %2727 : float = prim::GetAttr[name="drop_rate"](%2006)
  %2728 : bool = aten::gt(%2727, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.98 : Tensor = prim::If(%2728) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %2731 : bool = prim::GetAttr[name="training"](%2006)
      %2732 : bool = aten::lt(%2727, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %2733 : bool = prim::If(%2732) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %2734 : bool = aten::gt(%2727, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%2734)
       = prim::If(%2733) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %2735 : str = aten::format(%17, %2727) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%2735) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %2736 : Tensor = aten::dropout(%new_features.97, %2727, %2731) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%2736)
    block1():
      -> (%new_features.97)
  %2737 : Tensor[] = aten::append(%features.4, %new_features.98) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %2739 : bool = prim::GetAttr[name="memory_efficient"](%2007)
  %2740 : bool = prim::If(%2739) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %2741 : bool = prim::Uninitialized()
      %2742 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %2743 : bool = aten::gt(%2742, %6)
      %2744 : bool, %2745 : bool, %2746 : int = prim::Loop(%12, %2743, %10, %2741, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%2747 : int, %2748 : bool, %2749 : bool, %2750 : int):
          %tensor.50 : Tensor = aten::__getitem__(%features.4, %2750) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %2752 : bool = prim::requires_grad(%tensor.50)
          %2753 : bool, %2754 : bool = prim::If(%2752) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %2741)
          %2755 : int = aten::add(%2750, %19)
          %2756 : bool = aten::lt(%2755, %2742)
          %2757 : bool = aten::__and__(%2756, %2753)
          -> (%2757, %2752, %2754, %2755)
      %2758 : bool = prim::If(%2744)
        block0():
          -> (%2745)
        block1():
          -> (%10)
      -> (%2758)
    block1():
      -> (%10)
  %bottleneck_output.98 : Tensor = prim::If(%2740) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.50 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %2761 : __torch__.torch.nn.modules.conv.___torch_mangle_39.Conv2d = prim::GetAttr[name="conv1"](%2007)
      %2762 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_38.BatchNorm2d = prim::GetAttr[name="norm1"](%2007)
      %2763 : int = aten::dim(%concated_features.50) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %2764 : bool = aten::ne(%2763, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%2764) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %2766 : str = aten::format(%14, %2763) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%2766) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %2767 : bool = prim::GetAttr[name="training"](%2762)
       = prim::If(%2767) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2768 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2762)
          %2769 : Tensor = aten::add(%2768, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2762, %2769)
          -> ()
        block1():
          -> ()
      %2770 : bool = prim::GetAttr[name="training"](%2762)
      %2771 : Tensor = prim::GetAttr[name="running_mean"](%2762)
      %2772 : Tensor = prim::GetAttr[name="running_var"](%2762)
      %2773 : Tensor = prim::GetAttr[name="weight"](%2762)
      %2774 : Tensor = prim::GetAttr[name="bias"](%2762)
       = prim::If(%2770) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2775 : int[] = aten::size(%concated_features.50) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.408 : int = aten::__getitem__(%2775, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2777 : int = aten::len(%2775) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2778 : int = aten::sub(%2777, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.409 : int = prim::Loop(%2778, %5, %size_prods.408) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.103 : int, %size_prods.410 : int):
              %2782 : int = aten::add(%i.103, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2783 : int = aten::__getitem__(%2775, %2782) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.411 : int = aten::mul(%size_prods.410, %2783) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.411)
          %2785 : bool = aten::eq(%size_prods.409, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2785) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2786 : str = aten::format(%7, %2775) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2786) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %2787 : Tensor = aten::batch_norm(%concated_features.50, %2773, %2774, %2771, %2772, %2770, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.99 : Tensor = aten::relu_(%2787) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2789 : Tensor = prim::GetAttr[name="weight"](%2761)
      %2790 : Tensor? = prim::GetAttr[name="bias"](%2761)
      %bottleneck_output.99 : Tensor = aten::conv2d(%result.99, %2789, %2790, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.99)
  %2795 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2007)
  %2796 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2007)
  %2797 : int = aten::dim(%bottleneck_output.98) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %2798 : bool = aten::ne(%2797, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%2798) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %2800 : str = aten::format(%14, %2797) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%2800) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %2801 : bool = prim::GetAttr[name="training"](%2796)
   = prim::If(%2801) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %2802 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2796)
      %2803 : Tensor = aten::add(%2802, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%2796, %2803)
      -> ()
    block1():
      -> ()
  %2804 : bool = prim::GetAttr[name="training"](%2796)
  %2805 : Tensor = prim::GetAttr[name="running_mean"](%2796)
  %2806 : Tensor = prim::GetAttr[name="running_var"](%2796)
  %2807 : Tensor = prim::GetAttr[name="weight"](%2796)
  %2808 : Tensor = prim::GetAttr[name="bias"](%2796)
   = prim::If(%2804) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %2809 : int[] = aten::size(%bottleneck_output.98) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.412 : int = aten::__getitem__(%2809, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %2811 : int = aten::len(%2809) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %2812 : int = aten::sub(%2811, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.413 : int = prim::Loop(%2812, %5, %size_prods.412) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.104 : int, %size_prods.414 : int):
          %2816 : int = aten::add(%i.104, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %2817 : int = aten::__getitem__(%2809, %2816) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.415 : int = aten::mul(%size_prods.414, %2817) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.415)
      %2819 : bool = aten::eq(%size_prods.413, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%2819) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %2820 : str = aten::format(%7, %2809) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%2820) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %2821 : Tensor = aten::batch_norm(%bottleneck_output.98, %2807, %2808, %2805, %2806, %2804, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.100 : Tensor = aten::relu_(%2821) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %2823 : Tensor = prim::GetAttr[name="weight"](%2795)
  %2824 : Tensor? = prim::GetAttr[name="bias"](%2795)
  %new_features.99 : Tensor = aten::conv2d(%result.100, %2823, %2824, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %2829 : float = prim::GetAttr[name="drop_rate"](%2007)
  %2830 : bool = aten::gt(%2829, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.100 : Tensor = prim::If(%2830) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %2833 : bool = prim::GetAttr[name="training"](%2007)
      %2834 : bool = aten::lt(%2829, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %2835 : bool = prim::If(%2834) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %2836 : bool = aten::gt(%2829, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%2836)
       = prim::If(%2835) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %2837 : str = aten::format(%17, %2829) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%2837) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %2838 : Tensor = aten::dropout(%new_features.99, %2829, %2833) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%2838)
    block1():
      -> (%new_features.99)
  %2839 : Tensor[] = aten::append(%features.4, %new_features.100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %2841 : bool = prim::GetAttr[name="memory_efficient"](%2008)
  %2842 : bool = prim::If(%2841) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %2843 : bool = prim::Uninitialized()
      %2844 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %2845 : bool = aten::gt(%2844, %6)
      %2846 : bool, %2847 : bool, %2848 : int = prim::Loop(%12, %2845, %10, %2843, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%2849 : int, %2850 : bool, %2851 : bool, %2852 : int):
          %tensor.51 : Tensor = aten::__getitem__(%features.4, %2852) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %2854 : bool = prim::requires_grad(%tensor.51)
          %2855 : bool, %2856 : bool = prim::If(%2854) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %2843)
          %2857 : int = aten::add(%2852, %19)
          %2858 : bool = aten::lt(%2857, %2844)
          %2859 : bool = aten::__and__(%2858, %2855)
          -> (%2859, %2854, %2856, %2857)
      %2860 : bool = prim::If(%2846)
        block0():
          -> (%2847)
        block1():
          -> (%10)
      -> (%2860)
    block1():
      -> (%10)
  %bottleneck_output.100 : Tensor = prim::If(%2842) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.51 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %2863 : __torch__.torch.nn.modules.conv.___torch_mangle_45.Conv2d = prim::GetAttr[name="conv1"](%2008)
      %2864 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_42.BatchNorm2d = prim::GetAttr[name="norm1"](%2008)
      %2865 : int = aten::dim(%concated_features.51) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %2866 : bool = aten::ne(%2865, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%2866) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %2868 : str = aten::format(%14, %2865) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%2868) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %2869 : bool = prim::GetAttr[name="training"](%2864)
       = prim::If(%2869) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2870 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2864)
          %2871 : Tensor = aten::add(%2870, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2864, %2871)
          -> ()
        block1():
          -> ()
      %2872 : bool = prim::GetAttr[name="training"](%2864)
      %2873 : Tensor = prim::GetAttr[name="running_mean"](%2864)
      %2874 : Tensor = prim::GetAttr[name="running_var"](%2864)
      %2875 : Tensor = prim::GetAttr[name="weight"](%2864)
      %2876 : Tensor = prim::GetAttr[name="bias"](%2864)
       = prim::If(%2872) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2877 : int[] = aten::size(%concated_features.51) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.416 : int = aten::__getitem__(%2877, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2879 : int = aten::len(%2877) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2880 : int = aten::sub(%2879, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.417 : int = prim::Loop(%2880, %5, %size_prods.416) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.105 : int, %size_prods.418 : int):
              %2884 : int = aten::add(%i.105, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2885 : int = aten::__getitem__(%2877, %2884) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.419 : int = aten::mul(%size_prods.418, %2885) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.419)
          %2887 : bool = aten::eq(%size_prods.417, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2887) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2888 : str = aten::format(%7, %2877) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2888) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %2889 : Tensor = aten::batch_norm(%concated_features.51, %2875, %2876, %2873, %2874, %2872, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.101 : Tensor = aten::relu_(%2889) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2891 : Tensor = prim::GetAttr[name="weight"](%2863)
      %2892 : Tensor? = prim::GetAttr[name="bias"](%2863)
      %bottleneck_output.101 : Tensor = aten::conv2d(%result.101, %2891, %2892, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.101)
  %2897 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2008)
  %2898 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2008)
  %2899 : int = aten::dim(%bottleneck_output.100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %2900 : bool = aten::ne(%2899, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%2900) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %2902 : str = aten::format(%14, %2899) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%2902) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %2903 : bool = prim::GetAttr[name="training"](%2898)
   = prim::If(%2903) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %2904 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2898)
      %2905 : Tensor = aten::add(%2904, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%2898, %2905)
      -> ()
    block1():
      -> ()
  %2906 : bool = prim::GetAttr[name="training"](%2898)
  %2907 : Tensor = prim::GetAttr[name="running_mean"](%2898)
  %2908 : Tensor = prim::GetAttr[name="running_var"](%2898)
  %2909 : Tensor = prim::GetAttr[name="weight"](%2898)
  %2910 : Tensor = prim::GetAttr[name="bias"](%2898)
   = prim::If(%2906) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %2911 : int[] = aten::size(%bottleneck_output.100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.420 : int = aten::__getitem__(%2911, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %2913 : int = aten::len(%2911) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %2914 : int = aten::sub(%2913, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.421 : int = prim::Loop(%2914, %5, %size_prods.420) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.106 : int, %size_prods.422 : int):
          %2918 : int = aten::add(%i.106, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %2919 : int = aten::__getitem__(%2911, %2918) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.423 : int = aten::mul(%size_prods.422, %2919) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.423)
      %2921 : bool = aten::eq(%size_prods.421, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%2921) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %2922 : str = aten::format(%7, %2911) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%2922) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %2923 : Tensor = aten::batch_norm(%bottleneck_output.100, %2909, %2910, %2907, %2908, %2906, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.102 : Tensor = aten::relu_(%2923) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %2925 : Tensor = prim::GetAttr[name="weight"](%2897)
  %2926 : Tensor? = prim::GetAttr[name="bias"](%2897)
  %new_features.101 : Tensor = aten::conv2d(%result.102, %2925, %2926, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %2931 : float = prim::GetAttr[name="drop_rate"](%2008)
  %2932 : bool = aten::gt(%2931, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.102 : Tensor = prim::If(%2932) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %2935 : bool = prim::GetAttr[name="training"](%2008)
      %2936 : bool = aten::lt(%2931, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %2937 : bool = prim::If(%2936) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %2938 : bool = aten::gt(%2931, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%2938)
       = prim::If(%2937) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %2939 : str = aten::format(%17, %2931) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%2939) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %2940 : Tensor = aten::dropout(%new_features.101, %2931, %2935) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%2940)
    block1():
      -> (%new_features.101)
  %2941 : Tensor[] = aten::append(%features.4, %new_features.102) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %2943 : bool = prim::GetAttr[name="memory_efficient"](%2009)
  %2944 : bool = prim::If(%2943) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %2945 : bool = prim::Uninitialized()
      %2946 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %2947 : bool = aten::gt(%2946, %6)
      %2948 : bool, %2949 : bool, %2950 : int = prim::Loop(%12, %2947, %10, %2945, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%2951 : int, %2952 : bool, %2953 : bool, %2954 : int):
          %tensor.52 : Tensor = aten::__getitem__(%features.4, %2954) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %2956 : bool = prim::requires_grad(%tensor.52)
          %2957 : bool, %2958 : bool = prim::If(%2956) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %2945)
          %2959 : int = aten::add(%2954, %19)
          %2960 : bool = aten::lt(%2959, %2946)
          %2961 : bool = aten::__and__(%2960, %2957)
          -> (%2961, %2956, %2958, %2959)
      %2962 : bool = prim::If(%2948)
        block0():
          -> (%2949)
        block1():
          -> (%10)
      -> (%2962)
    block1():
      -> (%10)
  %bottleneck_output.102 : Tensor = prim::If(%2944) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.52 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %2965 : __torch__.torch.nn.modules.conv.___torch_mangle_48.Conv2d = prim::GetAttr[name="conv1"](%2009)
      %2966 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_47.BatchNorm2d = prim::GetAttr[name="norm1"](%2009)
      %2967 : int = aten::dim(%concated_features.52) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %2968 : bool = aten::ne(%2967, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%2968) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %2970 : str = aten::format(%14, %2967) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%2970) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %2971 : bool = prim::GetAttr[name="training"](%2966)
       = prim::If(%2971) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %2972 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2966)
          %2973 : Tensor = aten::add(%2972, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2966, %2973)
          -> ()
        block1():
          -> ()
      %2974 : bool = prim::GetAttr[name="training"](%2966)
      %2975 : Tensor = prim::GetAttr[name="running_mean"](%2966)
      %2976 : Tensor = prim::GetAttr[name="running_var"](%2966)
      %2977 : Tensor = prim::GetAttr[name="weight"](%2966)
      %2978 : Tensor = prim::GetAttr[name="bias"](%2966)
       = prim::If(%2974) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %2979 : int[] = aten::size(%concated_features.52) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.424 : int = aten::__getitem__(%2979, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %2981 : int = aten::len(%2979) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %2982 : int = aten::sub(%2981, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.425 : int = prim::Loop(%2982, %5, %size_prods.424) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.107 : int, %size_prods.426 : int):
              %2986 : int = aten::add(%i.107, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %2987 : int = aten::__getitem__(%2979, %2986) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.427 : int = aten::mul(%size_prods.426, %2987) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.427)
          %2989 : bool = aten::eq(%size_prods.425, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%2989) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %2990 : str = aten::format(%7, %2979) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%2990) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %2991 : Tensor = aten::batch_norm(%concated_features.52, %2977, %2978, %2975, %2976, %2974, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.103 : Tensor = aten::relu_(%2991) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %2993 : Tensor = prim::GetAttr[name="weight"](%2965)
      %2994 : Tensor? = prim::GetAttr[name="bias"](%2965)
      %bottleneck_output.103 : Tensor = aten::conv2d(%result.103, %2993, %2994, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.103)
  %2999 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2009)
  %3000 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2009)
  %3001 : int = aten::dim(%bottleneck_output.102) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %3002 : bool = aten::ne(%3001, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%3002) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %3004 : str = aten::format(%14, %3001) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%3004) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %3005 : bool = prim::GetAttr[name="training"](%3000)
   = prim::If(%3005) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %3006 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3000)
      %3007 : Tensor = aten::add(%3006, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%3000, %3007)
      -> ()
    block1():
      -> ()
  %3008 : bool = prim::GetAttr[name="training"](%3000)
  %3009 : Tensor = prim::GetAttr[name="running_mean"](%3000)
  %3010 : Tensor = prim::GetAttr[name="running_var"](%3000)
  %3011 : Tensor = prim::GetAttr[name="weight"](%3000)
  %3012 : Tensor = prim::GetAttr[name="bias"](%3000)
   = prim::If(%3008) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %3013 : int[] = aten::size(%bottleneck_output.102) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.428 : int = aten::__getitem__(%3013, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %3015 : int = aten::len(%3013) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %3016 : int = aten::sub(%3015, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.429 : int = prim::Loop(%3016, %5, %size_prods.428) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.108 : int, %size_prods.430 : int):
          %3020 : int = aten::add(%i.108, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %3021 : int = aten::__getitem__(%3013, %3020) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.431 : int = aten::mul(%size_prods.430, %3021) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.431)
      %3023 : bool = aten::eq(%size_prods.429, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%3023) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %3024 : str = aten::format(%7, %3013) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%3024) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %3025 : Tensor = aten::batch_norm(%bottleneck_output.102, %3011, %3012, %3009, %3010, %3008, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.104 : Tensor = aten::relu_(%3025) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %3027 : Tensor = prim::GetAttr[name="weight"](%2999)
  %3028 : Tensor? = prim::GetAttr[name="bias"](%2999)
  %new_features.103 : Tensor = aten::conv2d(%result.104, %3027, %3028, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %3033 : float = prim::GetAttr[name="drop_rate"](%2009)
  %3034 : bool = aten::gt(%3033, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.104 : Tensor = prim::If(%3034) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %3037 : bool = prim::GetAttr[name="training"](%2009)
      %3038 : bool = aten::lt(%3033, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %3039 : bool = prim::If(%3038) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %3040 : bool = aten::gt(%3033, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%3040)
       = prim::If(%3039) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %3041 : str = aten::format(%17, %3033) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%3041) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %3042 : Tensor = aten::dropout(%new_features.103, %3033, %3037) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%3042)
    block1():
      -> (%new_features.103)
  %3043 : Tensor[] = aten::append(%features.4, %new_features.104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %3045 : bool = prim::GetAttr[name="memory_efficient"](%2010)
  %3046 : bool = prim::If(%3045) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %3047 : bool = prim::Uninitialized()
      %3048 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %3049 : bool = aten::gt(%3048, %6)
      %3050 : bool, %3051 : bool, %3052 : int = prim::Loop(%12, %3049, %10, %3047, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%3053 : int, %3054 : bool, %3055 : bool, %3056 : int):
          %tensor.53 : Tensor = aten::__getitem__(%features.4, %3056) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %3058 : bool = prim::requires_grad(%tensor.53)
          %3059 : bool, %3060 : bool = prim::If(%3058) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %3047)
          %3061 : int = aten::add(%3056, %19)
          %3062 : bool = aten::lt(%3061, %3048)
          %3063 : bool = aten::__and__(%3062, %3059)
          -> (%3063, %3058, %3060, %3061)
      %3064 : bool = prim::If(%3050)
        block0():
          -> (%3051)
        block1():
          -> (%10)
      -> (%3064)
    block1():
      -> (%10)
  %bottleneck_output.104 : Tensor = prim::If(%3046) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.53 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %3067 : __torch__.torch.nn.modules.conv.___torch_mangle_51.Conv2d = prim::GetAttr[name="conv1"](%2010)
      %3068 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_50.BatchNorm2d = prim::GetAttr[name="norm1"](%2010)
      %3069 : int = aten::dim(%concated_features.53) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %3070 : bool = aten::ne(%3069, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%3070) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %3072 : str = aten::format(%14, %3069) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%3072) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %3073 : bool = prim::GetAttr[name="training"](%3068)
       = prim::If(%3073) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3074 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3068)
          %3075 : Tensor = aten::add(%3074, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3068, %3075)
          -> ()
        block1():
          -> ()
      %3076 : bool = prim::GetAttr[name="training"](%3068)
      %3077 : Tensor = prim::GetAttr[name="running_mean"](%3068)
      %3078 : Tensor = prim::GetAttr[name="running_var"](%3068)
      %3079 : Tensor = prim::GetAttr[name="weight"](%3068)
      %3080 : Tensor = prim::GetAttr[name="bias"](%3068)
       = prim::If(%3076) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3081 : int[] = aten::size(%concated_features.53) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.432 : int = aten::__getitem__(%3081, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3083 : int = aten::len(%3081) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3084 : int = aten::sub(%3083, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.433 : int = prim::Loop(%3084, %5, %size_prods.432) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.109 : int, %size_prods.434 : int):
              %3088 : int = aten::add(%i.109, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3089 : int = aten::__getitem__(%3081, %3088) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.435 : int = aten::mul(%size_prods.434, %3089) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.435)
          %3091 : bool = aten::eq(%size_prods.433, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3091) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3092 : str = aten::format(%7, %3081) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3092) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %3093 : Tensor = aten::batch_norm(%concated_features.53, %3079, %3080, %3077, %3078, %3076, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.105 : Tensor = aten::relu_(%3093) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3095 : Tensor = prim::GetAttr[name="weight"](%3067)
      %3096 : Tensor? = prim::GetAttr[name="bias"](%3067)
      %bottleneck_output.105 : Tensor = aten::conv2d(%result.105, %3095, %3096, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.105)
  %3101 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2010)
  %3102 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2010)
  %3103 : int = aten::dim(%bottleneck_output.104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %3104 : bool = aten::ne(%3103, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%3104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %3106 : str = aten::format(%14, %3103) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%3106) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %3107 : bool = prim::GetAttr[name="training"](%3102)
   = prim::If(%3107) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %3108 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3102)
      %3109 : Tensor = aten::add(%3108, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%3102, %3109)
      -> ()
    block1():
      -> ()
  %3110 : bool = prim::GetAttr[name="training"](%3102)
  %3111 : Tensor = prim::GetAttr[name="running_mean"](%3102)
  %3112 : Tensor = prim::GetAttr[name="running_var"](%3102)
  %3113 : Tensor = prim::GetAttr[name="weight"](%3102)
  %3114 : Tensor = prim::GetAttr[name="bias"](%3102)
   = prim::If(%3110) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %3115 : int[] = aten::size(%bottleneck_output.104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.436 : int = aten::__getitem__(%3115, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %3117 : int = aten::len(%3115) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %3118 : int = aten::sub(%3117, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.437 : int = prim::Loop(%3118, %5, %size_prods.436) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.110 : int, %size_prods.438 : int):
          %3122 : int = aten::add(%i.110, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %3123 : int = aten::__getitem__(%3115, %3122) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.439 : int = aten::mul(%size_prods.438, %3123) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.439)
      %3125 : bool = aten::eq(%size_prods.437, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%3125) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %3126 : str = aten::format(%7, %3115) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%3126) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %3127 : Tensor = aten::batch_norm(%bottleneck_output.104, %3113, %3114, %3111, %3112, %3110, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.106 : Tensor = aten::relu_(%3127) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %3129 : Tensor = prim::GetAttr[name="weight"](%3101)
  %3130 : Tensor? = prim::GetAttr[name="bias"](%3101)
  %new_features.105 : Tensor = aten::conv2d(%result.106, %3129, %3130, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %3135 : float = prim::GetAttr[name="drop_rate"](%2010)
  %3136 : bool = aten::gt(%3135, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.106 : Tensor = prim::If(%3136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %3139 : bool = prim::GetAttr[name="training"](%2010)
      %3140 : bool = aten::lt(%3135, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %3141 : bool = prim::If(%3140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %3142 : bool = aten::gt(%3135, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%3142)
       = prim::If(%3141) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %3143 : str = aten::format(%17, %3135) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%3143) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %3144 : Tensor = aten::dropout(%new_features.105, %3135, %3139) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%3144)
    block1():
      -> (%new_features.105)
  %3145 : Tensor[] = aten::append(%features.4, %new_features.106) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %3147 : bool = prim::GetAttr[name="memory_efficient"](%2011)
  %3148 : bool = prim::If(%3147) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %3149 : bool = prim::Uninitialized()
      %3150 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %3151 : bool = aten::gt(%3150, %6)
      %3152 : bool, %3153 : bool, %3154 : int = prim::Loop(%12, %3151, %10, %3149, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%3155 : int, %3156 : bool, %3157 : bool, %3158 : int):
          %tensor.54 : Tensor = aten::__getitem__(%features.4, %3158) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %3160 : bool = prim::requires_grad(%tensor.54)
          %3161 : bool, %3162 : bool = prim::If(%3160) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %3149)
          %3163 : int = aten::add(%3158, %19)
          %3164 : bool = aten::lt(%3163, %3150)
          %3165 : bool = aten::__and__(%3164, %3161)
          -> (%3165, %3160, %3162, %3163)
      %3166 : bool = prim::If(%3152)
        block0():
          -> (%3153)
        block1():
          -> (%10)
      -> (%3166)
    block1():
      -> (%10)
  %bottleneck_output.106 : Tensor = prim::If(%3148) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.54 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %3169 : __torch__.torch.nn.modules.conv.___torch_mangle_54.Conv2d = prim::GetAttr[name="conv1"](%2011)
      %3170 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_53.BatchNorm2d = prim::GetAttr[name="norm1"](%2011)
      %3171 : int = aten::dim(%concated_features.54) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %3172 : bool = aten::ne(%3171, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%3172) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %3174 : str = aten::format(%14, %3171) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%3174) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %3175 : bool = prim::GetAttr[name="training"](%3170)
       = prim::If(%3175) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3176 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3170)
          %3177 : Tensor = aten::add(%3176, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3170, %3177)
          -> ()
        block1():
          -> ()
      %3178 : bool = prim::GetAttr[name="training"](%3170)
      %3179 : Tensor = prim::GetAttr[name="running_mean"](%3170)
      %3180 : Tensor = prim::GetAttr[name="running_var"](%3170)
      %3181 : Tensor = prim::GetAttr[name="weight"](%3170)
      %3182 : Tensor = prim::GetAttr[name="bias"](%3170)
       = prim::If(%3178) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3183 : int[] = aten::size(%concated_features.54) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.440 : int = aten::__getitem__(%3183, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3185 : int = aten::len(%3183) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3186 : int = aten::sub(%3185, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.441 : int = prim::Loop(%3186, %5, %size_prods.440) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.111 : int, %size_prods.442 : int):
              %3190 : int = aten::add(%i.111, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3191 : int = aten::__getitem__(%3183, %3190) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.443 : int = aten::mul(%size_prods.442, %3191) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.443)
          %3193 : bool = aten::eq(%size_prods.441, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3193) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3194 : str = aten::format(%7, %3183) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3194) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %3195 : Tensor = aten::batch_norm(%concated_features.54, %3181, %3182, %3179, %3180, %3178, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.107 : Tensor = aten::relu_(%3195) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3197 : Tensor = prim::GetAttr[name="weight"](%3169)
      %3198 : Tensor? = prim::GetAttr[name="bias"](%3169)
      %bottleneck_output.107 : Tensor = aten::conv2d(%result.107, %3197, %3198, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.107)
  %3203 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2011)
  %3204 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2011)
  %3205 : int = aten::dim(%bottleneck_output.106) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %3206 : bool = aten::ne(%3205, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%3206) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %3208 : str = aten::format(%14, %3205) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%3208) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %3209 : bool = prim::GetAttr[name="training"](%3204)
   = prim::If(%3209) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %3210 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3204)
      %3211 : Tensor = aten::add(%3210, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%3204, %3211)
      -> ()
    block1():
      -> ()
  %3212 : bool = prim::GetAttr[name="training"](%3204)
  %3213 : Tensor = prim::GetAttr[name="running_mean"](%3204)
  %3214 : Tensor = prim::GetAttr[name="running_var"](%3204)
  %3215 : Tensor = prim::GetAttr[name="weight"](%3204)
  %3216 : Tensor = prim::GetAttr[name="bias"](%3204)
   = prim::If(%3212) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %3217 : int[] = aten::size(%bottleneck_output.106) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.444 : int = aten::__getitem__(%3217, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %3219 : int = aten::len(%3217) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %3220 : int = aten::sub(%3219, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.445 : int = prim::Loop(%3220, %5, %size_prods.444) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.112 : int, %size_prods.446 : int):
          %3224 : int = aten::add(%i.112, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %3225 : int = aten::__getitem__(%3217, %3224) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.447 : int = aten::mul(%size_prods.446, %3225) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.447)
      %3227 : bool = aten::eq(%size_prods.445, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%3227) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %3228 : str = aten::format(%7, %3217) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%3228) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %3229 : Tensor = aten::batch_norm(%bottleneck_output.106, %3215, %3216, %3213, %3214, %3212, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.108 : Tensor = aten::relu_(%3229) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %3231 : Tensor = prim::GetAttr[name="weight"](%3203)
  %3232 : Tensor? = prim::GetAttr[name="bias"](%3203)
  %new_features.107 : Tensor = aten::conv2d(%result.108, %3231, %3232, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %3237 : float = prim::GetAttr[name="drop_rate"](%2011)
  %3238 : bool = aten::gt(%3237, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.108 : Tensor = prim::If(%3238) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %3241 : bool = prim::GetAttr[name="training"](%2011)
      %3242 : bool = aten::lt(%3237, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %3243 : bool = prim::If(%3242) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %3244 : bool = aten::gt(%3237, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%3244)
       = prim::If(%3243) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %3245 : str = aten::format(%17, %3237) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%3245) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %3246 : Tensor = aten::dropout(%new_features.107, %3237, %3241) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%3246)
    block1():
      -> (%new_features.107)
  %3247 : Tensor[] = aten::append(%features.4, %new_features.108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %3249 : bool = prim::GetAttr[name="memory_efficient"](%2012)
  %3250 : bool = prim::If(%3249) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %3251 : bool = prim::Uninitialized()
      %3252 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %3253 : bool = aten::gt(%3252, %6)
      %3254 : bool, %3255 : bool, %3256 : int = prim::Loop(%12, %3253, %10, %3251, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%3257 : int, %3258 : bool, %3259 : bool, %3260 : int):
          %tensor.55 : Tensor = aten::__getitem__(%features.4, %3260) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %3262 : bool = prim::requires_grad(%tensor.55)
          %3263 : bool, %3264 : bool = prim::If(%3262) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %3251)
          %3265 : int = aten::add(%3260, %19)
          %3266 : bool = aten::lt(%3265, %3252)
          %3267 : bool = aten::__and__(%3266, %3263)
          -> (%3267, %3262, %3264, %3265)
      %3268 : bool = prim::If(%3254)
        block0():
          -> (%3255)
        block1():
          -> (%10)
      -> (%3268)
    block1():
      -> (%10)
  %bottleneck_output.108 : Tensor = prim::If(%3250) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.55 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %3271 : __torch__.torch.nn.modules.conv.___torch_mangle_57.Conv2d = prim::GetAttr[name="conv1"](%2012)
      %3272 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_56.BatchNorm2d = prim::GetAttr[name="norm1"](%2012)
      %3273 : int = aten::dim(%concated_features.55) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %3274 : bool = aten::ne(%3273, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%3274) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %3276 : str = aten::format(%14, %3273) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%3276) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %3277 : bool = prim::GetAttr[name="training"](%3272)
       = prim::If(%3277) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3278 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3272)
          %3279 : Tensor = aten::add(%3278, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3272, %3279)
          -> ()
        block1():
          -> ()
      %3280 : bool = prim::GetAttr[name="training"](%3272)
      %3281 : Tensor = prim::GetAttr[name="running_mean"](%3272)
      %3282 : Tensor = prim::GetAttr[name="running_var"](%3272)
      %3283 : Tensor = prim::GetAttr[name="weight"](%3272)
      %3284 : Tensor = prim::GetAttr[name="bias"](%3272)
       = prim::If(%3280) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3285 : int[] = aten::size(%concated_features.55) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.448 : int = aten::__getitem__(%3285, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3287 : int = aten::len(%3285) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3288 : int = aten::sub(%3287, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.449 : int = prim::Loop(%3288, %5, %size_prods.448) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.113 : int, %size_prods.450 : int):
              %3292 : int = aten::add(%i.113, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3293 : int = aten::__getitem__(%3285, %3292) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.451 : int = aten::mul(%size_prods.450, %3293) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.451)
          %3295 : bool = aten::eq(%size_prods.449, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3295) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3296 : str = aten::format(%7, %3285) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3296) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %3297 : Tensor = aten::batch_norm(%concated_features.55, %3283, %3284, %3281, %3282, %3280, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.109 : Tensor = aten::relu_(%3297) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3299 : Tensor = prim::GetAttr[name="weight"](%3271)
      %3300 : Tensor? = prim::GetAttr[name="bias"](%3271)
      %bottleneck_output.109 : Tensor = aten::conv2d(%result.109, %3299, %3300, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.109)
  %3305 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2012)
  %3306 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2012)
  %3307 : int = aten::dim(%bottleneck_output.108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %3308 : bool = aten::ne(%3307, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%3308) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %3310 : str = aten::format(%14, %3307) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%3310) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %3311 : bool = prim::GetAttr[name="training"](%3306)
   = prim::If(%3311) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %3312 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3306)
      %3313 : Tensor = aten::add(%3312, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%3306, %3313)
      -> ()
    block1():
      -> ()
  %3314 : bool = prim::GetAttr[name="training"](%3306)
  %3315 : Tensor = prim::GetAttr[name="running_mean"](%3306)
  %3316 : Tensor = prim::GetAttr[name="running_var"](%3306)
  %3317 : Tensor = prim::GetAttr[name="weight"](%3306)
  %3318 : Tensor = prim::GetAttr[name="bias"](%3306)
   = prim::If(%3314) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %3319 : int[] = aten::size(%bottleneck_output.108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.452 : int = aten::__getitem__(%3319, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %3321 : int = aten::len(%3319) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %3322 : int = aten::sub(%3321, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.453 : int = prim::Loop(%3322, %5, %size_prods.452) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.114 : int, %size_prods.454 : int):
          %3326 : int = aten::add(%i.114, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %3327 : int = aten::__getitem__(%3319, %3326) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.455 : int = aten::mul(%size_prods.454, %3327) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.455)
      %3329 : bool = aten::eq(%size_prods.453, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%3329) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %3330 : str = aten::format(%7, %3319) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%3330) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %3331 : Tensor = aten::batch_norm(%bottleneck_output.108, %3317, %3318, %3315, %3316, %3314, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.110 : Tensor = aten::relu_(%3331) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %3333 : Tensor = prim::GetAttr[name="weight"](%3305)
  %3334 : Tensor? = prim::GetAttr[name="bias"](%3305)
  %new_features.109 : Tensor = aten::conv2d(%result.110, %3333, %3334, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %3339 : float = prim::GetAttr[name="drop_rate"](%2012)
  %3340 : bool = aten::gt(%3339, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.110 : Tensor = prim::If(%3340) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %3343 : bool = prim::GetAttr[name="training"](%2012)
      %3344 : bool = aten::lt(%3339, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %3345 : bool = prim::If(%3344) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %3346 : bool = aten::gt(%3339, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%3346)
       = prim::If(%3345) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %3347 : str = aten::format(%17, %3339) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%3347) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %3348 : Tensor = aten::dropout(%new_features.109, %3339, %3343) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%3348)
    block1():
      -> (%new_features.109)
  %3349 : Tensor[] = aten::append(%features.4, %new_features.110) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %3351 : bool = prim::GetAttr[name="memory_efficient"](%2013)
  %3352 : bool = prim::If(%3351) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %3353 : bool = prim::Uninitialized()
      %3354 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %3355 : bool = aten::gt(%3354, %6)
      %3356 : bool, %3357 : bool, %3358 : int = prim::Loop(%12, %3355, %10, %3353, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%3359 : int, %3360 : bool, %3361 : bool, %3362 : int):
          %tensor.56 : Tensor = aten::__getitem__(%features.4, %3362) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %3364 : bool = prim::requires_grad(%tensor.56)
          %3365 : bool, %3366 : bool = prim::If(%3364) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %3353)
          %3367 : int = aten::add(%3362, %19)
          %3368 : bool = aten::lt(%3367, %3354)
          %3369 : bool = aten::__and__(%3368, %3365)
          -> (%3369, %3364, %3366, %3367)
      %3370 : bool = prim::If(%3356)
        block0():
          -> (%3357)
        block1():
          -> (%10)
      -> (%3370)
    block1():
      -> (%10)
  %bottleneck_output.110 : Tensor = prim::If(%3352) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.56 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %3373 : __torch__.torch.nn.modules.conv.___torch_mangle_60.Conv2d = prim::GetAttr[name="conv1"](%2013)
      %3374 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="norm1"](%2013)
      %3375 : int = aten::dim(%concated_features.56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %3376 : bool = aten::ne(%3375, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%3376) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %3378 : str = aten::format(%14, %3375) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%3378) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %3379 : bool = prim::GetAttr[name="training"](%3374)
       = prim::If(%3379) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3380 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3374)
          %3381 : Tensor = aten::add(%3380, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3374, %3381)
          -> ()
        block1():
          -> ()
      %3382 : bool = prim::GetAttr[name="training"](%3374)
      %3383 : Tensor = prim::GetAttr[name="running_mean"](%3374)
      %3384 : Tensor = prim::GetAttr[name="running_var"](%3374)
      %3385 : Tensor = prim::GetAttr[name="weight"](%3374)
      %3386 : Tensor = prim::GetAttr[name="bias"](%3374)
       = prim::If(%3382) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3387 : int[] = aten::size(%concated_features.56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.456 : int = aten::__getitem__(%3387, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3389 : int = aten::len(%3387) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3390 : int = aten::sub(%3389, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.457 : int = prim::Loop(%3390, %5, %size_prods.456) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.115 : int, %size_prods.458 : int):
              %3394 : int = aten::add(%i.115, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3395 : int = aten::__getitem__(%3387, %3394) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.459 : int = aten::mul(%size_prods.458, %3395) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.459)
          %3397 : bool = aten::eq(%size_prods.457, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3397) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3398 : str = aten::format(%7, %3387) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3398) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %3399 : Tensor = aten::batch_norm(%concated_features.56, %3385, %3386, %3383, %3384, %3382, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.111 : Tensor = aten::relu_(%3399) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3401 : Tensor = prim::GetAttr[name="weight"](%3373)
      %3402 : Tensor? = prim::GetAttr[name="bias"](%3373)
      %bottleneck_output.111 : Tensor = aten::conv2d(%result.111, %3401, %3402, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.111)
  %3407 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2013)
  %3408 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2013)
  %3409 : int = aten::dim(%bottleneck_output.110) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %3410 : bool = aten::ne(%3409, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%3410) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %3412 : str = aten::format(%14, %3409) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%3412) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %3413 : bool = prim::GetAttr[name="training"](%3408)
   = prim::If(%3413) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %3414 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3408)
      %3415 : Tensor = aten::add(%3414, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%3408, %3415)
      -> ()
    block1():
      -> ()
  %3416 : bool = prim::GetAttr[name="training"](%3408)
  %3417 : Tensor = prim::GetAttr[name="running_mean"](%3408)
  %3418 : Tensor = prim::GetAttr[name="running_var"](%3408)
  %3419 : Tensor = prim::GetAttr[name="weight"](%3408)
  %3420 : Tensor = prim::GetAttr[name="bias"](%3408)
   = prim::If(%3416) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %3421 : int[] = aten::size(%bottleneck_output.110) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.460 : int = aten::__getitem__(%3421, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %3423 : int = aten::len(%3421) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %3424 : int = aten::sub(%3423, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.461 : int = prim::Loop(%3424, %5, %size_prods.460) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.116 : int, %size_prods.462 : int):
          %3428 : int = aten::add(%i.116, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %3429 : int = aten::__getitem__(%3421, %3428) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.463 : int = aten::mul(%size_prods.462, %3429) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.463)
      %3431 : bool = aten::eq(%size_prods.461, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%3431) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %3432 : str = aten::format(%7, %3421) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%3432) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %3433 : Tensor = aten::batch_norm(%bottleneck_output.110, %3419, %3420, %3417, %3418, %3416, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.112 : Tensor = aten::relu_(%3433) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %3435 : Tensor = prim::GetAttr[name="weight"](%3407)
  %3436 : Tensor? = prim::GetAttr[name="bias"](%3407)
  %new_features.111 : Tensor = aten::conv2d(%result.112, %3435, %3436, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %3441 : float = prim::GetAttr[name="drop_rate"](%2013)
  %3442 : bool = aten::gt(%3441, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.112 : Tensor = prim::If(%3442) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %3445 : bool = prim::GetAttr[name="training"](%2013)
      %3446 : bool = aten::lt(%3441, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %3447 : bool = prim::If(%3446) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %3448 : bool = aten::gt(%3441, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%3448)
       = prim::If(%3447) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %3449 : str = aten::format(%17, %3441) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%3449) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %3450 : Tensor = aten::dropout(%new_features.111, %3441, %3445) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%3450)
    block1():
      -> (%new_features.111)
  %3451 : Tensor[] = aten::append(%features.4, %new_features.112) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %3453 : bool = prim::GetAttr[name="memory_efficient"](%2014)
  %3454 : bool = prim::If(%3453) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %3455 : bool = prim::Uninitialized()
      %3456 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %3457 : bool = aten::gt(%3456, %6)
      %3458 : bool, %3459 : bool, %3460 : int = prim::Loop(%12, %3457, %10, %3455, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%3461 : int, %3462 : bool, %3463 : bool, %3464 : int):
          %tensor.57 : Tensor = aten::__getitem__(%features.4, %3464) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %3466 : bool = prim::requires_grad(%tensor.57)
          %3467 : bool, %3468 : bool = prim::If(%3466) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %3455)
          %3469 : int = aten::add(%3464, %19)
          %3470 : bool = aten::lt(%3469, %3456)
          %3471 : bool = aten::__and__(%3470, %3467)
          -> (%3471, %3466, %3468, %3469)
      %3472 : bool = prim::If(%3458)
        block0():
          -> (%3459)
        block1():
          -> (%10)
      -> (%3472)
    block1():
      -> (%10)
  %bottleneck_output.112 : Tensor = prim::If(%3454) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.57 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %3475 : __torch__.torch.nn.modules.conv.___torch_mangle_63.Conv2d = prim::GetAttr[name="conv1"](%2014)
      %3476 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_62.BatchNorm2d = prim::GetAttr[name="norm1"](%2014)
      %3477 : int = aten::dim(%concated_features.57) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %3478 : bool = aten::ne(%3477, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%3478) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %3480 : str = aten::format(%14, %3477) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%3480) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %3481 : bool = prim::GetAttr[name="training"](%3476)
       = prim::If(%3481) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3482 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3476)
          %3483 : Tensor = aten::add(%3482, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3476, %3483)
          -> ()
        block1():
          -> ()
      %3484 : bool = prim::GetAttr[name="training"](%3476)
      %3485 : Tensor = prim::GetAttr[name="running_mean"](%3476)
      %3486 : Tensor = prim::GetAttr[name="running_var"](%3476)
      %3487 : Tensor = prim::GetAttr[name="weight"](%3476)
      %3488 : Tensor = prim::GetAttr[name="bias"](%3476)
       = prim::If(%3484) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3489 : int[] = aten::size(%concated_features.57) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.464 : int = aten::__getitem__(%3489, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3491 : int = aten::len(%3489) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3492 : int = aten::sub(%3491, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.465 : int = prim::Loop(%3492, %5, %size_prods.464) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.117 : int, %size_prods.466 : int):
              %3496 : int = aten::add(%i.117, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3497 : int = aten::__getitem__(%3489, %3496) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.467 : int = aten::mul(%size_prods.466, %3497) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.467)
          %3499 : bool = aten::eq(%size_prods.465, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3499) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3500 : str = aten::format(%7, %3489) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3500) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %3501 : Tensor = aten::batch_norm(%concated_features.57, %3487, %3488, %3485, %3486, %3484, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.113 : Tensor = aten::relu_(%3501) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3503 : Tensor = prim::GetAttr[name="weight"](%3475)
      %3504 : Tensor? = prim::GetAttr[name="bias"](%3475)
      %bottleneck_output.113 : Tensor = aten::conv2d(%result.113, %3503, %3504, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.113)
  %3509 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2014)
  %3510 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2014)
  %3511 : int = aten::dim(%bottleneck_output.112) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %3512 : bool = aten::ne(%3511, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%3512) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %3514 : str = aten::format(%14, %3511) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%3514) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %3515 : bool = prim::GetAttr[name="training"](%3510)
   = prim::If(%3515) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %3516 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3510)
      %3517 : Tensor = aten::add(%3516, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%3510, %3517)
      -> ()
    block1():
      -> ()
  %3518 : bool = prim::GetAttr[name="training"](%3510)
  %3519 : Tensor = prim::GetAttr[name="running_mean"](%3510)
  %3520 : Tensor = prim::GetAttr[name="running_var"](%3510)
  %3521 : Tensor = prim::GetAttr[name="weight"](%3510)
  %3522 : Tensor = prim::GetAttr[name="bias"](%3510)
   = prim::If(%3518) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %3523 : int[] = aten::size(%bottleneck_output.112) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.468 : int = aten::__getitem__(%3523, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %3525 : int = aten::len(%3523) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %3526 : int = aten::sub(%3525, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.469 : int = prim::Loop(%3526, %5, %size_prods.468) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.118 : int, %size_prods.470 : int):
          %3530 : int = aten::add(%i.118, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %3531 : int = aten::__getitem__(%3523, %3530) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.471 : int = aten::mul(%size_prods.470, %3531) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.471)
      %3533 : bool = aten::eq(%size_prods.469, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%3533) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %3534 : str = aten::format(%7, %3523) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%3534) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %3535 : Tensor = aten::batch_norm(%bottleneck_output.112, %3521, %3522, %3519, %3520, %3518, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.114 : Tensor = aten::relu_(%3535) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %3537 : Tensor = prim::GetAttr[name="weight"](%3509)
  %3538 : Tensor? = prim::GetAttr[name="bias"](%3509)
  %new_features.113 : Tensor = aten::conv2d(%result.114, %3537, %3538, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %3543 : float = prim::GetAttr[name="drop_rate"](%2014)
  %3544 : bool = aten::gt(%3543, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.114 : Tensor = prim::If(%3544) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %3547 : bool = prim::GetAttr[name="training"](%2014)
      %3548 : bool = aten::lt(%3543, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %3549 : bool = prim::If(%3548) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %3550 : bool = aten::gt(%3543, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%3550)
       = prim::If(%3549) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %3551 : str = aten::format(%17, %3543) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%3551) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %3552 : Tensor = aten::dropout(%new_features.113, %3543, %3547) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%3552)
    block1():
      -> (%new_features.113)
  %3553 : Tensor[] = aten::append(%features.4, %new_features.114) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %3555 : bool = prim::GetAttr[name="memory_efficient"](%2015)
  %3556 : bool = prim::If(%3555) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %3557 : bool = prim::Uninitialized()
      %3558 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %3559 : bool = aten::gt(%3558, %6)
      %3560 : bool, %3561 : bool, %3562 : int = prim::Loop(%12, %3559, %10, %3557, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%3563 : int, %3564 : bool, %3565 : bool, %3566 : int):
          %tensor.17 : Tensor = aten::__getitem__(%features.4, %3566) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %3568 : bool = prim::requires_grad(%tensor.17)
          %3569 : bool, %3570 : bool = prim::If(%3568) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %3557)
          %3571 : int = aten::add(%3566, %19)
          %3572 : bool = aten::lt(%3571, %3558)
          %3573 : bool = aten::__and__(%3572, %3569)
          -> (%3573, %3568, %3570, %3571)
      %3574 : bool = prim::If(%3560)
        block0():
          -> (%3561)
        block1():
          -> (%10)
      -> (%3574)
    block1():
      -> (%10)
  %bottleneck_output.32 : Tensor = prim::If(%3556) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.17 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %3577 : __torch__.torch.nn.modules.conv.___torch_mangle_66.Conv2d = prim::GetAttr[name="conv1"](%2015)
      %3578 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_65.BatchNorm2d = prim::GetAttr[name="norm1"](%2015)
      %3579 : int = aten::dim(%concated_features.17) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %3580 : bool = aten::ne(%3579, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%3580) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %3582 : str = aten::format(%14, %3579) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%3582) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %3583 : bool = prim::GetAttr[name="training"](%3578)
       = prim::If(%3583) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3584 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3578)
          %3585 : Tensor = aten::add(%3584, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3578, %3585)
          -> ()
        block1():
          -> ()
      %3586 : bool = prim::GetAttr[name="training"](%3578)
      %3587 : Tensor = prim::GetAttr[name="running_mean"](%3578)
      %3588 : Tensor = prim::GetAttr[name="running_var"](%3578)
      %3589 : Tensor = prim::GetAttr[name="weight"](%3578)
      %3590 : Tensor = prim::GetAttr[name="bias"](%3578)
       = prim::If(%3586) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3591 : int[] = aten::size(%concated_features.17) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.128 : int = aten::__getitem__(%3591, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3593 : int = aten::len(%3591) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3594 : int = aten::sub(%3593, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.129 : int = prim::Loop(%3594, %5, %size_prods.128) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.33 : int, %size_prods.130 : int):
              %3598 : int = aten::add(%i.33, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3599 : int = aten::__getitem__(%3591, %3598) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.131 : int = aten::mul(%size_prods.130, %3599) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.131)
          %3601 : bool = aten::eq(%size_prods.129, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3601) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3602 : str = aten::format(%7, %3591) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3602) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %3603 : Tensor = aten::batch_norm(%concated_features.17, %3589, %3590, %3587, %3588, %3586, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.33 : Tensor = aten::relu_(%3603) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3605 : Tensor = prim::GetAttr[name="weight"](%3577)
      %3606 : Tensor? = prim::GetAttr[name="bias"](%3577)
      %bottleneck_output.33 : Tensor = aten::conv2d(%result.33, %3605, %3606, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.33)
  %3611 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2015)
  %3612 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2015)
  %3613 : int = aten::dim(%bottleneck_output.32) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %3614 : bool = aten::ne(%3613, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%3614) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %3616 : str = aten::format(%14, %3613) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%3616) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %3617 : bool = prim::GetAttr[name="training"](%3612)
   = prim::If(%3617) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %3618 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3612)
      %3619 : Tensor = aten::add(%3618, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%3612, %3619)
      -> ()
    block1():
      -> ()
  %3620 : bool = prim::GetAttr[name="training"](%3612)
  %3621 : Tensor = prim::GetAttr[name="running_mean"](%3612)
  %3622 : Tensor = prim::GetAttr[name="running_var"](%3612)
  %3623 : Tensor = prim::GetAttr[name="weight"](%3612)
  %3624 : Tensor = prim::GetAttr[name="bias"](%3612)
   = prim::If(%3620) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %3625 : int[] = aten::size(%bottleneck_output.32) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.132 : int = aten::__getitem__(%3625, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %3627 : int = aten::len(%3625) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %3628 : int = aten::sub(%3627, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.133 : int = prim::Loop(%3628, %5, %size_prods.132) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.34 : int, %size_prods.134 : int):
          %3632 : int = aten::add(%i.34, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %3633 : int = aten::__getitem__(%3625, %3632) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.135 : int = aten::mul(%size_prods.134, %3633) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.135)
      %3635 : bool = aten::eq(%size_prods.133, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%3635) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %3636 : str = aten::format(%7, %3625) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%3636) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %3637 : Tensor = aten::batch_norm(%bottleneck_output.32, %3623, %3624, %3621, %3622, %3620, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.34 : Tensor = aten::relu_(%3637) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %3639 : Tensor = prim::GetAttr[name="weight"](%3611)
  %3640 : Tensor? = prim::GetAttr[name="bias"](%3611)
  %new_features.34 : Tensor = aten::conv2d(%result.34, %3639, %3640, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %3645 : float = prim::GetAttr[name="drop_rate"](%2015)
  %3646 : bool = aten::gt(%3645, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.116 : Tensor = prim::If(%3646) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %3649 : bool = prim::GetAttr[name="training"](%2015)
      %3650 : bool = aten::lt(%3645, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %3651 : bool = prim::If(%3650) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %3652 : bool = aten::gt(%3645, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%3652)
       = prim::If(%3651) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %3653 : str = aten::format(%17, %3645) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%3653) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %3654 : Tensor = aten::dropout(%new_features.34, %3645, %3649) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%3654)
    block1():
      -> (%new_features.34)
  %3655 : Tensor[] = aten::append(%features.4, %new_features.116) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %3657 : bool = prim::GetAttr[name="memory_efficient"](%2016)
  %3658 : bool = prim::If(%3657) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %3659 : bool = prim::Uninitialized()
      %3660 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %3661 : bool = aten::gt(%3660, %6)
      %3662 : bool, %3663 : bool, %3664 : int = prim::Loop(%12, %3661, %10, %3659, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%3665 : int, %3666 : bool, %3667 : bool, %3668 : int):
          %tensor.18 : Tensor = aten::__getitem__(%features.4, %3668) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %3670 : bool = prim::requires_grad(%tensor.18)
          %3671 : bool, %3672 : bool = prim::If(%3670) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %3659)
          %3673 : int = aten::add(%3668, %19)
          %3674 : bool = aten::lt(%3673, %3660)
          %3675 : bool = aten::__and__(%3674, %3671)
          -> (%3675, %3670, %3672, %3673)
      %3676 : bool = prim::If(%3662)
        block0():
          -> (%3663)
        block1():
          -> (%10)
      -> (%3676)
    block1():
      -> (%10)
  %bottleneck_output.34 : Tensor = prim::If(%3658) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.18 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %3679 : __torch__.torch.nn.modules.conv.___torch_mangle_69.Conv2d = prim::GetAttr[name="conv1"](%2016)
      %3680 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_68.BatchNorm2d = prim::GetAttr[name="norm1"](%2016)
      %3681 : int = aten::dim(%concated_features.18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %3682 : bool = aten::ne(%3681, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%3682) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %3684 : str = aten::format(%14, %3681) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%3684) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %3685 : bool = prim::GetAttr[name="training"](%3680)
       = prim::If(%3685) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3686 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3680)
          %3687 : Tensor = aten::add(%3686, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3680, %3687)
          -> ()
        block1():
          -> ()
      %3688 : bool = prim::GetAttr[name="training"](%3680)
      %3689 : Tensor = prim::GetAttr[name="running_mean"](%3680)
      %3690 : Tensor = prim::GetAttr[name="running_var"](%3680)
      %3691 : Tensor = prim::GetAttr[name="weight"](%3680)
      %3692 : Tensor = prim::GetAttr[name="bias"](%3680)
       = prim::If(%3688) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3693 : int[] = aten::size(%concated_features.18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.136 : int = aten::__getitem__(%3693, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3695 : int = aten::len(%3693) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3696 : int = aten::sub(%3695, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.137 : int = prim::Loop(%3696, %5, %size_prods.136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.35 : int, %size_prods.138 : int):
              %3700 : int = aten::add(%i.35, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3701 : int = aten::__getitem__(%3693, %3700) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.139 : int = aten::mul(%size_prods.138, %3701) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.139)
          %3703 : bool = aten::eq(%size_prods.137, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3703) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3704 : str = aten::format(%7, %3693) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3704) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %3705 : Tensor = aten::batch_norm(%concated_features.18, %3691, %3692, %3689, %3690, %3688, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.35 : Tensor = aten::relu_(%3705) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3707 : Tensor = prim::GetAttr[name="weight"](%3679)
      %3708 : Tensor? = prim::GetAttr[name="bias"](%3679)
      %bottleneck_output.35 : Tensor = aten::conv2d(%result.35, %3707, %3708, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.35)
  %3713 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2016)
  %3714 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2016)
  %3715 : int = aten::dim(%bottleneck_output.34) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %3716 : bool = aten::ne(%3715, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%3716) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %3718 : str = aten::format(%14, %3715) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%3718) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %3719 : bool = prim::GetAttr[name="training"](%3714)
   = prim::If(%3719) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %3720 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3714)
      %3721 : Tensor = aten::add(%3720, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%3714, %3721)
      -> ()
    block1():
      -> ()
  %3722 : bool = prim::GetAttr[name="training"](%3714)
  %3723 : Tensor = prim::GetAttr[name="running_mean"](%3714)
  %3724 : Tensor = prim::GetAttr[name="running_var"](%3714)
  %3725 : Tensor = prim::GetAttr[name="weight"](%3714)
  %3726 : Tensor = prim::GetAttr[name="bias"](%3714)
   = prim::If(%3722) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %3727 : int[] = aten::size(%bottleneck_output.34) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.140 : int = aten::__getitem__(%3727, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %3729 : int = aten::len(%3727) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %3730 : int = aten::sub(%3729, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.141 : int = prim::Loop(%3730, %5, %size_prods.140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.36 : int, %size_prods.142 : int):
          %3734 : int = aten::add(%i.36, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %3735 : int = aten::__getitem__(%3727, %3734) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.143 : int = aten::mul(%size_prods.142, %3735) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.143)
      %3737 : bool = aten::eq(%size_prods.141, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%3737) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %3738 : str = aten::format(%7, %3727) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%3738) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %3739 : Tensor = aten::batch_norm(%bottleneck_output.34, %3725, %3726, %3723, %3724, %3722, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.36 : Tensor = aten::relu_(%3739) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %3741 : Tensor = prim::GetAttr[name="weight"](%3713)
  %3742 : Tensor? = prim::GetAttr[name="bias"](%3713)
  %new_features.36 : Tensor = aten::conv2d(%result.36, %3741, %3742, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %3747 : float = prim::GetAttr[name="drop_rate"](%2016)
  %3748 : bool = aten::gt(%3747, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.33 : Tensor = prim::If(%3748) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %3751 : bool = prim::GetAttr[name="training"](%2016)
      %3752 : bool = aten::lt(%3747, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %3753 : bool = prim::If(%3752) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %3754 : bool = aten::gt(%3747, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%3754)
       = prim::If(%3753) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %3755 : str = aten::format(%17, %3747) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%3755) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %3756 : Tensor = aten::dropout(%new_features.36, %3747, %3751) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%3756)
    block1():
      -> (%new_features.36)
  %3757 : Tensor[] = aten::append(%features.4, %new_features.33) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %3759 : bool = prim::GetAttr[name="memory_efficient"](%2017)
  %3760 : bool = prim::If(%3759) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %3761 : bool = prim::Uninitialized()
      %3762 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %3763 : bool = aten::gt(%3762, %6)
      %3764 : bool, %3765 : bool, %3766 : int = prim::Loop(%12, %3763, %10, %3761, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%3767 : int, %3768 : bool, %3769 : bool, %3770 : int):
          %tensor.19 : Tensor = aten::__getitem__(%features.4, %3770) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %3772 : bool = prim::requires_grad(%tensor.19)
          %3773 : bool, %3774 : bool = prim::If(%3772) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %3761)
          %3775 : int = aten::add(%3770, %19)
          %3776 : bool = aten::lt(%3775, %3762)
          %3777 : bool = aten::__and__(%3776, %3773)
          -> (%3777, %3772, %3774, %3775)
      %3778 : bool = prim::If(%3764)
        block0():
          -> (%3765)
        block1():
          -> (%10)
      -> (%3778)
    block1():
      -> (%10)
  %bottleneck_output.36 : Tensor = prim::If(%3760) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.19 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %3781 : __torch__.torch.nn.modules.conv.___torch_mangle_72.Conv2d = prim::GetAttr[name="conv1"](%2017)
      %3782 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_71.BatchNorm2d = prim::GetAttr[name="norm1"](%2017)
      %3783 : int = aten::dim(%concated_features.19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %3784 : bool = aten::ne(%3783, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%3784) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %3786 : str = aten::format(%14, %3783) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%3786) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %3787 : bool = prim::GetAttr[name="training"](%3782)
       = prim::If(%3787) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3788 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3782)
          %3789 : Tensor = aten::add(%3788, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3782, %3789)
          -> ()
        block1():
          -> ()
      %3790 : bool = prim::GetAttr[name="training"](%3782)
      %3791 : Tensor = prim::GetAttr[name="running_mean"](%3782)
      %3792 : Tensor = prim::GetAttr[name="running_var"](%3782)
      %3793 : Tensor = prim::GetAttr[name="weight"](%3782)
      %3794 : Tensor = prim::GetAttr[name="bias"](%3782)
       = prim::If(%3790) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3795 : int[] = aten::size(%concated_features.19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.144 : int = aten::__getitem__(%3795, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3797 : int = aten::len(%3795) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3798 : int = aten::sub(%3797, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.145 : int = prim::Loop(%3798, %5, %size_prods.144) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.37 : int, %size_prods.146 : int):
              %3802 : int = aten::add(%i.37, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3803 : int = aten::__getitem__(%3795, %3802) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.147 : int = aten::mul(%size_prods.146, %3803) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.147)
          %3805 : bool = aten::eq(%size_prods.145, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3805) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3806 : str = aten::format(%7, %3795) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3806) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %3807 : Tensor = aten::batch_norm(%concated_features.19, %3793, %3794, %3791, %3792, %3790, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.37 : Tensor = aten::relu_(%3807) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3809 : Tensor = prim::GetAttr[name="weight"](%3781)
      %3810 : Tensor? = prim::GetAttr[name="bias"](%3781)
      %bottleneck_output.37 : Tensor = aten::conv2d(%result.37, %3809, %3810, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.37)
  %3815 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2017)
  %3816 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2017)
  %3817 : int = aten::dim(%bottleneck_output.36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %3818 : bool = aten::ne(%3817, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%3818) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %3820 : str = aten::format(%14, %3817) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%3820) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %3821 : bool = prim::GetAttr[name="training"](%3816)
   = prim::If(%3821) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %3822 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3816)
      %3823 : Tensor = aten::add(%3822, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%3816, %3823)
      -> ()
    block1():
      -> ()
  %3824 : bool = prim::GetAttr[name="training"](%3816)
  %3825 : Tensor = prim::GetAttr[name="running_mean"](%3816)
  %3826 : Tensor = prim::GetAttr[name="running_var"](%3816)
  %3827 : Tensor = prim::GetAttr[name="weight"](%3816)
  %3828 : Tensor = prim::GetAttr[name="bias"](%3816)
   = prim::If(%3824) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %3829 : int[] = aten::size(%bottleneck_output.36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.148 : int = aten::__getitem__(%3829, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %3831 : int = aten::len(%3829) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %3832 : int = aten::sub(%3831, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.149 : int = prim::Loop(%3832, %5, %size_prods.148) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.38 : int, %size_prods.150 : int):
          %3836 : int = aten::add(%i.38, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %3837 : int = aten::__getitem__(%3829, %3836) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.151 : int = aten::mul(%size_prods.150, %3837) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.151)
      %3839 : bool = aten::eq(%size_prods.149, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%3839) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %3840 : str = aten::format(%7, %3829) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%3840) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %3841 : Tensor = aten::batch_norm(%bottleneck_output.36, %3827, %3828, %3825, %3826, %3824, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.38 : Tensor = aten::relu_(%3841) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %3843 : Tensor = prim::GetAttr[name="weight"](%3815)
  %3844 : Tensor? = prim::GetAttr[name="bias"](%3815)
  %new_features.38 : Tensor = aten::conv2d(%result.38, %3843, %3844, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %3849 : float = prim::GetAttr[name="drop_rate"](%2017)
  %3850 : bool = aten::gt(%3849, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.35 : Tensor = prim::If(%3850) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %3853 : bool = prim::GetAttr[name="training"](%2017)
      %3854 : bool = aten::lt(%3849, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %3855 : bool = prim::If(%3854) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %3856 : bool = aten::gt(%3849, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%3856)
       = prim::If(%3855) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %3857 : str = aten::format(%17, %3849) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%3857) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %3858 : Tensor = aten::dropout(%new_features.38, %3849, %3853) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%3858)
    block1():
      -> (%new_features.38)
  %3859 : Tensor[] = aten::append(%features.4, %new_features.35) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %3861 : bool = prim::GetAttr[name="memory_efficient"](%2018)
  %3862 : bool = prim::If(%3861) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %3863 : bool = prim::Uninitialized()
      %3864 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %3865 : bool = aten::gt(%3864, %6)
      %3866 : bool, %3867 : bool, %3868 : int = prim::Loop(%12, %3865, %10, %3863, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%3869 : int, %3870 : bool, %3871 : bool, %3872 : int):
          %tensor.20 : Tensor = aten::__getitem__(%features.4, %3872) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %3874 : bool = prim::requires_grad(%tensor.20)
          %3875 : bool, %3876 : bool = prim::If(%3874) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %3863)
          %3877 : int = aten::add(%3872, %19)
          %3878 : bool = aten::lt(%3877, %3864)
          %3879 : bool = aten::__and__(%3878, %3875)
          -> (%3879, %3874, %3876, %3877)
      %3880 : bool = prim::If(%3866)
        block0():
          -> (%3867)
        block1():
          -> (%10)
      -> (%3880)
    block1():
      -> (%10)
  %bottleneck_output.38 : Tensor = prim::If(%3862) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.20 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %3883 : __torch__.torch.nn.modules.conv.___torch_mangle_75.Conv2d = prim::GetAttr[name="conv1"](%2018)
      %3884 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_74.BatchNorm2d = prim::GetAttr[name="norm1"](%2018)
      %3885 : int = aten::dim(%concated_features.20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %3886 : bool = aten::ne(%3885, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%3886) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %3888 : str = aten::format(%14, %3885) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%3888) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %3889 : bool = prim::GetAttr[name="training"](%3884)
       = prim::If(%3889) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3890 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3884)
          %3891 : Tensor = aten::add(%3890, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3884, %3891)
          -> ()
        block1():
          -> ()
      %3892 : bool = prim::GetAttr[name="training"](%3884)
      %3893 : Tensor = prim::GetAttr[name="running_mean"](%3884)
      %3894 : Tensor = prim::GetAttr[name="running_var"](%3884)
      %3895 : Tensor = prim::GetAttr[name="weight"](%3884)
      %3896 : Tensor = prim::GetAttr[name="bias"](%3884)
       = prim::If(%3892) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3897 : int[] = aten::size(%concated_features.20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.152 : int = aten::__getitem__(%3897, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %3899 : int = aten::len(%3897) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %3900 : int = aten::sub(%3899, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.153 : int = prim::Loop(%3900, %5, %size_prods.152) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.39 : int, %size_prods.154 : int):
              %3904 : int = aten::add(%i.39, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %3905 : int = aten::__getitem__(%3897, %3904) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.155 : int = aten::mul(%size_prods.154, %3905) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.155)
          %3907 : bool = aten::eq(%size_prods.153, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%3907) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %3908 : str = aten::format(%7, %3897) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%3908) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %3909 : Tensor = aten::batch_norm(%concated_features.20, %3895, %3896, %3893, %3894, %3892, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.39 : Tensor = aten::relu_(%3909) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %3911 : Tensor = prim::GetAttr[name="weight"](%3883)
      %3912 : Tensor? = prim::GetAttr[name="bias"](%3883)
      %bottleneck_output.39 : Tensor = aten::conv2d(%result.39, %3911, %3912, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.39)
  %3917 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2018)
  %3918 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2018)
  %3919 : int = aten::dim(%bottleneck_output.38) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %3920 : bool = aten::ne(%3919, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%3920) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %3922 : str = aten::format(%14, %3919) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%3922) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %3923 : bool = prim::GetAttr[name="training"](%3918)
   = prim::If(%3923) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %3924 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3918)
      %3925 : Tensor = aten::add(%3924, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%3918, %3925)
      -> ()
    block1():
      -> ()
  %3926 : bool = prim::GetAttr[name="training"](%3918)
  %3927 : Tensor = prim::GetAttr[name="running_mean"](%3918)
  %3928 : Tensor = prim::GetAttr[name="running_var"](%3918)
  %3929 : Tensor = prim::GetAttr[name="weight"](%3918)
  %3930 : Tensor = prim::GetAttr[name="bias"](%3918)
   = prim::If(%3926) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %3931 : int[] = aten::size(%bottleneck_output.38) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.156 : int = aten::__getitem__(%3931, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %3933 : int = aten::len(%3931) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %3934 : int = aten::sub(%3933, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.157 : int = prim::Loop(%3934, %5, %size_prods.156) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.40 : int, %size_prods.158 : int):
          %3938 : int = aten::add(%i.40, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %3939 : int = aten::__getitem__(%3931, %3938) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.159 : int = aten::mul(%size_prods.158, %3939) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.159)
      %3941 : bool = aten::eq(%size_prods.157, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%3941) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %3942 : str = aten::format(%7, %3931) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%3942) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %3943 : Tensor = aten::batch_norm(%bottleneck_output.38, %3929, %3930, %3927, %3928, %3926, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.40 : Tensor = aten::relu_(%3943) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %3945 : Tensor = prim::GetAttr[name="weight"](%3917)
  %3946 : Tensor? = prim::GetAttr[name="bias"](%3917)
  %new_features.40 : Tensor = aten::conv2d(%result.40, %3945, %3946, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %3951 : float = prim::GetAttr[name="drop_rate"](%2018)
  %3952 : bool = aten::gt(%3951, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.37 : Tensor = prim::If(%3952) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %3955 : bool = prim::GetAttr[name="training"](%2018)
      %3956 : bool = aten::lt(%3951, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %3957 : bool = prim::If(%3956) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %3958 : bool = aten::gt(%3951, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%3958)
       = prim::If(%3957) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %3959 : str = aten::format(%17, %3951) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%3959) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %3960 : Tensor = aten::dropout(%new_features.40, %3951, %3955) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%3960)
    block1():
      -> (%new_features.40)
  %3961 : Tensor[] = aten::append(%features.4, %new_features.37) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %3963 : bool = prim::GetAttr[name="memory_efficient"](%2019)
  %3964 : bool = prim::If(%3963) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %3965 : bool = prim::Uninitialized()
      %3966 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %3967 : bool = aten::gt(%3966, %6)
      %3968 : bool, %3969 : bool, %3970 : int = prim::Loop(%12, %3967, %10, %3965, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%3971 : int, %3972 : bool, %3973 : bool, %3974 : int):
          %tensor.21 : Tensor = aten::__getitem__(%features.4, %3974) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %3976 : bool = prim::requires_grad(%tensor.21)
          %3977 : bool, %3978 : bool = prim::If(%3976) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %3965)
          %3979 : int = aten::add(%3974, %19)
          %3980 : bool = aten::lt(%3979, %3966)
          %3981 : bool = aten::__and__(%3980, %3977)
          -> (%3981, %3976, %3978, %3979)
      %3982 : bool = prim::If(%3968)
        block0():
          -> (%3969)
        block1():
          -> (%10)
      -> (%3982)
    block1():
      -> (%10)
  %bottleneck_output.40 : Tensor = prim::If(%3964) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.21 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %3985 : __torch__.torch.nn.modules.conv.___torch_mangle_78.Conv2d = prim::GetAttr[name="conv1"](%2019)
      %3986 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_77.BatchNorm2d = prim::GetAttr[name="norm1"](%2019)
      %3987 : int = aten::dim(%concated_features.21) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %3988 : bool = aten::ne(%3987, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%3988) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %3990 : str = aten::format(%14, %3987) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%3990) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %3991 : bool = prim::GetAttr[name="training"](%3986)
       = prim::If(%3991) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %3992 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3986)
          %3993 : Tensor = aten::add(%3992, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3986, %3993)
          -> ()
        block1():
          -> ()
      %3994 : bool = prim::GetAttr[name="training"](%3986)
      %3995 : Tensor = prim::GetAttr[name="running_mean"](%3986)
      %3996 : Tensor = prim::GetAttr[name="running_var"](%3986)
      %3997 : Tensor = prim::GetAttr[name="weight"](%3986)
      %3998 : Tensor = prim::GetAttr[name="bias"](%3986)
       = prim::If(%3994) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %3999 : int[] = aten::size(%concated_features.21) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.160 : int = aten::__getitem__(%3999, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %4001 : int = aten::len(%3999) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %4002 : int = aten::sub(%4001, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.161 : int = prim::Loop(%4002, %5, %size_prods.160) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.41 : int, %size_prods.162 : int):
              %4006 : int = aten::add(%i.41, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %4007 : int = aten::__getitem__(%3999, %4006) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.163 : int = aten::mul(%size_prods.162, %4007) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.163)
          %4009 : bool = aten::eq(%size_prods.161, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%4009) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %4010 : str = aten::format(%7, %3999) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%4010) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %4011 : Tensor = aten::batch_norm(%concated_features.21, %3997, %3998, %3995, %3996, %3994, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.41 : Tensor = aten::relu_(%4011) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %4013 : Tensor = prim::GetAttr[name="weight"](%3985)
      %4014 : Tensor? = prim::GetAttr[name="bias"](%3985)
      %bottleneck_output.41 : Tensor = aten::conv2d(%result.41, %4013, %4014, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.41)
  %4019 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2019)
  %4020 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2019)
  %4021 : int = aten::dim(%bottleneck_output.40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %4022 : bool = aten::ne(%4021, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%4022) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %4024 : str = aten::format(%14, %4021) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%4024) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %4025 : bool = prim::GetAttr[name="training"](%4020)
   = prim::If(%4025) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %4026 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4020)
      %4027 : Tensor = aten::add(%4026, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%4020, %4027)
      -> ()
    block1():
      -> ()
  %4028 : bool = prim::GetAttr[name="training"](%4020)
  %4029 : Tensor = prim::GetAttr[name="running_mean"](%4020)
  %4030 : Tensor = prim::GetAttr[name="running_var"](%4020)
  %4031 : Tensor = prim::GetAttr[name="weight"](%4020)
  %4032 : Tensor = prim::GetAttr[name="bias"](%4020)
   = prim::If(%4028) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %4033 : int[] = aten::size(%bottleneck_output.40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.164 : int = aten::__getitem__(%4033, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %4035 : int = aten::len(%4033) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %4036 : int = aten::sub(%4035, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.165 : int = prim::Loop(%4036, %5, %size_prods.164) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.42 : int, %size_prods.166 : int):
          %4040 : int = aten::add(%i.42, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %4041 : int = aten::__getitem__(%4033, %4040) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.167 : int = aten::mul(%size_prods.166, %4041) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.167)
      %4043 : bool = aten::eq(%size_prods.165, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%4043) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %4044 : str = aten::format(%7, %4033) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%4044) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %4045 : Tensor = aten::batch_norm(%bottleneck_output.40, %4031, %4032, %4029, %4030, %4028, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.42 : Tensor = aten::relu_(%4045) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %4047 : Tensor = prim::GetAttr[name="weight"](%4019)
  %4048 : Tensor? = prim::GetAttr[name="bias"](%4019)
  %new_features.42 : Tensor = aten::conv2d(%result.42, %4047, %4048, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %4053 : float = prim::GetAttr[name="drop_rate"](%2019)
  %4054 : bool = aten::gt(%4053, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.39 : Tensor = prim::If(%4054) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %4057 : bool = prim::GetAttr[name="training"](%2019)
      %4058 : bool = aten::lt(%4053, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %4059 : bool = prim::If(%4058) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %4060 : bool = aten::gt(%4053, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%4060)
       = prim::If(%4059) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %4061 : str = aten::format(%17, %4053) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%4061) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %4062 : Tensor = aten::dropout(%new_features.42, %4053, %4057) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%4062)
    block1():
      -> (%new_features.42)
  %4063 : Tensor[] = aten::append(%features.4, %new_features.39) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %4065 : bool = prim::GetAttr[name="memory_efficient"](%2020)
  %4066 : bool = prim::If(%4065) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %4067 : bool = prim::Uninitialized()
      %4068 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %4069 : bool = aten::gt(%4068, %6)
      %4070 : bool, %4071 : bool, %4072 : int = prim::Loop(%12, %4069, %10, %4067, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%4073 : int, %4074 : bool, %4075 : bool, %4076 : int):
          %tensor.22 : Tensor = aten::__getitem__(%features.4, %4076) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %4078 : bool = prim::requires_grad(%tensor.22)
          %4079 : bool, %4080 : bool = prim::If(%4078) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %4067)
          %4081 : int = aten::add(%4076, %19)
          %4082 : bool = aten::lt(%4081, %4068)
          %4083 : bool = aten::__and__(%4082, %4079)
          -> (%4083, %4078, %4080, %4081)
      %4084 : bool = prim::If(%4070)
        block0():
          -> (%4071)
        block1():
          -> (%10)
      -> (%4084)
    block1():
      -> (%10)
  %bottleneck_output.42 : Tensor = prim::If(%4066) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.22 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %4087 : __torch__.torch.nn.modules.conv.___torch_mangle_81.Conv2d = prim::GetAttr[name="conv1"](%2020)
      %4088 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_80.BatchNorm2d = prim::GetAttr[name="norm1"](%2020)
      %4089 : int = aten::dim(%concated_features.22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %4090 : bool = aten::ne(%4089, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%4090) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %4092 : str = aten::format(%14, %4089) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%4092) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %4093 : bool = prim::GetAttr[name="training"](%4088)
       = prim::If(%4093) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %4094 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4088)
          %4095 : Tensor = aten::add(%4094, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%4088, %4095)
          -> ()
        block1():
          -> ()
      %4096 : bool = prim::GetAttr[name="training"](%4088)
      %4097 : Tensor = prim::GetAttr[name="running_mean"](%4088)
      %4098 : Tensor = prim::GetAttr[name="running_var"](%4088)
      %4099 : Tensor = prim::GetAttr[name="weight"](%4088)
      %4100 : Tensor = prim::GetAttr[name="bias"](%4088)
       = prim::If(%4096) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %4101 : int[] = aten::size(%concated_features.22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.168 : int = aten::__getitem__(%4101, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %4103 : int = aten::len(%4101) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %4104 : int = aten::sub(%4103, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.169 : int = prim::Loop(%4104, %5, %size_prods.168) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.43 : int, %size_prods.170 : int):
              %4108 : int = aten::add(%i.43, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %4109 : int = aten::__getitem__(%4101, %4108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.171 : int = aten::mul(%size_prods.170, %4109) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.171)
          %4111 : bool = aten::eq(%size_prods.169, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%4111) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %4112 : str = aten::format(%7, %4101) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%4112) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %4113 : Tensor = aten::batch_norm(%concated_features.22, %4099, %4100, %4097, %4098, %4096, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.43 : Tensor = aten::relu_(%4113) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %4115 : Tensor = prim::GetAttr[name="weight"](%4087)
      %4116 : Tensor? = prim::GetAttr[name="bias"](%4087)
      %bottleneck_output.43 : Tensor = aten::conv2d(%result.43, %4115, %4116, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.43)
  %4121 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2020)
  %4122 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2020)
  %4123 : int = aten::dim(%bottleneck_output.42) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %4124 : bool = aten::ne(%4123, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%4124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %4126 : str = aten::format(%14, %4123) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%4126) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %4127 : bool = prim::GetAttr[name="training"](%4122)
   = prim::If(%4127) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %4128 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4122)
      %4129 : Tensor = aten::add(%4128, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%4122, %4129)
      -> ()
    block1():
      -> ()
  %4130 : bool = prim::GetAttr[name="training"](%4122)
  %4131 : Tensor = prim::GetAttr[name="running_mean"](%4122)
  %4132 : Tensor = prim::GetAttr[name="running_var"](%4122)
  %4133 : Tensor = prim::GetAttr[name="weight"](%4122)
  %4134 : Tensor = prim::GetAttr[name="bias"](%4122)
   = prim::If(%4130) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %4135 : int[] = aten::size(%bottleneck_output.42) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.172 : int = aten::__getitem__(%4135, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %4137 : int = aten::len(%4135) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %4138 : int = aten::sub(%4137, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.173 : int = prim::Loop(%4138, %5, %size_prods.172) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.44 : int, %size_prods.174 : int):
          %4142 : int = aten::add(%i.44, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %4143 : int = aten::__getitem__(%4135, %4142) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.175 : int = aten::mul(%size_prods.174, %4143) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.175)
      %4145 : bool = aten::eq(%size_prods.173, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%4145) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %4146 : str = aten::format(%7, %4135) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%4146) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %4147 : Tensor = aten::batch_norm(%bottleneck_output.42, %4133, %4134, %4131, %4132, %4130, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.44 : Tensor = aten::relu_(%4147) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %4149 : Tensor = prim::GetAttr[name="weight"](%4121)
  %4150 : Tensor? = prim::GetAttr[name="bias"](%4121)
  %new_features.44 : Tensor = aten::conv2d(%result.44, %4149, %4150, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %4155 : float = prim::GetAttr[name="drop_rate"](%2020)
  %4156 : bool = aten::gt(%4155, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.41 : Tensor = prim::If(%4156) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %4159 : bool = prim::GetAttr[name="training"](%2020)
      %4160 : bool = aten::lt(%4155, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %4161 : bool = prim::If(%4160) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %4162 : bool = aten::gt(%4155, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%4162)
       = prim::If(%4161) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %4163 : str = aten::format(%17, %4155) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%4163) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %4164 : Tensor = aten::dropout(%new_features.44, %4155, %4159) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%4164)
    block1():
      -> (%new_features.44)
  %4165 : Tensor[] = aten::append(%features.4, %new_features.41) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %4167 : bool = prim::GetAttr[name="memory_efficient"](%2021)
  %4168 : bool = prim::If(%4167) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %4169 : bool = prim::Uninitialized()
      %4170 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %4171 : bool = aten::gt(%4170, %6)
      %4172 : bool, %4173 : bool, %4174 : int = prim::Loop(%12, %4171, %10, %4169, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%4175 : int, %4176 : bool, %4177 : bool, %4178 : int):
          %tensor.23 : Tensor = aten::__getitem__(%features.4, %4178) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %4180 : bool = prim::requires_grad(%tensor.23)
          %4181 : bool, %4182 : bool = prim::If(%4180) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %4169)
          %4183 : int = aten::add(%4178, %19)
          %4184 : bool = aten::lt(%4183, %4170)
          %4185 : bool = aten::__and__(%4184, %4181)
          -> (%4185, %4180, %4182, %4183)
      %4186 : bool = prim::If(%4172)
        block0():
          -> (%4173)
        block1():
          -> (%10)
      -> (%4186)
    block1():
      -> (%10)
  %bottleneck_output.44 : Tensor = prim::If(%4168) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.23 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %4189 : __torch__.torch.nn.modules.conv.___torch_mangle_84.Conv2d = prim::GetAttr[name="conv1"](%2021)
      %4190 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_83.BatchNorm2d = prim::GetAttr[name="norm1"](%2021)
      %4191 : int = aten::dim(%concated_features.23) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %4192 : bool = aten::ne(%4191, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%4192) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %4194 : str = aten::format(%14, %4191) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%4194) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %4195 : bool = prim::GetAttr[name="training"](%4190)
       = prim::If(%4195) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %4196 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4190)
          %4197 : Tensor = aten::add(%4196, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%4190, %4197)
          -> ()
        block1():
          -> ()
      %4198 : bool = prim::GetAttr[name="training"](%4190)
      %4199 : Tensor = prim::GetAttr[name="running_mean"](%4190)
      %4200 : Tensor = prim::GetAttr[name="running_var"](%4190)
      %4201 : Tensor = prim::GetAttr[name="weight"](%4190)
      %4202 : Tensor = prim::GetAttr[name="bias"](%4190)
       = prim::If(%4198) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %4203 : int[] = aten::size(%concated_features.23) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.176 : int = aten::__getitem__(%4203, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %4205 : int = aten::len(%4203) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %4206 : int = aten::sub(%4205, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.177 : int = prim::Loop(%4206, %5, %size_prods.176) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.45 : int, %size_prods.178 : int):
              %4210 : int = aten::add(%i.45, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %4211 : int = aten::__getitem__(%4203, %4210) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.179 : int = aten::mul(%size_prods.178, %4211) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.179)
          %4213 : bool = aten::eq(%size_prods.177, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%4213) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %4214 : str = aten::format(%7, %4203) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%4214) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %4215 : Tensor = aten::batch_norm(%concated_features.23, %4201, %4202, %4199, %4200, %4198, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.45 : Tensor = aten::relu_(%4215) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %4217 : Tensor = prim::GetAttr[name="weight"](%4189)
      %4218 : Tensor? = prim::GetAttr[name="bias"](%4189)
      %bottleneck_output.45 : Tensor = aten::conv2d(%result.45, %4217, %4218, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.45)
  %4223 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2021)
  %4224 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2021)
  %4225 : int = aten::dim(%bottleneck_output.44) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %4226 : bool = aten::ne(%4225, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%4226) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %4228 : str = aten::format(%14, %4225) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%4228) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %4229 : bool = prim::GetAttr[name="training"](%4224)
   = prim::If(%4229) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %4230 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4224)
      %4231 : Tensor = aten::add(%4230, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%4224, %4231)
      -> ()
    block1():
      -> ()
  %4232 : bool = prim::GetAttr[name="training"](%4224)
  %4233 : Tensor = prim::GetAttr[name="running_mean"](%4224)
  %4234 : Tensor = prim::GetAttr[name="running_var"](%4224)
  %4235 : Tensor = prim::GetAttr[name="weight"](%4224)
  %4236 : Tensor = prim::GetAttr[name="bias"](%4224)
   = prim::If(%4232) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %4237 : int[] = aten::size(%bottleneck_output.44) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.180 : int = aten::__getitem__(%4237, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %4239 : int = aten::len(%4237) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %4240 : int = aten::sub(%4239, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.181 : int = prim::Loop(%4240, %5, %size_prods.180) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.46 : int, %size_prods.182 : int):
          %4244 : int = aten::add(%i.46, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %4245 : int = aten::__getitem__(%4237, %4244) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.183 : int = aten::mul(%size_prods.182, %4245) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.183)
      %4247 : bool = aten::eq(%size_prods.181, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%4247) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %4248 : str = aten::format(%7, %4237) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%4248) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %4249 : Tensor = aten::batch_norm(%bottleneck_output.44, %4235, %4236, %4233, %4234, %4232, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.46 : Tensor = aten::relu_(%4249) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %4251 : Tensor = prim::GetAttr[name="weight"](%4223)
  %4252 : Tensor? = prim::GetAttr[name="bias"](%4223)
  %new_features.46 : Tensor = aten::conv2d(%result.46, %4251, %4252, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %4257 : float = prim::GetAttr[name="drop_rate"](%2021)
  %4258 : bool = aten::gt(%4257, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.43 : Tensor = prim::If(%4258) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %4261 : bool = prim::GetAttr[name="training"](%2021)
      %4262 : bool = aten::lt(%4257, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %4263 : bool = prim::If(%4262) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %4264 : bool = aten::gt(%4257, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%4264)
       = prim::If(%4263) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %4265 : str = aten::format(%17, %4257) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%4265) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %4266 : Tensor = aten::dropout(%new_features.46, %4257, %4261) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%4266)
    block1():
      -> (%new_features.46)
  %4267 : Tensor[] = aten::append(%features.4, %new_features.43) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %4269 : bool = prim::GetAttr[name="memory_efficient"](%2022)
  %4270 : bool = prim::If(%4269) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %4271 : bool = prim::Uninitialized()
      %4272 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %4273 : bool = aten::gt(%4272, %6)
      %4274 : bool, %4275 : bool, %4276 : int = prim::Loop(%12, %4273, %10, %4271, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%4277 : int, %4278 : bool, %4279 : bool, %4280 : int):
          %tensor.24 : Tensor = aten::__getitem__(%features.4, %4280) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %4282 : bool = prim::requires_grad(%tensor.24)
          %4283 : bool, %4284 : bool = prim::If(%4282) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %4271)
          %4285 : int = aten::add(%4280, %19)
          %4286 : bool = aten::lt(%4285, %4272)
          %4287 : bool = aten::__and__(%4286, %4283)
          -> (%4287, %4282, %4284, %4285)
      %4288 : bool = prim::If(%4274)
        block0():
          -> (%4275)
        block1():
          -> (%10)
      -> (%4288)
    block1():
      -> (%10)
  %bottleneck_output.46 : Tensor = prim::If(%4270) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.24 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %4291 : __torch__.torch.nn.modules.conv.___torch_mangle_87.Conv2d = prim::GetAttr[name="conv1"](%2022)
      %4292 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_86.BatchNorm2d = prim::GetAttr[name="norm1"](%2022)
      %4293 : int = aten::dim(%concated_features.24) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %4294 : bool = aten::ne(%4293, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%4294) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %4296 : str = aten::format(%14, %4293) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%4296) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %4297 : bool = prim::GetAttr[name="training"](%4292)
       = prim::If(%4297) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %4298 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4292)
          %4299 : Tensor = aten::add(%4298, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%4292, %4299)
          -> ()
        block1():
          -> ()
      %4300 : bool = prim::GetAttr[name="training"](%4292)
      %4301 : Tensor = prim::GetAttr[name="running_mean"](%4292)
      %4302 : Tensor = prim::GetAttr[name="running_var"](%4292)
      %4303 : Tensor = prim::GetAttr[name="weight"](%4292)
      %4304 : Tensor = prim::GetAttr[name="bias"](%4292)
       = prim::If(%4300) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %4305 : int[] = aten::size(%concated_features.24) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.184 : int = aten::__getitem__(%4305, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %4307 : int = aten::len(%4305) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %4308 : int = aten::sub(%4307, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.185 : int = prim::Loop(%4308, %5, %size_prods.184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.47 : int, %size_prods.186 : int):
              %4312 : int = aten::add(%i.47, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %4313 : int = aten::__getitem__(%4305, %4312) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.187 : int = aten::mul(%size_prods.186, %4313) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.187)
          %4315 : bool = aten::eq(%size_prods.185, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%4315) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %4316 : str = aten::format(%7, %4305) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%4316) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %4317 : Tensor = aten::batch_norm(%concated_features.24, %4303, %4304, %4301, %4302, %4300, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.47 : Tensor = aten::relu_(%4317) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %4319 : Tensor = prim::GetAttr[name="weight"](%4291)
      %4320 : Tensor? = prim::GetAttr[name="bias"](%4291)
      %bottleneck_output.47 : Tensor = aten::conv2d(%result.47, %4319, %4320, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.47)
  %4325 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2022)
  %4326 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2022)
  %4327 : int = aten::dim(%bottleneck_output.46) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %4328 : bool = aten::ne(%4327, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%4328) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %4330 : str = aten::format(%14, %4327) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%4330) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %4331 : bool = prim::GetAttr[name="training"](%4326)
   = prim::If(%4331) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %4332 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4326)
      %4333 : Tensor = aten::add(%4332, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%4326, %4333)
      -> ()
    block1():
      -> ()
  %4334 : bool = prim::GetAttr[name="training"](%4326)
  %4335 : Tensor = prim::GetAttr[name="running_mean"](%4326)
  %4336 : Tensor = prim::GetAttr[name="running_var"](%4326)
  %4337 : Tensor = prim::GetAttr[name="weight"](%4326)
  %4338 : Tensor = prim::GetAttr[name="bias"](%4326)
   = prim::If(%4334) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %4339 : int[] = aten::size(%bottleneck_output.46) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.188 : int = aten::__getitem__(%4339, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %4341 : int = aten::len(%4339) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %4342 : int = aten::sub(%4341, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.189 : int = prim::Loop(%4342, %5, %size_prods.188) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.48 : int, %size_prods.190 : int):
          %4346 : int = aten::add(%i.48, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %4347 : int = aten::__getitem__(%4339, %4346) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.191 : int = aten::mul(%size_prods.190, %4347) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.191)
      %4349 : bool = aten::eq(%size_prods.189, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%4349) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %4350 : str = aten::format(%7, %4339) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%4350) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %4351 : Tensor = aten::batch_norm(%bottleneck_output.46, %4337, %4338, %4335, %4336, %4334, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.48 : Tensor = aten::relu_(%4351) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %4353 : Tensor = prim::GetAttr[name="weight"](%4325)
  %4354 : Tensor? = prim::GetAttr[name="bias"](%4325)
  %new_features.48 : Tensor = aten::conv2d(%result.48, %4353, %4354, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %4359 : float = prim::GetAttr[name="drop_rate"](%2022)
  %4360 : bool = aten::gt(%4359, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.45 : Tensor = prim::If(%4360) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %4363 : bool = prim::GetAttr[name="training"](%2022)
      %4364 : bool = aten::lt(%4359, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %4365 : bool = prim::If(%4364) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %4366 : bool = aten::gt(%4359, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%4366)
       = prim::If(%4365) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %4367 : str = aten::format(%17, %4359) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%4367) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %4368 : Tensor = aten::dropout(%new_features.48, %4359, %4363) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%4368)
    block1():
      -> (%new_features.48)
  %4369 : Tensor[] = aten::append(%features.4, %new_features.45) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %4371 : bool = prim::GetAttr[name="memory_efficient"](%2023)
  %4372 : bool = prim::If(%4371) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %4373 : bool = prim::Uninitialized()
      %4374 : int = aten::len(%features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %4375 : bool = aten::gt(%4374, %6)
      %4376 : bool, %4377 : bool, %4378 : int = prim::Loop(%12, %4375, %10, %4373, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%4379 : int, %4380 : bool, %4381 : bool, %4382 : int):
          %tensor.58 : Tensor = aten::__getitem__(%features.4, %4382) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %4384 : bool = prim::requires_grad(%tensor.58)
          %4385 : bool, %4386 : bool = prim::If(%4384) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %4373)
          %4387 : int = aten::add(%4382, %19)
          %4388 : bool = aten::lt(%4387, %4374)
          %4389 : bool = aten::__and__(%4388, %4385)
          -> (%4389, %4384, %4386, %4387)
      %4390 : bool = prim::If(%4376)
        block0():
          -> (%4377)
        block1():
          -> (%10)
      -> (%4390)
    block1():
      -> (%10)
  %bottleneck_output.114 : Tensor = prim::If(%4372) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.58 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %4393 : __torch__.torch.nn.modules.conv.___torch_mangle_90.Conv2d = prim::GetAttr[name="conv1"](%2023)
      %4394 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_89.BatchNorm2d = prim::GetAttr[name="norm1"](%2023)
      %4395 : int = aten::dim(%concated_features.58) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %4396 : bool = aten::ne(%4395, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%4396) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %4398 : str = aten::format(%14, %4395) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%4398) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %4399 : bool = prim::GetAttr[name="training"](%4394)
       = prim::If(%4399) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %4400 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4394)
          %4401 : Tensor = aten::add(%4400, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%4394, %4401)
          -> ()
        block1():
          -> ()
      %4402 : bool = prim::GetAttr[name="training"](%4394)
      %4403 : Tensor = prim::GetAttr[name="running_mean"](%4394)
      %4404 : Tensor = prim::GetAttr[name="running_var"](%4394)
      %4405 : Tensor = prim::GetAttr[name="weight"](%4394)
      %4406 : Tensor = prim::GetAttr[name="bias"](%4394)
       = prim::If(%4402) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %4407 : int[] = aten::size(%concated_features.58) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.472 : int = aten::__getitem__(%4407, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %4409 : int = aten::len(%4407) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %4410 : int = aten::sub(%4409, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.473 : int = prim::Loop(%4410, %5, %size_prods.472) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.119 : int, %size_prods.474 : int):
              %4414 : int = aten::add(%i.119, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %4415 : int = aten::__getitem__(%4407, %4414) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.475 : int = aten::mul(%size_prods.474, %4415) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.475)
          %4417 : bool = aten::eq(%size_prods.473, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%4417) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %4418 : str = aten::format(%7, %4407) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%4418) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %4419 : Tensor = aten::batch_norm(%concated_features.58, %4405, %4406, %4403, %4404, %4402, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.115 : Tensor = aten::relu_(%4419) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %4421 : Tensor = prim::GetAttr[name="weight"](%4393)
      %4422 : Tensor? = prim::GetAttr[name="bias"](%4393)
      %bottleneck_output.115 : Tensor = aten::conv2d(%result.115, %4421, %4422, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.115)
  %4427 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%2023)
  %4428 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%2023)
  %4429 : int = aten::dim(%bottleneck_output.114) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %4430 : bool = aten::ne(%4429, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%4430) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %4432 : str = aten::format(%14, %4429) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%4432) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %4433 : bool = prim::GetAttr[name="training"](%4428)
   = prim::If(%4433) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %4434 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4428)
      %4435 : Tensor = aten::add(%4434, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%4428, %4435)
      -> ()
    block1():
      -> ()
  %4436 : bool = prim::GetAttr[name="training"](%4428)
  %4437 : Tensor = prim::GetAttr[name="running_mean"](%4428)
  %4438 : Tensor = prim::GetAttr[name="running_var"](%4428)
  %4439 : Tensor = prim::GetAttr[name="weight"](%4428)
  %4440 : Tensor = prim::GetAttr[name="bias"](%4428)
   = prim::If(%4436) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %4441 : int[] = aten::size(%bottleneck_output.114) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.348 : int = aten::__getitem__(%4441, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %4443 : int = aten::len(%4441) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %4444 : int = aten::sub(%4443, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.349 : int = prim::Loop(%4444, %5, %size_prods.348) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.88 : int, %size_prods.350 : int):
          %4448 : int = aten::add(%i.88, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %4449 : int = aten::__getitem__(%4441, %4448) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.351 : int = aten::mul(%size_prods.350, %4449) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.351)
      %4451 : bool = aten::eq(%size_prods.349, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%4451) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %4452 : str = aten::format(%7, %4441) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%4452) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %4453 : Tensor = aten::batch_norm(%bottleneck_output.114, %4439, %4440, %4437, %4438, %4436, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.116 : Tensor = aten::relu_(%4453) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %4455 : Tensor = prim::GetAttr[name="weight"](%4427)
  %4456 : Tensor? = prim::GetAttr[name="bias"](%4427)
  %new_features.115 : Tensor = aten::conv2d(%result.116, %4455, %4456, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %4461 : float = prim::GetAttr[name="drop_rate"](%2023)
  %4462 : bool = aten::gt(%4461, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.47 : Tensor = prim::If(%4462) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %4465 : bool = prim::GetAttr[name="training"](%2023)
      %4466 : bool = aten::lt(%4461, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %4467 : bool = prim::If(%4466) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %4468 : bool = aten::gt(%4461, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%4468)
       = prim::If(%4467) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %4469 : str = aten::format(%17, %4461) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%4469) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %4470 : Tensor = aten::dropout(%new_features.115, %4461, %4465) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%4470)
    block1():
      -> (%new_features.115)
  %4471 : Tensor[] = aten::append(%features.4, %new_features.47) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %input.19 : Tensor = aten::cat(%features.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:129:15
  %4473 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_93.BatchNorm2d = prim::GetAttr[name="norm"](%29)
  %4474 : __torch__.torch.nn.modules.conv.___torch_mangle_94.Conv2d = prim::GetAttr[name="conv"](%29)
  %4475 : int = aten::dim(%input.19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %4476 : bool = aten::ne(%4475, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%4476) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %4478 : str = aten::format(%14, %4475) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%4478) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %4479 : bool = prim::GetAttr[name="training"](%4473)
   = prim::If(%4479) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %4480 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4473)
      %4481 : Tensor = aten::add(%4480, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%4473, %4481)
      -> ()
    block1():
      -> ()
  %4482 : bool = prim::GetAttr[name="training"](%4473)
  %4483 : Tensor = prim::GetAttr[name="running_mean"](%4473)
  %4484 : Tensor = prim::GetAttr[name="running_var"](%4473)
  %4485 : Tensor = prim::GetAttr[name="weight"](%4473)
  %4486 : Tensor = prim::GetAttr[name="bias"](%4473)
   = prim::If(%4482) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %4487 : int[] = aten::size(%input.19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.476 : int = aten::__getitem__(%4487, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %4489 : int = aten::len(%4487) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %4490 : int = aten::sub(%4489, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.477 : int = prim::Loop(%4490, %5, %size_prods.476) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.120 : int, %size_prods.478 : int):
          %4494 : int = aten::add(%i.120, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %4495 : int = aten::__getitem__(%4487, %4494) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.479 : int = aten::mul(%size_prods.478, %4495) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.479)
      %4497 : bool = aten::eq(%size_prods.477, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%4497) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %4498 : str = aten::format(%7, %4487) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%4498) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.3 : Tensor = aten::batch_norm(%input.19, %4485, %4486, %4483, %4484, %4482, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %input.5 : Tensor = aten::relu_(%input.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %4501 : Tensor = prim::GetAttr[name="weight"](%4474)
  %4502 : Tensor? = prim::GetAttr[name="bias"](%4474)
  %input.7 : Tensor = aten::conv2d(%input.5, %4501, %4502, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %input.21 : Tensor = aten::avg_pool2d(%input.7, %6197, %6197, %6205, %10, %5, %18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/pooling.py:615:15
  %features.1 : Tensor[] = prim::ListConstruct(%input.21)
  %4512 : __torch__.torchvision.models.densenet.___torch_mangle_46._DenseLayer = prim::GetAttr[name="denselayer1"](%30)
  %4513 : __torch__.torchvision.models.densenet.___torch_mangle_49._DenseLayer = prim::GetAttr[name="denselayer2"](%30)
  %4514 : __torch__.torchvision.models.densenet.___torch_mangle_52._DenseLayer = prim::GetAttr[name="denselayer3"](%30)
  %4515 : __torch__.torchvision.models.densenet.___torch_mangle_55._DenseLayer = prim::GetAttr[name="denselayer4"](%30)
  %4516 : __torch__.torchvision.models.densenet.___torch_mangle_58._DenseLayer = prim::GetAttr[name="denselayer5"](%30)
  %4517 : __torch__.torchvision.models.densenet.___torch_mangle_61._DenseLayer = prim::GetAttr[name="denselayer6"](%30)
  %4518 : __torch__.torchvision.models.densenet.___torch_mangle_64._DenseLayer = prim::GetAttr[name="denselayer7"](%30)
  %4519 : __torch__.torchvision.models.densenet.___torch_mangle_67._DenseLayer = prim::GetAttr[name="denselayer8"](%30)
  %4520 : __torch__.torchvision.models.densenet.___torch_mangle_70._DenseLayer = prim::GetAttr[name="denselayer9"](%30)
  %4521 : __torch__.torchvision.models.densenet.___torch_mangle_73._DenseLayer = prim::GetAttr[name="denselayer10"](%30)
  %4522 : __torch__.torchvision.models.densenet.___torch_mangle_76._DenseLayer = prim::GetAttr[name="denselayer11"](%30)
  %4523 : __torch__.torchvision.models.densenet.___torch_mangle_79._DenseLayer = prim::GetAttr[name="denselayer12"](%30)
  %4524 : __torch__.torchvision.models.densenet.___torch_mangle_82._DenseLayer = prim::GetAttr[name="denselayer13"](%30)
  %4525 : __torch__.torchvision.models.densenet.___torch_mangle_85._DenseLayer = prim::GetAttr[name="denselayer14"](%30)
  %4526 : __torch__.torchvision.models.densenet.___torch_mangle_88._DenseLayer = prim::GetAttr[name="denselayer15"](%30)
  %4527 : __torch__.torchvision.models.densenet.___torch_mangle_91._DenseLayer = prim::GetAttr[name="denselayer16"](%30)
  %4529 : bool = prim::GetAttr[name="memory_efficient"](%4512)
  %4530 : bool = prim::If(%4529) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %4531 : bool = prim::Uninitialized()
      %4532 : int = aten::len(%features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %4533 : bool = aten::gt(%4532, %6)
      %4534 : bool, %4535 : bool, %4536 : int = prim::Loop(%12, %4533, %10, %4531, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%4537 : int, %4538 : bool, %4539 : bool, %4540 : int):
          %tensor.2 : Tensor = aten::__getitem__(%features.1, %4540) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %4542 : bool = prim::requires_grad(%tensor.2)
          %4543 : bool, %4544 : bool = prim::If(%4542) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %4531)
          %4545 : int = aten::add(%4540, %19)
          %4546 : bool = aten::lt(%4545, %4532)
          %4547 : bool = aten::__and__(%4546, %4543)
          -> (%4547, %4542, %4544, %4545)
      %4548 : bool = prim::If(%4534)
        block0():
          -> (%4535)
        block1():
          -> (%10)
      -> (%4548)
    block1():
      -> (%10)
  %bottleneck_output.1 : Tensor = prim::If(%4530) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.2 : Tensor = aten::cat(%features.1, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %4551 : __torch__.torch.nn.modules.conv.___torch_mangle_45.Conv2d = prim::GetAttr[name="conv1"](%4512)
      %4552 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_42.BatchNorm2d = prim::GetAttr[name="norm1"](%4512)
      %4553 : int = aten::dim(%concated_features.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %4554 : bool = aten::ne(%4553, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%4554) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %4556 : str = aten::format(%14, %4553) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%4556) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %4557 : bool = prim::GetAttr[name="training"](%4552)
       = prim::If(%4557) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %4558 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4552)
          %4559 : Tensor = aten::add(%4558, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%4552, %4559)
          -> ()
        block1():
          -> ()
      %4560 : bool = prim::GetAttr[name="training"](%4552)
      %4561 : Tensor = prim::GetAttr[name="running_mean"](%4552)
      %4562 : Tensor = prim::GetAttr[name="running_var"](%4552)
      %4563 : Tensor = prim::GetAttr[name="weight"](%4552)
      %4564 : Tensor = prim::GetAttr[name="bias"](%4552)
       = prim::If(%4560) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %4565 : int[] = aten::size(%concated_features.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.8 : int = aten::__getitem__(%4565, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %4567 : int = aten::len(%4565) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %4568 : int = aten::sub(%4567, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.9 : int = prim::Loop(%4568, %5, %size_prods.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.3 : int, %size_prods.10 : int):
              %4572 : int = aten::add(%i.3, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %4573 : int = aten::__getitem__(%4565, %4572) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.11 : int = aten::mul(%size_prods.10, %4573) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.11)
          %4575 : bool = aten::eq(%size_prods.9, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%4575) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %4576 : str = aten::format(%7, %4565) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%4576) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %4577 : Tensor = aten::batch_norm(%concated_features.2, %4563, %4564, %4561, %4562, %4560, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.3 : Tensor = aten::relu_(%4577) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %4579 : Tensor = prim::GetAttr[name="weight"](%4551)
      %4580 : Tensor? = prim::GetAttr[name="bias"](%4551)
      %bottleneck_output.3 : Tensor = aten::conv2d(%result.3, %4579, %4580, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.3)
  %4585 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%4512)
  %4586 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%4512)
  %4587 : int = aten::dim(%bottleneck_output.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %4588 : bool = aten::ne(%4587, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%4588) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %4590 : str = aten::format(%14, %4587) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%4590) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %4591 : bool = prim::GetAttr[name="training"](%4586)
   = prim::If(%4591) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %4592 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4586)
      %4593 : Tensor = aten::add(%4592, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%4586, %4593)
      -> ()
    block1():
      -> ()
  %4594 : bool = prim::GetAttr[name="training"](%4586)
  %4595 : Tensor = prim::GetAttr[name="running_mean"](%4586)
  %4596 : Tensor = prim::GetAttr[name="running_var"](%4586)
  %4597 : Tensor = prim::GetAttr[name="weight"](%4586)
  %4598 : Tensor = prim::GetAttr[name="bias"](%4586)
   = prim::If(%4594) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %4599 : int[] = aten::size(%bottleneck_output.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.12 : int = aten::__getitem__(%4599, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %4601 : int = aten::len(%4599) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %4602 : int = aten::sub(%4601, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.13 : int = prim::Loop(%4602, %5, %size_prods.12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.4 : int, %size_prods.14 : int):
          %4606 : int = aten::add(%i.4, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %4607 : int = aten::__getitem__(%4599, %4606) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.15 : int = aten::mul(%size_prods.14, %4607) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.15)
      %4609 : bool = aten::eq(%size_prods.13, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%4609) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %4610 : str = aten::format(%7, %4599) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%4610) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %4611 : Tensor = aten::batch_norm(%bottleneck_output.1, %4597, %4598, %4595, %4596, %4594, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.4 : Tensor = aten::relu_(%4611) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %4613 : Tensor = prim::GetAttr[name="weight"](%4585)
  %4614 : Tensor? = prim::GetAttr[name="bias"](%4585)
  %new_features.4 : Tensor = aten::conv2d(%result.4, %4613, %4614, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %4619 : float = prim::GetAttr[name="drop_rate"](%4512)
  %4620 : bool = aten::gt(%4619, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.2 : Tensor = prim::If(%4620) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %4623 : bool = prim::GetAttr[name="training"](%4512)
      %4624 : bool = aten::lt(%4619, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %4625 : bool = prim::If(%4624) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %4626 : bool = aten::gt(%4619, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%4626)
       = prim::If(%4625) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %4627 : str = aten::format(%17, %4619) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%4627) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %4628 : Tensor = aten::dropout(%new_features.4, %4619, %4623) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%4628)
    block1():
      -> (%new_features.4)
  %4629 : Tensor[] = aten::append(%features.1, %new_features.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %4631 : bool = prim::GetAttr[name="memory_efficient"](%4513)
  %4632 : bool = prim::If(%4631) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %4633 : bool = prim::Uninitialized()
      %4634 : int = aten::len(%features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %4635 : bool = aten::gt(%4634, %6)
      %4636 : bool, %4637 : bool, %4638 : int = prim::Loop(%12, %4635, %10, %4633, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%4639 : int, %4640 : bool, %4641 : bool, %4642 : int):
          %tensor.3 : Tensor = aten::__getitem__(%features.1, %4642) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %4644 : bool = prim::requires_grad(%tensor.3)
          %4645 : bool, %4646 : bool = prim::If(%4644) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %4633)
          %4647 : int = aten::add(%4642, %19)
          %4648 : bool = aten::lt(%4647, %4634)
          %4649 : bool = aten::__and__(%4648, %4645)
          -> (%4649, %4644, %4646, %4647)
      %4650 : bool = prim::If(%4636)
        block0():
          -> (%4637)
        block1():
          -> (%10)
      -> (%4650)
    block1():
      -> (%10)
  %bottleneck_output.4 : Tensor = prim::If(%4632) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.3 : Tensor = aten::cat(%features.1, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %4653 : __torch__.torch.nn.modules.conv.___torch_mangle_48.Conv2d = prim::GetAttr[name="conv1"](%4513)
      %4654 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_47.BatchNorm2d = prim::GetAttr[name="norm1"](%4513)
      %4655 : int = aten::dim(%concated_features.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %4656 : bool = aten::ne(%4655, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%4656) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %4658 : str = aten::format(%14, %4655) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%4658) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %4659 : bool = prim::GetAttr[name="training"](%4654)
       = prim::If(%4659) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %4660 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4654)
          %4661 : Tensor = aten::add(%4660, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%4654, %4661)
          -> ()
        block1():
          -> ()
      %4662 : bool = prim::GetAttr[name="training"](%4654)
      %4663 : Tensor = prim::GetAttr[name="running_mean"](%4654)
      %4664 : Tensor = prim::GetAttr[name="running_var"](%4654)
      %4665 : Tensor = prim::GetAttr[name="weight"](%4654)
      %4666 : Tensor = prim::GetAttr[name="bias"](%4654)
       = prim::If(%4662) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %4667 : int[] = aten::size(%concated_features.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.16 : int = aten::__getitem__(%4667, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %4669 : int = aten::len(%4667) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %4670 : int = aten::sub(%4669, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.17 : int = prim::Loop(%4670, %5, %size_prods.16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.5 : int, %size_prods.18 : int):
              %4674 : int = aten::add(%i.5, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %4675 : int = aten::__getitem__(%4667, %4674) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.19 : int = aten::mul(%size_prods.18, %4675) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.19)
          %4677 : bool = aten::eq(%size_prods.17, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%4677) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %4678 : str = aten::format(%7, %4667) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%4678) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %4679 : Tensor = aten::batch_norm(%concated_features.3, %4665, %4666, %4663, %4664, %4662, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.5 : Tensor = aten::relu_(%4679) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %4681 : Tensor = prim::GetAttr[name="weight"](%4653)
      %4682 : Tensor? = prim::GetAttr[name="bias"](%4653)
      %bottleneck_output.5 : Tensor = aten::conv2d(%result.5, %4681, %4682, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.5)
  %4687 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%4513)
  %4688 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%4513)
  %4689 : int = aten::dim(%bottleneck_output.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %4690 : bool = aten::ne(%4689, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%4690) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %4692 : str = aten::format(%14, %4689) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%4692) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %4693 : bool = prim::GetAttr[name="training"](%4688)
   = prim::If(%4693) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %4694 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4688)
      %4695 : Tensor = aten::add(%4694, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%4688, %4695)
      -> ()
    block1():
      -> ()
  %4696 : bool = prim::GetAttr[name="training"](%4688)
  %4697 : Tensor = prim::GetAttr[name="running_mean"](%4688)
  %4698 : Tensor = prim::GetAttr[name="running_var"](%4688)
  %4699 : Tensor = prim::GetAttr[name="weight"](%4688)
  %4700 : Tensor = prim::GetAttr[name="bias"](%4688)
   = prim::If(%4696) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %4701 : int[] = aten::size(%bottleneck_output.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.20 : int = aten::__getitem__(%4701, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %4703 : int = aten::len(%4701) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %4704 : int = aten::sub(%4703, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.21 : int = prim::Loop(%4704, %5, %size_prods.20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.6 : int, %size_prods.22 : int):
          %4708 : int = aten::add(%i.6, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %4709 : int = aten::__getitem__(%4701, %4708) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.23 : int = aten::mul(%size_prods.22, %4709) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.23)
      %4711 : bool = aten::eq(%size_prods.21, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%4711) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %4712 : str = aten::format(%7, %4701) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%4712) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %4713 : Tensor = aten::batch_norm(%bottleneck_output.4, %4699, %4700, %4697, %4698, %4696, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.6 : Tensor = aten::relu_(%4713) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %4715 : Tensor = prim::GetAttr[name="weight"](%4687)
  %4716 : Tensor? = prim::GetAttr[name="bias"](%4687)
  %new_features.6 : Tensor = aten::conv2d(%result.6, %4715, %4716, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %4721 : float = prim::GetAttr[name="drop_rate"](%4513)
  %4722 : bool = aten::gt(%4721, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.3 : Tensor = prim::If(%4722) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %4725 : bool = prim::GetAttr[name="training"](%4513)
      %4726 : bool = aten::lt(%4721, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %4727 : bool = prim::If(%4726) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %4728 : bool = aten::gt(%4721, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%4728)
       = prim::If(%4727) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %4729 : str = aten::format(%17, %4721) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%4729) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %4730 : Tensor = aten::dropout(%new_features.6, %4721, %4725) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%4730)
    block1():
      -> (%new_features.6)
  %4731 : Tensor[] = aten::append(%features.1, %new_features.3) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %4733 : bool = prim::GetAttr[name="memory_efficient"](%4514)
  %4734 : bool = prim::If(%4733) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %4735 : bool = prim::Uninitialized()
      %4736 : int = aten::len(%features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %4737 : bool = aten::gt(%4736, %6)
      %4738 : bool, %4739 : bool, %4740 : int = prim::Loop(%12, %4737, %10, %4735, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%4741 : int, %4742 : bool, %4743 : bool, %4744 : int):
          %tensor.4 : Tensor = aten::__getitem__(%features.1, %4744) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %4746 : bool = prim::requires_grad(%tensor.4)
          %4747 : bool, %4748 : bool = prim::If(%4746) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %4735)
          %4749 : int = aten::add(%4744, %19)
          %4750 : bool = aten::lt(%4749, %4736)
          %4751 : bool = aten::__and__(%4750, %4747)
          -> (%4751, %4746, %4748, %4749)
      %4752 : bool = prim::If(%4738)
        block0():
          -> (%4739)
        block1():
          -> (%10)
      -> (%4752)
    block1():
      -> (%10)
  %bottleneck_output.6 : Tensor = prim::If(%4734) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.4 : Tensor = aten::cat(%features.1, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %4755 : __torch__.torch.nn.modules.conv.___torch_mangle_51.Conv2d = prim::GetAttr[name="conv1"](%4514)
      %4756 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_50.BatchNorm2d = prim::GetAttr[name="norm1"](%4514)
      %4757 : int = aten::dim(%concated_features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %4758 : bool = aten::ne(%4757, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%4758) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %4760 : str = aten::format(%14, %4757) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%4760) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %4761 : bool = prim::GetAttr[name="training"](%4756)
       = prim::If(%4761) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %4762 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4756)
          %4763 : Tensor = aten::add(%4762, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%4756, %4763)
          -> ()
        block1():
          -> ()
      %4764 : bool = prim::GetAttr[name="training"](%4756)
      %4765 : Tensor = prim::GetAttr[name="running_mean"](%4756)
      %4766 : Tensor = prim::GetAttr[name="running_var"](%4756)
      %4767 : Tensor = prim::GetAttr[name="weight"](%4756)
      %4768 : Tensor = prim::GetAttr[name="bias"](%4756)
       = prim::If(%4764) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %4769 : int[] = aten::size(%concated_features.4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.24 : int = aten::__getitem__(%4769, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %4771 : int = aten::len(%4769) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %4772 : int = aten::sub(%4771, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.25 : int = prim::Loop(%4772, %5, %size_prods.24) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.7 : int, %size_prods.26 : int):
              %4776 : int = aten::add(%i.7, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %4777 : int = aten::__getitem__(%4769, %4776) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.27 : int = aten::mul(%size_prods.26, %4777) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.27)
          %4779 : bool = aten::eq(%size_prods.25, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%4779) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %4780 : str = aten::format(%7, %4769) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%4780) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %4781 : Tensor = aten::batch_norm(%concated_features.4, %4767, %4768, %4765, %4766, %4764, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.7 : Tensor = aten::relu_(%4781) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %4783 : Tensor = prim::GetAttr[name="weight"](%4755)
      %4784 : Tensor? = prim::GetAttr[name="bias"](%4755)
      %bottleneck_output.7 : Tensor = aten::conv2d(%result.7, %4783, %4784, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.7)
  %4789 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%4514)
  %4790 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%4514)
  %4791 : int = aten::dim(%bottleneck_output.6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %4792 : bool = aten::ne(%4791, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%4792) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %4794 : str = aten::format(%14, %4791) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%4794) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %4795 : bool = prim::GetAttr[name="training"](%4790)
   = prim::If(%4795) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %4796 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4790)
      %4797 : Tensor = aten::add(%4796, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%4790, %4797)
      -> ()
    block1():
      -> ()
  %4798 : bool = prim::GetAttr[name="training"](%4790)
  %4799 : Tensor = prim::GetAttr[name="running_mean"](%4790)
  %4800 : Tensor = prim::GetAttr[name="running_var"](%4790)
  %4801 : Tensor = prim::GetAttr[name="weight"](%4790)
  %4802 : Tensor = prim::GetAttr[name="bias"](%4790)
   = prim::If(%4798) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %4803 : int[] = aten::size(%bottleneck_output.6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.28 : int = aten::__getitem__(%4803, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %4805 : int = aten::len(%4803) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %4806 : int = aten::sub(%4805, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.29 : int = prim::Loop(%4806, %5, %size_prods.28) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.8 : int, %size_prods.30 : int):
          %4810 : int = aten::add(%i.8, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %4811 : int = aten::__getitem__(%4803, %4810) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.31 : int = aten::mul(%size_prods.30, %4811) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.31)
      %4813 : bool = aten::eq(%size_prods.29, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%4813) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %4814 : str = aten::format(%7, %4803) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%4814) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %4815 : Tensor = aten::batch_norm(%bottleneck_output.6, %4801, %4802, %4799, %4800, %4798, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.8 : Tensor = aten::relu_(%4815) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %4817 : Tensor = prim::GetAttr[name="weight"](%4789)
  %4818 : Tensor? = prim::GetAttr[name="bias"](%4789)
  %new_features.8 : Tensor = aten::conv2d(%result.8, %4817, %4818, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %4823 : float = prim::GetAttr[name="drop_rate"](%4514)
  %4824 : bool = aten::gt(%4823, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.5 : Tensor = prim::If(%4824) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %4827 : bool = prim::GetAttr[name="training"](%4514)
      %4828 : bool = aten::lt(%4823, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %4829 : bool = prim::If(%4828) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %4830 : bool = aten::gt(%4823, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%4830)
       = prim::If(%4829) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %4831 : str = aten::format(%17, %4823) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%4831) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %4832 : Tensor = aten::dropout(%new_features.8, %4823, %4827) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%4832)
    block1():
      -> (%new_features.8)
  %4833 : Tensor[] = aten::append(%features.1, %new_features.5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %4835 : bool = prim::GetAttr[name="memory_efficient"](%4515)
  %4836 : bool = prim::If(%4835) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %4837 : bool = prim::Uninitialized()
      %4838 : int = aten::len(%features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %4839 : bool = aten::gt(%4838, %6)
      %4840 : bool, %4841 : bool, %4842 : int = prim::Loop(%12, %4839, %10, %4837, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%4843 : int, %4844 : bool, %4845 : bool, %4846 : int):
          %tensor.5 : Tensor = aten::__getitem__(%features.1, %4846) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %4848 : bool = prim::requires_grad(%tensor.5)
          %4849 : bool, %4850 : bool = prim::If(%4848) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %4837)
          %4851 : int = aten::add(%4846, %19)
          %4852 : bool = aten::lt(%4851, %4838)
          %4853 : bool = aten::__and__(%4852, %4849)
          -> (%4853, %4848, %4850, %4851)
      %4854 : bool = prim::If(%4840)
        block0():
          -> (%4841)
        block1():
          -> (%10)
      -> (%4854)
    block1():
      -> (%10)
  %bottleneck_output.8 : Tensor = prim::If(%4836) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.5 : Tensor = aten::cat(%features.1, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %4857 : __torch__.torch.nn.modules.conv.___torch_mangle_54.Conv2d = prim::GetAttr[name="conv1"](%4515)
      %4858 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_53.BatchNorm2d = prim::GetAttr[name="norm1"](%4515)
      %4859 : int = aten::dim(%concated_features.5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %4860 : bool = aten::ne(%4859, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%4860) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %4862 : str = aten::format(%14, %4859) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%4862) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %4863 : bool = prim::GetAttr[name="training"](%4858)
       = prim::If(%4863) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %4864 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4858)
          %4865 : Tensor = aten::add(%4864, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%4858, %4865)
          -> ()
        block1():
          -> ()
      %4866 : bool = prim::GetAttr[name="training"](%4858)
      %4867 : Tensor = prim::GetAttr[name="running_mean"](%4858)
      %4868 : Tensor = prim::GetAttr[name="running_var"](%4858)
      %4869 : Tensor = prim::GetAttr[name="weight"](%4858)
      %4870 : Tensor = prim::GetAttr[name="bias"](%4858)
       = prim::If(%4866) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %4871 : int[] = aten::size(%concated_features.5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.32 : int = aten::__getitem__(%4871, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %4873 : int = aten::len(%4871) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %4874 : int = aten::sub(%4873, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.33 : int = prim::Loop(%4874, %5, %size_prods.32) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.9 : int, %size_prods.34 : int):
              %4878 : int = aten::add(%i.9, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %4879 : int = aten::__getitem__(%4871, %4878) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.35 : int = aten::mul(%size_prods.34, %4879) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.35)
          %4881 : bool = aten::eq(%size_prods.33, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%4881) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %4882 : str = aten::format(%7, %4871) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%4882) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %4883 : Tensor = aten::batch_norm(%concated_features.5, %4869, %4870, %4867, %4868, %4866, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.9 : Tensor = aten::relu_(%4883) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %4885 : Tensor = prim::GetAttr[name="weight"](%4857)
      %4886 : Tensor? = prim::GetAttr[name="bias"](%4857)
      %bottleneck_output.9 : Tensor = aten::conv2d(%result.9, %4885, %4886, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.9)
  %4891 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%4515)
  %4892 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%4515)
  %4893 : int = aten::dim(%bottleneck_output.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %4894 : bool = aten::ne(%4893, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%4894) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %4896 : str = aten::format(%14, %4893) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%4896) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %4897 : bool = prim::GetAttr[name="training"](%4892)
   = prim::If(%4897) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %4898 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4892)
      %4899 : Tensor = aten::add(%4898, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%4892, %4899)
      -> ()
    block1():
      -> ()
  %4900 : bool = prim::GetAttr[name="training"](%4892)
  %4901 : Tensor = prim::GetAttr[name="running_mean"](%4892)
  %4902 : Tensor = prim::GetAttr[name="running_var"](%4892)
  %4903 : Tensor = prim::GetAttr[name="weight"](%4892)
  %4904 : Tensor = prim::GetAttr[name="bias"](%4892)
   = prim::If(%4900) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %4905 : int[] = aten::size(%bottleneck_output.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.36 : int = aten::__getitem__(%4905, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %4907 : int = aten::len(%4905) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %4908 : int = aten::sub(%4907, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.37 : int = prim::Loop(%4908, %5, %size_prods.36) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.10 : int, %size_prods.38 : int):
          %4912 : int = aten::add(%i.10, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %4913 : int = aten::__getitem__(%4905, %4912) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.39 : int = aten::mul(%size_prods.38, %4913) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.39)
      %4915 : bool = aten::eq(%size_prods.37, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%4915) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %4916 : str = aten::format(%7, %4905) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%4916) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %4917 : Tensor = aten::batch_norm(%bottleneck_output.8, %4903, %4904, %4901, %4902, %4900, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.10 : Tensor = aten::relu_(%4917) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %4919 : Tensor = prim::GetAttr[name="weight"](%4891)
  %4920 : Tensor? = prim::GetAttr[name="bias"](%4891)
  %new_features.10 : Tensor = aten::conv2d(%result.10, %4919, %4920, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %4925 : float = prim::GetAttr[name="drop_rate"](%4515)
  %4926 : bool = aten::gt(%4925, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.7 : Tensor = prim::If(%4926) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %4929 : bool = prim::GetAttr[name="training"](%4515)
      %4930 : bool = aten::lt(%4925, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %4931 : bool = prim::If(%4930) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %4932 : bool = aten::gt(%4925, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%4932)
       = prim::If(%4931) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %4933 : str = aten::format(%17, %4925) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%4933) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %4934 : Tensor = aten::dropout(%new_features.10, %4925, %4929) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%4934)
    block1():
      -> (%new_features.10)
  %4935 : Tensor[] = aten::append(%features.1, %new_features.7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %4937 : bool = prim::GetAttr[name="memory_efficient"](%4516)
  %4938 : bool = prim::If(%4937) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %4939 : bool = prim::Uninitialized()
      %4940 : int = aten::len(%features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %4941 : bool = aten::gt(%4940, %6)
      %4942 : bool, %4943 : bool, %4944 : int = prim::Loop(%12, %4941, %10, %4939, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%4945 : int, %4946 : bool, %4947 : bool, %4948 : int):
          %tensor.6 : Tensor = aten::__getitem__(%features.1, %4948) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %4950 : bool = prim::requires_grad(%tensor.6)
          %4951 : bool, %4952 : bool = prim::If(%4950) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %4939)
          %4953 : int = aten::add(%4948, %19)
          %4954 : bool = aten::lt(%4953, %4940)
          %4955 : bool = aten::__and__(%4954, %4951)
          -> (%4955, %4950, %4952, %4953)
      %4956 : bool = prim::If(%4942)
        block0():
          -> (%4943)
        block1():
          -> (%10)
      -> (%4956)
    block1():
      -> (%10)
  %bottleneck_output.10 : Tensor = prim::If(%4938) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.6 : Tensor = aten::cat(%features.1, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %4959 : __torch__.torch.nn.modules.conv.___torch_mangle_57.Conv2d = prim::GetAttr[name="conv1"](%4516)
      %4960 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_56.BatchNorm2d = prim::GetAttr[name="norm1"](%4516)
      %4961 : int = aten::dim(%concated_features.6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %4962 : bool = aten::ne(%4961, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%4962) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %4964 : str = aten::format(%14, %4961) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%4964) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %4965 : bool = prim::GetAttr[name="training"](%4960)
       = prim::If(%4965) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %4966 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4960)
          %4967 : Tensor = aten::add(%4966, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%4960, %4967)
          -> ()
        block1():
          -> ()
      %4968 : bool = prim::GetAttr[name="training"](%4960)
      %4969 : Tensor = prim::GetAttr[name="running_mean"](%4960)
      %4970 : Tensor = prim::GetAttr[name="running_var"](%4960)
      %4971 : Tensor = prim::GetAttr[name="weight"](%4960)
      %4972 : Tensor = prim::GetAttr[name="bias"](%4960)
       = prim::If(%4968) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %4973 : int[] = aten::size(%concated_features.6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.40 : int = aten::__getitem__(%4973, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %4975 : int = aten::len(%4973) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %4976 : int = aten::sub(%4975, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.41 : int = prim::Loop(%4976, %5, %size_prods.40) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.11 : int, %size_prods.42 : int):
              %4980 : int = aten::add(%i.11, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %4981 : int = aten::__getitem__(%4973, %4980) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.43 : int = aten::mul(%size_prods.42, %4981) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.43)
          %4983 : bool = aten::eq(%size_prods.41, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%4983) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %4984 : str = aten::format(%7, %4973) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%4984) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %4985 : Tensor = aten::batch_norm(%concated_features.6, %4971, %4972, %4969, %4970, %4968, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.11 : Tensor = aten::relu_(%4985) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %4987 : Tensor = prim::GetAttr[name="weight"](%4959)
      %4988 : Tensor? = prim::GetAttr[name="bias"](%4959)
      %bottleneck_output.11 : Tensor = aten::conv2d(%result.11, %4987, %4988, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.11)
  %4993 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%4516)
  %4994 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%4516)
  %4995 : int = aten::dim(%bottleneck_output.10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %4996 : bool = aten::ne(%4995, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%4996) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %4998 : str = aten::format(%14, %4995) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%4998) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %4999 : bool = prim::GetAttr[name="training"](%4994)
   = prim::If(%4999) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %5000 : Tensor = prim::GetAttr[name="num_batches_tracked"](%4994)
      %5001 : Tensor = aten::add(%5000, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%4994, %5001)
      -> ()
    block1():
      -> ()
  %5002 : bool = prim::GetAttr[name="training"](%4994)
  %5003 : Tensor = prim::GetAttr[name="running_mean"](%4994)
  %5004 : Tensor = prim::GetAttr[name="running_var"](%4994)
  %5005 : Tensor = prim::GetAttr[name="weight"](%4994)
  %5006 : Tensor = prim::GetAttr[name="bias"](%4994)
   = prim::If(%5002) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %5007 : int[] = aten::size(%bottleneck_output.10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.44 : int = aten::__getitem__(%5007, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %5009 : int = aten::len(%5007) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %5010 : int = aten::sub(%5009, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.45 : int = prim::Loop(%5010, %5, %size_prods.44) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.12 : int, %size_prods.46 : int):
          %5014 : int = aten::add(%i.12, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %5015 : int = aten::__getitem__(%5007, %5014) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.47 : int = aten::mul(%size_prods.46, %5015) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.47)
      %5017 : bool = aten::eq(%size_prods.45, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%5017) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %5018 : str = aten::format(%7, %5007) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%5018) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %5019 : Tensor = aten::batch_norm(%bottleneck_output.10, %5005, %5006, %5003, %5004, %5002, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.12 : Tensor = aten::relu_(%5019) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %5021 : Tensor = prim::GetAttr[name="weight"](%4993)
  %5022 : Tensor? = prim::GetAttr[name="bias"](%4993)
  %new_features.12 : Tensor = aten::conv2d(%result.12, %5021, %5022, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %5027 : float = prim::GetAttr[name="drop_rate"](%4516)
  %5028 : bool = aten::gt(%5027, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.9 : Tensor = prim::If(%5028) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %5031 : bool = prim::GetAttr[name="training"](%4516)
      %5032 : bool = aten::lt(%5027, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %5033 : bool = prim::If(%5032) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %5034 : bool = aten::gt(%5027, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%5034)
       = prim::If(%5033) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %5035 : str = aten::format(%17, %5027) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%5035) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %5036 : Tensor = aten::dropout(%new_features.12, %5027, %5031) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%5036)
    block1():
      -> (%new_features.12)
  %5037 : Tensor[] = aten::append(%features.1, %new_features.9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %5039 : bool = prim::GetAttr[name="memory_efficient"](%4517)
  %5040 : bool = prim::If(%5039) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %5041 : bool = prim::Uninitialized()
      %5042 : int = aten::len(%features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %5043 : bool = aten::gt(%5042, %6)
      %5044 : bool, %5045 : bool, %5046 : int = prim::Loop(%12, %5043, %10, %5041, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%5047 : int, %5048 : bool, %5049 : bool, %5050 : int):
          %tensor.7 : Tensor = aten::__getitem__(%features.1, %5050) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %5052 : bool = prim::requires_grad(%tensor.7)
          %5053 : bool, %5054 : bool = prim::If(%5052) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %5041)
          %5055 : int = aten::add(%5050, %19)
          %5056 : bool = aten::lt(%5055, %5042)
          %5057 : bool = aten::__and__(%5056, %5053)
          -> (%5057, %5052, %5054, %5055)
      %5058 : bool = prim::If(%5044)
        block0():
          -> (%5045)
        block1():
          -> (%10)
      -> (%5058)
    block1():
      -> (%10)
  %bottleneck_output.12 : Tensor = prim::If(%5040) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.7 : Tensor = aten::cat(%features.1, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %5061 : __torch__.torch.nn.modules.conv.___torch_mangle_60.Conv2d = prim::GetAttr[name="conv1"](%4517)
      %5062 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_59.BatchNorm2d = prim::GetAttr[name="norm1"](%4517)
      %5063 : int = aten::dim(%concated_features.7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %5064 : bool = aten::ne(%5063, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%5064) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %5066 : str = aten::format(%14, %5063) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%5066) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %5067 : bool = prim::GetAttr[name="training"](%5062)
       = prim::If(%5067) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %5068 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5062)
          %5069 : Tensor = aten::add(%5068, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%5062, %5069)
          -> ()
        block1():
          -> ()
      %5070 : bool = prim::GetAttr[name="training"](%5062)
      %5071 : Tensor = prim::GetAttr[name="running_mean"](%5062)
      %5072 : Tensor = prim::GetAttr[name="running_var"](%5062)
      %5073 : Tensor = prim::GetAttr[name="weight"](%5062)
      %5074 : Tensor = prim::GetAttr[name="bias"](%5062)
       = prim::If(%5070) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %5075 : int[] = aten::size(%concated_features.7) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.48 : int = aten::__getitem__(%5075, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %5077 : int = aten::len(%5075) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %5078 : int = aten::sub(%5077, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.49 : int = prim::Loop(%5078, %5, %size_prods.48) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.13 : int, %size_prods.50 : int):
              %5082 : int = aten::add(%i.13, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %5083 : int = aten::__getitem__(%5075, %5082) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.51 : int = aten::mul(%size_prods.50, %5083) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.51)
          %5085 : bool = aten::eq(%size_prods.49, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%5085) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %5086 : str = aten::format(%7, %5075) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%5086) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %5087 : Tensor = aten::batch_norm(%concated_features.7, %5073, %5074, %5071, %5072, %5070, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.13 : Tensor = aten::relu_(%5087) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %5089 : Tensor = prim::GetAttr[name="weight"](%5061)
      %5090 : Tensor? = prim::GetAttr[name="bias"](%5061)
      %bottleneck_output.13 : Tensor = aten::conv2d(%result.13, %5089, %5090, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.13)
  %5095 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%4517)
  %5096 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%4517)
  %5097 : int = aten::dim(%bottleneck_output.12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %5098 : bool = aten::ne(%5097, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%5098) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %5100 : str = aten::format(%14, %5097) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%5100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %5101 : bool = prim::GetAttr[name="training"](%5096)
   = prim::If(%5101) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %5102 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5096)
      %5103 : Tensor = aten::add(%5102, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%5096, %5103)
      -> ()
    block1():
      -> ()
  %5104 : bool = prim::GetAttr[name="training"](%5096)
  %5105 : Tensor = prim::GetAttr[name="running_mean"](%5096)
  %5106 : Tensor = prim::GetAttr[name="running_var"](%5096)
  %5107 : Tensor = prim::GetAttr[name="weight"](%5096)
  %5108 : Tensor = prim::GetAttr[name="bias"](%5096)
   = prim::If(%5104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %5109 : int[] = aten::size(%bottleneck_output.12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.52 : int = aten::__getitem__(%5109, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %5111 : int = aten::len(%5109) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %5112 : int = aten::sub(%5111, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.53 : int = prim::Loop(%5112, %5, %size_prods.52) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.14 : int, %size_prods.54 : int):
          %5116 : int = aten::add(%i.14, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %5117 : int = aten::__getitem__(%5109, %5116) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.55 : int = aten::mul(%size_prods.54, %5117) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.55)
      %5119 : bool = aten::eq(%size_prods.53, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%5119) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %5120 : str = aten::format(%7, %5109) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%5120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %5121 : Tensor = aten::batch_norm(%bottleneck_output.12, %5107, %5108, %5105, %5106, %5104, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.14 : Tensor = aten::relu_(%5121) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %5123 : Tensor = prim::GetAttr[name="weight"](%5095)
  %5124 : Tensor? = prim::GetAttr[name="bias"](%5095)
  %new_features.14 : Tensor = aten::conv2d(%result.14, %5123, %5124, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %5129 : float = prim::GetAttr[name="drop_rate"](%4517)
  %5130 : bool = aten::gt(%5129, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.11 : Tensor = prim::If(%5130) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %5133 : bool = prim::GetAttr[name="training"](%4517)
      %5134 : bool = aten::lt(%5129, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %5135 : bool = prim::If(%5134) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %5136 : bool = aten::gt(%5129, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%5136)
       = prim::If(%5135) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %5137 : str = aten::format(%17, %5129) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%5137) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %5138 : Tensor = aten::dropout(%new_features.14, %5129, %5133) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%5138)
    block1():
      -> (%new_features.14)
  %5139 : Tensor[] = aten::append(%features.1, %new_features.11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %5141 : bool = prim::GetAttr[name="memory_efficient"](%4518)
  %5142 : bool = prim::If(%5141) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %5143 : bool = prim::Uninitialized()
      %5144 : int = aten::len(%features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %5145 : bool = aten::gt(%5144, %6)
      %5146 : bool, %5147 : bool, %5148 : int = prim::Loop(%12, %5145, %10, %5143, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%5149 : int, %5150 : bool, %5151 : bool, %5152 : int):
          %tensor.8 : Tensor = aten::__getitem__(%features.1, %5152) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %5154 : bool = prim::requires_grad(%tensor.8)
          %5155 : bool, %5156 : bool = prim::If(%5154) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %5143)
          %5157 : int = aten::add(%5152, %19)
          %5158 : bool = aten::lt(%5157, %5144)
          %5159 : bool = aten::__and__(%5158, %5155)
          -> (%5159, %5154, %5156, %5157)
      %5160 : bool = prim::If(%5146)
        block0():
          -> (%5147)
        block1():
          -> (%10)
      -> (%5160)
    block1():
      -> (%10)
  %bottleneck_output.14 : Tensor = prim::If(%5142) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.8 : Tensor = aten::cat(%features.1, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %5163 : __torch__.torch.nn.modules.conv.___torch_mangle_63.Conv2d = prim::GetAttr[name="conv1"](%4518)
      %5164 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_62.BatchNorm2d = prim::GetAttr[name="norm1"](%4518)
      %5165 : int = aten::dim(%concated_features.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %5166 : bool = aten::ne(%5165, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%5166) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %5168 : str = aten::format(%14, %5165) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%5168) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %5169 : bool = prim::GetAttr[name="training"](%5164)
       = prim::If(%5169) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %5170 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5164)
          %5171 : Tensor = aten::add(%5170, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%5164, %5171)
          -> ()
        block1():
          -> ()
      %5172 : bool = prim::GetAttr[name="training"](%5164)
      %5173 : Tensor = prim::GetAttr[name="running_mean"](%5164)
      %5174 : Tensor = prim::GetAttr[name="running_var"](%5164)
      %5175 : Tensor = prim::GetAttr[name="weight"](%5164)
      %5176 : Tensor = prim::GetAttr[name="bias"](%5164)
       = prim::If(%5172) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %5177 : int[] = aten::size(%concated_features.8) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.56 : int = aten::__getitem__(%5177, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %5179 : int = aten::len(%5177) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %5180 : int = aten::sub(%5179, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.57 : int = prim::Loop(%5180, %5, %size_prods.56) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.15 : int, %size_prods.58 : int):
              %5184 : int = aten::add(%i.15, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %5185 : int = aten::__getitem__(%5177, %5184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.59 : int = aten::mul(%size_prods.58, %5185) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.59)
          %5187 : bool = aten::eq(%size_prods.57, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%5187) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %5188 : str = aten::format(%7, %5177) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%5188) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %5189 : Tensor = aten::batch_norm(%concated_features.8, %5175, %5176, %5173, %5174, %5172, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.15 : Tensor = aten::relu_(%5189) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %5191 : Tensor = prim::GetAttr[name="weight"](%5163)
      %5192 : Tensor? = prim::GetAttr[name="bias"](%5163)
      %bottleneck_output.15 : Tensor = aten::conv2d(%result.15, %5191, %5192, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.15)
  %5197 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%4518)
  %5198 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%4518)
  %5199 : int = aten::dim(%bottleneck_output.14) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %5200 : bool = aten::ne(%5199, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%5200) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %5202 : str = aten::format(%14, %5199) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%5202) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %5203 : bool = prim::GetAttr[name="training"](%5198)
   = prim::If(%5203) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %5204 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5198)
      %5205 : Tensor = aten::add(%5204, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%5198, %5205)
      -> ()
    block1():
      -> ()
  %5206 : bool = prim::GetAttr[name="training"](%5198)
  %5207 : Tensor = prim::GetAttr[name="running_mean"](%5198)
  %5208 : Tensor = prim::GetAttr[name="running_var"](%5198)
  %5209 : Tensor = prim::GetAttr[name="weight"](%5198)
  %5210 : Tensor = prim::GetAttr[name="bias"](%5198)
   = prim::If(%5206) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %5211 : int[] = aten::size(%bottleneck_output.14) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.60 : int = aten::__getitem__(%5211, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %5213 : int = aten::len(%5211) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %5214 : int = aten::sub(%5213, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.61 : int = prim::Loop(%5214, %5, %size_prods.60) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.16 : int, %size_prods.62 : int):
          %5218 : int = aten::add(%i.16, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %5219 : int = aten::__getitem__(%5211, %5218) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.63 : int = aten::mul(%size_prods.62, %5219) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.63)
      %5221 : bool = aten::eq(%size_prods.61, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%5221) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %5222 : str = aten::format(%7, %5211) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%5222) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %5223 : Tensor = aten::batch_norm(%bottleneck_output.14, %5209, %5210, %5207, %5208, %5206, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.16 : Tensor = aten::relu_(%5223) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %5225 : Tensor = prim::GetAttr[name="weight"](%5197)
  %5226 : Tensor? = prim::GetAttr[name="bias"](%5197)
  %new_features.16 : Tensor = aten::conv2d(%result.16, %5225, %5226, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %5231 : float = prim::GetAttr[name="drop_rate"](%4518)
  %5232 : bool = aten::gt(%5231, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.13 : Tensor = prim::If(%5232) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %5235 : bool = prim::GetAttr[name="training"](%4518)
      %5236 : bool = aten::lt(%5231, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %5237 : bool = prim::If(%5236) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %5238 : bool = aten::gt(%5231, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%5238)
       = prim::If(%5237) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %5239 : str = aten::format(%17, %5231) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%5239) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %5240 : Tensor = aten::dropout(%new_features.16, %5231, %5235) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%5240)
    block1():
      -> (%new_features.16)
  %5241 : Tensor[] = aten::append(%features.1, %new_features.13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %5243 : bool = prim::GetAttr[name="memory_efficient"](%4519)
  %5244 : bool = prim::If(%5243) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %5245 : bool = prim::Uninitialized()
      %5246 : int = aten::len(%features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %5247 : bool = aten::gt(%5246, %6)
      %5248 : bool, %5249 : bool, %5250 : int = prim::Loop(%12, %5247, %10, %5245, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%5251 : int, %5252 : bool, %5253 : bool, %5254 : int):
          %tensor.9 : Tensor = aten::__getitem__(%features.1, %5254) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %5256 : bool = prim::requires_grad(%tensor.9)
          %5257 : bool, %5258 : bool = prim::If(%5256) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %5245)
          %5259 : int = aten::add(%5254, %19)
          %5260 : bool = aten::lt(%5259, %5246)
          %5261 : bool = aten::__and__(%5260, %5257)
          -> (%5261, %5256, %5258, %5259)
      %5262 : bool = prim::If(%5248)
        block0():
          -> (%5249)
        block1():
          -> (%10)
      -> (%5262)
    block1():
      -> (%10)
  %bottleneck_output.16 : Tensor = prim::If(%5244) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.9 : Tensor = aten::cat(%features.1, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %5265 : __torch__.torch.nn.modules.conv.___torch_mangle_66.Conv2d = prim::GetAttr[name="conv1"](%4519)
      %5266 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_65.BatchNorm2d = prim::GetAttr[name="norm1"](%4519)
      %5267 : int = aten::dim(%concated_features.9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %5268 : bool = aten::ne(%5267, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%5268) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %5270 : str = aten::format(%14, %5267) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%5270) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %5271 : bool = prim::GetAttr[name="training"](%5266)
       = prim::If(%5271) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %5272 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5266)
          %5273 : Tensor = aten::add(%5272, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%5266, %5273)
          -> ()
        block1():
          -> ()
      %5274 : bool = prim::GetAttr[name="training"](%5266)
      %5275 : Tensor = prim::GetAttr[name="running_mean"](%5266)
      %5276 : Tensor = prim::GetAttr[name="running_var"](%5266)
      %5277 : Tensor = prim::GetAttr[name="weight"](%5266)
      %5278 : Tensor = prim::GetAttr[name="bias"](%5266)
       = prim::If(%5274) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %5279 : int[] = aten::size(%concated_features.9) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.64 : int = aten::__getitem__(%5279, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %5281 : int = aten::len(%5279) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %5282 : int = aten::sub(%5281, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.65 : int = prim::Loop(%5282, %5, %size_prods.64) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.17 : int, %size_prods.66 : int):
              %5286 : int = aten::add(%i.17, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %5287 : int = aten::__getitem__(%5279, %5286) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.67 : int = aten::mul(%size_prods.66, %5287) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.67)
          %5289 : bool = aten::eq(%size_prods.65, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%5289) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %5290 : str = aten::format(%7, %5279) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%5290) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %5291 : Tensor = aten::batch_norm(%concated_features.9, %5277, %5278, %5275, %5276, %5274, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.17 : Tensor = aten::relu_(%5291) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %5293 : Tensor = prim::GetAttr[name="weight"](%5265)
      %5294 : Tensor? = prim::GetAttr[name="bias"](%5265)
      %bottleneck_output.17 : Tensor = aten::conv2d(%result.17, %5293, %5294, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.17)
  %5299 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%4519)
  %5300 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%4519)
  %5301 : int = aten::dim(%bottleneck_output.16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %5302 : bool = aten::ne(%5301, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%5302) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %5304 : str = aten::format(%14, %5301) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%5304) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %5305 : bool = prim::GetAttr[name="training"](%5300)
   = prim::If(%5305) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %5306 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5300)
      %5307 : Tensor = aten::add(%5306, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%5300, %5307)
      -> ()
    block1():
      -> ()
  %5308 : bool = prim::GetAttr[name="training"](%5300)
  %5309 : Tensor = prim::GetAttr[name="running_mean"](%5300)
  %5310 : Tensor = prim::GetAttr[name="running_var"](%5300)
  %5311 : Tensor = prim::GetAttr[name="weight"](%5300)
  %5312 : Tensor = prim::GetAttr[name="bias"](%5300)
   = prim::If(%5308) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %5313 : int[] = aten::size(%bottleneck_output.16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.68 : int = aten::__getitem__(%5313, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %5315 : int = aten::len(%5313) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %5316 : int = aten::sub(%5315, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.69 : int = prim::Loop(%5316, %5, %size_prods.68) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.18 : int, %size_prods.70 : int):
          %5320 : int = aten::add(%i.18, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %5321 : int = aten::__getitem__(%5313, %5320) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.71 : int = aten::mul(%size_prods.70, %5321) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.71)
      %5323 : bool = aten::eq(%size_prods.69, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%5323) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %5324 : str = aten::format(%7, %5313) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%5324) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %5325 : Tensor = aten::batch_norm(%bottleneck_output.16, %5311, %5312, %5309, %5310, %5308, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.18 : Tensor = aten::relu_(%5325) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %5327 : Tensor = prim::GetAttr[name="weight"](%5299)
  %5328 : Tensor? = prim::GetAttr[name="bias"](%5299)
  %new_features.18 : Tensor = aten::conv2d(%result.18, %5327, %5328, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %5333 : float = prim::GetAttr[name="drop_rate"](%4519)
  %5334 : bool = aten::gt(%5333, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.15 : Tensor = prim::If(%5334) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %5337 : bool = prim::GetAttr[name="training"](%4519)
      %5338 : bool = aten::lt(%5333, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %5339 : bool = prim::If(%5338) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %5340 : bool = aten::gt(%5333, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%5340)
       = prim::If(%5339) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %5341 : str = aten::format(%17, %5333) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%5341) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %5342 : Tensor = aten::dropout(%new_features.18, %5333, %5337) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%5342)
    block1():
      -> (%new_features.18)
  %5343 : Tensor[] = aten::append(%features.1, %new_features.15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %5345 : bool = prim::GetAttr[name="memory_efficient"](%4520)
  %5346 : bool = prim::If(%5345) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %5347 : bool = prim::Uninitialized()
      %5348 : int = aten::len(%features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %5349 : bool = aten::gt(%5348, %6)
      %5350 : bool, %5351 : bool, %5352 : int = prim::Loop(%12, %5349, %10, %5347, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%5353 : int, %5354 : bool, %5355 : bool, %5356 : int):
          %tensor.10 : Tensor = aten::__getitem__(%features.1, %5356) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %5358 : bool = prim::requires_grad(%tensor.10)
          %5359 : bool, %5360 : bool = prim::If(%5358) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %5347)
          %5361 : int = aten::add(%5356, %19)
          %5362 : bool = aten::lt(%5361, %5348)
          %5363 : bool = aten::__and__(%5362, %5359)
          -> (%5363, %5358, %5360, %5361)
      %5364 : bool = prim::If(%5350)
        block0():
          -> (%5351)
        block1():
          -> (%10)
      -> (%5364)
    block1():
      -> (%10)
  %bottleneck_output.18 : Tensor = prim::If(%5346) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.10 : Tensor = aten::cat(%features.1, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %5367 : __torch__.torch.nn.modules.conv.___torch_mangle_69.Conv2d = prim::GetAttr[name="conv1"](%4520)
      %5368 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_68.BatchNorm2d = prim::GetAttr[name="norm1"](%4520)
      %5369 : int = aten::dim(%concated_features.10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %5370 : bool = aten::ne(%5369, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%5370) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %5372 : str = aten::format(%14, %5369) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%5372) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %5373 : bool = prim::GetAttr[name="training"](%5368)
       = prim::If(%5373) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %5374 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5368)
          %5375 : Tensor = aten::add(%5374, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%5368, %5375)
          -> ()
        block1():
          -> ()
      %5376 : bool = prim::GetAttr[name="training"](%5368)
      %5377 : Tensor = prim::GetAttr[name="running_mean"](%5368)
      %5378 : Tensor = prim::GetAttr[name="running_var"](%5368)
      %5379 : Tensor = prim::GetAttr[name="weight"](%5368)
      %5380 : Tensor = prim::GetAttr[name="bias"](%5368)
       = prim::If(%5376) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %5381 : int[] = aten::size(%concated_features.10) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.72 : int = aten::__getitem__(%5381, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %5383 : int = aten::len(%5381) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %5384 : int = aten::sub(%5383, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.73 : int = prim::Loop(%5384, %5, %size_prods.72) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.19 : int, %size_prods.74 : int):
              %5388 : int = aten::add(%i.19, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %5389 : int = aten::__getitem__(%5381, %5388) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.75 : int = aten::mul(%size_prods.74, %5389) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.75)
          %5391 : bool = aten::eq(%size_prods.73, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%5391) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %5392 : str = aten::format(%7, %5381) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%5392) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %5393 : Tensor = aten::batch_norm(%concated_features.10, %5379, %5380, %5377, %5378, %5376, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.19 : Tensor = aten::relu_(%5393) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %5395 : Tensor = prim::GetAttr[name="weight"](%5367)
      %5396 : Tensor? = prim::GetAttr[name="bias"](%5367)
      %bottleneck_output.19 : Tensor = aten::conv2d(%result.19, %5395, %5396, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.19)
  %5401 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%4520)
  %5402 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%4520)
  %5403 : int = aten::dim(%bottleneck_output.18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %5404 : bool = aten::ne(%5403, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%5404) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %5406 : str = aten::format(%14, %5403) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%5406) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %5407 : bool = prim::GetAttr[name="training"](%5402)
   = prim::If(%5407) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %5408 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5402)
      %5409 : Tensor = aten::add(%5408, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%5402, %5409)
      -> ()
    block1():
      -> ()
  %5410 : bool = prim::GetAttr[name="training"](%5402)
  %5411 : Tensor = prim::GetAttr[name="running_mean"](%5402)
  %5412 : Tensor = prim::GetAttr[name="running_var"](%5402)
  %5413 : Tensor = prim::GetAttr[name="weight"](%5402)
  %5414 : Tensor = prim::GetAttr[name="bias"](%5402)
   = prim::If(%5410) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %5415 : int[] = aten::size(%bottleneck_output.18) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.76 : int = aten::__getitem__(%5415, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %5417 : int = aten::len(%5415) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %5418 : int = aten::sub(%5417, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.77 : int = prim::Loop(%5418, %5, %size_prods.76) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.20 : int, %size_prods.78 : int):
          %5422 : int = aten::add(%i.20, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %5423 : int = aten::__getitem__(%5415, %5422) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.79 : int = aten::mul(%size_prods.78, %5423) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.79)
      %5425 : bool = aten::eq(%size_prods.77, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%5425) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %5426 : str = aten::format(%7, %5415) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%5426) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %5427 : Tensor = aten::batch_norm(%bottleneck_output.18, %5413, %5414, %5411, %5412, %5410, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.20 : Tensor = aten::relu_(%5427) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %5429 : Tensor = prim::GetAttr[name="weight"](%5401)
  %5430 : Tensor? = prim::GetAttr[name="bias"](%5401)
  %new_features.20 : Tensor = aten::conv2d(%result.20, %5429, %5430, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %5435 : float = prim::GetAttr[name="drop_rate"](%4520)
  %5436 : bool = aten::gt(%5435, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.17 : Tensor = prim::If(%5436) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %5439 : bool = prim::GetAttr[name="training"](%4520)
      %5440 : bool = aten::lt(%5435, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %5441 : bool = prim::If(%5440) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %5442 : bool = aten::gt(%5435, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%5442)
       = prim::If(%5441) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %5443 : str = aten::format(%17, %5435) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%5443) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %5444 : Tensor = aten::dropout(%new_features.20, %5435, %5439) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%5444)
    block1():
      -> (%new_features.20)
  %5445 : Tensor[] = aten::append(%features.1, %new_features.17) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %5447 : bool = prim::GetAttr[name="memory_efficient"](%4521)
  %5448 : bool = prim::If(%5447) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %5449 : bool = prim::Uninitialized()
      %5450 : int = aten::len(%features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %5451 : bool = aten::gt(%5450, %6)
      %5452 : bool, %5453 : bool, %5454 : int = prim::Loop(%12, %5451, %10, %5449, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%5455 : int, %5456 : bool, %5457 : bool, %5458 : int):
          %tensor.11 : Tensor = aten::__getitem__(%features.1, %5458) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %5460 : bool = prim::requires_grad(%tensor.11)
          %5461 : bool, %5462 : bool = prim::If(%5460) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %5449)
          %5463 : int = aten::add(%5458, %19)
          %5464 : bool = aten::lt(%5463, %5450)
          %5465 : bool = aten::__and__(%5464, %5461)
          -> (%5465, %5460, %5462, %5463)
      %5466 : bool = prim::If(%5452)
        block0():
          -> (%5453)
        block1():
          -> (%10)
      -> (%5466)
    block1():
      -> (%10)
  %bottleneck_output.20 : Tensor = prim::If(%5448) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.11 : Tensor = aten::cat(%features.1, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %5469 : __torch__.torch.nn.modules.conv.___torch_mangle_72.Conv2d = prim::GetAttr[name="conv1"](%4521)
      %5470 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_71.BatchNorm2d = prim::GetAttr[name="norm1"](%4521)
      %5471 : int = aten::dim(%concated_features.11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %5472 : bool = aten::ne(%5471, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%5472) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %5474 : str = aten::format(%14, %5471) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%5474) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %5475 : bool = prim::GetAttr[name="training"](%5470)
       = prim::If(%5475) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %5476 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5470)
          %5477 : Tensor = aten::add(%5476, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%5470, %5477)
          -> ()
        block1():
          -> ()
      %5478 : bool = prim::GetAttr[name="training"](%5470)
      %5479 : Tensor = prim::GetAttr[name="running_mean"](%5470)
      %5480 : Tensor = prim::GetAttr[name="running_var"](%5470)
      %5481 : Tensor = prim::GetAttr[name="weight"](%5470)
      %5482 : Tensor = prim::GetAttr[name="bias"](%5470)
       = prim::If(%5478) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %5483 : int[] = aten::size(%concated_features.11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.80 : int = aten::__getitem__(%5483, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %5485 : int = aten::len(%5483) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %5486 : int = aten::sub(%5485, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.81 : int = prim::Loop(%5486, %5, %size_prods.80) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.21 : int, %size_prods.82 : int):
              %5490 : int = aten::add(%i.21, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %5491 : int = aten::__getitem__(%5483, %5490) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.83 : int = aten::mul(%size_prods.82, %5491) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.83)
          %5493 : bool = aten::eq(%size_prods.81, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%5493) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %5494 : str = aten::format(%7, %5483) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%5494) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %5495 : Tensor = aten::batch_norm(%concated_features.11, %5481, %5482, %5479, %5480, %5478, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.21 : Tensor = aten::relu_(%5495) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %5497 : Tensor = prim::GetAttr[name="weight"](%5469)
      %5498 : Tensor? = prim::GetAttr[name="bias"](%5469)
      %bottleneck_output.21 : Tensor = aten::conv2d(%result.21, %5497, %5498, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.21)
  %5503 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%4521)
  %5504 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%4521)
  %5505 : int = aten::dim(%bottleneck_output.20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %5506 : bool = aten::ne(%5505, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%5506) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %5508 : str = aten::format(%14, %5505) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%5508) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %5509 : bool = prim::GetAttr[name="training"](%5504)
   = prim::If(%5509) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %5510 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5504)
      %5511 : Tensor = aten::add(%5510, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%5504, %5511)
      -> ()
    block1():
      -> ()
  %5512 : bool = prim::GetAttr[name="training"](%5504)
  %5513 : Tensor = prim::GetAttr[name="running_mean"](%5504)
  %5514 : Tensor = prim::GetAttr[name="running_var"](%5504)
  %5515 : Tensor = prim::GetAttr[name="weight"](%5504)
  %5516 : Tensor = prim::GetAttr[name="bias"](%5504)
   = prim::If(%5512) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %5517 : int[] = aten::size(%bottleneck_output.20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.84 : int = aten::__getitem__(%5517, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %5519 : int = aten::len(%5517) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %5520 : int = aten::sub(%5519, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.85 : int = prim::Loop(%5520, %5, %size_prods.84) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.22 : int, %size_prods.86 : int):
          %5524 : int = aten::add(%i.22, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %5525 : int = aten::__getitem__(%5517, %5524) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.87 : int = aten::mul(%size_prods.86, %5525) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.87)
      %5527 : bool = aten::eq(%size_prods.85, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%5527) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %5528 : str = aten::format(%7, %5517) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%5528) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %5529 : Tensor = aten::batch_norm(%bottleneck_output.20, %5515, %5516, %5513, %5514, %5512, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.22 : Tensor = aten::relu_(%5529) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %5531 : Tensor = prim::GetAttr[name="weight"](%5503)
  %5532 : Tensor? = prim::GetAttr[name="bias"](%5503)
  %new_features.22 : Tensor = aten::conv2d(%result.22, %5531, %5532, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %5537 : float = prim::GetAttr[name="drop_rate"](%4521)
  %5538 : bool = aten::gt(%5537, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.19 : Tensor = prim::If(%5538) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %5541 : bool = prim::GetAttr[name="training"](%4521)
      %5542 : bool = aten::lt(%5537, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %5543 : bool = prim::If(%5542) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %5544 : bool = aten::gt(%5537, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%5544)
       = prim::If(%5543) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %5545 : str = aten::format(%17, %5537) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%5545) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %5546 : Tensor = aten::dropout(%new_features.22, %5537, %5541) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%5546)
    block1():
      -> (%new_features.22)
  %5547 : Tensor[] = aten::append(%features.1, %new_features.19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %5549 : bool = prim::GetAttr[name="memory_efficient"](%4522)
  %5550 : bool = prim::If(%5549) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %5551 : bool = prim::Uninitialized()
      %5552 : int = aten::len(%features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %5553 : bool = aten::gt(%5552, %6)
      %5554 : bool, %5555 : bool, %5556 : int = prim::Loop(%12, %5553, %10, %5551, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%5557 : int, %5558 : bool, %5559 : bool, %5560 : int):
          %tensor.12 : Tensor = aten::__getitem__(%features.1, %5560) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %5562 : bool = prim::requires_grad(%tensor.12)
          %5563 : bool, %5564 : bool = prim::If(%5562) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %5551)
          %5565 : int = aten::add(%5560, %19)
          %5566 : bool = aten::lt(%5565, %5552)
          %5567 : bool = aten::__and__(%5566, %5563)
          -> (%5567, %5562, %5564, %5565)
      %5568 : bool = prim::If(%5554)
        block0():
          -> (%5555)
        block1():
          -> (%10)
      -> (%5568)
    block1():
      -> (%10)
  %bottleneck_output.22 : Tensor = prim::If(%5550) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.12 : Tensor = aten::cat(%features.1, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %5571 : __torch__.torch.nn.modules.conv.___torch_mangle_75.Conv2d = prim::GetAttr[name="conv1"](%4522)
      %5572 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_74.BatchNorm2d = prim::GetAttr[name="norm1"](%4522)
      %5573 : int = aten::dim(%concated_features.12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %5574 : bool = aten::ne(%5573, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%5574) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %5576 : str = aten::format(%14, %5573) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%5576) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %5577 : bool = prim::GetAttr[name="training"](%5572)
       = prim::If(%5577) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %5578 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5572)
          %5579 : Tensor = aten::add(%5578, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%5572, %5579)
          -> ()
        block1():
          -> ()
      %5580 : bool = prim::GetAttr[name="training"](%5572)
      %5581 : Tensor = prim::GetAttr[name="running_mean"](%5572)
      %5582 : Tensor = prim::GetAttr[name="running_var"](%5572)
      %5583 : Tensor = prim::GetAttr[name="weight"](%5572)
      %5584 : Tensor = prim::GetAttr[name="bias"](%5572)
       = prim::If(%5580) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %5585 : int[] = aten::size(%concated_features.12) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.88 : int = aten::__getitem__(%5585, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %5587 : int = aten::len(%5585) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %5588 : int = aten::sub(%5587, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.89 : int = prim::Loop(%5588, %5, %size_prods.88) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.23 : int, %size_prods.90 : int):
              %5592 : int = aten::add(%i.23, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %5593 : int = aten::__getitem__(%5585, %5592) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.91 : int = aten::mul(%size_prods.90, %5593) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.91)
          %5595 : bool = aten::eq(%size_prods.89, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%5595) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %5596 : str = aten::format(%7, %5585) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%5596) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %5597 : Tensor = aten::batch_norm(%concated_features.12, %5583, %5584, %5581, %5582, %5580, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.23 : Tensor = aten::relu_(%5597) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %5599 : Tensor = prim::GetAttr[name="weight"](%5571)
      %5600 : Tensor? = prim::GetAttr[name="bias"](%5571)
      %bottleneck_output.23 : Tensor = aten::conv2d(%result.23, %5599, %5600, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.23)
  %5605 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%4522)
  %5606 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%4522)
  %5607 : int = aten::dim(%bottleneck_output.22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %5608 : bool = aten::ne(%5607, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%5608) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %5610 : str = aten::format(%14, %5607) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%5610) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %5611 : bool = prim::GetAttr[name="training"](%5606)
   = prim::If(%5611) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %5612 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5606)
      %5613 : Tensor = aten::add(%5612, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%5606, %5613)
      -> ()
    block1():
      -> ()
  %5614 : bool = prim::GetAttr[name="training"](%5606)
  %5615 : Tensor = prim::GetAttr[name="running_mean"](%5606)
  %5616 : Tensor = prim::GetAttr[name="running_var"](%5606)
  %5617 : Tensor = prim::GetAttr[name="weight"](%5606)
  %5618 : Tensor = prim::GetAttr[name="bias"](%5606)
   = prim::If(%5614) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %5619 : int[] = aten::size(%bottleneck_output.22) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.92 : int = aten::__getitem__(%5619, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %5621 : int = aten::len(%5619) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %5622 : int = aten::sub(%5621, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.93 : int = prim::Loop(%5622, %5, %size_prods.92) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.24 : int, %size_prods.94 : int):
          %5626 : int = aten::add(%i.24, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %5627 : int = aten::__getitem__(%5619, %5626) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.95 : int = aten::mul(%size_prods.94, %5627) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.95)
      %5629 : bool = aten::eq(%size_prods.93, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%5629) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %5630 : str = aten::format(%7, %5619) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%5630) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %5631 : Tensor = aten::batch_norm(%bottleneck_output.22, %5617, %5618, %5615, %5616, %5614, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.24 : Tensor = aten::relu_(%5631) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %5633 : Tensor = prim::GetAttr[name="weight"](%5605)
  %5634 : Tensor? = prim::GetAttr[name="bias"](%5605)
  %new_features.24 : Tensor = aten::conv2d(%result.24, %5633, %5634, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %5639 : float = prim::GetAttr[name="drop_rate"](%4522)
  %5640 : bool = aten::gt(%5639, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.21 : Tensor = prim::If(%5640) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %5643 : bool = prim::GetAttr[name="training"](%4522)
      %5644 : bool = aten::lt(%5639, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %5645 : bool = prim::If(%5644) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %5646 : bool = aten::gt(%5639, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%5646)
       = prim::If(%5645) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %5647 : str = aten::format(%17, %5639) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%5647) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %5648 : Tensor = aten::dropout(%new_features.24, %5639, %5643) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%5648)
    block1():
      -> (%new_features.24)
  %5649 : Tensor[] = aten::append(%features.1, %new_features.21) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %5651 : bool = prim::GetAttr[name="memory_efficient"](%4523)
  %5652 : bool = prim::If(%5651) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %5653 : bool = prim::Uninitialized()
      %5654 : int = aten::len(%features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %5655 : bool = aten::gt(%5654, %6)
      %5656 : bool, %5657 : bool, %5658 : int = prim::Loop(%12, %5655, %10, %5653, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%5659 : int, %5660 : bool, %5661 : bool, %5662 : int):
          %tensor.13 : Tensor = aten::__getitem__(%features.1, %5662) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %5664 : bool = prim::requires_grad(%tensor.13)
          %5665 : bool, %5666 : bool = prim::If(%5664) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %5653)
          %5667 : int = aten::add(%5662, %19)
          %5668 : bool = aten::lt(%5667, %5654)
          %5669 : bool = aten::__and__(%5668, %5665)
          -> (%5669, %5664, %5666, %5667)
      %5670 : bool = prim::If(%5656)
        block0():
          -> (%5657)
        block1():
          -> (%10)
      -> (%5670)
    block1():
      -> (%10)
  %bottleneck_output.24 : Tensor = prim::If(%5652) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.13 : Tensor = aten::cat(%features.1, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %5673 : __torch__.torch.nn.modules.conv.___torch_mangle_78.Conv2d = prim::GetAttr[name="conv1"](%4523)
      %5674 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_77.BatchNorm2d = prim::GetAttr[name="norm1"](%4523)
      %5675 : int = aten::dim(%concated_features.13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %5676 : bool = aten::ne(%5675, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%5676) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %5678 : str = aten::format(%14, %5675) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%5678) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %5679 : bool = prim::GetAttr[name="training"](%5674)
       = prim::If(%5679) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %5680 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5674)
          %5681 : Tensor = aten::add(%5680, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%5674, %5681)
          -> ()
        block1():
          -> ()
      %5682 : bool = prim::GetAttr[name="training"](%5674)
      %5683 : Tensor = prim::GetAttr[name="running_mean"](%5674)
      %5684 : Tensor = prim::GetAttr[name="running_var"](%5674)
      %5685 : Tensor = prim::GetAttr[name="weight"](%5674)
      %5686 : Tensor = prim::GetAttr[name="bias"](%5674)
       = prim::If(%5682) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %5687 : int[] = aten::size(%concated_features.13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.96 : int = aten::__getitem__(%5687, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %5689 : int = aten::len(%5687) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %5690 : int = aten::sub(%5689, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.97 : int = prim::Loop(%5690, %5, %size_prods.96) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.25 : int, %size_prods.98 : int):
              %5694 : int = aten::add(%i.25, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %5695 : int = aten::__getitem__(%5687, %5694) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.99 : int = aten::mul(%size_prods.98, %5695) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.99)
          %5697 : bool = aten::eq(%size_prods.97, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%5697) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %5698 : str = aten::format(%7, %5687) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%5698) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %5699 : Tensor = aten::batch_norm(%concated_features.13, %5685, %5686, %5683, %5684, %5682, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.25 : Tensor = aten::relu_(%5699) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %5701 : Tensor = prim::GetAttr[name="weight"](%5673)
      %5702 : Tensor? = prim::GetAttr[name="bias"](%5673)
      %bottleneck_output.25 : Tensor = aten::conv2d(%result.25, %5701, %5702, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.25)
  %5707 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%4523)
  %5708 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%4523)
  %5709 : int = aten::dim(%bottleneck_output.24) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %5710 : bool = aten::ne(%5709, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%5710) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %5712 : str = aten::format(%14, %5709) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%5712) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %5713 : bool = prim::GetAttr[name="training"](%5708)
   = prim::If(%5713) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %5714 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5708)
      %5715 : Tensor = aten::add(%5714, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%5708, %5715)
      -> ()
    block1():
      -> ()
  %5716 : bool = prim::GetAttr[name="training"](%5708)
  %5717 : Tensor = prim::GetAttr[name="running_mean"](%5708)
  %5718 : Tensor = prim::GetAttr[name="running_var"](%5708)
  %5719 : Tensor = prim::GetAttr[name="weight"](%5708)
  %5720 : Tensor = prim::GetAttr[name="bias"](%5708)
   = prim::If(%5716) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %5721 : int[] = aten::size(%bottleneck_output.24) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.100 : int = aten::__getitem__(%5721, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %5723 : int = aten::len(%5721) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %5724 : int = aten::sub(%5723, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.101 : int = prim::Loop(%5724, %5, %size_prods.100) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.26 : int, %size_prods.102 : int):
          %5728 : int = aten::add(%i.26, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %5729 : int = aten::__getitem__(%5721, %5728) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.103 : int = aten::mul(%size_prods.102, %5729) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.103)
      %5731 : bool = aten::eq(%size_prods.101, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%5731) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %5732 : str = aten::format(%7, %5721) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%5732) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %5733 : Tensor = aten::batch_norm(%bottleneck_output.24, %5719, %5720, %5717, %5718, %5716, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.26 : Tensor = aten::relu_(%5733) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %5735 : Tensor = prim::GetAttr[name="weight"](%5707)
  %5736 : Tensor? = prim::GetAttr[name="bias"](%5707)
  %new_features.26 : Tensor = aten::conv2d(%result.26, %5735, %5736, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %5741 : float = prim::GetAttr[name="drop_rate"](%4523)
  %5742 : bool = aten::gt(%5741, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.23 : Tensor = prim::If(%5742) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %5745 : bool = prim::GetAttr[name="training"](%4523)
      %5746 : bool = aten::lt(%5741, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %5747 : bool = prim::If(%5746) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %5748 : bool = aten::gt(%5741, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%5748)
       = prim::If(%5747) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %5749 : str = aten::format(%17, %5741) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%5749) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %5750 : Tensor = aten::dropout(%new_features.26, %5741, %5745) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%5750)
    block1():
      -> (%new_features.26)
  %5751 : Tensor[] = aten::append(%features.1, %new_features.23) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %5753 : bool = prim::GetAttr[name="memory_efficient"](%4524)
  %5754 : bool = prim::If(%5753) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %5755 : bool = prim::Uninitialized()
      %5756 : int = aten::len(%features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %5757 : bool = aten::gt(%5756, %6)
      %5758 : bool, %5759 : bool, %5760 : int = prim::Loop(%12, %5757, %10, %5755, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%5761 : int, %5762 : bool, %5763 : bool, %5764 : int):
          %tensor.14 : Tensor = aten::__getitem__(%features.1, %5764) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %5766 : bool = prim::requires_grad(%tensor.14)
          %5767 : bool, %5768 : bool = prim::If(%5766) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %5755)
          %5769 : int = aten::add(%5764, %19)
          %5770 : bool = aten::lt(%5769, %5756)
          %5771 : bool = aten::__and__(%5770, %5767)
          -> (%5771, %5766, %5768, %5769)
      %5772 : bool = prim::If(%5758)
        block0():
          -> (%5759)
        block1():
          -> (%10)
      -> (%5772)
    block1():
      -> (%10)
  %bottleneck_output.26 : Tensor = prim::If(%5754) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.14 : Tensor = aten::cat(%features.1, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %5775 : __torch__.torch.nn.modules.conv.___torch_mangle_81.Conv2d = prim::GetAttr[name="conv1"](%4524)
      %5776 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_80.BatchNorm2d = prim::GetAttr[name="norm1"](%4524)
      %5777 : int = aten::dim(%concated_features.14) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %5778 : bool = aten::ne(%5777, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%5778) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %5780 : str = aten::format(%14, %5777) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%5780) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %5781 : bool = prim::GetAttr[name="training"](%5776)
       = prim::If(%5781) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %5782 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5776)
          %5783 : Tensor = aten::add(%5782, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%5776, %5783)
          -> ()
        block1():
          -> ()
      %5784 : bool = prim::GetAttr[name="training"](%5776)
      %5785 : Tensor = prim::GetAttr[name="running_mean"](%5776)
      %5786 : Tensor = prim::GetAttr[name="running_var"](%5776)
      %5787 : Tensor = prim::GetAttr[name="weight"](%5776)
      %5788 : Tensor = prim::GetAttr[name="bias"](%5776)
       = prim::If(%5784) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %5789 : int[] = aten::size(%concated_features.14) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.104 : int = aten::__getitem__(%5789, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %5791 : int = aten::len(%5789) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %5792 : int = aten::sub(%5791, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.105 : int = prim::Loop(%5792, %5, %size_prods.104) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.27 : int, %size_prods.106 : int):
              %5796 : int = aten::add(%i.27, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %5797 : int = aten::__getitem__(%5789, %5796) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.107 : int = aten::mul(%size_prods.106, %5797) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.107)
          %5799 : bool = aten::eq(%size_prods.105, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%5799) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %5800 : str = aten::format(%7, %5789) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%5800) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %5801 : Tensor = aten::batch_norm(%concated_features.14, %5787, %5788, %5785, %5786, %5784, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.27 : Tensor = aten::relu_(%5801) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %5803 : Tensor = prim::GetAttr[name="weight"](%5775)
      %5804 : Tensor? = prim::GetAttr[name="bias"](%5775)
      %bottleneck_output.27 : Tensor = aten::conv2d(%result.27, %5803, %5804, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.27)
  %5809 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%4524)
  %5810 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%4524)
  %5811 : int = aten::dim(%bottleneck_output.26) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %5812 : bool = aten::ne(%5811, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%5812) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %5814 : str = aten::format(%14, %5811) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%5814) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %5815 : bool = prim::GetAttr[name="training"](%5810)
   = prim::If(%5815) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %5816 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5810)
      %5817 : Tensor = aten::add(%5816, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%5810, %5817)
      -> ()
    block1():
      -> ()
  %5818 : bool = prim::GetAttr[name="training"](%5810)
  %5819 : Tensor = prim::GetAttr[name="running_mean"](%5810)
  %5820 : Tensor = prim::GetAttr[name="running_var"](%5810)
  %5821 : Tensor = prim::GetAttr[name="weight"](%5810)
  %5822 : Tensor = prim::GetAttr[name="bias"](%5810)
   = prim::If(%5818) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %5823 : int[] = aten::size(%bottleneck_output.26) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.108 : int = aten::__getitem__(%5823, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %5825 : int = aten::len(%5823) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %5826 : int = aten::sub(%5825, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.109 : int = prim::Loop(%5826, %5, %size_prods.108) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.28 : int, %size_prods.110 : int):
          %5830 : int = aten::add(%i.28, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %5831 : int = aten::__getitem__(%5823, %5830) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.111 : int = aten::mul(%size_prods.110, %5831) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.111)
      %5833 : bool = aten::eq(%size_prods.109, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%5833) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %5834 : str = aten::format(%7, %5823) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%5834) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %5835 : Tensor = aten::batch_norm(%bottleneck_output.26, %5821, %5822, %5819, %5820, %5818, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.28 : Tensor = aten::relu_(%5835) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %5837 : Tensor = prim::GetAttr[name="weight"](%5809)
  %5838 : Tensor? = prim::GetAttr[name="bias"](%5809)
  %new_features.28 : Tensor = aten::conv2d(%result.28, %5837, %5838, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %5843 : float = prim::GetAttr[name="drop_rate"](%4524)
  %5844 : bool = aten::gt(%5843, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.25 : Tensor = prim::If(%5844) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %5847 : bool = prim::GetAttr[name="training"](%4524)
      %5848 : bool = aten::lt(%5843, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %5849 : bool = prim::If(%5848) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %5850 : bool = aten::gt(%5843, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%5850)
       = prim::If(%5849) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %5851 : str = aten::format(%17, %5843) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%5851) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %5852 : Tensor = aten::dropout(%new_features.28, %5843, %5847) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%5852)
    block1():
      -> (%new_features.28)
  %5853 : Tensor[] = aten::append(%features.1, %new_features.25) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %5855 : bool = prim::GetAttr[name="memory_efficient"](%4525)
  %5856 : bool = prim::If(%5855) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %5857 : bool = prim::Uninitialized()
      %5858 : int = aten::len(%features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %5859 : bool = aten::gt(%5858, %6)
      %5860 : bool, %5861 : bool, %5862 : int = prim::Loop(%12, %5859, %10, %5857, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%5863 : int, %5864 : bool, %5865 : bool, %5866 : int):
          %tensor.15 : Tensor = aten::__getitem__(%features.1, %5866) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %5868 : bool = prim::requires_grad(%tensor.15)
          %5869 : bool, %5870 : bool = prim::If(%5868) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %5857)
          %5871 : int = aten::add(%5866, %19)
          %5872 : bool = aten::lt(%5871, %5858)
          %5873 : bool = aten::__and__(%5872, %5869)
          -> (%5873, %5868, %5870, %5871)
      %5874 : bool = prim::If(%5860)
        block0():
          -> (%5861)
        block1():
          -> (%10)
      -> (%5874)
    block1():
      -> (%10)
  %bottleneck_output.28 : Tensor = prim::If(%5856) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.15 : Tensor = aten::cat(%features.1, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %5877 : __torch__.torch.nn.modules.conv.___torch_mangle_84.Conv2d = prim::GetAttr[name="conv1"](%4525)
      %5878 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_83.BatchNorm2d = prim::GetAttr[name="norm1"](%4525)
      %5879 : int = aten::dim(%concated_features.15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %5880 : bool = aten::ne(%5879, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%5880) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %5882 : str = aten::format(%14, %5879) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%5882) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %5883 : bool = prim::GetAttr[name="training"](%5878)
       = prim::If(%5883) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %5884 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5878)
          %5885 : Tensor = aten::add(%5884, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%5878, %5885)
          -> ()
        block1():
          -> ()
      %5886 : bool = prim::GetAttr[name="training"](%5878)
      %5887 : Tensor = prim::GetAttr[name="running_mean"](%5878)
      %5888 : Tensor = prim::GetAttr[name="running_var"](%5878)
      %5889 : Tensor = prim::GetAttr[name="weight"](%5878)
      %5890 : Tensor = prim::GetAttr[name="bias"](%5878)
       = prim::If(%5886) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %5891 : int[] = aten::size(%concated_features.15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.112 : int = aten::__getitem__(%5891, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %5893 : int = aten::len(%5891) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %5894 : int = aten::sub(%5893, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.113 : int = prim::Loop(%5894, %5, %size_prods.112) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.29 : int, %size_prods.114 : int):
              %5898 : int = aten::add(%i.29, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %5899 : int = aten::__getitem__(%5891, %5898) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.115 : int = aten::mul(%size_prods.114, %5899) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.115)
          %5901 : bool = aten::eq(%size_prods.113, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%5901) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %5902 : str = aten::format(%7, %5891) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%5902) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %5903 : Tensor = aten::batch_norm(%concated_features.15, %5889, %5890, %5887, %5888, %5886, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.29 : Tensor = aten::relu_(%5903) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %5905 : Tensor = prim::GetAttr[name="weight"](%5877)
      %5906 : Tensor? = prim::GetAttr[name="bias"](%5877)
      %bottleneck_output.29 : Tensor = aten::conv2d(%result.29, %5905, %5906, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.29)
  %5911 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%4525)
  %5912 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%4525)
  %5913 : int = aten::dim(%bottleneck_output.28) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %5914 : bool = aten::ne(%5913, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%5914) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %5916 : str = aten::format(%14, %5913) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%5916) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %5917 : bool = prim::GetAttr[name="training"](%5912)
   = prim::If(%5917) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %5918 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5912)
      %5919 : Tensor = aten::add(%5918, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%5912, %5919)
      -> ()
    block1():
      -> ()
  %5920 : bool = prim::GetAttr[name="training"](%5912)
  %5921 : Tensor = prim::GetAttr[name="running_mean"](%5912)
  %5922 : Tensor = prim::GetAttr[name="running_var"](%5912)
  %5923 : Tensor = prim::GetAttr[name="weight"](%5912)
  %5924 : Tensor = prim::GetAttr[name="bias"](%5912)
   = prim::If(%5920) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %5925 : int[] = aten::size(%bottleneck_output.28) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.116 : int = aten::__getitem__(%5925, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %5927 : int = aten::len(%5925) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %5928 : int = aten::sub(%5927, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.117 : int = prim::Loop(%5928, %5, %size_prods.116) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.30 : int, %size_prods.118 : int):
          %5932 : int = aten::add(%i.30, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %5933 : int = aten::__getitem__(%5925, %5932) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.119 : int = aten::mul(%size_prods.118, %5933) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.119)
      %5935 : bool = aten::eq(%size_prods.117, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%5935) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %5936 : str = aten::format(%7, %5925) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%5936) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %5937 : Tensor = aten::batch_norm(%bottleneck_output.28, %5923, %5924, %5921, %5922, %5920, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.30 : Tensor = aten::relu_(%5937) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %5939 : Tensor = prim::GetAttr[name="weight"](%5911)
  %5940 : Tensor? = prim::GetAttr[name="bias"](%5911)
  %new_features.30 : Tensor = aten::conv2d(%result.30, %5939, %5940, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %5945 : float = prim::GetAttr[name="drop_rate"](%4525)
  %5946 : bool = aten::gt(%5945, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.27 : Tensor = prim::If(%5946) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %5949 : bool = prim::GetAttr[name="training"](%4525)
      %5950 : bool = aten::lt(%5945, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %5951 : bool = prim::If(%5950) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %5952 : bool = aten::gt(%5945, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%5952)
       = prim::If(%5951) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %5953 : str = aten::format(%17, %5945) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%5953) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %5954 : Tensor = aten::dropout(%new_features.30, %5945, %5949) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%5954)
    block1():
      -> (%new_features.30)
  %5955 : Tensor[] = aten::append(%features.1, %new_features.27) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %5957 : bool = prim::GetAttr[name="memory_efficient"](%4526)
  %5958 : bool = prim::If(%5957) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %5959 : bool = prim::Uninitialized()
      %5960 : int = aten::len(%features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %5961 : bool = aten::gt(%5960, %6)
      %5962 : bool, %5963 : bool, %5964 : int = prim::Loop(%12, %5961, %10, %5959, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%5965 : int, %5966 : bool, %5967 : bool, %5968 : int):
          %tensor.16 : Tensor = aten::__getitem__(%features.1, %5968) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %5970 : bool = prim::requires_grad(%tensor.16)
          %5971 : bool, %5972 : bool = prim::If(%5970) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %5959)
          %5973 : int = aten::add(%5968, %19)
          %5974 : bool = aten::lt(%5973, %5960)
          %5975 : bool = aten::__and__(%5974, %5971)
          -> (%5975, %5970, %5972, %5973)
      %5976 : bool = prim::If(%5962)
        block0():
          -> (%5963)
        block1():
          -> (%10)
      -> (%5976)
    block1():
      -> (%10)
  %bottleneck_output.30 : Tensor = prim::If(%5958) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.16 : Tensor = aten::cat(%features.1, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %5979 : __torch__.torch.nn.modules.conv.___torch_mangle_87.Conv2d = prim::GetAttr[name="conv1"](%4526)
      %5980 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_86.BatchNorm2d = prim::GetAttr[name="norm1"](%4526)
      %5981 : int = aten::dim(%concated_features.16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %5982 : bool = aten::ne(%5981, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%5982) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %5984 : str = aten::format(%14, %5981) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%5984) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %5985 : bool = prim::GetAttr[name="training"](%5980)
       = prim::If(%5985) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %5986 : Tensor = prim::GetAttr[name="num_batches_tracked"](%5980)
          %5987 : Tensor = aten::add(%5986, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%5980, %5987)
          -> ()
        block1():
          -> ()
      %5988 : bool = prim::GetAttr[name="training"](%5980)
      %5989 : Tensor = prim::GetAttr[name="running_mean"](%5980)
      %5990 : Tensor = prim::GetAttr[name="running_var"](%5980)
      %5991 : Tensor = prim::GetAttr[name="weight"](%5980)
      %5992 : Tensor = prim::GetAttr[name="bias"](%5980)
       = prim::If(%5988) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %5993 : int[] = aten::size(%concated_features.16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.120 : int = aten::__getitem__(%5993, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %5995 : int = aten::len(%5993) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %5996 : int = aten::sub(%5995, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.121 : int = prim::Loop(%5996, %5, %size_prods.120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.31 : int, %size_prods.122 : int):
              %6000 : int = aten::add(%i.31, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %6001 : int = aten::__getitem__(%5993, %6000) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.123 : int = aten::mul(%size_prods.122, %6001) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.123)
          %6003 : bool = aten::eq(%size_prods.121, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%6003) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %6004 : str = aten::format(%7, %5993) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%6004) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %6005 : Tensor = aten::batch_norm(%concated_features.16, %5991, %5992, %5989, %5990, %5988, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.31 : Tensor = aten::relu_(%6005) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %6007 : Tensor = prim::GetAttr[name="weight"](%5979)
      %6008 : Tensor? = prim::GetAttr[name="bias"](%5979)
      %bottleneck_output.31 : Tensor = aten::conv2d(%result.31, %6007, %6008, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.31)
  %6013 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%4526)
  %6014 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%4526)
  %6015 : int = aten::dim(%bottleneck_output.30) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %6016 : bool = aten::ne(%6015, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%6016) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %6018 : str = aten::format(%14, %6015) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%6018) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %6019 : bool = prim::GetAttr[name="training"](%6014)
   = prim::If(%6019) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %6020 : Tensor = prim::GetAttr[name="num_batches_tracked"](%6014)
      %6021 : Tensor = aten::add(%6020, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%6014, %6021)
      -> ()
    block1():
      -> ()
  %6022 : bool = prim::GetAttr[name="training"](%6014)
  %6023 : Tensor = prim::GetAttr[name="running_mean"](%6014)
  %6024 : Tensor = prim::GetAttr[name="running_var"](%6014)
  %6025 : Tensor = prim::GetAttr[name="weight"](%6014)
  %6026 : Tensor = prim::GetAttr[name="bias"](%6014)
   = prim::If(%6022) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %6027 : int[] = aten::size(%bottleneck_output.30) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.124 : int = aten::__getitem__(%6027, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %6029 : int = aten::len(%6027) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %6030 : int = aten::sub(%6029, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.125 : int = prim::Loop(%6030, %5, %size_prods.124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.32 : int, %size_prods.126 : int):
          %6034 : int = aten::add(%i.32, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %6035 : int = aten::__getitem__(%6027, %6034) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.127 : int = aten::mul(%size_prods.126, %6035) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.127)
      %6037 : bool = aten::eq(%size_prods.125, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%6037) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %6038 : str = aten::format(%7, %6027) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%6038) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %6039 : Tensor = aten::batch_norm(%bottleneck_output.30, %6025, %6026, %6023, %6024, %6022, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.32 : Tensor = aten::relu_(%6039) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %6041 : Tensor = prim::GetAttr[name="weight"](%6013)
  %6042 : Tensor? = prim::GetAttr[name="bias"](%6013)
  %new_features.32 : Tensor = aten::conv2d(%result.32, %6041, %6042, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %6047 : float = prim::GetAttr[name="drop_rate"](%4526)
  %6048 : bool = aten::gt(%6047, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.29 : Tensor = prim::If(%6048) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %6051 : bool = prim::GetAttr[name="training"](%4526)
      %6052 : bool = aten::lt(%6047, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %6053 : bool = prim::If(%6052) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %6054 : bool = aten::gt(%6047, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%6054)
       = prim::If(%6053) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %6055 : str = aten::format(%17, %6047) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%6055) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %6056 : Tensor = aten::dropout(%new_features.32, %6047, %6051) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%6056)
    block1():
      -> (%new_features.32)
  %6057 : Tensor[] = aten::append(%features.1, %new_features.29) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %6059 : bool = prim::GetAttr[name="memory_efficient"](%4527)
  %6060 : bool = prim::If(%6059) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:11
    block0():
      %6061 : bool = prim::Uninitialized()
      %6062 : int = aten::len(%features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
      %6063 : bool = aten::gt(%6062, %6)
      %6064 : bool, %6065 : bool, %6066 : int = prim::Loop(%12, %6063, %10, %6061, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
        block0(%6067 : int, %6068 : bool, %6069 : bool, %6070 : int):
          %tensor.1 : Tensor = aten::__getitem__(%features.1, %6070) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:58:8
          %6072 : bool = prim::requires_grad(%tensor.1)
          %6073 : bool, %6074 : bool = prim::If(%6072) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:59:12
            block0():
              -> (%10, %5)
            block1():
              -> (%5, %6061)
          %6075 : int = aten::add(%6070, %19)
          %6076 : bool = aten::lt(%6075, %6062)
          %6077 : bool = aten::__and__(%6076, %6073)
          -> (%6077, %6072, %6074, %6075)
      %6078 : bool = prim::If(%6064)
        block0():
          -> (%6065)
        block1():
          -> (%10)
      -> (%6078)
    block1():
      -> (%10)
  %bottleneck_output : Tensor = prim::If(%6060) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:86:8
    block0():
       = prim::RaiseException(%11) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:88:16
      -> (%72)
    block1():
      %concated_features.1 : Tensor = aten::cat(%features.1, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:52:28
      %6081 : __torch__.torch.nn.modules.conv.___torch_mangle_90.Conv2d = prim::GetAttr[name="conv1"](%4527)
      %6082 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_89.BatchNorm2d = prim::GetAttr[name="norm1"](%4527)
      %6083 : int = aten::dim(%concated_features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
      %6084 : bool = aten::ne(%6083, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
       = prim::If(%6084) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
        block0():
          %6086 : str = aten::format(%14, %6083) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
           = prim::RaiseException(%6086) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
          -> ()
        block1():
          -> ()
      %6087 : bool = prim::GetAttr[name="training"](%6082)
       = prim::If(%6087) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
        block0():
          %6088 : Tensor = prim::GetAttr[name="num_batches_tracked"](%6082)
          %6089 : Tensor = aten::add(%6088, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%6082, %6089)
          -> ()
        block1():
          -> ()
      %6090 : bool = prim::GetAttr[name="training"](%6082)
      %6091 : Tensor = prim::GetAttr[name="running_mean"](%6082)
      %6092 : Tensor = prim::GetAttr[name="running_var"](%6082)
      %6093 : Tensor = prim::GetAttr[name="weight"](%6082)
      %6094 : Tensor = prim::GetAttr[name="bias"](%6082)
       = prim::If(%6090) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
        block0():
          %6095 : int[] = aten::size(%concated_features.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
          %size_prods.2 : int = aten::__getitem__(%6095, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
          %6097 : int = aten::len(%6095) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %6098 : int = aten::sub(%6097, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
          %size_prods.4 : int = prim::Loop(%6098, %5, %size_prods.2) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
            block0(%i.2 : int, %size_prods.7 : int):
              %6102 : int = aten::add(%i.2, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
              %6103 : int = aten::__getitem__(%6095, %6102) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
              %size_prods.5 : int = aten::mul(%size_prods.7, %6103) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
              -> (%5, %size_prods.5)
          %6105 : bool = aten::eq(%size_prods.4, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
           = prim::If(%6105) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
            block0():
              %6106 : str = aten::format(%7, %6095) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
               = prim::RaiseException(%6106) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %6107 : Tensor = aten::batch_norm(%concated_features.1, %6093, %6094, %6091, %6092, %6090, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
      %result.118 : Tensor = aten::relu_(%6107) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
      %6109 : Tensor = prim::GetAttr[name="weight"](%6081)
      %6110 : Tensor? = prim::GetAttr[name="bias"](%6081)
      %bottleneck_output.2 : Tensor = aten::conv2d(%result.118, %6109, %6110, %6199, %6205, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
      -> (%bottleneck_output.2)
  %6115 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%4527)
  %6116 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1.BatchNorm2d = prim::GetAttr[name="norm2"](%4527)
  %6117 : int = aten::dim(%bottleneck_output) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %6118 : bool = aten::ne(%6117, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%6118) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %6120 : str = aten::format(%14, %6117) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%6120) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %6121 : bool = prim::GetAttr[name="training"](%6116)
   = prim::If(%6121) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %6122 : Tensor = prim::GetAttr[name="num_batches_tracked"](%6116)
      %6123 : Tensor = aten::add(%6122, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%6116, %6123)
      -> ()
    block1():
      -> ()
  %6124 : bool = prim::GetAttr[name="training"](%6116)
  %6125 : Tensor = prim::GetAttr[name="running_mean"](%6116)
  %6126 : Tensor = prim::GetAttr[name="running_var"](%6116)
  %6127 : Tensor = prim::GetAttr[name="weight"](%6116)
  %6128 : Tensor = prim::GetAttr[name="bias"](%6116)
   = prim::If(%6124) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %6129 : int[] = aten::size(%bottleneck_output) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.480 : int = aten::__getitem__(%6129, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %6131 : int = aten::len(%6129) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %6132 : int = aten::sub(%6131, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods.481 : int = prim::Loop(%6132, %5, %size_prods.480) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.121 : int, %size_prods.482 : int):
          %6136 : int = aten::add(%i.121, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %6137 : int = aten::__getitem__(%6129, %6136) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.483 : int = aten::mul(%size_prods.482, %6137) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.483)
      %6139 : bool = aten::eq(%size_prods.481, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%6139) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %6140 : str = aten::format(%7, %6129) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%6140) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %6141 : Tensor = aten::batch_norm(%bottleneck_output, %6127, %6128, %6125, %6126, %6124, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.117 : Tensor = aten::relu_(%6141) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %6143 : Tensor = prim::GetAttr[name="weight"](%6115)
  %6144 : Tensor? = prim::GetAttr[name="bias"](%6115)
  %new_features.1 : Tensor = aten::conv2d(%result.117, %6143, %6144, %6199, %6199, %6199, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:395:15
  %6149 : float = prim::GetAttr[name="drop_rate"](%4527)
  %6150 : bool = aten::gt(%6149, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:11
  %new_features.31 : Tensor = prim::If(%6150) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:95:8
    block0():
      %6153 : bool = prim::GetAttr[name="training"](%4527)
      %6154 : bool = aten::lt(%6149, %16) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
      %6155 : bool = prim::If(%6154) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:7
        block0():
          -> (%5)
        block1():
          %6156 : bool = aten::gt(%6149, %15) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:18
          -> (%6156)
       = prim::If(%6155) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1074:4
        block0():
          %6157 : str = aten::format(%17, %6149) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:25
           = prim::RaiseException(%6157) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1075:8
          -> ()
        block1():
          -> ()
      %6158 : Tensor = aten::dropout(%new_features.1, %6149, %6153) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1076:60
      -> (%6158)
    block1():
      -> (%new_features.1)
  %6159 : Tensor[] = aten::append(%features.1, %new_features.31) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:128:12
  %input.23 : Tensor = aten::cat(%features.1, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:129:15
  %6161 : int = aten::dim(%input.23) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
  %6162 : bool = aten::ne(%6161, %13) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:11
   = prim::If(%6162) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:284:8
    block0():
      %6164 : str = aten::format(%14, %6161) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:29
       = prim::RaiseException(%6164) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:285:12
      -> ()
    block1():
      -> ()
  %6165 : bool = prim::GetAttr[name="training"](%31)
   = prim::If(%6165) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:110:11
    block0():
      %6166 : Tensor = prim::GetAttr[name="num_batches_tracked"](%31)
      %6167 : Tensor = aten::add(%6166, %19, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%31, %6167)
      -> ()
    block1():
      -> ()
  %6168 : bool = prim::GetAttr[name="training"](%31)
  %6169 : Tensor = prim::GetAttr[name="running_mean"](%31)
  %6170 : Tensor = prim::GetAttr[name="running_var"](%31)
  %6171 : Tensor = prim::GetAttr[name="weight"](%31)
  %6172 : Tensor = prim::GetAttr[name="bias"](%31)
   = prim::If(%6168) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2143:4
    block0():
      %6173 : int[] = aten::size(%input.23) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2144:27
      %size_prods.1 : int = aten::__getitem__(%6173, %6) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2107:17
      %6175 : int = aten::len(%6173) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %6176 : int = aten::sub(%6175, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:19
      %size_prods : int = prim::Loop(%6176, %5, %size_prods.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2108:4
        block0(%i.1 : int, %size_prods.6 : int):
          %6180 : int = aten::add(%i.1, %4) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:27
          %6181 : int = aten::__getitem__(%6173, %6180) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:22
          %size_prods.3 : int = aten::mul(%size_prods.6, %6181) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2109:8
          -> (%5, %size_prods.3)
      %6183 : bool = aten::eq(%size_prods, %19) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:7
       = prim::If(%6183) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2110:4
        block0():
          %6184 : str = aten::format(%7, %6173) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:25
           = prim::RaiseException(%6184) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2111:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %features.5 : Tensor = aten::batch_norm(%input.23, %6171, %6172, %6169, %6170, %6168, %8, %9, %5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2146:11
  %result.1 : Tensor = aten::relu_(%features.5) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1204:17
  %6188 : int[] = aten::size(%result.1) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1036:51
  %6189 : int = aten::len(%6188) # <string>:5:9
  %6190 : bool = aten::gt(%6189, %4) # <string>:5:9
   = prim::If(%6190) # <string>:5:2
    block0():
      -> ()
    block1():
       = prim::RaiseException(%2) # <string>:5:2
      -> ()
  %out.3 : Tensor = aten::adaptive_avg_pool2d(%result.1, %6199) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1037:11
  %out.5 : Tensor = aten::flatten(%out.3, %19, %20) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torchvision-0.9.0a0+767b23e-py3.8-linux-x86_64.egg/torchvision/models/densenet.py:219:14
  %6193 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="classifier"](%self)
  %6194 : Tensor = prim::GetAttr[name="weight"](%6193)
  %6195 : Tensor = prim::GetAttr[name="bias"](%6193)
  %out.7 : Tensor = aten::linear(%out.5, %6194, %6195) # /home/pengwu/local/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:1753:11
  return (%out.7)

