=======================================================================================================
Note: "others" is the sum of unreported ops (block*() block-ret return graph graph-others )
=======================================================================================================
Logfile (ir counts)                            aten::*    prim::*    fb::*    quantized::*    internal::*    caffe2::*    if    loop    call      setattr    getattr    all [others]
---------------------------------------------  ---------  ---------  -------  --------------  -------------  -----------  ----  ------  --------  ---------  ---------  --------------
BERT_pytorch.cpu.last_executed_graph_dump.log  697 (52%)  651 (48%)  -        -               -              -            -     -       12 ( 1%)  12 ( 1%)   562 (42%)  1353 [3]
-------------------------------------------------------------------------------------------------------

Detailed op stats for [BERT_pytorch.cpu.last_executed_graph_dump.log]
    - "prim::Loop": 0 found
    - "prim::CallMethod": 1 distinct sources (source:line [count])
        + /mnt/ssd1/pengwu/projects/torchbenchmark/torchbenchmark/models/BERT_pytorch/bert_pytorch/model/attention/single.py:23 [12]
    - "prim::If": 0 found
    - "fb::*": not found
    - "caffe2::*": not found
    - "quantized::*": not found
    - "prim::*": 6 distinct names (name [count])
        + prim::CallMethod (12)
        + prim::Constant (16)
        + prim::GetAttr (562)
        + prim::ListConstruct (37)
        + prim::ListUnpack (12)
        + prim::SetAttr (12)
    - "internal::*": not found
    - "aten::*": 25 distinct names (name [count])
        + aten::add (98)
        + aten::append (36)
        + aten::contiguous (12)
        + aten::div (36)
        + aten::dropout (49)
        + aten::embedding (2)
        + aten::eq (12)
        + aten::gt (1)
        + aten::linear (72)
        + aten::masked_fill (12)
        + aten::matmul (24)
        + aten::mean (24)
        + aten::mul (84)
        + aten::pow (12)
        + aten::repeat (1)
        + aten::size (26)
        + aten::slice (2)
        + aten::softmax (12)
        + aten::sqrt (12)
        + aten::std (24)
        + aten::sub (24)
        + aten::tanh (12)
        + aten::transpose (60)
        + aten::unsqueeze (2)
        + aten::view (48)
    - "prim::GetAttr": 38 distinct attr names (attr [count])
        + "0" (13)
        + "1" (13)
        + "10" (1)
        + "11" (1)
        + "2" (13)
        + "3" (1)
        + "4" (1)
        + "5" (1)
        + "6" (1)
        + "7" (1)
        + "8" (1)
        + "9" (1)
        + "a_2" (24)
        + "attention" (12)
        + "b_2" (24)
        + "bias" (72)
        + "d_k" (12)
        + "dropout" (61)
        + "embedding" (1)
        + "eps" (24)
        + "feed_forward" (12)
        + "h" (12)
        + "input_sublayer" (12)
        + "lambda_module" (24)
        + "linear_layers" (12)
        + "mask" (12)
        + "norm" (24)
        + "output_linear" (12)
        + "output_sublayer" (12)
        + "pe" (1)
        + "position" (1)
        + "segment" (1)
        + "token" (1)
        + "training" (49)
        + "transformer_blocks" (1)
        + "w_1" (12)
        + "w_2" (12)
        + "weight" (74)
    - "prim::SetAttr": 1 distinct attr names (attr [count])
        + "mask" (12)
